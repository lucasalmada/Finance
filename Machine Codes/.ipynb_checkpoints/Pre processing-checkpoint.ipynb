{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T18:20:31.604576Z",
     "start_time": "2019-11-08T18:20:26.836108Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T18:20:35.008005Z",
     "start_time": "2019-11-08T18:20:31.606555Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Conv2D\n",
    "from time import time\n",
    "from keras.callbacks import TensorBoard, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T18:20:35.137430Z",
     "start_time": "2019-11-08T18:20:35.011974Z"
    }
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_hdf('df_dataDOL1.hdf', key='hdf')\n",
    "df2 = pd.read_hdf('df_dataDOL2.hdf', key='hdf')\n",
    "df3 = pd.read_hdf('df_dataDOL3.hdf', key='hdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T18:20:35.201626Z",
     "start_time": "2019-11-08T18:20:35.140412Z"
    }
   },
   "outputs": [],
   "source": [
    "df_total = pd.concat([df1,df2,df3],  ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T18:20:35.458240Z",
     "start_time": "2019-11-08T18:20:35.204624Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Contratos Abertos</th>\n",
       "      <th>Contratos Fechados</th>\n",
       "      <th>Número Negócios</th>\n",
       "      <th>Contratos Negociados</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Abertura</th>\n",
       "      <th>Mínimo</th>\n",
       "      <th>Máximo</th>\n",
       "      <th>Médio</th>\n",
       "      <th>Último Preço</th>\n",
       "      <th>Ajuste</th>\n",
       "      <th>Var pontos</th>\n",
       "      <th>Última oferta de compra</th>\n",
       "      <th>Última oferta de venda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29/07/2019</td>\n",
       "      <td>851537</td>\n",
       "      <td>719017</td>\n",
       "      <td>27192</td>\n",
       "      <td>226625</td>\n",
       "      <td>42939771125</td>\n",
       "      <td>3.7850</td>\n",
       "      <td>3.7775</td>\n",
       "      <td>3.8015</td>\n",
       "      <td>3.789499</td>\n",
       "      <td>3.7820</td>\n",
       "      <td>3.784797</td>\n",
       "      <td>145520</td>\n",
       "      <td>3.7820</td>\n",
       "      <td>3.7825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26/07/2019</td>\n",
       "      <td>875047</td>\n",
       "      <td>851537</td>\n",
       "      <td>32128</td>\n",
       "      <td>309480</td>\n",
       "      <td>58414828000</td>\n",
       "      <td>3.7800</td>\n",
       "      <td>3.7610</td>\n",
       "      <td>3.7955</td>\n",
       "      <td>3.775030</td>\n",
       "      <td>3.7760</td>\n",
       "      <td>3.770245</td>\n",
       "      <td>125890</td>\n",
       "      <td>3.7765</td>\n",
       "      <td>3.7780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25/07/2019</td>\n",
       "      <td>890941</td>\n",
       "      <td>875047</td>\n",
       "      <td>41651</td>\n",
       "      <td>381060</td>\n",
       "      <td>72105906125</td>\n",
       "      <td>3.7680</td>\n",
       "      <td>3.7570</td>\n",
       "      <td>3.8070</td>\n",
       "      <td>3.784490</td>\n",
       "      <td>3.7795</td>\n",
       "      <td>3.782834</td>\n",
       "      <td>129780</td>\n",
       "      <td>3.7795</td>\n",
       "      <td>3.7805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24/07/2019</td>\n",
       "      <td>883412</td>\n",
       "      <td>890941</td>\n",
       "      <td>26137</td>\n",
       "      <td>269620</td>\n",
       "      <td>50725252625</td>\n",
       "      <td>3.7675</td>\n",
       "      <td>3.7540</td>\n",
       "      <td>3.7795</td>\n",
       "      <td>3.762721</td>\n",
       "      <td>3.7735</td>\n",
       "      <td>3.769856</td>\n",
       "      <td>31160</td>\n",
       "      <td>3.7735</td>\n",
       "      <td>3.7755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23/07/2019</td>\n",
       "      <td>880504</td>\n",
       "      <td>883412</td>\n",
       "      <td>33586</td>\n",
       "      <td>313840</td>\n",
       "      <td>59121712875</td>\n",
       "      <td>3.7450</td>\n",
       "      <td>3.7430</td>\n",
       "      <td>3.7820</td>\n",
       "      <td>3.767634</td>\n",
       "      <td>3.7750</td>\n",
       "      <td>3.772972</td>\n",
       "      <td>356000</td>\n",
       "      <td>3.7750</td>\n",
       "      <td>3.7770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Data  Contratos Abertos  Contratos Fechados  Número Negócios  \\\n",
       "0  29/07/2019             851537              719017            27192   \n",
       "1  26/07/2019             875047              851537            32128   \n",
       "2  25/07/2019             890941              875047            41651   \n",
       "3  24/07/2019             883412              890941            26137   \n",
       "4  23/07/2019             880504              883412            33586   \n",
       "\n",
       "   Contratos Negociados       Volume  Abertura  Mínimo  Máximo     Médio  \\\n",
       "0                226625  42939771125    3.7850  3.7775  3.8015  3.789499   \n",
       "1                309480  58414828000    3.7800  3.7610  3.7955  3.775030   \n",
       "2                381060  72105906125    3.7680  3.7570  3.8070  3.784490   \n",
       "3                269620  50725252625    3.7675  3.7540  3.7795  3.762721   \n",
       "4                313840  59121712875    3.7450  3.7430  3.7820  3.767634   \n",
       "\n",
       "   Último Preço    Ajuste  Var pontos  Última oferta de compra  \\\n",
       "0        3.7820  3.784797      145520                   3.7820   \n",
       "1        3.7760  3.770245      125890                   3.7765   \n",
       "2        3.7795  3.782834      129780                   3.7795   \n",
       "3        3.7735  3.769856       31160                   3.7735   \n",
       "4        3.7750  3.772972      356000                   3.7750   \n",
       "\n",
       "   Última oferta de venda  \n",
       "0                  3.7825  \n",
       "1                  3.7780  \n",
       "2                  3.7805  \n",
       "3                  3.7755  \n",
       "4                  3.7770  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features criadas:\n",
    "\n",
    "-- Diferença entre Contratos abertos e fechados\n",
    "-- Diferença entre Máximo e mínimo\n",
    "-- Diferença entre Abertura e ùltima oferta de compra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Novos Testes:\n",
    "\n",
    "- Diferença entre Ajuste e Máximo ou Mínimo\n",
    "- Gráfico do Ajuste com o tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T18:20:38.245989Z",
     "start_time": "2019-11-08T18:20:38.167026Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Número Negócios</th>\n",
       "      <th>Contratos Negociados</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Abertura</th>\n",
       "      <th>Mínimo</th>\n",
       "      <th>Máximo</th>\n",
       "      <th>Médio</th>\n",
       "      <th>Último Preço</th>\n",
       "      <th>Ajuste</th>\n",
       "      <th>...</th>\n",
       "      <th>Dif_contratos</th>\n",
       "      <th>Dif_minmax</th>\n",
       "      <th>Dif_abert_ultimo</th>\n",
       "      <th>Dif_abert_ajuste</th>\n",
       "      <th>Dif_abert_min</th>\n",
       "      <th>Dif_abert_max</th>\n",
       "      <th>Dif_abert_medio</th>\n",
       "      <th>Dif_ajuste_ultimo</th>\n",
       "      <th>Dif_ajuste_medio</th>\n",
       "      <th>Dif_ultimacomp_ultimavend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29/07/2019</td>\n",
       "      <td>271.92</td>\n",
       "      <td>22.6625</td>\n",
       "      <td>42.939771</td>\n",
       "      <td>3.7850</td>\n",
       "      <td>3.7775</td>\n",
       "      <td>3.8015</td>\n",
       "      <td>3.789499</td>\n",
       "      <td>3.7820</td>\n",
       "      <td>3.784797</td>\n",
       "      <td>...</td>\n",
       "      <td>132520</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>7.5</td>\n",
       "      <td>-16.5</td>\n",
       "      <td>-4.499</td>\n",
       "      <td>2.797</td>\n",
       "      <td>-4.702</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26/07/2019</td>\n",
       "      <td>321.28</td>\n",
       "      <td>30.9480</td>\n",
       "      <td>58.414828</td>\n",
       "      <td>3.7800</td>\n",
       "      <td>3.7610</td>\n",
       "      <td>3.7955</td>\n",
       "      <td>3.775030</td>\n",
       "      <td>3.7760</td>\n",
       "      <td>3.770245</td>\n",
       "      <td>...</td>\n",
       "      <td>23510</td>\n",
       "      <td>34.5</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-9.755</td>\n",
       "      <td>19.0</td>\n",
       "      <td>-15.5</td>\n",
       "      <td>4.970</td>\n",
       "      <td>-5.755</td>\n",
       "      <td>-4.785</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25/07/2019</td>\n",
       "      <td>416.51</td>\n",
       "      <td>38.1060</td>\n",
       "      <td>72.105906</td>\n",
       "      <td>3.7680</td>\n",
       "      <td>3.7570</td>\n",
       "      <td>3.8070</td>\n",
       "      <td>3.784490</td>\n",
       "      <td>3.7795</td>\n",
       "      <td>3.782834</td>\n",
       "      <td>...</td>\n",
       "      <td>15894</td>\n",
       "      <td>50.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>14.834</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-39.0</td>\n",
       "      <td>-16.490</td>\n",
       "      <td>3.334</td>\n",
       "      <td>-1.656</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24/07/2019</td>\n",
       "      <td>261.37</td>\n",
       "      <td>26.9620</td>\n",
       "      <td>50.725253</td>\n",
       "      <td>3.7675</td>\n",
       "      <td>3.7540</td>\n",
       "      <td>3.7795</td>\n",
       "      <td>3.762721</td>\n",
       "      <td>3.7735</td>\n",
       "      <td>3.769856</td>\n",
       "      <td>...</td>\n",
       "      <td>-7529</td>\n",
       "      <td>25.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.356</td>\n",
       "      <td>13.5</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>4.779</td>\n",
       "      <td>-3.644</td>\n",
       "      <td>7.135</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23/07/2019</td>\n",
       "      <td>335.86</td>\n",
       "      <td>31.3840</td>\n",
       "      <td>59.121713</td>\n",
       "      <td>3.7450</td>\n",
       "      <td>3.7430</td>\n",
       "      <td>3.7820</td>\n",
       "      <td>3.767634</td>\n",
       "      <td>3.7750</td>\n",
       "      <td>3.772972</td>\n",
       "      <td>...</td>\n",
       "      <td>-2908</td>\n",
       "      <td>39.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>27.972</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>-22.634</td>\n",
       "      <td>-2.028</td>\n",
       "      <td>5.338</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Data  Número Negócios  Contratos Negociados     Volume  Abertura  \\\n",
       "0  29/07/2019           271.92               22.6625  42.939771    3.7850   \n",
       "1  26/07/2019           321.28               30.9480  58.414828    3.7800   \n",
       "2  25/07/2019           416.51               38.1060  72.105906    3.7680   \n",
       "3  24/07/2019           261.37               26.9620  50.725253    3.7675   \n",
       "4  23/07/2019           335.86               31.3840  59.121713    3.7450   \n",
       "\n",
       "   Mínimo  Máximo     Médio  Último Preço    Ajuste  ...  Dif_contratos  \\\n",
       "0  3.7775  3.8015  3.789499        3.7820  3.784797  ...         132520   \n",
       "1  3.7610  3.7955  3.775030        3.7760  3.770245  ...          23510   \n",
       "2  3.7570  3.8070  3.784490        3.7795  3.782834  ...          15894   \n",
       "3  3.7540  3.7795  3.762721        3.7735  3.769856  ...          -7529   \n",
       "4  3.7430  3.7820  3.767634        3.7750  3.772972  ...          -2908   \n",
       "\n",
       "   Dif_minmax  Dif_abert_ultimo  Dif_abert_ajuste  Dif_abert_min  \\\n",
       "0        24.0              -3.0            -0.203            7.5   \n",
       "1        34.5              -4.0            -9.755           19.0   \n",
       "2        50.0              11.5            14.834           11.0   \n",
       "3        25.5               6.0             2.356           13.5   \n",
       "4        39.0              30.0            27.972            2.0   \n",
       "\n",
       "   Dif_abert_max  Dif_abert_medio  Dif_ajuste_ultimo  Dif_ajuste_medio  \\\n",
       "0          -16.5           -4.499              2.797            -4.702   \n",
       "1          -15.5            4.970             -5.755            -4.785   \n",
       "2          -39.0          -16.490              3.334            -1.656   \n",
       "3          -12.0            4.779             -3.644             7.135   \n",
       "4          -37.0          -22.634             -2.028             5.338   \n",
       "\n",
       "   Dif_ultimacomp_ultimavend  \n",
       "0                        0.5  \n",
       "1                        1.5  \n",
       "2                        1.0  \n",
       "3                        2.0  \n",
       "4                        2.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_total.copy()\n",
    "\n",
    "df['Dif_contratos'] = df['Contratos Abertos'] -df['Contratos Fechados']\n",
    "df['Dif_minmax'] = (df['Máximo'] - df['Mínimo'])*1000\n",
    "df['Dif_abert_ultimo'] = (df['Último Preço'] - df['Abertura'])*1000\n",
    "df['Dif_abert_ajuste'] = (df['Ajuste'] - df['Abertura'])*1000\n",
    "df['Dif_abert_min'] = (df['Abertura'] - df['Mínimo'])*1000\n",
    "df['Dif_abert_max'] = (df['Abertura'] - df['Máximo'])*1000\n",
    "df['Dif_abert_medio'] = (df['Abertura'] - df['Médio'])*1000\n",
    "df['Dif_ajuste_ultimo'] = (df['Ajuste'] - df['Último Preço'])*1000\n",
    "df['Dif_ajuste_medio'] = (df['Ajuste'] - df['Médio'])*1000\n",
    "df['Dif_ultimacomp_ultimavend'] = (df['Última oferta de venda'] - df['Última oferta de compra'])*1000\n",
    "\n",
    "df['Contratos Negociados'] = df['Contratos Negociados']/10000\n",
    "df['Número Negócios'] = df['Número Negócios']/100\n",
    "df['Volume'] = df['Volume']/1000000000\n",
    "\n",
    "df = df.drop(columns = ['Contratos Abertos', 'Contratos Fechados'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### Prever relação de ABERTURA com ÚLTIMO PREÇO do dia anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T15:32:36.727514Z",
     "start_time": "2019-09-13T15:32:36.676522Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Número Negócios</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Var pontos</th>\n",
       "      <th>Dif_contratos</th>\n",
       "      <th>Dif_minmax</th>\n",
       "      <th>Dif_abert_ultimo</th>\n",
       "      <th>Dif_abert_ajuste</th>\n",
       "      <th>Média</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29/07/2019</td>\n",
       "      <td>271.92</td>\n",
       "      <td>42.939771</td>\n",
       "      <td>145520</td>\n",
       "      <td>132520</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>3.785600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26/07/2019</td>\n",
       "      <td>321.28</td>\n",
       "      <td>58.414828</td>\n",
       "      <td>125890</td>\n",
       "      <td>23510</td>\n",
       "      <td>34.5</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-9.755</td>\n",
       "      <td>3.776534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25/07/2019</td>\n",
       "      <td>416.51</td>\n",
       "      <td>72.105906</td>\n",
       "      <td>129780</td>\n",
       "      <td>15894</td>\n",
       "      <td>50.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>14.834</td>\n",
       "      <td>3.779853</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24/07/2019</td>\n",
       "      <td>261.37</td>\n",
       "      <td>50.725253</td>\n",
       "      <td>31160</td>\n",
       "      <td>-7529</td>\n",
       "      <td>25.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.356</td>\n",
       "      <td>3.769510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23/07/2019</td>\n",
       "      <td>335.86</td>\n",
       "      <td>59.121713</td>\n",
       "      <td>356000</td>\n",
       "      <td>-2908</td>\n",
       "      <td>39.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>27.972</td>\n",
       "      <td>3.767201</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Data  Número Negócios     Volume  Var pontos  Dif_contratos  \\\n",
       "0  29/07/2019           271.92  42.939771      145520         132520   \n",
       "1  26/07/2019           321.28  58.414828      125890          23510   \n",
       "2  25/07/2019           416.51  72.105906      129780          15894   \n",
       "3  24/07/2019           261.37  50.725253       31160          -7529   \n",
       "4  23/07/2019           335.86  59.121713      356000          -2908   \n",
       "\n",
       "   Dif_minmax  Dif_abert_ultimo  Dif_abert_ajuste     Média  target  \n",
       "0        24.0              -3.0            -0.203  3.785600       0  \n",
       "1        34.5              -4.0            -9.755  3.776534       0  \n",
       "2        50.0              11.5            14.834  3.779853       0  \n",
       "3        25.5               6.0             2.356  3.769510       0  \n",
       "4        39.0              30.0            27.972  3.767201       0  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_abert_old = df.copy()\n",
    "\n",
    "#1 se o Ajuste for maior que a abertura\n",
    "\n",
    "df_abert_old['target'] = df_abert_old.Abertura.shift(-1) - df_abert_old['Último Preço']\n",
    "df_abert_old['target'] = df_abert_old['target'].apply(lambda x: 1 if x > 0 else 0)\n",
    "df_abert_old= df_abert_old.drop(len(df_abert_old)-1)\n",
    "\n",
    "df_abert_old['Média'] = (df_abert_old['Último Preço'] + df_abert_old['Abertura'] + df_abert_old['Máximo'] + df_abert_old['Mínimo'] + df_abert_old['Médio'] + df_abert_old['Ajuste'] + df_abert_old['Última oferta de compra']+ df_abert_old['Última oferta de venda'])/8\n",
    "df_abert_old = df_abert_old.drop(columns = ['Último Preço','Abertura','Máximo','Mínimo','Médio','Última oferta de compra','Última oferta de venda','Contratos Negociados', 'Ajuste'])\n",
    "\n",
    "\n",
    "df_change = df_abert_old[['target']]\n",
    "df_abert_old = df_abert_old.drop(columns = 'target')\n",
    "df_abert_old['target'] = df_change\n",
    "\n",
    "df_abert_old.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T15:32:37.498122Z",
     "start_time": "2019-09-13T15:32:37.424163Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "df_abert_old.iloc[:,1:-1]  = sc.fit_transform(df_abert_old.iloc[:,1:-1])\n",
    "\n",
    "df_moeda = pd.read_csv('moedas_features.csv')\n",
    "\n",
    "sc = StandardScaler()\n",
    "df_moeda.iloc[:,1:-1] = sc.fit_transform(df_moeda.iloc[:,1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T15:32:37.911746Z",
     "start_time": "2019-09-13T15:32:37.887757Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "dataset = pca.fit_transform(df_moeda.iloc[:,1:])\n",
    "df_moeda_pca = pd.DataFrame(dataset)\n",
    "df_moeda_pca['Data'] = df_moeda.iloc[:,0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T15:32:38.281847Z",
     "start_time": "2019-09-13T15:32:38.266857Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_abert = pd.merge(df_moeda_pca, df_abert_old, on = 'Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T15:32:38.469048Z",
     "start_time": "2019-09-13T15:32:38.449061Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.95102858,  0.964283  ,  0.39995442, ...,  1.45966275,\n",
       "        -0.14090923,  2.00404183],\n",
       "       [ 1.95712812,  0.04031302,  0.45639442, ..., -0.04228311,\n",
       "        -0.20152269,  1.96200735],\n",
       "       [ 1.93249635,  0.6734895 ,  0.12126157, ...,  0.32404515,\n",
       "        -0.22171399,  1.97132267],\n",
       "       ...,\n",
       "       [ 2.84623392, -0.2660859 ,  0.78113855, ..., -0.44524419,\n",
       "        -0.23640773, -0.5714771 ],\n",
       "       [ 2.86827015, -0.70844314, -1.60936722, ..., -0.44890747,\n",
       "        -0.23044289, -0.55704584],\n",
       "       [ 2.83320426,  0.75089211,  0.27847416, ...,  0.34236156,\n",
       "        -0.19171189, -0.55159947]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df_abert[['target']]\n",
    "X = df_abert.drop(columns = ['Data','target'])\n",
    "X_columns = df_abert.drop(columns = ['Data','target'])\n",
    "\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "#X = X.values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T15:32:38.730813Z",
     "start_time": "2019-09-13T15:32:38.722813Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T15:32:39.249233Z",
     "start_time": "2019-09-13T15:32:39.221246Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\choice\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\choice\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7493975903614458"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression().fit(x_train, y_train)\n",
    "\n",
    "predictions = clf.predict(x_test)\n",
    "\n",
    "probas = clf.predict_proba(x_test) \n",
    "\n",
    "\n",
    "score = clf.score(x_test, y_test)\n",
    "\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T15:32:40.097809Z",
     "start_time": "2019-09-13T15:32:39.986871Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\choice\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "c:\\users\\choice\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.689156626506024"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = RandomForestClassifier()\n",
    "r.fit(x_train, y_train)  \n",
    "\n",
    "predictions = r.predict(x_test)\n",
    "\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T15:32:44.705325Z",
     "start_time": "2019-09-13T15:32:44.480765Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcAAAAEWCAYAAADxQkdBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xm4HFWZx/HvjySQmEBCTEDCdoEBVBgIJAFxEFlkER0RwUnYJKKDjCwCIrjMCMLogCgqZhgmOgHZArIOm4RFAsiafQOCkIRhkwQCIYGAJHnnjzrXVJq+S9/bt7tv6vd5nn5u9amqc97uu7z3VFXXq4jAzMysaNapdwBmZmb14ARoZmaF5ARoZmaF5ARoZmaF5ARoZmaF5ARoZmaF5ARoZmaF5ARo1gmSFkhaLmlZ7jGkk33uLenFasXYzjEvl/TvtRyzJZLOkXRVveOwtZ8ToFnn/WNE9Ms9Xq5nMJJ61nP8zujOsVv34wRo1kUkfULSI5LelDRD0t65dV+V9JSkpZLmSfpGau8L/AEYkp9Rls7QSmeJaSZ6lqSZwNuSeqb9bpS0SNJ8Sae0M+4mSZFifEHSG5JOkDRC0sz0esbkth8t6WFJv5a0RNLTkvbLrR8i6VZJiyU9K+mfc+vOkXSDpKskvQWcAHwfGJle+4zW3q/8eyHp25IWSnpF0ldz6/tI+rmk51N8f5LUpx3fo9FprKXp/TuqPe+fdR/+b8usC0jaFLgDOAa4C9gPuFHSRyNiEbAQ+DwwD9gL+IOkSRExVdJngasiYrNcf+0Z9gjgc8BrwCrgNuB/U/tmwL2S5kbEhHa+jN2BbVN8t6bX8RmgFzBN0vUR8UBu2xuAQcCXgJskbRURi4HxwBxgCPBR4B5J8yLivrTvIcCXga8A66U+/i4ijs7F0uL7ldZ/BOgPbArsD9wg6ZaIeAP4GbAD8EngLynWVa19j4B3gIuBERExV9ImwMB2vm/WTXgGaNZ5t6QZxJuSbkltRwN3RsSdEbEqIu4BJgMHA0TEHRHxXGQeAO4GPtXJOC6OiBciYjkwAhgcEedGxF8jYh7wG2BUBf2dFxHvRsTdwNvA+IhYGBEvAQ8Bu+S2XQj8MiLej4jrgLnA5yRtDuwJnJX6mg78lizpNHs0Im5J79PycoG04/16Hzg3jX8nsAzYXtI6wHHAtyLipYhYGRGPRMR7tPE9IvsnYkdJfSLilYiYU8F7Z92AE6BZ530xIgakxxdT25bAl3OJ8U2yRLAJgKTPSnosHRZ8k+yP7qBOxvFCbnlLssOo+fG/D2xcQX+v5paXl3neL/f8pVjzzvrPk834hgCLI2JpybpNW4i7rHa8X69HxIrc83dSfIOA3sBzZbpt8XsUEW8DI8kOyb4i6Y40M7S1iBOgWdd4AbgylxgHRETfiDhf0nrAjWSH5jaOiAHAnUDzcc5yJVreBj6Ue/6RMtvk93sBmF8y/voRcXCZ/aphU615nHYL4OX0GChp/ZJ1L7UQ9weet+P9as1rwLvANmXWtfg9AoiICRGxP9k/LU+TzaBtLeIEaNY1rgL+UdKBknpI6p0u1tgMWJfsXNciYEU653dAbt9XgQ9L6p9rmw4cLGmgpI8Ap7Yx/hPAW+nCmD4phh0ljajaK1zTRsApknpJ+jLwMbLDiy8AjwD/kd6DnYCvAVe30terQFM6fAltv18tiohVwDjgonQxTg9Je6Sk2uL3SNLGkr6g7KKk98gOqa6s8D2xBucEaNYF0h/+Q8gOOy4im218B1gnHQ48Bfg98AZwJNlFJs37Pk124ci8dGhuCHAlMANYQHb+67o2xl8J/CMwFJhPNhP6LdmFIl3hcbILZl4DfgwcHhGvp3VHAE1ks8GbgbPT+baWXJ++vi5palvvVzucAcwCJgGLgQvIvg8tfo/S49sp5sXAp4FvVjCmdQNyQVwz6wxJo4GvR8Se9Y7FrBKeAZqZWSE5AZqZWSH5EKiZmRWSZ4BmZlZIvhVaAxs0aFA0NTXVOwwzs25j0KBBTJgwYUJEHNTWtk6ADaypqYnJkyfXOwwzs25FUrvuquRDoGZmVkhOgGZmVkhOgGZmVkhOgGZmVkhOgGZmVkhOgGZmVkhOgGZmVkhOgGZmVkj+IHwDmzIF1J6a12Zma5Fa3aLaM0AzMyskJ0AzMyskJ0AzMyskJ0AzMyukTiVASSslTZc0R9IMSadLWietGy7p4rS8nqR707YjKxxjoqThnYixSdKRHdx3iKQbOrjvaElDOrKvmZl1vc5eBbo8IoYCSNoIuAboD5wdEZOB5lo+uwC9mretFUk9gSbgyBRbRSLiZeDwDg4/GpgNvNzB/c3MrAtV7RBoRCwEjgdOUmZvSbenxHgVMDTNALcpt7+kH0qaJGm2pLHSGh8AOFrSI2ndbmn7vpLGpX2mSToktY+WdL2k24C7gfOBT6WxT2th7CZJD0mamh6fzLXPzvU7JrfP7ek19pB0eYptlqTTJB0ODAeuTuP2kTRM0gOSpkiaIGmTzr3jZmbWGVX9HGBEzEuHQDfKtS2U9HXgjIj4fCu7j4mIcwEkXQl8HrgtresbEZ+UtBcwDtgR+AHwx4g4TtIA4AlJ96bt9wB2iojFkvZux9gLgf0j4l1J2wLjyRJYewwFNo2IHVPsAyLiTUknpXEnS+oF/Bo4JCIWpcPAPwaOK+1M0vFk/0gAW7QzBDMzq1RXfBC+ox/d3kfSmcCHgIHAHFYnwPEAEfGgpA1SwjsA+IKkM9I2vVmdMe6JiMUVjN0LGCNpKLAS2K6CfecBW0v6NXAH2ayz1PZkSfueNLHtAbxSrrOIGAuMBZCG1+jjoGZmxVPVBChpa7IEshD4WAX79QYuAYZHxAuSziFLaM1KE0GQJdrDImJuSV+7A29XGPppwKvAzmSHhd8ts80K1jxk3BsgIt6QtDNwIHAi8E98cGYnYE5E7FFhXGZm1kWqdg5Q0mDgUrJDmZXOXJqT3WuS+vHBC09GpjH2BJZExBJgAnBy87lCSbu00PdSYP02xu8PvBIRq4BjyGZopRaQncdcR9LmQPO5yEHAOhFxI/BvwK5lxp0LDJa0R9qnl6Qd2ojJzMy6UGdngH0kTSc7hLgCuBK4qNJO0jmz3wCzyBLNpJJN3pD0CLABq2dX5wG/BGamJLiA7LxhqZnACkkzgMsj4hdltrkEuFHSl4H7WXMG2ZzMHwbmpxhnA1NT+6bAZc0f/wC+l75eDlwqaTnZOcnDgYsl9Sd7339JdpjXzMzqQJVP1opD0jDgooj4dH3GHx6rP0liZlYMnU1LkqZERJsXMvpOMC1IH74fD/yq3rGYmVn11bwckqSbga1Kms+KiAk1GPtA4IKS5vkRcWjptumD/JVcDVp1w4bBZE8Azcy6RM0TYLlkU8OxJ5BdPGNmZgXnQ6BmZlZIToBmZlZINT8Eau03ZQqoo/fVMbNuyxfn14ZngGZmVkhOgGZmVkhOgGZmVkhOgGZmVkgdToCSVqZir3MkzZB0evP9MCUNl3RxWl5P0r1p25EVjjEx3ZGlozE2STqyE/svkDRI0gBJ38y1D5F0Q0f7NTOz+uvMVaDLI2IoQKr6fg1ZVYWz011Umu9hsgvQq3nbWpHUE2gCjkyxdcYA4JtkN80mIl7mgxUrzMysG6nKIdCIWEhWxfwkZfaWdHtKjFeRlRGaLmmbcvtL+qGkSZJmSxrbXOIoOVrSI2ldcwmivpLGpX2mSToktY+WdL2k28gK054PfCqNfVoLY4+WNCb3/PZURT7vfGCb1M+FaWY5O7f/LZJukzRf0klpNjxN0mOSBqbthqbnMyXdLGnDFuI5XtJkSZNhURvvvJmZdVTVzgFGxLzU30a5toXA14GHImJoRDzXwu5jImJEROwI9GHNskZ9I+KTZDOwcantB8AfI2IEsA9woaS+ad0ewLERsS/w3dzY5cogtdd3gedSP98ps35HspnmbsCPgXciYhfgUeAraZsryO55uhNZSaWzyw0UEWMjYnh2J/PBnQjZzMxaU+2LYDr6se19JD0uaRawL5AvFjseICIeBDaQNAA4APhuqkU4kayg7hZp+3siYnEH4+io+yNiaUQsApYAt6X2WUBTqgE4ICIeSO2/A/aqcYxmZpZTtTvBSNoaWAksBD5WwX69yc6tDY+IFySdw+oK8bC6IG3+uYDDImJuSV+7s2Yx2/ZYwZr/CPRuacNWvJdbXpV7vgrfbcfMrCFVZQYoaTBwKdmhzEpv4tOccF6T1I8PXlwyMo2xJ7AkIpaQVXQ4uflcoaRdWuh7KbB+G+MvIDtHuY6kzckOY3aknxalmN+Q9KnUdAzwQCu7mJlZF+vM7KRPOgTZi2wWdSVwUaWdRMSbkn5DdrhwATCpZJM3JD0CbAAcl9rOA34JzExJcAFrnjdsNhNYIWkGcHkL5wEfBuan8WcDU8vE+Lqkh9OFL38A/rOiF5k5FrhU0oeAecBXO9CHmZlViSqfsFmtSMNj9adJzKwo/Ge5cyRNyS4kbJ3PTzUwV4Q3M+s6NU2Akm4GtippPitVau/qsQ8ELihpnl/PCvVmZlY/NU2A9Uw2Kcl2eaI1M7PuwTfDNjOzQvI5wAbmivBmjccXqKw9PAM0M7NCcgI0M7NCcgI0M7NC6jYJMBXHPbCk7VRJl9QrplwcnSq8a2ZmtddtEiBZVYhRJW2jUnubUp3Crnq9TWTlkMzMrJvoTgnwBuDzktaDbNYFDAH+JKmfpPskTZU0K1cgt0nSU2mWOBXYPN+hpAWSLpD0RHr8XWrfMvU3M33dIrVfLuniVKB3nqTmG3evUXhXUm9Jl6VYpknaJ+2/Qxpneup72y5/18zMrKxukwAj4nXgCeCg1DQKuC5Vn3gXODQidiUrkPvzXFX57YErImKXiHi+TNdvRcRuwBiyG2yTlq9IxWuvBi7Obb8JsCfZzbfPT22lhXdPTDH/PXAE8LtU9ukE4FcRMRQYDrxYGowrwpuZ1Ua3SYBJ/jBo/vCngJ9ImgncC2wKbJzWPR8Rj7XRZ/PXPdLyHsA1aflKsoTX7JaIWBURT+bGKLVn2o+IeBp4HtiOrEL89yWdBWwZEctLd3RFeDOz2uhuCfAWYD9JuwJ9IqK5dNFRZNliWJpdvcrqOoNtFciNFpZb2iZf/Lalj6mXbY+Ia4AvAMuBCZL2bSM2MzPrIt0qAUbEMmAiMI41L37pDyyMiPfT+bYtK+h2ZO7ro2n5EVbPNI8C/tRGH6UFcx9M+yFpO2ALYK6krYF5EXExcCuwUwVxmplZFXXHW6GNB25izStCrwZuy86bMR14uoL+1pP0ONk/A0ektlOAcZK+Q3Yirq3itWsU3gUuISt+O4usWPDoiHhP0kjgaEnvA38Bzq0gTjMzq6JCF8SVtAAYHhGv1TuWclwQ16zxFPhPZrfR3oK43eoQqJmZWbV0x0OgVRMRTfWOoTWuCG9m1nU8AzQzs0JyAjQzs0JyAjQzs0Iq9DnARueK8NZofAWkrU08AzQzs0JyAjQzs0JyAjQzs0JyAqwRSeMkLZQ0u96xmJmZE2AtXc7qWoZmZlZnToA1EhEPAovrHYeZmWWcABuMK8KbmdWGE2CDcUV4M7PacAI0M7NCcgI0M7NCcgKsEUnjgUeB7SW9KOlr9Y7JzKzIfC/QGomII+odg5mZreYZoJmZFZIToJmZFZIPgTawYcNg8uR6R2FmtnbyDNDMzArJCdDMzArJh0AbmCvCW2tcnd2sczwDNDOzQnICNDOzQnICNDOzQnIC7CBJ35C0Yb3jMDOzjnECzJEUkq7MPe8paZGk20u2+yGwOCLeaKGfiZKGp+U7JQ3o0sDNzKxivgp0TW8DO0rqExHLgf2Bl0o3iohz29thRBxcxfjMzKxKPAP8oD8An0vLRwDjm1dI6itpnKRJkqZJOiS195F0raSZkq4D+uT2WSBpUFq+RdIUSXMkHV+7l2RmZqWcAD/oWmCUpN7ATsDjuXU/AP4YESOAfYALJfUF/gV4JyJ2An4MDGuh7+MiYhgwHDhF0odLN5B0vKTJkibDouq9KjMzW4MTYImImAk0kc3+7ixZfQDwXUnTgYlAb2ALYC/gqtz+M1vo/hRJM4DHgM2BbcuMPzYihkfEcBjc6ddjZmbl+RxgebcCPwP2BvKzNAGHRcTc/MbKbtfS6n05JO0NfAbYIyLekTSRLIGamVkdeAZY3jjg3IiYVdI+AThZKeNJ2iW1Pwgcldp2JDt0Wqo/8EZKfh8FPtElkZuZWbs4AZYRES9GxK/KrDoP6AXMlDQ7PQf4L6CfpJnAmcATZfa9C+iZtjmP7DComZnVicJ31G1Y0vAAFwS08vyra1aepCnZdRSt8wzQzMwKyRfBNDBXhDcz6zqeAZqZWSE5AZqZWSE5AZqZWSH5HGADmzIFsk8cmvmqT7Nq8wzQzMwKyQnQzMwKqWoJUNKJkvpVq79GImmkpKZ6x2FmZtXTZgJMVdJ/nnt+hqRzSrY5BhgYEcuqH2L7SGpKsZ6caxsjaXQn+z0a2CIiFrSx3bmSPtOZsczMrHbaMwN8D/hSc1HXFvQA/r06Ia1JUiUX6iwEviVp3WqNHxFXRcSF7djuhxFxb7XGNTOzrtWeBLgCGAucVrpC0uWSDo+IyyMiJC1L7XtLekDS7yU9I+l8SUdJekLSLEnbpO0GS7oxVVifJOkfUvs5ksZKuhu4QlJvSZelfadJ2qeFWBcB9wHHlol1G0l3pYrsD6WKDM3tj6Xxz829Bkm6UNLsNO7IXF9nprYZks7Pvxdpeb8U56xUQX691H6+pCdT5fifteO9NzOzLtLe2dV/klVA+GkFfe8MfAxYDMwDfhsRu0n6FnAycCrwK+AXEfEnSVuQlRv6WNp/GLBnRCyX9G2AiPj7lLjulrRdRLxbZtzzgT9IGlfSPhY4ISL+LGl34BJg3xTDryJivKQTctt/CRiaXscgYJKkB1PbF4HdU2mjgflBUiX5y4H9IuIZSVcA/5K+Hgp8NP2zMKDcmybpeOD47NkW5TYxM7MqaNdFMBHxFnAFcEoFfU+KiFci4j3gOeDu1D6LrOI6ZAVix6QK67cCG0haP627NSKWp+U9gStTLE8DzwPbtRDrfLJyREc2t6WLcz4JXJ/G+m9gk7R6D+D6tHxNrqs9gfERsTIiXgUeAEakmC+LiHfSeItLQtgemB8Rz6TnvyOrGP8W8C7wW0lfAt5pIX5XhDczq4FKzq/9EpgKXJZrW0FKoqlIbP7c23u55VW556ty465DViF9eW7b5grrb+ebKogT4CfADWSFapvHeTMihlbQR0tjitarv5fdLyJWSNoN2A8YBZxENgM1M7M6aPfHINJM5/fA13LNC8gOVQIcQlYsthJ3kyUCACS1lKDyFde3Izs2OLeVWJ8GngQ+n56/BcyX9OXUhyTtnDZ/DDgsLY8qGXOkpB6SBpPN4p5IMR8n6UOprzUOgQJPA02S/i49PwZ4IM1C+0fEnWSHfytJxmZmVmWVfg7w52Tnw5r9Bvi0pCeA3Vlz1tYepwDD00UhTwIntLDdJUAPSbOA64DR6dBqa34MbJZ7fhTwNUkzgDlkCRuyZHR6eg2bAEtS+83ATGAG8EfgzIj4S0TcRXa4dnI6nHpGftB0XvKrZIdbZ5HNeC8F1gduV1YR/gHKXFRkZma1U/iK8GkmtzxdmDIKOCIiDmlrv1pwRXjLK/ivqlm7qZ0V4X0z7OwQ7ph0DvNN4Lg6x2NmZjVQ+AQYEQ+RfdSh4bgivJlZ1/HNsM3MrJCcAM3MrJCcAM3MrJAKfw6wkbkivPnKT7Ou4xmgmZkVkhOgmZkVkhOgmZkVkhOgmZkVUt0SoKSVkqZLmpMKy54uqbmyxHBJF6fl9STdm7Yd2XqvnY7p+x3c79Tmm2ObmVn3ULd7gUpaFhH90vJGZLX4Ho6Is0u2+wRwQUR8upYxlbSL7L1a1cJ+C4DhEfFadePxvUCLzleBmlWuvfcCbYhDoBGxkKwK+kmpVNHekm5PifEqYGiaAW5Tbn9JIyQ9kmaST0haX1JvSZdJmiVpmqR90rajJd0k6S5Jf26uci/pfKBPGudqSU2SnpJ0CVkdxM0l/ZekyWnW+qO03ynAEOB+SfentiPSuLMlXZDaeki6PLXNklS2GoSk49MYk2FRFd9lMzNbQ0TU5QEsK9P2BrAxsDdwe2r723IL/awLzANGpOcbkH2+8dtkldsBPgr8H9AbGJ2275+ePw9sXhoTWdX6VcAncm0D09cewERgp/R8ATAoLQ9JYw1OcfwR+CLZTbfvyfU1oO33aFhkcwA/ivows8oBkyPazkMNMQPM6cjHvrcHXomISQAR8VZErAD2BK5MbU+TJbrt0j73RcSSyGr3PQls2ULfz0fEY7nn/yRpKjAN2AH4eJl9RgATI2JRiuNqsmK684CtJf1a0kHAWx14rWZmViUNkwAlbQ2sBBZWuisQLbS3JF9MdyUt3xHnbwV+JW1FVvx2v4jYCbiDbAbZrnEj4g2yqhMTgROB37YSn5mZdbGGSICSBpNVTR+Tpq+VeBoYImlE6mt9ST2BB8mqwCNpO2ALYG4bfb0vqVcL6zYgS4hLJG0MfDa3bilZxXeAx4FPSxokqQdwBPCApEHAOhFxI/BvwK4Vvk4zM6uiet4LtI+k6UAvYAXZ4cqLKu0kIv6aPh7xa0l9gOXAZ4BLgEslzUr9j46I99T6zTXHAjPTYc4flIwzQ9I0YA7Z4cyHS/b7g6RXImIfSd8D7iebDd4ZEf8raWfgsuaPegDfq/S1mplZ9dTtYxDWNn8MwvzraVa5bvUxCDMzs1rrVuWQJN0MbFXSfFZETKhHPF1t2DCY7AmgmVmX6FYJMCIOrXcMZma2dvAhUDMzK6RuNQMsGleELy5f/GLW9TwDNDOzQnICNDOzQnICNDOzQnICNDOzQnICrCFJB0maK+lZSd+tdzxmZkXmBFgj6cbY/0l2E+2PA0dIKldOyczMasAJsHZ2A56NiHkR8VfgWuCQOsdkZlZYToC1synwQu75i6ltDZKOlzRZ0mRYVLPgzMyKxgmwdsp9pP0DH3eOiLERMTy7k/ngGoRlZlZMToC18yKwee75ZsDLdYrFzKzwnABrZxKwraStJK0LjAJurXNMZmaF5XuB1khErJB0EjAB6AGMi4g5dQ7LzKywnABrKCLuBO6sdxxmZuZDoGZmVlCeATYwV4Q3M+s6ngGamVkhOQGamVkhOQGamVkh+RxgA5syBVTu/jG21ooP3BvIzLqKZ4BmZlZIToBmZlZIToBmZlZIToA1ImlzSfdLekrSHEnfqndMZmZF5otgamcF8O2ImCppfWCKpHsi4sl6B2ZmVkSeAdZIRLwSEVPT8lLgKcoUxDUzs9pwAqwDSU3ALsDjZda5IryZWQ04AdaYpH7AjcCpEfFW6XpXhDczqw0nwBqS1Iss+V0dETfVOx4zsyJzAqwRSQL+B3gqIi6qdzxmZkXnBFg7/wAcA+wraXp6HFzvoMzMisofg6iRiPgT4Dt7mpk1CM8AzcyskDwDbGCuCG9m1nU8AzQzs0JyAjQzs0JyAjQzs0LyOcAG5orwxeFK8Ga15xmgmZkVkhOgmZkVkhOgmZkVkhOgmZkVUkMmQEkr070y50iaIel0SeukdcMlXZyW15N0b9p2ZCfGGyLphmrFb2Zmja9RrwJdHhFDASRtBFwD9AfOjojJQPP9UXYBejVv21ER8TJweGf6MDOz7qUhZ4B5EbEQOB44SZm9Jd2eEuNVwNA0A9ym3P6SFkj6iaRHU6X1XSVNkPScpBPSNk2SZqfl0ZJuknSXpD9L+mmur2WSLpA0Jc08d5M0UdI8SV/I9fWQpKnp8cnUfmjaR5I2kfSMpI+UidcV4c3MaqDhEyBARMwji3WjXNtC4OvAQxExNCKea6WLFyJiD+Ah4HKy2d4ngHNb2H4oMBL4e2CkpM1Te19gYkQMA5YC/w7sDxya62shsH9E7Jr6uDjFezPwF+BE4Ddks9m/lHmtrghvZlYDjXoItJzOfCT81vR1FtAvIpYCSyW9K2lAme3vi4glAJKeBLYEXgD+CtyV6+u9iHhf0iygKbX3AsZIGgqsBLbL9XsyMBt4LCLGd+L1mJlZJ3WLGaCkrcmSycIOdvFe+roqt9z8vNw/AfltVua2eT/ib/fs+FtfEZHv5zTgVWBnYDiwbq6vTdN+Gzdf1GNmZvXR8H+EJQ0GLgXG5JJPI+sPvJKS4jFADwBJPYHLgCOBp4DT6xahmZk17CHQPpKmkx1OXAFcCVxU35Da7RLgRklfBu4H3k7t3yc7X/lQem2TJN0REU/VK1AzsyJT95hUFZM0PFZ/4sPWZv41NKseSVOyCwlb1/CHQM3MzLpCox4CrZikm4GtSprPiogJ9YinGoYNg8meAJqZdYm1JgFGxKH1jsHMzLoPHwI1M7NCWmtmgGsjV4Rf+/niF7P68QzQzMwKyQnQzMwKyQnQzMwKqTAJMJUtOrCk7VRJl7Sw/d9KJJmZ2dqnMAkQGA+MKmkbldrNzKxgipQAbwA+L2k9yGZ4wBDgT5IulDRb0ixJI0t3TEVyx+Se3y5p77TcniK5PdIYkyTNlPSNrn+5ZmbWmsIkwIh4HXgCOCg1jQKuA75EVgB3Z+AzwIWSNqmg6/YUyf0asCQiRgAjgH+WVHrXGjMzq6HCJMAkfxi0+fDnnsD4iFgZEa8CD5AlqfYqLZL7QES8n5abUvsBwFdSFYjHgQ8D25brTNLxkiZLmgyLKgjDzMwqUbQEeAuwn6RdgT4RMZX2VZpfwZrvVe/ccnuK5Ao4OSKGpsdWEXF3uYEiYmxEDM/uZD64/a/MzMwqUqgEGBHLgInAOFZf/PIgMDKdpxsM7EV2qDRvATBU0jqSNgd2q3DoCcC/SOoFIGk7SX079irMzKwaingrtPHATaw+FHozsAcwAwjgzIj4S7pIptnDwHyyw5qzgakVjvlbssOhUyWJ7NjmFzsWvpmZVYML4jYwF8Rd+/nXz6z6XBDXzMysFU6AZmZWSEU8B9htuCK8mVnX8QzQzMwKyQnQzMwKyQnQzMwKyQnQzMwKyQnQzMwKyQnQzMwKyQnQzMwKyQnQzMwKyQnQzMwKyTfDbmCSlgJz6x1rne2uAAAIyElEQVRHiUHAa/UOokQjxgSNGZdjar9GjMsxte01gIg4qK0NfSu0xja3PXc0ryVJkx1T+zRiXI6p/RoxLsdUXT4EamZmheQEaGZmheQE2NjG1juAMhxT+zViXI6p/RoxLsdURb4IxszMCskzQDMzKyQnQDMzKyQnwDqQdJCkuZKelfTdMuvXk3RdWv+4pKbcuu+l9rmSDmyEuCTtL2mKpFnp6771jim3fgtJyySd0QgxSdpJ0qOS5qT3q3e945LUS9LvUjxPSfpeDWPaS9JUSSskHV6y7lhJf06PY+sdk6Shue/dTEkj6x1Tbv0Gkl6SNKZaMXU2rvS7d3f6mXqy9HezIUSEHzV8AD2A54CtgXWBGcDHS7b5JnBpWh4FXJeWP562Xw/YKvXTowHi2gUYkpZ3BF6qd0y59TcC1wNn1Dsmss/dzgR2Ts8/3CDfvyOBa9Pyh4AFQFONYmoCdgKuAA7PtQ8E5qWvG6blDesc03bAtml5CPAKMKCeMeXW/wq4BhhTjZ+nasQFTAT2T8v9gA9VK7ZqPTwDrL3dgGcjYl5E/BW4FjikZJtDgN+l5RuA/SQptV8bEe9FxHzg2dRfXeOKiGkR8XJqnwP0lrRePWMCkPRFsj+cc6oQSzViOgCYGREzACLi9YhY2QBxBdBXUk+gD/BX4K1axBQRCyJiJrCqZN8DgXsiYnFEvAHcA7R5Z4+ujCkinomIP6fll4GFwOB6xgQgaRiwMXB3FWKpSlySPg70jIh70nbLIuKdKsfXaU6Atbcp8ELu+Yuprew2EbECWEI2W2jPvvWIK+8wYFpEvFfPmCT1Bc4CflSFOKoSE9kMIiRNSIeNzmyQuG4A3iab0fwf8LOIWFyjmLpi3y7vV9JuZLOi5+oZk6R1gJ8D36lCHFWLi+xn/U1JN0maJulCST2qHmEn+VZotacybaWfRWlpm/bs21GdiStbKe0AXEA206l3TD8CfhERy9KEsFo6E1NPYE9gBPAOcJ+kKRFxX53j2g1YSXZYb0PgIUn3RsS8GsTUFft2ab+SNgGuBI6NiA/MyGoc0zeBOyPihSr/nEPn4uoJfIrs9Mj/AdcBo4H/qUpkVeIZYO29CGyee74Z8HJL26TDUv2Bxe3ctx5xIWkz4GbgKxFRjf+KOxvT7sBPJS0ATgW+L+mkOsf0IvBARLyWDgfdCexahZg6G9eRwF0R8X5ELAQeBqpxb8fO/Lx21c96p/qVtAFwB/CvEfFYFeLpbEx7ACeln/OfAV+RdH4DxPUi2ZGgeelowy1U72e9eup9ErJoD7L/jOaRXcTSfGJ5h5JtTmTNixV+n5Z3YM2LYOZRvYsoOhPXgLT9YY3yXpVscw7VuwimM+/ThsBUsgtNegL3Ap9rgLjOAi4j+4+/L/AksFMtYsptezkfvAhmfnrPNkzLA+sc07rAfcCptf45bymmknWjqe5FMJ15r3qk7Qen55cBJ1bzfavKa6x3AEV8AAcDz5CdP/hBajsX+EJa7k125eKzwBPA1rl9f5D2mwt8thHiAv6V7BzS9Nxjo3q/V7k+zqFKCbAK37+jyS7KmQ38tEG+f/1S+xyy5PedGsY0gmy28DbwOjAnt+9xKdZnga/WO6b0vXu/5Od8aL3fp1wfo6liAqzC929/squeZ5ElyHWrGVs1Hr4VmpmZFZLPAZqZWSE5AZqZWSE5AZqZWSE5AZqZWSE5AZqZWSE5AZrVmKSVkqZLmi3pNkkD2rHPsjbWD5D0zdzzIZJuqEKsTZJmd7afCsccKungWo5pxeQEaFZ7yyNiaETsSHYnlhOr0OcAsttiAdnNmiPiA2VzGl26Q81Qss+fmXUpJ0Cz+nqU3A2GJX1H0qRUb+4DN/KW1E/Sfelm2rMkNd+d/3xgmzSzvDA/c0u1/3bI9TFR0jBJfSWNS+NNy/VVlqTRkm5Js9b5kk6SdHra9zFJA3P9/1LSI2mWu1tqH5j2n5m23ym1nyNprKS7ycrqnAuMTK9lpKTdUl/T0tftc/HcJOkuZTUDf5qL9aD0Hs2QdF9qq+j1WgHU+5P4fvhRtAewLH3tQXYHloPS8wOAsWS3JFsHuB3Yq2SfnsAGaXkQ2V1SRFaXbXZujL89B04DfpSWNwGeScs/AY5OywPI7vjRtyTWfD+j03jrk5UBWgKckNb9gnSLMLI6cL9Jy3vl9v81cHZa3heYnpbPAaYAfXLjjMnFsAFZaR2AzwA35rabR3ZP097A82T3rhxMVsVgq7TdwPa+Xj+K9XA1CLPa6yNpOllymUJW6w6yBHgAMC097wdsCzyY21fATyTtRVaDbVOyWnCt+X0a42zgn8iSbvN4X5B0RnreG9gCeKqVvu6PiKXAUklLgNtS+yyywqjNxgNExIPKqpUPIKuEcVhq/6OkD0vqn7a/NSKWtzBmf+B3krYlq0bQK7fuvohYAiDpSWBLsnuHPhhZzUxidWmnjrxeW4s5AZrV3vKIGJr++N9Odg7wYrLk9h8R8d+t7HsU2QxnWES8n6oA9G5tsIh4SdLr6ZDjSOAbaZXIbmA+t4LY83UeV+Wer2LNvyel91hsq5zX262MeR5Z4j1UUhPZDLNcPCtTDM1Ffkt15PXaWsznAM3qJM1cTgHOkNQLmAAcJ6kfgKRNJW1Uslt/YGFKfvuQzXgAlpIdmmzJtcCZQP+ImJXaJgAnKxWSk7RLNV5XMjL1uSewJL3WB8kSOJL2Bl6LiHKV50tfS3/gpbQ8uh1jPwp8WtJWaayBqb0rX691Q06AZnUUEdPIysaMioi7gWuARyXNIqvUXprUrgaGS5pMlkyeTv28DjycLjq5sMxQN5BKIOXaziM7nDgzXTBzXvVeGW9IegS4FPhaajsnxT6T7KKdY1vY937g480XwQA/Bf5D0sNk501bFRGLgOOBmyTNICvGCl37eq0bcjUIM6sqSRPJyk9NrncsZq3xDNDMzArJM0AzMyskzwDNzKyQnADNzKyQnADNzKyQnADNzKyQnADNzKyQ/h+vmbW7GgeLigAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = X_columns.columns\n",
    "importances = r.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T15:33:09.188377Z",
     "start_time": "2019-09-13T15:32:48.379645Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3731 samples, validate on 415 samples\n",
      "Epoch 1/200\n",
      "3731/3731 [==============================] - 1s 148us/step - loss: 0.6726 - acc: 0.6199 - val_loss: 0.6502 - val_acc: 0.6386\n",
      "Epoch 2/200\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.6165 - acc: 0.6950 - val_loss: 0.5956 - val_acc: 0.6675\n",
      "Epoch 3/200\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.5673 - acc: 0.7188 - val_loss: 0.5613 - val_acc: 0.7012\n",
      "Epoch 4/200\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.5436 - acc: 0.7285 - val_loss: 0.5493 - val_acc: 0.7133\n",
      "Epoch 5/200\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.5361 - acc: 0.7341 - val_loss: 0.5450 - val_acc: 0.7084\n",
      "Epoch 6/200\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.5317 - acc: 0.7330 - val_loss: 0.5387 - val_acc: 0.7084\n",
      "Epoch 7/200\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.5294 - acc: 0.7349 - val_loss: 0.5349 - val_acc: 0.7108\n",
      "Epoch 8/200\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.5271 - acc: 0.7360 - val_loss: 0.5332 - val_acc: 0.7157\n",
      "Epoch 9/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.5253 - acc: 0.7355 - val_loss: 0.5311 - val_acc: 0.7205\n",
      "Epoch 10/200\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.5237 - acc: 0.7365 - val_loss: 0.5266 - val_acc: 0.7205\n",
      "Epoch 11/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.5223 - acc: 0.7389 - val_loss: 0.5268 - val_acc: 0.7181\n",
      "Epoch 12/200\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.5211 - acc: 0.7406 - val_loss: 0.5249 - val_acc: 0.7133\n",
      "Epoch 13/200\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.5200 - acc: 0.7387 - val_loss: 0.5220 - val_acc: 0.7229\n",
      "Epoch 14/200\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.5192 - acc: 0.7365 - val_loss: 0.5214 - val_acc: 0.7229\n",
      "Epoch 15/200\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.5178 - acc: 0.7400 - val_loss: 0.5183 - val_acc: 0.7253\n",
      "Epoch 16/200\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.5172 - acc: 0.7360 - val_loss: 0.5195 - val_acc: 0.7229\n",
      "Epoch 17/200\n",
      "3731/3731 [==============================] - 0s 66us/step - loss: 0.5161 - acc: 0.7397 - val_loss: 0.5178 - val_acc: 0.7229\n",
      "Epoch 18/200\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.5150 - acc: 0.7376 - val_loss: 0.5164 - val_acc: 0.7205\n",
      "Epoch 19/200\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.5146 - acc: 0.7344 - val_loss: 0.5174 - val_acc: 0.7205\n",
      "Epoch 20/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.5138 - acc: 0.7381 - val_loss: 0.5158 - val_acc: 0.7205\n",
      "Epoch 21/200\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.5130 - acc: 0.7355 - val_loss: 0.5129 - val_acc: 0.7277\n",
      "Epoch 22/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.5128 - acc: 0.7379 - val_loss: 0.5122 - val_acc: 0.7253\n",
      "Epoch 23/200\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.5122 - acc: 0.7376 - val_loss: 0.5129 - val_acc: 0.7229\n",
      "Epoch 24/200\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.5114 - acc: 0.7373 - val_loss: 0.5110 - val_acc: 0.7277\n",
      "Epoch 25/200\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.5111 - acc: 0.7384 - val_loss: 0.5127 - val_acc: 0.7205\n",
      "Epoch 26/200\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.5103 - acc: 0.7395 - val_loss: 0.5115 - val_acc: 0.7229\n",
      "Epoch 27/200\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.5107 - acc: 0.7363 - val_loss: 0.5119 - val_acc: 0.7229\n",
      "Epoch 28/200\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.5095 - acc: 0.7427 - val_loss: 0.5110 - val_acc: 0.7253\n",
      "Epoch 29/200\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.5095 - acc: 0.7408 - val_loss: 0.5104 - val_acc: 0.7229\n",
      "Epoch 30/200\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.5088 - acc: 0.7408 - val_loss: 0.5108 - val_acc: 0.7229\n",
      "Epoch 31/200\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.5086 - acc: 0.7403 - val_loss: 0.5102 - val_acc: 0.7277\n",
      "Epoch 32/200\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.5085 - acc: 0.7400 - val_loss: 0.5091 - val_acc: 0.7253\n",
      "Epoch 33/200\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.5078 - acc: 0.7414 - val_loss: 0.5087 - val_acc: 0.7229\n",
      "Epoch 34/200\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.5075 - acc: 0.7403 - val_loss: 0.5089 - val_acc: 0.7229\n",
      "Epoch 35/200\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.5077 - acc: 0.7397 - val_loss: 0.5086 - val_acc: 0.7253\n",
      "Epoch 36/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.5069 - acc: 0.7432 - val_loss: 0.5067 - val_acc: 0.7253\n",
      "Epoch 37/200\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.5068 - acc: 0.7432 - val_loss: 0.5070 - val_acc: 0.7229\n",
      "Epoch 38/200\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.5061 - acc: 0.7424 - val_loss: 0.5064 - val_acc: 0.7253\n",
      "Epoch 39/200\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.5057 - acc: 0.7422 - val_loss: 0.5069 - val_acc: 0.7253\n",
      "Epoch 40/200\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.5054 - acc: 0.7416 - val_loss: 0.5065 - val_acc: 0.7253\n",
      "Epoch 41/200\n",
      "3731/3731 [==============================] - 0s 58us/step - loss: 0.5051 - acc: 0.7454 - val_loss: 0.5059 - val_acc: 0.7277\n",
      "Epoch 42/200\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.5047 - acc: 0.7440 - val_loss: 0.5049 - val_acc: 0.7229\n",
      "Epoch 43/200\n",
      "3731/3731 [==============================] - 0s 67us/step - loss: 0.5045 - acc: 0.7435 - val_loss: 0.5047 - val_acc: 0.7253\n",
      "Epoch 44/200\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.5041 - acc: 0.7464 - val_loss: 0.5037 - val_acc: 0.7253\n",
      "Epoch 45/200\n",
      "3731/3731 [==============================] - 0s 61us/step - loss: 0.5038 - acc: 0.7454 - val_loss: 0.5035 - val_acc: 0.7205\n",
      "Epoch 46/200\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.5035 - acc: 0.7406 - val_loss: 0.5025 - val_acc: 0.7253\n",
      "Epoch 47/200\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.5030 - acc: 0.7448 - val_loss: 0.5022 - val_acc: 0.7229\n",
      "Epoch 48/200\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.5030 - acc: 0.7435 - val_loss: 0.5031 - val_acc: 0.7205\n",
      "Epoch 49/200\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.5023 - acc: 0.7470 - val_loss: 0.5027 - val_acc: 0.7205\n",
      "Epoch 50/200\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.5022 - acc: 0.7462 - val_loss: 0.5019 - val_acc: 0.7229\n",
      "Epoch 51/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.5019 - acc: 0.7464 - val_loss: 0.5015 - val_acc: 0.7253\n",
      "Epoch 52/200\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.5017 - acc: 0.7451 - val_loss: 0.5010 - val_acc: 0.7253\n",
      "Epoch 53/200\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.5013 - acc: 0.7454 - val_loss: 0.5005 - val_acc: 0.7277\n",
      "Epoch 54/200\n",
      "3731/3731 [==============================] - 0s 59us/step - loss: 0.5016 - acc: 0.7448 - val_loss: 0.5005 - val_acc: 0.7253\n",
      "Epoch 55/200\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.5012 - acc: 0.7454 - val_loss: 0.5001 - val_acc: 0.7229\n",
      "Epoch 56/200\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.5008 - acc: 0.7459 - val_loss: 0.4998 - val_acc: 0.7253\n",
      "Epoch 57/200\n",
      "3731/3731 [==============================] - 0s 62us/step - loss: 0.5006 - acc: 0.7475 - val_loss: 0.4999 - val_acc: 0.7229\n",
      "Epoch 58/200\n",
      "3731/3731 [==============================] - 0s 59us/step - loss: 0.5005 - acc: 0.7443 - val_loss: 0.4991 - val_acc: 0.7325\n",
      "Epoch 59/200\n",
      "3731/3731 [==============================] - 0s 61us/step - loss: 0.5003 - acc: 0.7443 - val_loss: 0.4988 - val_acc: 0.7253\n",
      "Epoch 60/200\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.5005 - acc: 0.7438 - val_loss: 0.4992 - val_acc: 0.7301\n",
      "Epoch 61/200\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.4999 - acc: 0.7473 - val_loss: 0.4983 - val_acc: 0.7253\n",
      "Epoch 62/200\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.5001 - acc: 0.7446 - val_loss: 0.4979 - val_acc: 0.7277\n",
      "Epoch 63/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.5000 - acc: 0.7443 - val_loss: 0.4981 - val_acc: 0.7253\n",
      "Epoch 64/200\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.4994 - acc: 0.7464 - val_loss: 0.4971 - val_acc: 0.7253\n",
      "Epoch 65/200\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.4992 - acc: 0.7451 - val_loss: 0.4980 - val_acc: 0.7253\n",
      "Epoch 66/200\n",
      "3731/3731 [==============================] - 0s 44us/step - loss: 0.4992 - acc: 0.7454 - val_loss: 0.4976 - val_acc: 0.7301\n",
      "Epoch 67/200\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.4990 - acc: 0.7448 - val_loss: 0.4972 - val_acc: 0.7277\n",
      "Epoch 68/200\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.4986 - acc: 0.7473 - val_loss: 0.4983 - val_acc: 0.7277\n",
      "Epoch 69/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.4983 - acc: 0.7470 - val_loss: 0.4982 - val_acc: 0.7301\n",
      "Epoch 70/200\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.4983 - acc: 0.7467 - val_loss: 0.4977 - val_acc: 0.7277\n",
      "Epoch 71/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.4986 - acc: 0.7475 - val_loss: 0.4979 - val_acc: 0.7253\n",
      "Epoch 72/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.4985 - acc: 0.7497 - val_loss: 0.4979 - val_acc: 0.7277\n",
      "Epoch 73/200\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.4983 - acc: 0.7486 - val_loss: 0.4984 - val_acc: 0.7349\n",
      "Epoch 74/200\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.4979 - acc: 0.7470 - val_loss: 0.4980 - val_acc: 0.7325\n",
      "Epoch 75/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.4977 - acc: 0.7462 - val_loss: 0.4979 - val_acc: 0.7373\n",
      "Epoch 76/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.4977 - acc: 0.7489 - val_loss: 0.4985 - val_acc: 0.7422\n",
      "Epoch 77/200\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.4974 - acc: 0.7497 - val_loss: 0.4978 - val_acc: 0.7349\n",
      "Epoch 78/200\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.4971 - acc: 0.7486 - val_loss: 0.4989 - val_acc: 0.7373\n",
      "Epoch 79/200\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.4970 - acc: 0.7473 - val_loss: 0.4988 - val_acc: 0.7373\n",
      "Epoch 80/200\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.4968 - acc: 0.7489 - val_loss: 0.4986 - val_acc: 0.7422\n",
      "Epoch 81/200\n",
      "3731/3731 [==============================] - 0s 59us/step - loss: 0.4968 - acc: 0.7470 - val_loss: 0.4987 - val_acc: 0.7470\n",
      "Epoch 82/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.4968 - acc: 0.7473 - val_loss: 0.4974 - val_acc: 0.7398\n",
      "Epoch 83/200\n",
      "3731/3731 [==============================] - 0s 62us/step - loss: 0.4967 - acc: 0.7475 - val_loss: 0.4993 - val_acc: 0.7349\n",
      "Epoch 84/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.4965 - acc: 0.7483 - val_loss: 0.4985 - val_acc: 0.7446\n",
      "Epoch 85/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.4965 - acc: 0.7491 - val_loss: 0.4990 - val_acc: 0.7398\n",
      "Epoch 86/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.4964 - acc: 0.7505 - val_loss: 0.4983 - val_acc: 0.7398\n",
      "Epoch 87/200\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.4961 - acc: 0.7473 - val_loss: 0.4976 - val_acc: 0.7398\n",
      "Epoch 88/200\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.4960 - acc: 0.7483 - val_loss: 0.4978 - val_acc: 0.7422\n",
      "Epoch 89/200\n",
      "3731/3731 [==============================] - 0s 56us/step - loss: 0.4959 - acc: 0.7499 - val_loss: 0.4981 - val_acc: 0.7446\n",
      "Epoch 90/200\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.4955 - acc: 0.7502 - val_loss: 0.4990 - val_acc: 0.7349\n",
      "Epoch 91/200\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.4959 - acc: 0.7478 - val_loss: 0.4991 - val_acc: 0.7349\n",
      "Epoch 92/200\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.4962 - acc: 0.7462 - val_loss: 0.4985 - val_acc: 0.7398\n",
      "Epoch 93/200\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.4954 - acc: 0.7491 - val_loss: 0.4984 - val_acc: 0.7422\n",
      "Epoch 94/200\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.4951 - acc: 0.7481 - val_loss: 0.4983 - val_acc: 0.7373\n",
      "Epoch 95/200\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.4951 - acc: 0.7478 - val_loss: 0.4981 - val_acc: 0.7422\n",
      "Epoch 96/200\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.4948 - acc: 0.7489 - val_loss: 0.4978 - val_acc: 0.7398\n",
      "Epoch 97/200\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.4949 - acc: 0.7507 - val_loss: 0.4977 - val_acc: 0.7349\n",
      "Epoch 98/200\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.4947 - acc: 0.7502 - val_loss: 0.4991 - val_acc: 0.7373\n",
      "Epoch 99/200\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.4949 - acc: 0.7489 - val_loss: 0.4986 - val_acc: 0.7325\n",
      "Epoch 100/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.4946 - acc: 0.7513 - val_loss: 0.4987 - val_acc: 0.7349\n",
      "Epoch 101/200\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.4941 - acc: 0.7499 - val_loss: 0.4987 - val_acc: 0.7349\n",
      "Epoch 102/200\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.4952 - acc: 0.7507 - val_loss: 0.4990 - val_acc: 0.7349\n",
      "Epoch 103/200\n",
      "3360/3731 [==========================>...] - ETA: 0s - loss: 0.4973 - acc: 0.7488"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-96-15ec32c8a292>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\choice\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\choice\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\choice\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\choice\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\choice\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(8, kernel_initializer='normal', input_dim=len(X[0]), activation='relu'))\n",
    "model.add(Dense(8, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adamax',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X, y.values, epochs=200, validation_split = 0.1)\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-11T19:18:20.609679Z",
     "start_time": "2019-09-11T19:17:25.789017Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3730 samples, validate on 415 samples\n",
      "Epoch 1/200\n",
      "3730/3730 [==============================] - 2s 429us/step - loss: 0.6737 - acc: 0.6745 - val_loss: 0.6382 - val_acc: 0.6867\n",
      "Epoch 2/200\n",
      "3730/3730 [==============================] - 0s 66us/step - loss: 0.6025 - acc: 0.7043 - val_loss: 0.5708 - val_acc: 0.6916\n",
      "Epoch 3/200\n",
      "3730/3730 [==============================] - 0s 66us/step - loss: 0.5559 - acc: 0.7217 - val_loss: 0.5474 - val_acc: 0.6771\n",
      "Epoch 4/200\n",
      "3730/3730 [==============================] - 0s 66us/step - loss: 0.5397 - acc: 0.7303 - val_loss: 0.5388 - val_acc: 0.6867\n",
      "Epoch 5/200\n",
      "3730/3730 [==============================] - 0s 65us/step - loss: 0.5334 - acc: 0.7346 - val_loss: 0.5368 - val_acc: 0.6940\n",
      "Epoch 6/200\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5300 - acc: 0.7354 - val_loss: 0.5353 - val_acc: 0.6964\n",
      "Epoch 7/200\n",
      "3730/3730 [==============================] - 0s 66us/step - loss: 0.5277 - acc: 0.7340 - val_loss: 0.5313 - val_acc: 0.7036\n",
      "Epoch 8/200\n",
      "3730/3730 [==============================] - 0s 65us/step - loss: 0.5260 - acc: 0.7346 - val_loss: 0.5311 - val_acc: 0.7036\n",
      "Epoch 9/200\n",
      "3730/3730 [==============================] - 0s 65us/step - loss: 0.5247 - acc: 0.7381 - val_loss: 0.5287 - val_acc: 0.6940\n",
      "Epoch 10/200\n",
      "3730/3730 [==============================] - 0s 67us/step - loss: 0.5232 - acc: 0.7391 - val_loss: 0.5294 - val_acc: 0.6964\n",
      "Epoch 11/200\n",
      "3730/3730 [==============================] - 0s 65us/step - loss: 0.5221 - acc: 0.7394 - val_loss: 0.5264 - val_acc: 0.6940\n",
      "Epoch 12/200\n",
      "3730/3730 [==============================] - 0s 66us/step - loss: 0.5207 - acc: 0.7357 - val_loss: 0.5256 - val_acc: 0.7036\n",
      "Epoch 13/200\n",
      "3730/3730 [==============================] - 0s 65us/step - loss: 0.5203 - acc: 0.7367 - val_loss: 0.5244 - val_acc: 0.7012\n",
      "Epoch 14/200\n",
      "3730/3730 [==============================] - 0s 67us/step - loss: 0.5181 - acc: 0.7408 - val_loss: 0.5194 - val_acc: 0.7108\n",
      "Epoch 15/200\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5177 - acc: 0.7373 - val_loss: 0.5190 - val_acc: 0.7157\n",
      "Epoch 16/200\n",
      "3730/3730 [==============================] - 0s 65us/step - loss: 0.5162 - acc: 0.7351 - val_loss: 0.5225 - val_acc: 0.6988\n",
      "Epoch 17/200\n",
      "3730/3730 [==============================] - 0s 66us/step - loss: 0.5154 - acc: 0.7410 - val_loss: 0.5191 - val_acc: 0.7060\n",
      "Epoch 18/200\n",
      "3730/3730 [==============================] - 0s 66us/step - loss: 0.5150 - acc: 0.7381 - val_loss: 0.5179 - val_acc: 0.6964\n",
      "Epoch 19/200\n",
      "3730/3730 [==============================] - 0s 66us/step - loss: 0.5139 - acc: 0.7383 - val_loss: 0.5171 - val_acc: 0.7012\n",
      "Epoch 20/200\n",
      "3730/3730 [==============================] - 0s 67us/step - loss: 0.5129 - acc: 0.7367 - val_loss: 0.5172 - val_acc: 0.7012\n",
      "Epoch 21/200\n",
      "3730/3730 [==============================] - 0s 82us/step - loss: 0.5125 - acc: 0.7367 - val_loss: 0.5174 - val_acc: 0.7012\n",
      "Epoch 22/200\n",
      "3730/3730 [==============================] - 0s 85us/step - loss: 0.5122 - acc: 0.7357 - val_loss: 0.5159 - val_acc: 0.7036\n",
      "Epoch 23/200\n",
      "3730/3730 [==============================] - 0s 67us/step - loss: 0.5111 - acc: 0.7381 - val_loss: 0.5181 - val_acc: 0.6988\n",
      "Epoch 24/200\n",
      "3730/3730 [==============================] - 0s 68us/step - loss: 0.5113 - acc: 0.7389 - val_loss: 0.5165 - val_acc: 0.6988\n",
      "Epoch 25/200\n",
      "3730/3730 [==============================] - 0s 67us/step - loss: 0.5102 - acc: 0.7418 - val_loss: 0.5153 - val_acc: 0.7012\n",
      "Epoch 26/200\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.5094 - acc: 0.7381 - val_loss: 0.5170 - val_acc: 0.7012\n",
      "Epoch 27/200\n",
      "3730/3730 [==============================] - 0s 66us/step - loss: 0.5089 - acc: 0.7432 - val_loss: 0.5160 - val_acc: 0.7060\n",
      "Epoch 28/200\n",
      "3730/3730 [==============================] - 0s 65us/step - loss: 0.5080 - acc: 0.7421 - val_loss: 0.5155 - val_acc: 0.7060\n",
      "Epoch 29/200\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.5075 - acc: 0.7432 - val_loss: 0.5186 - val_acc: 0.7036\n",
      "Epoch 30/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5069 - acc: 0.7453 - val_loss: 0.5165 - val_acc: 0.7084\n",
      "Epoch 31/200\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.5068 - acc: 0.7464 - val_loss: 0.5164 - val_acc: 0.7036\n",
      "Epoch 32/200\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5063 - acc: 0.7453 - val_loss: 0.5181 - val_acc: 0.7108\n",
      "Epoch 33/200\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5059 - acc: 0.7480 - val_loss: 0.5170 - val_acc: 0.6988\n",
      "Epoch 34/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5049 - acc: 0.7456 - val_loss: 0.5189 - val_acc: 0.7012\n",
      "Epoch 35/200\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.5051 - acc: 0.7429 - val_loss: 0.5181 - val_acc: 0.7012\n",
      "Epoch 36/200\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5047 - acc: 0.7440 - val_loss: 0.5173 - val_acc: 0.7012\n",
      "Epoch 37/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5043 - acc: 0.7477 - val_loss: 0.5164 - val_acc: 0.7012\n",
      "Epoch 38/200\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5036 - acc: 0.7456 - val_loss: 0.5186 - val_acc: 0.7108\n",
      "Epoch 39/200\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5028 - acc: 0.7445 - val_loss: 0.5205 - val_acc: 0.7084\n",
      "Epoch 40/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5034 - acc: 0.7448 - val_loss: 0.5196 - val_acc: 0.7036\n",
      "Epoch 41/200\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.5027 - acc: 0.7437 - val_loss: 0.5184 - val_acc: 0.7108\n",
      "Epoch 42/200\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5026 - acc: 0.7475 - val_loss: 0.5180 - val_acc: 0.7108\n",
      "Epoch 43/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5021 - acc: 0.7472 - val_loss: 0.5155 - val_acc: 0.6964\n",
      "Epoch 44/200\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5018 - acc: 0.7437 - val_loss: 0.5153 - val_acc: 0.6988\n",
      "Epoch 45/200\n",
      "3730/3730 [==============================] - 0s 82us/step - loss: 0.5015 - acc: 0.7466 - val_loss: 0.5181 - val_acc: 0.7060\n",
      "Epoch 46/200\n",
      "3730/3730 [==============================] - 0s 66us/step - loss: 0.5010 - acc: 0.7458 - val_loss: 0.5141 - val_acc: 0.6940\n",
      "Epoch 47/200\n",
      "3730/3730 [==============================] - 0s 70us/step - loss: 0.5011 - acc: 0.7416 - val_loss: 0.5165 - val_acc: 0.7036\n",
      "Epoch 48/200\n",
      "3730/3730 [==============================] - 0s 83us/step - loss: 0.5001 - acc: 0.7464 - val_loss: 0.5164 - val_acc: 0.6964\n",
      "Epoch 49/200\n",
      "3730/3730 [==============================] - 0s 69us/step - loss: 0.5005 - acc: 0.7450 - val_loss: 0.5164 - val_acc: 0.7012\n",
      "Epoch 50/200\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.5005 - acc: 0.7453 - val_loss: 0.5159 - val_acc: 0.6916\n",
      "Epoch 51/200\n",
      "3730/3730 [==============================] - 0s 70us/step - loss: 0.4997 - acc: 0.7450 - val_loss: 0.5149 - val_acc: 0.6964\n",
      "Epoch 52/200\n",
      "3730/3730 [==============================] - 0s 68us/step - loss: 0.4996 - acc: 0.7434 - val_loss: 0.5163 - val_acc: 0.7084\n",
      "Epoch 53/200\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.4994 - acc: 0.7477 - val_loss: 0.5151 - val_acc: 0.6988\n",
      "Epoch 54/200\n",
      "3730/3730 [==============================] - 0s 69us/step - loss: 0.4989 - acc: 0.7466 - val_loss: 0.5156 - val_acc: 0.6964\n",
      "Epoch 55/200\n",
      "3730/3730 [==============================] - 0s 82us/step - loss: 0.4994 - acc: 0.7464 - val_loss: 0.5137 - val_acc: 0.6964\n",
      "Epoch 56/200\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.4985 - acc: 0.7440 - val_loss: 0.5134 - val_acc: 0.6988\n",
      "Epoch 57/200\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4993 - acc: 0.7445 - val_loss: 0.5122 - val_acc: 0.7012\n",
      "Epoch 58/200\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4980 - acc: 0.7475 - val_loss: 0.5131 - val_acc: 0.7012\n",
      "Epoch 59/200\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4980 - acc: 0.7472 - val_loss: 0.5127 - val_acc: 0.7012\n",
      "Epoch 60/200\n",
      "3730/3730 [==============================] - 0s 84us/step - loss: 0.4984 - acc: 0.7450 - val_loss: 0.5134 - val_acc: 0.6988\n",
      "Epoch 61/200\n",
      "3730/3730 [==============================] - 0s 66us/step - loss: 0.4976 - acc: 0.7477 - val_loss: 0.5126 - val_acc: 0.6988\n",
      "Epoch 62/200\n",
      "3730/3730 [==============================] - 0s 68us/step - loss: 0.4973 - acc: 0.7442 - val_loss: 0.5123 - val_acc: 0.7036\n",
      "Epoch 63/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4974 - acc: 0.7475 - val_loss: 0.5127 - val_acc: 0.7133\n",
      "Epoch 64/200\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.4970 - acc: 0.7453 - val_loss: 0.5137 - val_acc: 0.7108\n",
      "Epoch 65/200\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.4971 - acc: 0.7472 - val_loss: 0.5142 - val_acc: 0.7084\n",
      "Epoch 66/200\n",
      "3730/3730 [==============================] - 0s 66us/step - loss: 0.4980 - acc: 0.7442 - val_loss: 0.5154 - val_acc: 0.7060\n",
      "Epoch 67/200\n",
      "3730/3730 [==============================] - 0s 66us/step - loss: 0.4966 - acc: 0.7493 - val_loss: 0.5133 - val_acc: 0.7084\n",
      "Epoch 68/200\n",
      "3730/3730 [==============================] - 0s 66us/step - loss: 0.4967 - acc: 0.7499 - val_loss: 0.5145 - val_acc: 0.7084\n",
      "Epoch 69/200\n",
      "3730/3730 [==============================] - 0s 67us/step - loss: 0.4965 - acc: 0.7520 - val_loss: 0.5161 - val_acc: 0.7060\n",
      "Epoch 70/200\n",
      "3730/3730 [==============================] - 0s 102us/step - loss: 0.4958 - acc: 0.7493 - val_loss: 0.5114 - val_acc: 0.7133\n",
      "Epoch 71/200\n",
      "3730/3730 [==============================] - 0s 84us/step - loss: 0.4962 - acc: 0.7469 - val_loss: 0.5170 - val_acc: 0.7036\n",
      "Epoch 72/200\n",
      "3730/3730 [==============================] - 0s 70us/step - loss: 0.4962 - acc: 0.7475 - val_loss: 0.5163 - val_acc: 0.7108\n",
      "Epoch 73/200\n",
      "3730/3730 [==============================] - 0s 69us/step - loss: 0.4955 - acc: 0.7491 - val_loss: 0.5130 - val_acc: 0.7133\n",
      "Epoch 74/200\n",
      "3730/3730 [==============================] - 0s 69us/step - loss: 0.4956 - acc: 0.7507 - val_loss: 0.5151 - val_acc: 0.7157\n",
      "Epoch 75/200\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.4954 - acc: 0.7483 - val_loss: 0.5196 - val_acc: 0.7060\n",
      "Epoch 76/200\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4954 - acc: 0.7485 - val_loss: 0.5185 - val_acc: 0.7133\n",
      "Epoch 77/200\n",
      "3730/3730 [==============================] - 0s 69us/step - loss: 0.4951 - acc: 0.7509 - val_loss: 0.5136 - val_acc: 0.7157\n",
      "Epoch 78/200\n",
      "3730/3730 [==============================] - 0s 67us/step - loss: 0.4949 - acc: 0.7515 - val_loss: 0.5157 - val_acc: 0.7133\n",
      "Epoch 79/200\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.4946 - acc: 0.7475 - val_loss: 0.5142 - val_acc: 0.7060\n",
      "Epoch 80/200\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4944 - acc: 0.7509 - val_loss: 0.5163 - val_acc: 0.7133\n",
      "Epoch 81/200\n",
      "3730/3730 [==============================] - 0s 68us/step - loss: 0.4944 - acc: 0.7501 - val_loss: 0.5167 - val_acc: 0.7133\n",
      "Epoch 82/200\n",
      "3730/3730 [==============================] - 0s 68us/step - loss: 0.4944 - acc: 0.7504 - val_loss: 0.5156 - val_acc: 0.7133\n",
      "Epoch 83/200\n",
      "3730/3730 [==============================] - 0s 68us/step - loss: 0.4931 - acc: 0.7515 - val_loss: 0.5200 - val_acc: 0.7133\n",
      "Epoch 84/200\n",
      "3730/3730 [==============================] - 0s 67us/step - loss: 0.4944 - acc: 0.7507 - val_loss: 0.5179 - val_acc: 0.7084\n",
      "Epoch 85/200\n",
      "3730/3730 [==============================] - ETA: 0s - loss: 0.4964 - acc: 0.749 - 0s 68us/step - loss: 0.4940 - acc: 0.7493 - val_loss: 0.5164 - val_acc: 0.7133\n",
      "Epoch 86/200\n",
      "3730/3730 [==============================] - 0s 68us/step - loss: 0.4934 - acc: 0.7512 - val_loss: 0.5190 - val_acc: 0.7108\n",
      "Epoch 87/200\n",
      "3730/3730 [==============================] - 0s 67us/step - loss: 0.4935 - acc: 0.7493 - val_loss: 0.5181 - val_acc: 0.7181\n",
      "Epoch 88/200\n",
      "3730/3730 [==============================] - 0s 68us/step - loss: 0.4934 - acc: 0.7493 - val_loss: 0.5177 - val_acc: 0.7181\n",
      "Epoch 89/200\n",
      "3730/3730 [==============================] - 0s 68us/step - loss: 0.4934 - acc: 0.7509 - val_loss: 0.5159 - val_acc: 0.7181\n",
      "Epoch 90/200\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.4930 - acc: 0.7520 - val_loss: 0.5163 - val_acc: 0.7108\n",
      "Epoch 91/200\n",
      "3730/3730 [==============================] - 0s 69us/step - loss: 0.4931 - acc: 0.7496 - val_loss: 0.5163 - val_acc: 0.7181\n",
      "Epoch 92/200\n",
      "3730/3730 [==============================] - 0s 68us/step - loss: 0.4930 - acc: 0.7512 - val_loss: 0.5213 - val_acc: 0.7108\n",
      "Epoch 93/200\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.4931 - acc: 0.7504 - val_loss: 0.5173 - val_acc: 0.7181\n",
      "Epoch 94/200\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.4936 - acc: 0.7523 - val_loss: 0.5132 - val_acc: 0.7133\n",
      "Epoch 95/200\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.4921 - acc: 0.7493 - val_loss: 0.5172 - val_acc: 0.7157\n",
      "Epoch 96/200\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.4923 - acc: 0.7507 - val_loss: 0.5149 - val_acc: 0.7181\n",
      "Epoch 97/200\n",
      "3730/3730 [==============================] - 0s 68us/step - loss: 0.4927 - acc: 0.7507 - val_loss: 0.5133 - val_acc: 0.7108\n",
      "Epoch 98/200\n",
      "3730/3730 [==============================] - 0s 66us/step - loss: 0.4922 - acc: 0.7507 - val_loss: 0.5131 - val_acc: 0.7157\n",
      "Epoch 99/200\n",
      "3730/3730 [==============================] - ETA: 0s - loss: 0.4889 - acc: 0.754 - 0s 68us/step - loss: 0.4932 - acc: 0.7512 - val_loss: 0.5149 - val_acc: 0.7253\n",
      "Epoch 100/200\n",
      "3730/3730 [==============================] - 0s 66us/step - loss: 0.4925 - acc: 0.7509 - val_loss: 0.5135 - val_acc: 0.7181\n",
      "Epoch 101/200\n",
      "3730/3730 [==============================] - 0s 66us/step - loss: 0.4930 - acc: 0.7499 - val_loss: 0.5143 - val_acc: 0.7205\n",
      "Epoch 102/200\n",
      "3730/3730 [==============================] - 0s 67us/step - loss: 0.4920 - acc: 0.7509 - val_loss: 0.5155 - val_acc: 0.7253\n",
      "Epoch 103/200\n",
      "3730/3730 [==============================] - 0s 68us/step - loss: 0.4920 - acc: 0.7523 - val_loss: 0.5154 - val_acc: 0.7253\n",
      "Epoch 104/200\n",
      "3730/3730 [==============================] - 0s 66us/step - loss: 0.4919 - acc: 0.7517 - val_loss: 0.5150 - val_acc: 0.7084\n",
      "Epoch 105/200\n",
      "3730/3730 [==============================] - ETA: 0s - loss: 0.4926 - acc: 0.7503- ETA: 0s - loss: 0.4964 - acc: 0.74 - 0s 68us/step - loss: 0.4920 - acc: 0.7499 - val_loss: 0.5151 - val_acc: 0.7157\n",
      "Epoch 106/200\n",
      "3730/3730 [==============================] - 0s 66us/step - loss: 0.4916 - acc: 0.7496 - val_loss: 0.5156 - val_acc: 0.7181\n",
      "Epoch 107/200\n",
      "3730/3730 [==============================] - 0s 67us/step - loss: 0.4917 - acc: 0.7491 - val_loss: 0.5152 - val_acc: 0.7108\n",
      "Epoch 108/200\n",
      "3730/3730 [==============================] - 0s 69us/step - loss: 0.4914 - acc: 0.7515 - val_loss: 0.5191 - val_acc: 0.7205\n",
      "Epoch 109/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4918 - acc: 0.7501 - val_loss: 0.5186 - val_acc: 0.7133\n",
      "Epoch 110/200\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4918 - acc: 0.7507 - val_loss: 0.5160 - val_acc: 0.7181\n",
      "Epoch 111/200\n",
      "3730/3730 [==============================] - 0s 89us/step - loss: 0.4912 - acc: 0.7504 - val_loss: 0.5162 - val_acc: 0.7133\n",
      "Epoch 112/200\n",
      "3730/3730 [==============================] - 0s 90us/step - loss: 0.4909 - acc: 0.7520 - val_loss: 0.5146 - val_acc: 0.7133\n",
      "Epoch 113/200\n",
      "3730/3730 [==============================] - 0s 82us/step - loss: 0.4914 - acc: 0.7512 - val_loss: 0.5165 - val_acc: 0.7133\n",
      "Epoch 114/200\n",
      "3730/3730 [==============================] - 0s 68us/step - loss: 0.4909 - acc: 0.7509 - val_loss: 0.5182 - val_acc: 0.7157\n",
      "Epoch 115/200\n",
      "3730/3730 [==============================] - 0s 65us/step - loss: 0.4916 - acc: 0.7509 - val_loss: 0.5185 - val_acc: 0.7133\n",
      "Epoch 116/200\n",
      "3730/3730 [==============================] - 0s 64us/step - loss: 0.4905 - acc: 0.7536 - val_loss: 0.5145 - val_acc: 0.7084\n",
      "Epoch 117/200\n",
      "3730/3730 [==============================] - 0s 66us/step - loss: 0.4910 - acc: 0.7512 - val_loss: 0.5157 - val_acc: 0.7133\n",
      "Epoch 118/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3730/3730 [==============================] - 0s 68us/step - loss: 0.4907 - acc: 0.7504 - val_loss: 0.5178 - val_acc: 0.7133\n",
      "Epoch 119/200\n",
      "3730/3730 [==============================] - 0s 65us/step - loss: 0.4909 - acc: 0.7525 - val_loss: 0.5181 - val_acc: 0.7012\n",
      "Epoch 120/200\n",
      "3730/3730 [==============================] - 0s 63us/step - loss: 0.4907 - acc: 0.7493 - val_loss: 0.5164 - val_acc: 0.7060\n",
      "Epoch 121/200\n",
      "3730/3730 [==============================] - 0s 67us/step - loss: 0.4903 - acc: 0.7517 - val_loss: 0.5200 - val_acc: 0.7108\n",
      "Epoch 122/200\n",
      "3730/3730 [==============================] - 0s 65us/step - loss: 0.4908 - acc: 0.7528 - val_loss: 0.5160 - val_acc: 0.7036\n",
      "Epoch 123/200\n",
      "3730/3730 [==============================] - 0s 65us/step - loss: 0.4904 - acc: 0.7520 - val_loss: 0.5175 - val_acc: 0.7108\n",
      "Epoch 124/200\n",
      "3730/3730 [==============================] - 0s 64us/step - loss: 0.4903 - acc: 0.7534 - val_loss: 0.5223 - val_acc: 0.7108\n",
      "Epoch 125/200\n",
      "3730/3730 [==============================] - 0s 65us/step - loss: 0.4906 - acc: 0.7544 - val_loss: 0.5152 - val_acc: 0.7108\n",
      "Epoch 126/200\n",
      "3730/3730 [==============================] - 0s 65us/step - loss: 0.4903 - acc: 0.7558 - val_loss: 0.5171 - val_acc: 0.7133\n",
      "Epoch 127/200\n",
      "3730/3730 [==============================] - 0s 64us/step - loss: 0.4902 - acc: 0.7517 - val_loss: 0.5192 - val_acc: 0.7133\n",
      "Epoch 128/200\n",
      "3730/3730 [==============================] - 0s 65us/step - loss: 0.4902 - acc: 0.7520 - val_loss: 0.5172 - val_acc: 0.7084\n",
      "Epoch 129/200\n",
      "3730/3730 [==============================] - 0s 64us/step - loss: 0.4903 - acc: 0.7507 - val_loss: 0.5157 - val_acc: 0.7181\n",
      "Epoch 130/200\n",
      "3730/3730 [==============================] - 0s 66us/step - loss: 0.4899 - acc: 0.7539 - val_loss: 0.5170 - val_acc: 0.7133\n",
      "Epoch 131/200\n",
      "3730/3730 [==============================] - 0s 64us/step - loss: 0.4898 - acc: 0.7525 - val_loss: 0.5182 - val_acc: 0.7133\n",
      "Epoch 132/200\n",
      "3730/3730 [==============================] - 0s 65us/step - loss: 0.4910 - acc: 0.7520 - val_loss: 0.5178 - val_acc: 0.7108\n",
      "Epoch 133/200\n",
      "3730/3730 [==============================] - 0s 64us/step - loss: 0.4895 - acc: 0.7544 - val_loss: 0.5160 - val_acc: 0.7157\n",
      "Epoch 134/200\n",
      "3730/3730 [==============================] - 0s 65us/step - loss: 0.4903 - acc: 0.7525 - val_loss: 0.5210 - val_acc: 0.7133\n",
      "Epoch 135/200\n",
      "3730/3730 [==============================] - 0s 64us/step - loss: 0.4892 - acc: 0.7528 - val_loss: 0.5174 - val_acc: 0.7108\n",
      "Epoch 136/200\n",
      "3730/3730 [==============================] - 0s 65us/step - loss: 0.4897 - acc: 0.7558 - val_loss: 0.5164 - val_acc: 0.7157\n",
      "Epoch 137/200\n",
      "3730/3730 [==============================] - 0s 64us/step - loss: 0.4887 - acc: 0.7531 - val_loss: 0.5154 - val_acc: 0.7108\n",
      "Epoch 138/200\n",
      "3730/3730 [==============================] - 0s 66us/step - loss: 0.4898 - acc: 0.7531 - val_loss: 0.5160 - val_acc: 0.7181\n",
      "Epoch 139/200\n",
      "3730/3730 [==============================] - 0s 67us/step - loss: 0.4885 - acc: 0.7566 - val_loss: 0.5173 - val_acc: 0.7133\n",
      "Epoch 140/200\n",
      "3730/3730 [==============================] - 0s 65us/step - loss: 0.4892 - acc: 0.7555 - val_loss: 0.5191 - val_acc: 0.7157\n",
      "Epoch 141/200\n",
      "3730/3730 [==============================] - 0s 66us/step - loss: 0.4900 - acc: 0.7560 - val_loss: 0.5166 - val_acc: 0.7108\n",
      "Epoch 142/200\n",
      "3730/3730 [==============================] - 0s 65us/step - loss: 0.4890 - acc: 0.7568 - val_loss: 0.5172 - val_acc: 0.7157\n",
      "Epoch 143/200\n",
      "3730/3730 [==============================] - 0s 65us/step - loss: 0.4891 - acc: 0.7523 - val_loss: 0.5161 - val_acc: 0.7157\n",
      "Epoch 144/200\n",
      "3730/3730 [==============================] - 0s 65us/step - loss: 0.4892 - acc: 0.7536 - val_loss: 0.5156 - val_acc: 0.7157\n",
      "Epoch 145/200\n",
      "3730/3730 [==============================] - 0s 66us/step - loss: 0.4893 - acc: 0.7555 - val_loss: 0.5163 - val_acc: 0.7157\n",
      "Epoch 146/200\n",
      "3730/3730 [==============================] - 0s 67us/step - loss: 0.4894 - acc: 0.7552 - val_loss: 0.5172 - val_acc: 0.7157\n",
      "Epoch 147/200\n",
      "3730/3730 [==============================] - 0s 66us/step - loss: 0.4884 - acc: 0.7547 - val_loss: 0.5126 - val_acc: 0.7084\n",
      "Epoch 148/200\n",
      "3730/3730 [==============================] - 0s 63us/step - loss: 0.4893 - acc: 0.7542 - val_loss: 0.5127 - val_acc: 0.7181\n",
      "Epoch 149/200\n",
      "3730/3730 [==============================] - 0s 66us/step - loss: 0.4885 - acc: 0.7531 - val_loss: 0.5121 - val_acc: 0.7157\n",
      "Epoch 150/200\n",
      "3730/3730 [==============================] - 0s 66us/step - loss: 0.4890 - acc: 0.7558 - val_loss: 0.5144 - val_acc: 0.7108\n",
      "Epoch 151/200\n",
      "3730/3730 [==============================] - 0s 64us/step - loss: 0.4885 - acc: 0.7558 - val_loss: 0.5144 - val_acc: 0.7157\n",
      "Epoch 152/200\n",
      "3730/3730 [==============================] - 0s 64us/step - loss: 0.4887 - acc: 0.7555 - val_loss: 0.5143 - val_acc: 0.7157\n",
      "Epoch 153/200\n",
      "3730/3730 [==============================] - 0s 65us/step - loss: 0.4894 - acc: 0.7507 - val_loss: 0.5161 - val_acc: 0.7133\n",
      "Epoch 154/200\n",
      "3730/3730 [==============================] - 0s 65us/step - loss: 0.4878 - acc: 0.7566 - val_loss: 0.5165 - val_acc: 0.7133\n",
      "Epoch 155/200\n",
      "3730/3730 [==============================] - 0s 64us/step - loss: 0.4888 - acc: 0.7531 - val_loss: 0.5147 - val_acc: 0.7133\n",
      "Epoch 156/200\n",
      "3730/3730 [==============================] - 0s 65us/step - loss: 0.4883 - acc: 0.7579 - val_loss: 0.5155 - val_acc: 0.7133\n",
      "Epoch 157/200\n",
      "3730/3730 [==============================] - 0s 65us/step - loss: 0.4889 - acc: 0.7536 - val_loss: 0.5165 - val_acc: 0.7108\n",
      "Epoch 158/200\n",
      "3730/3730 [==============================] - 0s 65us/step - loss: 0.4886 - acc: 0.7525 - val_loss: 0.5174 - val_acc: 0.7084\n",
      "Epoch 159/200\n",
      "3730/3730 [==============================] - 0s 65us/step - loss: 0.4883 - acc: 0.7507 - val_loss: 0.5142 - val_acc: 0.7108\n",
      "Epoch 160/200\n",
      "3730/3730 [==============================] - 0s 64us/step - loss: 0.4877 - acc: 0.7544 - val_loss: 0.5137 - val_acc: 0.7157\n",
      "Epoch 161/200\n",
      "3730/3730 [==============================] - 0s 65us/step - loss: 0.4888 - acc: 0.7512 - val_loss: 0.5219 - val_acc: 0.7157\n",
      "Epoch 162/200\n",
      "3730/3730 [==============================] - 0s 66us/step - loss: 0.4882 - acc: 0.7544 - val_loss: 0.5162 - val_acc: 0.7108\n",
      "Epoch 163/200\n",
      "3730/3730 [==============================] - 0s 67us/step - loss: 0.4882 - acc: 0.7550 - val_loss: 0.5152 - val_acc: 0.7133\n",
      "Epoch 164/200\n",
      "3730/3730 [==============================] - 0s 66us/step - loss: 0.4885 - acc: 0.7536 - val_loss: 0.5146 - val_acc: 0.7157\n",
      "Epoch 165/200\n",
      "3730/3730 [==============================] - 0s 66us/step - loss: 0.4880 - acc: 0.7539 - val_loss: 0.5178 - val_acc: 0.7157\n",
      "Epoch 166/200\n",
      "3730/3730 [==============================] - 0s 66us/step - loss: 0.4882 - acc: 0.7544 - val_loss: 0.5181 - val_acc: 0.7108\n",
      "Epoch 167/200\n",
      "3730/3730 [==============================] - 0s 66us/step - loss: 0.4884 - acc: 0.7536 - val_loss: 0.5157 - val_acc: 0.7181\n",
      "Epoch 168/200\n",
      "3730/3730 [==============================] - 0s 70us/step - loss: 0.4876 - acc: 0.7536 - val_loss: 0.5158 - val_acc: 0.7133\n",
      "Epoch 169/200\n",
      "3730/3730 [==============================] - 0s 68us/step - loss: 0.4878 - acc: 0.7544 - val_loss: 0.5138 - val_acc: 0.7133\n",
      "Epoch 170/200\n",
      "3730/3730 [==============================] - 0s 66us/step - loss: 0.4877 - acc: 0.7539 - val_loss: 0.5144 - val_acc: 0.7205\n",
      "Epoch 171/200\n",
      "3730/3730 [==============================] - 0s 68us/step - loss: 0.4873 - acc: 0.7528 - val_loss: 0.5171 - val_acc: 0.7157\n",
      "Epoch 172/200\n",
      "3730/3730 [==============================] - 0s 65us/step - loss: 0.4884 - acc: 0.7558 - val_loss: 0.5163 - val_acc: 0.7181\n",
      "Epoch 173/200\n",
      "3730/3730 [==============================] - 0s 66us/step - loss: 0.4878 - acc: 0.7542 - val_loss: 0.5162 - val_acc: 0.7181\n",
      "Epoch 174/200\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4874 - acc: 0.7531 - val_loss: 0.5170 - val_acc: 0.7181\n",
      "Epoch 175/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4879 - acc: 0.7509 - val_loss: 0.5143 - val_acc: 0.7157\n",
      "Epoch 176/200\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4874 - acc: 0.7576 - val_loss: 0.5163 - val_acc: 0.7157\n",
      "Epoch 177/200\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4878 - acc: 0.7555 - val_loss: 0.5192 - val_acc: 0.7181\n",
      "Epoch 178/200\n",
      "3730/3730 [==============================] - 0s 67us/step - loss: 0.4874 - acc: 0.7528 - val_loss: 0.5179 - val_acc: 0.7205\n",
      "Epoch 179/200\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.4873 - acc: 0.7509 - val_loss: 0.5164 - val_acc: 0.7277\n",
      "Epoch 180/200\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.4867 - acc: 0.7568 - val_loss: 0.5153 - val_acc: 0.7205\n",
      "Epoch 181/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4872 - acc: 0.7566 - val_loss: 0.5151 - val_acc: 0.7181\n",
      "Epoch 182/200\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.4874 - acc: 0.7566 - val_loss: 0.5196 - val_acc: 0.7133\n",
      "Epoch 183/200\n",
      "3730/3730 [==============================] - 0s 67us/step - loss: 0.4863 - acc: 0.7552 - val_loss: 0.5155 - val_acc: 0.7253\n",
      "Epoch 184/200\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4873 - acc: 0.7550 - val_loss: 0.5168 - val_acc: 0.7205\n",
      "Epoch 185/200\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.4868 - acc: 0.7558 - val_loss: 0.5142 - val_acc: 0.7253\n",
      "Epoch 186/200\n",
      "3730/3730 [==============================] - 0s 65us/step - loss: 0.4871 - acc: 0.7542 - val_loss: 0.5182 - val_acc: 0.7205\n",
      "Epoch 187/200\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4870 - acc: 0.7571 - val_loss: 0.5172 - val_acc: 0.7205\n",
      "Epoch 188/200\n",
      "3730/3730 [==============================] - 0s 65us/step - loss: 0.4872 - acc: 0.7501 - val_loss: 0.5186 - val_acc: 0.7205\n",
      "Epoch 189/200\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4872 - acc: 0.7547 - val_loss: 0.5185 - val_acc: 0.7205\n",
      "Epoch 190/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4864 - acc: 0.7566 - val_loss: 0.5229 - val_acc: 0.7205\n",
      "Epoch 191/200\n",
      "3730/3730 [==============================] - 0s 68us/step - loss: 0.4871 - acc: 0.7563 - val_loss: 0.5204 - val_acc: 0.7181\n",
      "Epoch 192/200\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4869 - acc: 0.7587 - val_loss: 0.5213 - val_acc: 0.7181\n",
      "Epoch 193/200\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4868 - acc: 0.7563 - val_loss: 0.5230 - val_acc: 0.7229\n",
      "Epoch 194/200\n",
      "3730/3730 [==============================] - ETA: 0s - loss: 0.4847 - acc: 0.756 - 0s 68us/step - loss: 0.4872 - acc: 0.7555 - val_loss: 0.5222 - val_acc: 0.7181\n",
      "Epoch 195/200\n",
      "3730/3730 [==============================] - 0s 65us/step - loss: 0.4867 - acc: 0.7547 - val_loss: 0.5221 - val_acc: 0.7205\n",
      "Epoch 196/200\n",
      "3730/3730 [==============================] - 0s 67us/step - loss: 0.4867 - acc: 0.7552 - val_loss: 0.5226 - val_acc: 0.7205\n",
      "Epoch 197/200\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.4863 - acc: 0.7584 - val_loss: 0.5228 - val_acc: 0.7157\n",
      "Epoch 198/200\n",
      "3730/3730 [==============================] - 0s 67us/step - loss: 0.4864 - acc: 0.7568 - val_loss: 0.5237 - val_acc: 0.7181\n",
      "Epoch 199/200\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.4864 - acc: 0.7547 - val_loss: 0.5232 - val_acc: 0.7205\n",
      "Epoch 200/200\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.4866 - acc: 0.7584 - val_loss: 0.5237 - val_acc: 0.7205\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, kernel_initializer='normal', input_dim=len(X[0]), activation='relu'))\n",
    "model.add(Dense(10, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adamax',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X, y.values, epochs=200, validation_split = 0.1)\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-11T19:48:04.674391Z",
     "start_time": "2019-09-11T19:45:10.162080Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3730 samples, validate on 415 samples\n",
      "Epoch 1/600\n",
      "3730/3730 [==============================] - 2s 577us/step - loss: 0.6717 - acc: 0.6542 - val_loss: 0.6410 - val_acc: 0.6699\n",
      "Epoch 2/600\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.5855 - acc: 0.7094 - val_loss: 0.5615 - val_acc: 0.6699\n",
      "Epoch 3/600\n",
      "3730/3730 [==============================] - 0s 88us/step - loss: 0.5414 - acc: 0.7263 - val_loss: 0.5440 - val_acc: 0.6819\n",
      "Epoch 4/600\n",
      "3730/3730 [==============================] - 0s 84us/step - loss: 0.5322 - acc: 0.7295 - val_loss: 0.5352 - val_acc: 0.6892\n",
      "Epoch 5/600\n",
      "3730/3730 [==============================] - 0s 93us/step - loss: 0.5280 - acc: 0.7335 - val_loss: 0.5275 - val_acc: 0.6892\n",
      "Epoch 6/600\n",
      "3730/3730 [==============================] - 0s 88us/step - loss: 0.5253 - acc: 0.7335 - val_loss: 0.5239 - val_acc: 0.7036\n",
      "Epoch 7/600\n",
      "3730/3730 [==============================] - 0s 92us/step - loss: 0.5233 - acc: 0.7373 - val_loss: 0.5228 - val_acc: 0.7012\n",
      "Epoch 8/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5215 - acc: 0.7370 - val_loss: 0.5193 - val_acc: 0.7108\n",
      "Epoch 9/600\n",
      "3730/3730 [==============================] - 0s 98us/step - loss: 0.5203 - acc: 0.7381 - val_loss: 0.5211 - val_acc: 0.7181\n",
      "Epoch 10/600\n",
      "3730/3730 [==============================] - 0s 85us/step - loss: 0.5190 - acc: 0.7383 - val_loss: 0.5184 - val_acc: 0.7205\n",
      "Epoch 11/600\n",
      "3730/3730 [==============================] - 0s 87us/step - loss: 0.5172 - acc: 0.7381 - val_loss: 0.5188 - val_acc: 0.7133\n",
      "Epoch 12/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5162 - acc: 0.7365 - val_loss: 0.5171 - val_acc: 0.7181\n",
      "Epoch 13/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5154 - acc: 0.7370 - val_loss: 0.5160 - val_acc: 0.7205\n",
      "Epoch 14/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5142 - acc: 0.7343 - val_loss: 0.5162 - val_acc: 0.7229\n",
      "Epoch 15/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5137 - acc: 0.7386 - val_loss: 0.5156 - val_acc: 0.7205\n",
      "Epoch 16/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5131 - acc: 0.7410 - val_loss: 0.5153 - val_acc: 0.7205\n",
      "Epoch 17/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5121 - acc: 0.7383 - val_loss: 0.5155 - val_acc: 0.7205\n",
      "Epoch 18/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5115 - acc: 0.7381 - val_loss: 0.5140 - val_acc: 0.7181\n",
      "Epoch 19/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5110 - acc: 0.7391 - val_loss: 0.5149 - val_acc: 0.7205\n",
      "Epoch 20/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5106 - acc: 0.7397 - val_loss: 0.5134 - val_acc: 0.7205\n",
      "Epoch 21/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5105 - acc: 0.7402 - val_loss: 0.5132 - val_acc: 0.7253\n",
      "Epoch 22/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5096 - acc: 0.7426 - val_loss: 0.5135 - val_acc: 0.7253\n",
      "Epoch 23/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5090 - acc: 0.7410 - val_loss: 0.5129 - val_acc: 0.7277\n",
      "Epoch 24/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5090 - acc: 0.7402 - val_loss: 0.5135 - val_acc: 0.7301\n",
      "Epoch 25/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5083 - acc: 0.7389 - val_loss: 0.5140 - val_acc: 0.7277\n",
      "Epoch 26/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5082 - acc: 0.7405 - val_loss: 0.5132 - val_acc: 0.7229\n",
      "Epoch 27/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5082 - acc: 0.7413 - val_loss: 0.5139 - val_acc: 0.7325\n",
      "Epoch 28/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5072 - acc: 0.7421 - val_loss: 0.5135 - val_acc: 0.7301\n",
      "Epoch 29/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5070 - acc: 0.7386 - val_loss: 0.5143 - val_acc: 0.7301\n",
      "Epoch 30/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5069 - acc: 0.7386 - val_loss: 0.5139 - val_acc: 0.7349\n",
      "Epoch 31/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5061 - acc: 0.7437 - val_loss: 0.5126 - val_acc: 0.7229\n",
      "Epoch 32/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5061 - acc: 0.7424 - val_loss: 0.5152 - val_acc: 0.7349\n",
      "Epoch 33/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5056 - acc: 0.7418 - val_loss: 0.5136 - val_acc: 0.7349\n",
      "Epoch 34/600\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.5055 - acc: 0.7424 - val_loss: 0.5138 - val_acc: 0.7277\n",
      "Epoch 35/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5049 - acc: 0.7418 - val_loss: 0.5162 - val_acc: 0.7205\n",
      "Epoch 36/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5053 - acc: 0.7416 - val_loss: 0.5167 - val_acc: 0.7205\n",
      "Epoch 37/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5045 - acc: 0.7437 - val_loss: 0.5161 - val_acc: 0.7205\n",
      "Epoch 38/600\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.5042 - acc: 0.7424 - val_loss: 0.5136 - val_acc: 0.7229\n",
      "Epoch 39/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5041 - acc: 0.7429 - val_loss: 0.5158 - val_acc: 0.7229\n",
      "Epoch 40/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5035 - acc: 0.7453 - val_loss: 0.5153 - val_acc: 0.7229\n",
      "Epoch 41/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5034 - acc: 0.7434 - val_loss: 0.5139 - val_acc: 0.7181\n",
      "Epoch 42/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5031 - acc: 0.7432 - val_loss: 0.5148 - val_acc: 0.7205\n",
      "Epoch 43/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5031 - acc: 0.7424 - val_loss: 0.5162 - val_acc: 0.7181\n",
      "Epoch 44/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5023 - acc: 0.7440 - val_loss: 0.5143 - val_acc: 0.7181\n",
      "Epoch 45/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5021 - acc: 0.7437 - val_loss: 0.5154 - val_acc: 0.7133\n",
      "Epoch 46/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5016 - acc: 0.7426 - val_loss: 0.5141 - val_acc: 0.7229\n",
      "Epoch 47/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5017 - acc: 0.7437 - val_loss: 0.5156 - val_acc: 0.7157\n",
      "Epoch 48/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5021 - acc: 0.7408 - val_loss: 0.5154 - val_acc: 0.7205\n",
      "Epoch 49/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5010 - acc: 0.7466 - val_loss: 0.5135 - val_acc: 0.7229\n",
      "Epoch 50/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5009 - acc: 0.7410 - val_loss: 0.5144 - val_acc: 0.7133\n",
      "Epoch 51/600\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.5006 - acc: 0.7440 - val_loss: 0.5136 - val_acc: 0.7157\n",
      "Epoch 52/600\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.5003 - acc: 0.7437 - val_loss: 0.5119 - val_acc: 0.7277\n",
      "Epoch 53/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.4999 - acc: 0.7429 - val_loss: 0.5104 - val_acc: 0.7277\n",
      "Epoch 54/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.4992 - acc: 0.7440 - val_loss: 0.5121 - val_acc: 0.7157\n",
      "Epoch 55/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4983 - acc: 0.7434 - val_loss: 0.5102 - val_acc: 0.7277\n",
      "Epoch 56/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4995 - acc: 0.7426 - val_loss: 0.5131 - val_acc: 0.7253\n",
      "Epoch 57/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.4988 - acc: 0.7429 - val_loss: 0.5128 - val_acc: 0.7229\n",
      "Epoch 58/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.4984 - acc: 0.7432 - val_loss: 0.5126 - val_acc: 0.7157\n",
      "Epoch 59/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.4981 - acc: 0.7472 - val_loss: 0.5095 - val_acc: 0.7325\n",
      "Epoch 60/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4982 - acc: 0.7434 - val_loss: 0.5098 - val_acc: 0.7253\n",
      "Epoch 61/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4978 - acc: 0.7453 - val_loss: 0.5107 - val_acc: 0.7205\n",
      "Epoch 62/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4975 - acc: 0.7450 - val_loss: 0.5111 - val_acc: 0.7253\n",
      "Epoch 63/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4966 - acc: 0.7472 - val_loss: 0.5101 - val_acc: 0.7205\n",
      "Epoch 64/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4970 - acc: 0.7442 - val_loss: 0.5098 - val_acc: 0.7229\n",
      "Epoch 65/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4969 - acc: 0.7442 - val_loss: 0.5107 - val_acc: 0.7229\n",
      "Epoch 66/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4967 - acc: 0.7466 - val_loss: 0.5096 - val_acc: 0.7205\n",
      "Epoch 67/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4965 - acc: 0.7480 - val_loss: 0.5076 - val_acc: 0.7301\n",
      "Epoch 68/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4965 - acc: 0.7450 - val_loss: 0.5084 - val_acc: 0.7229\n",
      "Epoch 69/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.4969 - acc: 0.7448 - val_loss: 0.5103 - val_acc: 0.7205\n",
      "Epoch 70/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.4961 - acc: 0.7429 - val_loss: 0.5095 - val_acc: 0.7229\n",
      "Epoch 71/600\n",
      "3730/3730 [==============================] - 0s 70us/step - loss: 0.4960 - acc: 0.7458 - val_loss: 0.5071 - val_acc: 0.7253\n",
      "Epoch 72/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4959 - acc: 0.7450 - val_loss: 0.5086 - val_acc: 0.7205\n",
      "Epoch 73/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.4962 - acc: 0.7442 - val_loss: 0.5087 - val_acc: 0.7277\n",
      "Epoch 74/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4953 - acc: 0.7453 - val_loss: 0.5096 - val_acc: 0.7229\n",
      "Epoch 75/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4955 - acc: 0.7466 - val_loss: 0.5096 - val_acc: 0.7253\n",
      "Epoch 76/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4953 - acc: 0.7480 - val_loss: 0.5098 - val_acc: 0.7229\n",
      "Epoch 77/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.4944 - acc: 0.7483 - val_loss: 0.5105 - val_acc: 0.7229\n",
      "Epoch 78/600\n",
      "3730/3730 [==============================] - 0s 70us/step - loss: 0.4948 - acc: 0.7434 - val_loss: 0.5071 - val_acc: 0.7325\n",
      "Epoch 79/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4947 - acc: 0.7466 - val_loss: 0.5085 - val_acc: 0.7253\n",
      "Epoch 80/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4947 - acc: 0.7442 - val_loss: 0.5070 - val_acc: 0.7277\n",
      "Epoch 81/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4949 - acc: 0.7432 - val_loss: 0.5078 - val_acc: 0.7253\n",
      "Epoch 82/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4947 - acc: 0.7458 - val_loss: 0.5077 - val_acc: 0.7253\n",
      "Epoch 83/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4940 - acc: 0.7469 - val_loss: 0.5078 - val_acc: 0.7253\n",
      "Epoch 84/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4962 - acc: 0.7453 - val_loss: 0.5075 - val_acc: 0.7229\n",
      "Epoch 85/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4947 - acc: 0.7437 - val_loss: 0.5078 - val_acc: 0.7277\n",
      "Epoch 86/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4942 - acc: 0.7480 - val_loss: 0.5112 - val_acc: 0.7229\n",
      "Epoch 87/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4938 - acc: 0.7466 - val_loss: 0.5084 - val_acc: 0.7277\n",
      "Epoch 88/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4942 - acc: 0.7477 - val_loss: 0.5095 - val_acc: 0.7277\n",
      "Epoch 89/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4936 - acc: 0.7424 - val_loss: 0.5078 - val_acc: 0.7253\n",
      "Epoch 90/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4936 - acc: 0.7466 - val_loss: 0.5063 - val_acc: 0.7253\n",
      "Epoch 91/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4936 - acc: 0.7445 - val_loss: 0.5074 - val_acc: 0.7253\n",
      "Epoch 92/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4934 - acc: 0.7461 - val_loss: 0.5085 - val_acc: 0.7253\n",
      "Epoch 93/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4945 - acc: 0.7466 - val_loss: 0.5068 - val_acc: 0.7277\n",
      "Epoch 94/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4930 - acc: 0.7434 - val_loss: 0.5102 - val_acc: 0.7229\n",
      "Epoch 95/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4936 - acc: 0.7480 - val_loss: 0.5073 - val_acc: 0.7253\n",
      "Epoch 96/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4933 - acc: 0.7424 - val_loss: 0.5037 - val_acc: 0.7349\n",
      "Epoch 97/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4929 - acc: 0.7450 - val_loss: 0.5070 - val_acc: 0.7229\n",
      "Epoch 98/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4930 - acc: 0.7442 - val_loss: 0.5058 - val_acc: 0.7277\n",
      "Epoch 99/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4920 - acc: 0.7442 - val_loss: 0.5078 - val_acc: 0.7181\n",
      "Epoch 100/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4924 - acc: 0.7466 - val_loss: 0.5089 - val_acc: 0.7157\n",
      "Epoch 101/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4932 - acc: 0.7475 - val_loss: 0.5062 - val_acc: 0.7277\n",
      "Epoch 102/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4922 - acc: 0.7488 - val_loss: 0.5064 - val_acc: 0.7229\n",
      "Epoch 103/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4920 - acc: 0.7461 - val_loss: 0.5050 - val_acc: 0.7253\n",
      "Epoch 104/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4922 - acc: 0.7461 - val_loss: 0.5061 - val_acc: 0.7253\n",
      "Epoch 105/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4915 - acc: 0.7483 - val_loss: 0.5047 - val_acc: 0.7277\n",
      "Epoch 106/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4918 - acc: 0.7469 - val_loss: 0.5075 - val_acc: 0.7277\n",
      "Epoch 107/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.4921 - acc: 0.7448 - val_loss: 0.5059 - val_acc: 0.7301\n",
      "Epoch 108/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.4917 - acc: 0.7461 - val_loss: 0.5060 - val_acc: 0.7301\n",
      "Epoch 109/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.4914 - acc: 0.7499 - val_loss: 0.5045 - val_acc: 0.7301\n",
      "Epoch 110/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4910 - acc: 0.7432 - val_loss: 0.5080 - val_acc: 0.7229\n",
      "Epoch 111/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4911 - acc: 0.7480 - val_loss: 0.5072 - val_acc: 0.7301\n",
      "Epoch 112/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4911 - acc: 0.7472 - val_loss: 0.5050 - val_acc: 0.7301\n",
      "Epoch 113/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4916 - acc: 0.7453 - val_loss: 0.5060 - val_acc: 0.7301\n",
      "Epoch 114/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4912 - acc: 0.7426 - val_loss: 0.5072 - val_acc: 0.7301\n",
      "Epoch 115/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4918 - acc: 0.7466 - val_loss: 0.5083 - val_acc: 0.7301\n",
      "Epoch 116/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4909 - acc: 0.7485 - val_loss: 0.5081 - val_acc: 0.7253\n",
      "Epoch 117/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4906 - acc: 0.7456 - val_loss: 0.5041 - val_acc: 0.7349\n",
      "Epoch 118/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4905 - acc: 0.7491 - val_loss: 0.5049 - val_acc: 0.7373\n",
      "Epoch 119/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4906 - acc: 0.7523 - val_loss: 0.5086 - val_acc: 0.7277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4906 - acc: 0.7456 - val_loss: 0.5069 - val_acc: 0.7277\n",
      "Epoch 121/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4903 - acc: 0.7466 - val_loss: 0.5069 - val_acc: 0.7349\n",
      "Epoch 122/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4906 - acc: 0.7475 - val_loss: 0.5079 - val_acc: 0.7301\n",
      "Epoch 123/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4901 - acc: 0.7488 - val_loss: 0.5077 - val_acc: 0.7229\n",
      "Epoch 124/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4901 - acc: 0.7475 - val_loss: 0.5089 - val_acc: 0.7301\n",
      "Epoch 125/600\n",
      "3730/3730 [==============================] - 0s 70us/step - loss: 0.4912 - acc: 0.7456 - val_loss: 0.5118 - val_acc: 0.7133\n",
      "Epoch 126/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4902 - acc: 0.7469 - val_loss: 0.5096 - val_acc: 0.7229\n",
      "Epoch 127/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.4905 - acc: 0.7466 - val_loss: 0.5059 - val_acc: 0.7373\n",
      "Epoch 128/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4913 - acc: 0.7499 - val_loss: 0.5073 - val_acc: 0.7325\n",
      "Epoch 129/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.4900 - acc: 0.7480 - val_loss: 0.5065 - val_acc: 0.7373\n",
      "Epoch 130/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.4899 - acc: 0.7466 - val_loss: 0.5096 - val_acc: 0.7205\n",
      "Epoch 131/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4894 - acc: 0.7488 - val_loss: 0.5063 - val_acc: 0.7301\n",
      "Epoch 132/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4900 - acc: 0.7501 - val_loss: 0.5077 - val_acc: 0.7253\n",
      "Epoch 133/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4903 - acc: 0.7477 - val_loss: 0.5060 - val_acc: 0.7325\n",
      "Epoch 134/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4899 - acc: 0.7509 - val_loss: 0.5105 - val_acc: 0.7229\n",
      "Epoch 135/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4896 - acc: 0.7485 - val_loss: 0.5091 - val_acc: 0.7277\n",
      "Epoch 136/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4894 - acc: 0.7480 - val_loss: 0.5076 - val_acc: 0.7277\n",
      "Epoch 137/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4901 - acc: 0.7496 - val_loss: 0.5107 - val_acc: 0.7253\n",
      "Epoch 138/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4900 - acc: 0.7440 - val_loss: 0.5089 - val_acc: 0.7277\n",
      "Epoch 139/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4895 - acc: 0.7491 - val_loss: 0.5094 - val_acc: 0.7253\n",
      "Epoch 140/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4890 - acc: 0.7512 - val_loss: 0.5089 - val_acc: 0.7253\n",
      "Epoch 141/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4894 - acc: 0.7461 - val_loss: 0.5108 - val_acc: 0.7229\n",
      "Epoch 142/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4902 - acc: 0.7464 - val_loss: 0.5105 - val_acc: 0.7205\n",
      "Epoch 143/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4891 - acc: 0.7496 - val_loss: 0.5104 - val_acc: 0.7205\n",
      "Epoch 144/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4893 - acc: 0.7480 - val_loss: 0.5084 - val_acc: 0.7253\n",
      "Epoch 145/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4896 - acc: 0.7477 - val_loss: 0.5109 - val_acc: 0.7205\n",
      "Epoch 146/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4888 - acc: 0.7475 - val_loss: 0.5101 - val_acc: 0.7277\n",
      "Epoch 147/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4893 - acc: 0.7461 - val_loss: 0.5095 - val_acc: 0.7229\n",
      "Epoch 148/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4888 - acc: 0.7472 - val_loss: 0.5085 - val_acc: 0.7205\n",
      "Epoch 149/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4887 - acc: 0.7477 - val_loss: 0.5085 - val_acc: 0.7181\n",
      "Epoch 150/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4891 - acc: 0.7442 - val_loss: 0.5086 - val_acc: 0.7205\n",
      "Epoch 151/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4883 - acc: 0.7485 - val_loss: 0.5067 - val_acc: 0.7325\n",
      "Epoch 152/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4897 - acc: 0.7466 - val_loss: 0.5117 - val_acc: 0.7181\n",
      "Epoch 153/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4897 - acc: 0.7491 - val_loss: 0.5097 - val_acc: 0.7181\n",
      "Epoch 154/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4895 - acc: 0.7466 - val_loss: 0.5123 - val_acc: 0.7205\n",
      "Epoch 155/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4889 - acc: 0.7485 - val_loss: 0.5079 - val_acc: 0.7253\n",
      "Epoch 156/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4886 - acc: 0.7493 - val_loss: 0.5108 - val_acc: 0.7181\n",
      "Epoch 157/600\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.4880 - acc: 0.7485 - val_loss: 0.5108 - val_acc: 0.7205\n",
      "Epoch 158/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.4887 - acc: 0.7469 - val_loss: 0.5109 - val_acc: 0.7205\n",
      "Epoch 159/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4882 - acc: 0.7475 - val_loss: 0.5115 - val_acc: 0.7181\n",
      "Epoch 160/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4891 - acc: 0.7477 - val_loss: 0.5111 - val_acc: 0.7205\n",
      "Epoch 161/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4879 - acc: 0.7496 - val_loss: 0.5109 - val_acc: 0.7205\n",
      "Epoch 162/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4882 - acc: 0.7493 - val_loss: 0.5126 - val_acc: 0.7205\n",
      "Epoch 163/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4881 - acc: 0.7509 - val_loss: 0.5115 - val_acc: 0.7181\n",
      "Epoch 164/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4885 - acc: 0.7509 - val_loss: 0.5120 - val_acc: 0.7229\n",
      "Epoch 165/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4882 - acc: 0.7523 - val_loss: 0.5095 - val_acc: 0.7229\n",
      "Epoch 166/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4888 - acc: 0.7437 - val_loss: 0.5121 - val_acc: 0.7229\n",
      "Epoch 167/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.4888 - acc: 0.7499 - val_loss: 0.5108 - val_acc: 0.7181\n",
      "Epoch 168/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4878 - acc: 0.7488 - val_loss: 0.5093 - val_acc: 0.7157\n",
      "Epoch 169/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4875 - acc: 0.7512 - val_loss: 0.5080 - val_acc: 0.7253\n",
      "Epoch 170/600\n",
      "3730/3730 [==============================] - 0s 85us/step - loss: 0.4886 - acc: 0.7458 - val_loss: 0.5095 - val_acc: 0.7181\n",
      "Epoch 171/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.4881 - acc: 0.7475 - val_loss: 0.5073 - val_acc: 0.7253\n",
      "Epoch 172/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4885 - acc: 0.7493 - val_loss: 0.5099 - val_acc: 0.7181\n",
      "Epoch 173/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4886 - acc: 0.7499 - val_loss: 0.5083 - val_acc: 0.7229\n",
      "Epoch 174/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4883 - acc: 0.7488 - val_loss: 0.5095 - val_acc: 0.7181\n",
      "Epoch 175/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4881 - acc: 0.7523 - val_loss: 0.5099 - val_acc: 0.7157\n",
      "Epoch 176/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4876 - acc: 0.7477 - val_loss: 0.5089 - val_acc: 0.7205\n",
      "Epoch 177/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4878 - acc: 0.7496 - val_loss: 0.5101 - val_acc: 0.7157\n",
      "Epoch 178/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4876 - acc: 0.7469 - val_loss: 0.5100 - val_acc: 0.7157\n",
      "Epoch 179/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4873 - acc: 0.7525 - val_loss: 0.5093 - val_acc: 0.7181\n",
      "Epoch 180/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4881 - acc: 0.7469 - val_loss: 0.5106 - val_acc: 0.7205\n",
      "Epoch 181/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4886 - acc: 0.7472 - val_loss: 0.5107 - val_acc: 0.7181\n",
      "Epoch 182/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4878 - acc: 0.7466 - val_loss: 0.5109 - val_acc: 0.7157\n",
      "Epoch 183/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4874 - acc: 0.7469 - val_loss: 0.5089 - val_acc: 0.7205\n",
      "Epoch 184/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4872 - acc: 0.7442 - val_loss: 0.5111 - val_acc: 0.7229\n",
      "Epoch 185/600\n",
      "3730/3730 [==============================] - 0s 74us/step - loss: 0.4879 - acc: 0.7493 - val_loss: 0.5113 - val_acc: 0.7133\n",
      "Epoch 186/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4874 - acc: 0.7517 - val_loss: 0.5091 - val_acc: 0.7205\n",
      "Epoch 187/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4875 - acc: 0.7472 - val_loss: 0.5125 - val_acc: 0.7133\n",
      "Epoch 188/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4878 - acc: 0.7469 - val_loss: 0.5115 - val_acc: 0.7205\n",
      "Epoch 189/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.4871 - acc: 0.7472 - val_loss: 0.5114 - val_acc: 0.7157\n",
      "Epoch 190/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4875 - acc: 0.7493 - val_loss: 0.5106 - val_acc: 0.7205\n",
      "Epoch 191/600\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.4876 - acc: 0.7477 - val_loss: 0.5127 - val_acc: 0.7205\n",
      "Epoch 192/600\n",
      "3730/3730 [==============================] - 0s 94us/step - loss: 0.4879 - acc: 0.7512 - val_loss: 0.5085 - val_acc: 0.7181\n",
      "Epoch 193/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.4879 - acc: 0.7504 - val_loss: 0.5089 - val_acc: 0.7205\n",
      "Epoch 194/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4872 - acc: 0.7477 - val_loss: 0.5094 - val_acc: 0.7181\n",
      "Epoch 195/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4873 - acc: 0.7509 - val_loss: 0.5074 - val_acc: 0.7277\n",
      "Epoch 196/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4873 - acc: 0.7488 - val_loss: 0.5098 - val_acc: 0.7205\n",
      "Epoch 197/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4884 - acc: 0.7464 - val_loss: 0.5107 - val_acc: 0.7229\n",
      "Epoch 198/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4874 - acc: 0.7488 - val_loss: 0.5071 - val_acc: 0.7253\n",
      "Epoch 199/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4876 - acc: 0.7480 - val_loss: 0.5091 - val_acc: 0.7253\n",
      "Epoch 200/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4868 - acc: 0.7501 - val_loss: 0.5098 - val_acc: 0.7205\n",
      "Epoch 201/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4866 - acc: 0.7499 - val_loss: 0.5085 - val_acc: 0.7205\n",
      "Epoch 202/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4880 - acc: 0.7466 - val_loss: 0.5074 - val_acc: 0.7205\n",
      "Epoch 203/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4871 - acc: 0.7472 - val_loss: 0.5099 - val_acc: 0.7205\n",
      "Epoch 204/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4868 - acc: 0.7501 - val_loss: 0.5087 - val_acc: 0.7205\n",
      "Epoch 205/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4882 - acc: 0.7483 - val_loss: 0.5104 - val_acc: 0.7157\n",
      "Epoch 206/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4873 - acc: 0.7458 - val_loss: 0.5089 - val_acc: 0.7205\n",
      "Epoch 207/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4866 - acc: 0.7488 - val_loss: 0.5141 - val_acc: 0.7133\n",
      "Epoch 208/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4876 - acc: 0.7466 - val_loss: 0.5100 - val_acc: 0.7181\n",
      "Epoch 209/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.4867 - acc: 0.7507 - val_loss: 0.5085 - val_acc: 0.7157\n",
      "Epoch 210/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4871 - acc: 0.7472 - val_loss: 0.5091 - val_acc: 0.7205\n",
      "Epoch 211/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4875 - acc: 0.7485 - val_loss: 0.5113 - val_acc: 0.7157\n",
      "Epoch 212/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4864 - acc: 0.7456 - val_loss: 0.5120 - val_acc: 0.7157\n",
      "Epoch 213/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.4869 - acc: 0.7517 - val_loss: 0.5095 - val_acc: 0.7229\n",
      "Epoch 214/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4871 - acc: 0.7458 - val_loss: 0.5131 - val_acc: 0.7133\n",
      "Epoch 215/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4866 - acc: 0.7437 - val_loss: 0.5132 - val_acc: 0.7108\n",
      "Epoch 216/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4872 - acc: 0.7507 - val_loss: 0.5078 - val_acc: 0.7229\n",
      "Epoch 217/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4863 - acc: 0.7472 - val_loss: 0.5119 - val_acc: 0.7084\n",
      "Epoch 218/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4861 - acc: 0.7525 - val_loss: 0.5094 - val_acc: 0.7205\n",
      "Epoch 219/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4861 - acc: 0.7512 - val_loss: 0.5107 - val_acc: 0.7181\n",
      "Epoch 220/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4865 - acc: 0.7488 - val_loss: 0.5081 - val_acc: 0.7229\n",
      "Epoch 221/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4871 - acc: 0.7485 - val_loss: 0.5121 - val_acc: 0.7181\n",
      "Epoch 222/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4862 - acc: 0.7496 - val_loss: 0.5119 - val_acc: 0.7157\n",
      "Epoch 223/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4868 - acc: 0.7499 - val_loss: 0.5102 - val_acc: 0.7205\n",
      "Epoch 224/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4873 - acc: 0.7488 - val_loss: 0.5114 - val_acc: 0.7181\n",
      "Epoch 225/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4867 - acc: 0.7496 - val_loss: 0.5109 - val_acc: 0.7205\n",
      "Epoch 226/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.4861 - acc: 0.7483 - val_loss: 0.5112 - val_acc: 0.7181\n",
      "Epoch 227/600\n",
      "3730/3730 [==============================] - 0s 100us/step - loss: 0.4863 - acc: 0.7488 - val_loss: 0.5098 - val_acc: 0.7205\n",
      "Epoch 228/600\n",
      "3730/3730 [==============================] - 0s 86us/step - loss: 0.4871 - acc: 0.7504 - val_loss: 0.5110 - val_acc: 0.7181\n",
      "Epoch 229/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4863 - acc: 0.7488 - val_loss: 0.5112 - val_acc: 0.7205\n",
      "Epoch 230/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.4864 - acc: 0.7491 - val_loss: 0.5105 - val_acc: 0.7157\n",
      "Epoch 231/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4856 - acc: 0.7499 - val_loss: 0.5086 - val_acc: 0.7205\n",
      "Epoch 232/600\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.4862 - acc: 0.7493 - val_loss: 0.5114 - val_acc: 0.7157\n",
      "Epoch 233/600\n",
      "3730/3730 [==============================] - 0s 97us/step - loss: 0.4860 - acc: 0.7496 - val_loss: 0.5095 - val_acc: 0.7205\n",
      "Epoch 234/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4860 - acc: 0.7504 - val_loss: 0.5099 - val_acc: 0.7205\n",
      "Epoch 235/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.4861 - acc: 0.7504 - val_loss: 0.5090 - val_acc: 0.7229\n",
      "Epoch 236/600\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.4876 - acc: 0.7432 - val_loss: 0.5112 - val_acc: 0.7157\n",
      "Epoch 237/600\n",
      "3730/3730 [==============================] - 0s 83us/step - loss: 0.4860 - acc: 0.7493 - val_loss: 0.5102 - val_acc: 0.7181\n",
      "Epoch 238/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3730/3730 [==============================] - ETA: 0s - loss: 0.4915 - acc: 0.746 - 0s 82us/step - loss: 0.4863 - acc: 0.7480 - val_loss: 0.5111 - val_acc: 0.7181\n",
      "Epoch 239/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4863 - acc: 0.7491 - val_loss: 0.5107 - val_acc: 0.7181\n",
      "Epoch 240/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4866 - acc: 0.7491 - val_loss: 0.5106 - val_acc: 0.7205\n",
      "Epoch 241/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4871 - acc: 0.7499 - val_loss: 0.5124 - val_acc: 0.7181\n",
      "Epoch 242/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4861 - acc: 0.7493 - val_loss: 0.5136 - val_acc: 0.7181\n",
      "Epoch 243/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4866 - acc: 0.7466 - val_loss: 0.5112 - val_acc: 0.7205\n",
      "Epoch 244/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4857 - acc: 0.7483 - val_loss: 0.5115 - val_acc: 0.7181\n",
      "Epoch 245/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4863 - acc: 0.7501 - val_loss: 0.5106 - val_acc: 0.7181\n",
      "Epoch 246/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4860 - acc: 0.7493 - val_loss: 0.5104 - val_acc: 0.7181\n",
      "Epoch 247/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4855 - acc: 0.7493 - val_loss: 0.5105 - val_acc: 0.7205\n",
      "Epoch 248/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4855 - acc: 0.7499 - val_loss: 0.5083 - val_acc: 0.7205\n",
      "Epoch 249/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4857 - acc: 0.7477 - val_loss: 0.5126 - val_acc: 0.7181\n",
      "Epoch 250/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4857 - acc: 0.7517 - val_loss: 0.5154 - val_acc: 0.7108\n",
      "Epoch 251/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4852 - acc: 0.7507 - val_loss: 0.5110 - val_acc: 0.7229\n",
      "Epoch 252/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4865 - acc: 0.7499 - val_loss: 0.5130 - val_acc: 0.7084\n",
      "Epoch 253/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4862 - acc: 0.7483 - val_loss: 0.5099 - val_acc: 0.7229\n",
      "Epoch 254/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4864 - acc: 0.7491 - val_loss: 0.5087 - val_acc: 0.7277\n",
      "Epoch 255/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4851 - acc: 0.7507 - val_loss: 0.5089 - val_acc: 0.7229\n",
      "Epoch 256/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4861 - acc: 0.7512 - val_loss: 0.5093 - val_acc: 0.7253\n",
      "Epoch 257/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4864 - acc: 0.7469 - val_loss: 0.5121 - val_acc: 0.7205\n",
      "Epoch 258/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4855 - acc: 0.7491 - val_loss: 0.5083 - val_acc: 0.7205\n",
      "Epoch 259/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4857 - acc: 0.7488 - val_loss: 0.5109 - val_acc: 0.7181\n",
      "Epoch 260/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4865 - acc: 0.7501 - val_loss: 0.5112 - val_acc: 0.7205\n",
      "Epoch 261/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4857 - acc: 0.7469 - val_loss: 0.5069 - val_acc: 0.7277\n",
      "Epoch 262/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4861 - acc: 0.7477 - val_loss: 0.5085 - val_acc: 0.7253\n",
      "Epoch 263/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4871 - acc: 0.7477 - val_loss: 0.5103 - val_acc: 0.7205\n",
      "Epoch 264/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4860 - acc: 0.7485 - val_loss: 0.5120 - val_acc: 0.7205\n",
      "Epoch 265/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4853 - acc: 0.7493 - val_loss: 0.5074 - val_acc: 0.7229\n",
      "Epoch 266/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4857 - acc: 0.7491 - val_loss: 0.5074 - val_acc: 0.7205\n",
      "Epoch 267/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4858 - acc: 0.7453 - val_loss: 0.5105 - val_acc: 0.7133\n",
      "Epoch 268/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4857 - acc: 0.7509 - val_loss: 0.5122 - val_acc: 0.7108\n",
      "Epoch 269/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4849 - acc: 0.7464 - val_loss: 0.5092 - val_acc: 0.7253\n",
      "Epoch 270/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4856 - acc: 0.7480 - val_loss: 0.5102 - val_acc: 0.7157\n",
      "Epoch 271/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4854 - acc: 0.7517 - val_loss: 0.5085 - val_acc: 0.7253\n",
      "Epoch 272/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4851 - acc: 0.7477 - val_loss: 0.5113 - val_acc: 0.7108\n",
      "Epoch 273/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4848 - acc: 0.7483 - val_loss: 0.5076 - val_acc: 0.7229\n",
      "Epoch 274/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4848 - acc: 0.7499 - val_loss: 0.5090 - val_acc: 0.7133\n",
      "Epoch 275/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4844 - acc: 0.7523 - val_loss: 0.5079 - val_acc: 0.7277\n",
      "Epoch 276/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4861 - acc: 0.7477 - val_loss: 0.5103 - val_acc: 0.7157\n",
      "Epoch 277/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4846 - acc: 0.7480 - val_loss: 0.5112 - val_acc: 0.7133\n",
      "Epoch 278/600\n",
      "3730/3730 [==============================] - 0s 86us/step - loss: 0.4849 - acc: 0.7488 - val_loss: 0.5093 - val_acc: 0.7205\n",
      "Epoch 279/600\n",
      "3730/3730 [==============================] - 0s 86us/step - loss: 0.4854 - acc: 0.7461 - val_loss: 0.5093 - val_acc: 0.7133\n",
      "Epoch 280/600\n",
      "3730/3730 [==============================] - 0s 82us/step - loss: 0.4841 - acc: 0.7483 - val_loss: 0.5052 - val_acc: 0.7277\n",
      "Epoch 281/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4850 - acc: 0.7496 - val_loss: 0.5086 - val_acc: 0.7181\n",
      "Epoch 282/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4850 - acc: 0.7534 - val_loss: 0.5072 - val_acc: 0.7301\n",
      "Epoch 283/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4846 - acc: 0.7501 - val_loss: 0.5092 - val_acc: 0.7108\n",
      "Epoch 284/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4845 - acc: 0.7475 - val_loss: 0.5121 - val_acc: 0.7157\n",
      "Epoch 285/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4841 - acc: 0.7475 - val_loss: 0.5085 - val_acc: 0.7181\n",
      "Epoch 286/600\n",
      "3730/3730 [==============================] - 0s 94us/step - loss: 0.4840 - acc: 0.7507 - val_loss: 0.5079 - val_acc: 0.7229\n",
      "Epoch 287/600\n",
      "3730/3730 [==============================] - 0s 82us/step - loss: 0.4842 - acc: 0.7499 - val_loss: 0.5082 - val_acc: 0.7229\n",
      "Epoch 288/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4842 - acc: 0.7491 - val_loss: 0.5088 - val_acc: 0.7205\n",
      "Epoch 289/600\n",
      "3730/3730 [==============================] - 0s 95us/step - loss: 0.4852 - acc: 0.7528 - val_loss: 0.5117 - val_acc: 0.7108\n",
      "Epoch 290/600\n",
      "3730/3730 [==============================] - 0s 91us/step - loss: 0.4847 - acc: 0.7493 - val_loss: 0.5091 - val_acc: 0.7157\n",
      "Epoch 291/600\n",
      "3730/3730 [==============================] - 0s 85us/step - loss: 0.4849 - acc: 0.7499 - val_loss: 0.5063 - val_acc: 0.7277\n",
      "Epoch 292/600\n",
      "3730/3730 [==============================] - 0s 84us/step - loss: 0.4834 - acc: 0.7483 - val_loss: 0.5066 - val_acc: 0.7325\n",
      "Epoch 293/600\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.4845 - acc: 0.7493 - val_loss: 0.5083 - val_acc: 0.7205\n",
      "Epoch 294/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4838 - acc: 0.7507 - val_loss: 0.5083 - val_acc: 0.7181\n",
      "Epoch 295/600\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.4838 - acc: 0.7501 - val_loss: 0.5074 - val_acc: 0.7181\n",
      "Epoch 296/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4840 - acc: 0.7485 - val_loss: 0.5079 - val_acc: 0.7277\n",
      "Epoch 297/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.4838 - acc: 0.7507 - val_loss: 0.5097 - val_acc: 0.7133\n",
      "Epoch 298/600\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.4835 - acc: 0.7493 - val_loss: 0.5106 - val_acc: 0.7133\n",
      "Epoch 299/600\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.4836 - acc: 0.7504 - val_loss: 0.5072 - val_acc: 0.7205\n",
      "Epoch 300/600\n",
      "3730/3730 [==============================] - 0s 96us/step - loss: 0.4846 - acc: 0.7485 - val_loss: 0.5074 - val_acc: 0.7277\n",
      "Epoch 301/600\n",
      "3730/3730 [==============================] - 0s 90us/step - loss: 0.4840 - acc: 0.7493 - val_loss: 0.5073 - val_acc: 0.7277\n",
      "Epoch 302/600\n",
      "3730/3730 [==============================] - 0s 113us/step - loss: 0.4849 - acc: 0.7499 - val_loss: 0.5071 - val_acc: 0.7229\n",
      "Epoch 303/600\n",
      "3730/3730 [==============================] - 0s 102us/step - loss: 0.4838 - acc: 0.7475 - val_loss: 0.5092 - val_acc: 0.7133\n",
      "Epoch 304/600\n",
      "3730/3730 [==============================] - 0s 85us/step - loss: 0.4840 - acc: 0.7493 - val_loss: 0.5085 - val_acc: 0.7157\n",
      "Epoch 305/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.4838 - acc: 0.7525 - val_loss: 0.5078 - val_acc: 0.7157\n",
      "Epoch 306/600\n",
      "3730/3730 [==============================] - 0s 102us/step - loss: 0.4838 - acc: 0.7520 - val_loss: 0.5069 - val_acc: 0.7253\n",
      "Epoch 307/600\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.4832 - acc: 0.7488 - val_loss: 0.5081 - val_acc: 0.7157\n",
      "Epoch 308/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4832 - acc: 0.7493 - val_loss: 0.5072 - val_acc: 0.7301\n",
      "Epoch 309/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4844 - acc: 0.7480 - val_loss: 0.5082 - val_acc: 0.7205\n",
      "Epoch 310/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4838 - acc: 0.7493 - val_loss: 0.5085 - val_acc: 0.7205\n",
      "Epoch 311/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4833 - acc: 0.7531 - val_loss: 0.5077 - val_acc: 0.7181\n",
      "Epoch 312/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4827 - acc: 0.7547 - val_loss: 0.5065 - val_acc: 0.7253\n",
      "Epoch 313/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4836 - acc: 0.7501 - val_loss: 0.5074 - val_acc: 0.7229\n",
      "Epoch 314/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4838 - acc: 0.7499 - val_loss: 0.5085 - val_acc: 0.7205\n",
      "Epoch 315/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4836 - acc: 0.7488 - val_loss: 0.5053 - val_acc: 0.7253\n",
      "Epoch 316/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4830 - acc: 0.7507 - val_loss: 0.5077 - val_acc: 0.7205\n",
      "Epoch 317/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4835 - acc: 0.7493 - val_loss: 0.5058 - val_acc: 0.7349\n",
      "Epoch 318/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4846 - acc: 0.7507 - val_loss: 0.5068 - val_acc: 0.7277\n",
      "Epoch 319/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4833 - acc: 0.7496 - val_loss: 0.5061 - val_acc: 0.7229\n",
      "Epoch 320/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4834 - acc: 0.7539 - val_loss: 0.5072 - val_acc: 0.7229\n",
      "Epoch 321/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4829 - acc: 0.7515 - val_loss: 0.5096 - val_acc: 0.7229\n",
      "Epoch 322/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4838 - acc: 0.7512 - val_loss: 0.5081 - val_acc: 0.7181\n",
      "Epoch 323/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4837 - acc: 0.7509 - val_loss: 0.5102 - val_acc: 0.7157\n",
      "Epoch 324/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4830 - acc: 0.7507 - val_loss: 0.5078 - val_acc: 0.7181\n",
      "Epoch 325/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4832 - acc: 0.7512 - val_loss: 0.5075 - val_acc: 0.7253\n",
      "Epoch 326/600\n",
      "3730/3730 [==============================] - 0s 74us/step - loss: 0.4823 - acc: 0.7499 - val_loss: 0.5080 - val_acc: 0.7157\n",
      "Epoch 327/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4831 - acc: 0.7528 - val_loss: 0.5083 - val_acc: 0.7181\n",
      "Epoch 328/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4823 - acc: 0.7534 - val_loss: 0.5104 - val_acc: 0.7133\n",
      "Epoch 329/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4835 - acc: 0.7475 - val_loss: 0.5082 - val_acc: 0.7229\n",
      "Epoch 330/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4837 - acc: 0.7525 - val_loss: 0.5078 - val_acc: 0.7229\n",
      "Epoch 331/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4829 - acc: 0.7512 - val_loss: 0.5077 - val_acc: 0.7253\n",
      "Epoch 332/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4833 - acc: 0.7539 - val_loss: 0.5070 - val_acc: 0.7277\n",
      "Epoch 333/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4830 - acc: 0.7523 - val_loss: 0.5095 - val_acc: 0.7157\n",
      "Epoch 334/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4831 - acc: 0.7558 - val_loss: 0.5107 - val_acc: 0.7133\n",
      "Epoch 335/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4826 - acc: 0.7555 - val_loss: 0.5064 - val_acc: 0.7277\n",
      "Epoch 336/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4829 - acc: 0.7515 - val_loss: 0.5088 - val_acc: 0.7205\n",
      "Epoch 337/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4826 - acc: 0.7480 - val_loss: 0.5085 - val_acc: 0.7157\n",
      "Epoch 338/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4828 - acc: 0.7542 - val_loss: 0.5084 - val_acc: 0.7205\n",
      "Epoch 339/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.4824 - acc: 0.7515 - val_loss: 0.5080 - val_acc: 0.7325\n",
      "Epoch 340/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4833 - acc: 0.7520 - val_loss: 0.5093 - val_acc: 0.7157\n",
      "Epoch 341/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4828 - acc: 0.7499 - val_loss: 0.5107 - val_acc: 0.7108\n",
      "Epoch 342/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4831 - acc: 0.7499 - val_loss: 0.5080 - val_acc: 0.7253\n",
      "Epoch 343/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4827 - acc: 0.7496 - val_loss: 0.5094 - val_acc: 0.7181\n",
      "Epoch 344/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.4828 - acc: 0.7520 - val_loss: 0.5080 - val_acc: 0.7277\n",
      "Epoch 345/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4829 - acc: 0.7523 - val_loss: 0.5129 - val_acc: 0.7157\n",
      "Epoch 346/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4831 - acc: 0.7544 - val_loss: 0.5099 - val_acc: 0.7133\n",
      "Epoch 347/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4828 - acc: 0.7523 - val_loss: 0.5077 - val_acc: 0.7277\n",
      "Epoch 348/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4834 - acc: 0.7525 - val_loss: 0.5102 - val_acc: 0.7229\n",
      "Epoch 349/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4836 - acc: 0.7504 - val_loss: 0.5096 - val_acc: 0.7277\n",
      "Epoch 350/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.4832 - acc: 0.7515 - val_loss: 0.5112 - val_acc: 0.7157\n",
      "Epoch 351/600\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.4830 - acc: 0.7571 - val_loss: 0.5122 - val_acc: 0.7157\n",
      "Epoch 352/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4836 - acc: 0.7512 - val_loss: 0.5103 - val_acc: 0.7205\n",
      "Epoch 353/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4826 - acc: 0.7504 - val_loss: 0.5098 - val_acc: 0.7253\n",
      "Epoch 354/600\n",
      "3730/3730 [==============================] - 0s 85us/step - loss: 0.4827 - acc: 0.7531 - val_loss: 0.5091 - val_acc: 0.7325\n",
      "Epoch 355/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4826 - acc: 0.7525 - val_loss: 0.5117 - val_acc: 0.7157\n",
      "Epoch 356/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4819 - acc: 0.7542 - val_loss: 0.5094 - val_acc: 0.7277\n",
      "Epoch 357/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4822 - acc: 0.7536 - val_loss: 0.5094 - val_acc: 0.7301\n",
      "Epoch 358/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.4827 - acc: 0.7501 - val_loss: 0.5112 - val_acc: 0.7157\n",
      "Epoch 359/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4831 - acc: 0.7531 - val_loss: 0.5103 - val_acc: 0.7253\n",
      "Epoch 360/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4826 - acc: 0.7552 - val_loss: 0.5105 - val_acc: 0.7181\n",
      "Epoch 361/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4833 - acc: 0.7512 - val_loss: 0.5095 - val_acc: 0.7301\n",
      "Epoch 362/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4823 - acc: 0.7528 - val_loss: 0.5096 - val_acc: 0.7253\n",
      "Epoch 363/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4819 - acc: 0.7528 - val_loss: 0.5106 - val_acc: 0.7205\n",
      "Epoch 364/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4824 - acc: 0.7534 - val_loss: 0.5111 - val_acc: 0.7133\n",
      "Epoch 365/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4824 - acc: 0.7483 - val_loss: 0.5101 - val_acc: 0.7205\n",
      "Epoch 366/600\n",
      "3730/3730 [==============================] - 0s 85us/step - loss: 0.4825 - acc: 0.7552 - val_loss: 0.5128 - val_acc: 0.7157\n",
      "Epoch 367/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4836 - acc: 0.7504 - val_loss: 0.5103 - val_acc: 0.7253\n",
      "Epoch 368/600\n",
      "3730/3730 [==============================] - 0s 85us/step - loss: 0.4822 - acc: 0.7504 - val_loss: 0.5094 - val_acc: 0.7277\n",
      "Epoch 369/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4826 - acc: 0.7542 - val_loss: 0.5109 - val_acc: 0.7205\n",
      "Epoch 370/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4831 - acc: 0.7501 - val_loss: 0.5115 - val_acc: 0.7277\n",
      "Epoch 371/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4819 - acc: 0.7520 - val_loss: 0.5110 - val_acc: 0.7253\n",
      "Epoch 372/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4819 - acc: 0.7496 - val_loss: 0.5104 - val_acc: 0.7157\n",
      "Epoch 373/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4821 - acc: 0.7507 - val_loss: 0.5127 - val_acc: 0.7157\n",
      "Epoch 374/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4823 - acc: 0.7552 - val_loss: 0.5106 - val_acc: 0.7277\n",
      "Epoch 375/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4828 - acc: 0.7523 - val_loss: 0.5144 - val_acc: 0.7205\n",
      "Epoch 376/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4824 - acc: 0.7499 - val_loss: 0.5128 - val_acc: 0.7157\n",
      "Epoch 377/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4825 - acc: 0.7512 - val_loss: 0.5088 - val_acc: 0.7301\n",
      "Epoch 378/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4831 - acc: 0.7512 - val_loss: 0.5119 - val_acc: 0.7277\n",
      "Epoch 379/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4836 - acc: 0.7515 - val_loss: 0.5141 - val_acc: 0.7205\n",
      "Epoch 380/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4827 - acc: 0.7512 - val_loss: 0.5103 - val_acc: 0.7301\n",
      "Epoch 381/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4828 - acc: 0.7509 - val_loss: 0.5130 - val_acc: 0.7205\n",
      "Epoch 382/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4820 - acc: 0.7507 - val_loss: 0.5106 - val_acc: 0.7277\n",
      "Epoch 383/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4822 - acc: 0.7496 - val_loss: 0.5144 - val_acc: 0.7181\n",
      "Epoch 384/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4820 - acc: 0.7480 - val_loss: 0.5113 - val_acc: 0.7253\n",
      "Epoch 385/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4831 - acc: 0.7531 - val_loss: 0.5156 - val_acc: 0.7205\n",
      "Epoch 386/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4815 - acc: 0.7539 - val_loss: 0.5125 - val_acc: 0.7253\n",
      "Epoch 387/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4836 - acc: 0.7493 - val_loss: 0.5143 - val_acc: 0.7205\n",
      "Epoch 388/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4825 - acc: 0.7499 - val_loss: 0.5116 - val_acc: 0.7229\n",
      "Epoch 389/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.4822 - acc: 0.7475 - val_loss: 0.5142 - val_acc: 0.7205\n",
      "Epoch 390/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4827 - acc: 0.7523 - val_loss: 0.5119 - val_acc: 0.7181\n",
      "Epoch 391/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4821 - acc: 0.7485 - val_loss: 0.5132 - val_acc: 0.7205\n",
      "Epoch 392/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4816 - acc: 0.7504 - val_loss: 0.5130 - val_acc: 0.7205\n",
      "Epoch 393/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4827 - acc: 0.7555 - val_loss: 0.5120 - val_acc: 0.7301\n",
      "Epoch 394/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4824 - acc: 0.7515 - val_loss: 0.5135 - val_acc: 0.7205\n",
      "Epoch 395/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4825 - acc: 0.7525 - val_loss: 0.5142 - val_acc: 0.7205\n",
      "Epoch 396/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.4818 - acc: 0.7528 - val_loss: 0.5121 - val_acc: 0.7349\n",
      "Epoch 397/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4824 - acc: 0.7520 - val_loss: 0.5125 - val_acc: 0.7277\n",
      "Epoch 398/600\n",
      "3730/3730 [==============================] - 0s 84us/step - loss: 0.4819 - acc: 0.7515 - val_loss: 0.5116 - val_acc: 0.7301\n",
      "Epoch 399/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4816 - acc: 0.7507 - val_loss: 0.5130 - val_acc: 0.7301\n",
      "Epoch 400/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4817 - acc: 0.7539 - val_loss: 0.5118 - val_acc: 0.7253\n",
      "Epoch 401/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4831 - acc: 0.7453 - val_loss: 0.5131 - val_acc: 0.7277\n",
      "Epoch 402/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4819 - acc: 0.7512 - val_loss: 0.5127 - val_acc: 0.7277\n",
      "Epoch 403/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4814 - acc: 0.7485 - val_loss: 0.5124 - val_acc: 0.7349\n",
      "Epoch 404/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4820 - acc: 0.7509 - val_loss: 0.5125 - val_acc: 0.7301\n",
      "Epoch 405/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4819 - acc: 0.7499 - val_loss: 0.5149 - val_acc: 0.7157\n",
      "Epoch 406/600\n",
      "3730/3730 [==============================] - 0s 74us/step - loss: 0.4817 - acc: 0.7523 - val_loss: 0.5101 - val_acc: 0.7277\n",
      "Epoch 407/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4819 - acc: 0.7534 - val_loss: 0.5126 - val_acc: 0.7325\n",
      "Epoch 408/600\n",
      "3730/3730 [==============================] - 0s 74us/step - loss: 0.4816 - acc: 0.7509 - val_loss: 0.5137 - val_acc: 0.7301\n",
      "Epoch 409/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4819 - acc: 0.7523 - val_loss: 0.5124 - val_acc: 0.7349\n",
      "Epoch 410/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4817 - acc: 0.7496 - val_loss: 0.5144 - val_acc: 0.7253\n",
      "Epoch 411/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4824 - acc: 0.7493 - val_loss: 0.5145 - val_acc: 0.7253\n",
      "Epoch 412/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4819 - acc: 0.7504 - val_loss: 0.5120 - val_acc: 0.7349\n",
      "Epoch 413/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4819 - acc: 0.7445 - val_loss: 0.5145 - val_acc: 0.7253\n",
      "Epoch 414/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4815 - acc: 0.7491 - val_loss: 0.5139 - val_acc: 0.7325\n",
      "Epoch 415/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4817 - acc: 0.7531 - val_loss: 0.5171 - val_acc: 0.7108\n",
      "Epoch 416/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.4812 - acc: 0.7499 - val_loss: 0.5134 - val_acc: 0.7349\n",
      "Epoch 417/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.4812 - acc: 0.7525 - val_loss: 0.5135 - val_acc: 0.7325\n",
      "Epoch 418/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4826 - acc: 0.7501 - val_loss: 0.5139 - val_acc: 0.7325\n",
      "Epoch 419/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4812 - acc: 0.7491 - val_loss: 0.5135 - val_acc: 0.7349\n",
      "Epoch 420/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4807 - acc: 0.7517 - val_loss: 0.5136 - val_acc: 0.7325\n",
      "Epoch 421/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4822 - acc: 0.7515 - val_loss: 0.5119 - val_acc: 0.7373\n",
      "Epoch 422/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4808 - acc: 0.7517 - val_loss: 0.5138 - val_acc: 0.7325\n",
      "Epoch 423/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4810 - acc: 0.7542 - val_loss: 0.5127 - val_acc: 0.7373\n",
      "Epoch 424/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4818 - acc: 0.7523 - val_loss: 0.5150 - val_acc: 0.7253\n",
      "Epoch 425/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4804 - acc: 0.7493 - val_loss: 0.5131 - val_acc: 0.7349\n",
      "Epoch 426/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4812 - acc: 0.7534 - val_loss: 0.5144 - val_acc: 0.7229\n",
      "Epoch 427/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4815 - acc: 0.7501 - val_loss: 0.5122 - val_acc: 0.7373\n",
      "Epoch 428/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4815 - acc: 0.7483 - val_loss: 0.5125 - val_acc: 0.7373\n",
      "Epoch 429/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4812 - acc: 0.7523 - val_loss: 0.5148 - val_acc: 0.7277\n",
      "Epoch 430/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4816 - acc: 0.7523 - val_loss: 0.5142 - val_acc: 0.7301\n",
      "Epoch 431/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4812 - acc: 0.7504 - val_loss: 0.5142 - val_acc: 0.7253\n",
      "Epoch 432/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4799 - acc: 0.7496 - val_loss: 0.5104 - val_acc: 0.7398\n",
      "Epoch 433/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4816 - acc: 0.7501 - val_loss: 0.5137 - val_acc: 0.7349\n",
      "Epoch 434/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4815 - acc: 0.7550 - val_loss: 0.5134 - val_acc: 0.7349\n",
      "Epoch 435/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4812 - acc: 0.7536 - val_loss: 0.5140 - val_acc: 0.7325\n",
      "Epoch 436/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4820 - acc: 0.7517 - val_loss: 0.5143 - val_acc: 0.7325\n",
      "Epoch 437/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4809 - acc: 0.7501 - val_loss: 0.5141 - val_acc: 0.7325\n",
      "Epoch 438/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4815 - acc: 0.7563 - val_loss: 0.5152 - val_acc: 0.7301\n",
      "Epoch 439/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4808 - acc: 0.7536 - val_loss: 0.5164 - val_acc: 0.7157\n",
      "Epoch 440/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4811 - acc: 0.7517 - val_loss: 0.5129 - val_acc: 0.7277\n",
      "Epoch 441/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4811 - acc: 0.7515 - val_loss: 0.5170 - val_acc: 0.7205\n",
      "Epoch 442/600\n",
      "3730/3730 [==============================] - 0s 74us/step - loss: 0.4804 - acc: 0.7544 - val_loss: 0.5160 - val_acc: 0.7181\n",
      "Epoch 443/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4798 - acc: 0.7534 - val_loss: 0.5168 - val_acc: 0.7108\n",
      "Epoch 444/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4808 - acc: 0.7499 - val_loss: 0.5149 - val_acc: 0.7277\n",
      "Epoch 445/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4808 - acc: 0.7507 - val_loss: 0.5126 - val_acc: 0.7373\n",
      "Epoch 446/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.4819 - acc: 0.7496 - val_loss: 0.5129 - val_acc: 0.7422\n",
      "Epoch 447/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4809 - acc: 0.7507 - val_loss: 0.5160 - val_acc: 0.7181\n",
      "Epoch 448/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4819 - acc: 0.7544 - val_loss: 0.5134 - val_acc: 0.7398\n",
      "Epoch 449/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4812 - acc: 0.7491 - val_loss: 0.5150 - val_acc: 0.7205\n",
      "Epoch 450/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4801 - acc: 0.7507 - val_loss: 0.5166 - val_acc: 0.7157\n",
      "Epoch 451/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4809 - acc: 0.7552 - val_loss: 0.5120 - val_acc: 0.7422\n",
      "Epoch 452/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4816 - acc: 0.7512 - val_loss: 0.5110 - val_acc: 0.7446\n",
      "Epoch 453/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4806 - acc: 0.7528 - val_loss: 0.5138 - val_acc: 0.7373\n",
      "Epoch 454/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4811 - acc: 0.7531 - val_loss: 0.5120 - val_acc: 0.7446\n",
      "Epoch 455/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4812 - acc: 0.7507 - val_loss: 0.5147 - val_acc: 0.7301\n",
      "Epoch 456/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4810 - acc: 0.7528 - val_loss: 0.5139 - val_acc: 0.7325\n",
      "Epoch 457/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4800 - acc: 0.7491 - val_loss: 0.5111 - val_acc: 0.7398\n",
      "Epoch 458/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.4806 - acc: 0.7507 - val_loss: 0.5113 - val_acc: 0.7349\n",
      "Epoch 459/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4814 - acc: 0.7525 - val_loss: 0.5130 - val_acc: 0.7373\n",
      "Epoch 460/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4805 - acc: 0.7534 - val_loss: 0.5109 - val_acc: 0.7422\n",
      "Epoch 461/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4806 - acc: 0.7504 - val_loss: 0.5152 - val_acc: 0.7277\n",
      "Epoch 462/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4809 - acc: 0.7499 - val_loss: 0.5138 - val_acc: 0.7373\n",
      "Epoch 463/600\n",
      "3730/3730 [==============================] - 0s 74us/step - loss: 0.4805 - acc: 0.7520 - val_loss: 0.5143 - val_acc: 0.7325\n",
      "Epoch 464/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4807 - acc: 0.7520 - val_loss: 0.5139 - val_acc: 0.7325\n",
      "Epoch 465/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4804 - acc: 0.7542 - val_loss: 0.5123 - val_acc: 0.7349\n",
      "Epoch 466/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4812 - acc: 0.7544 - val_loss: 0.5127 - val_acc: 0.7398\n",
      "Epoch 467/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4806 - acc: 0.7515 - val_loss: 0.5160 - val_acc: 0.7253\n",
      "Epoch 468/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4813 - acc: 0.7515 - val_loss: 0.5107 - val_acc: 0.7373\n",
      "Epoch 469/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4806 - acc: 0.7534 - val_loss: 0.5121 - val_acc: 0.7422\n",
      "Epoch 470/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4808 - acc: 0.7534 - val_loss: 0.5112 - val_acc: 0.7349\n",
      "Epoch 471/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4800 - acc: 0.7536 - val_loss: 0.5125 - val_acc: 0.7398\n",
      "Epoch 472/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4821 - acc: 0.7525 - val_loss: 0.5169 - val_acc: 0.7205\n",
      "Epoch 473/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4805 - acc: 0.7493 - val_loss: 0.5130 - val_acc: 0.7398\n",
      "Epoch 474/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4812 - acc: 0.7512 - val_loss: 0.5116 - val_acc: 0.7398\n",
      "Epoch 475/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4801 - acc: 0.7520 - val_loss: 0.5125 - val_acc: 0.7398\n",
      "Epoch 476/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4807 - acc: 0.7504 - val_loss: 0.5124 - val_acc: 0.7349\n",
      "Epoch 477/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4809 - acc: 0.7520 - val_loss: 0.5128 - val_acc: 0.7325\n",
      "Epoch 478/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4805 - acc: 0.7523 - val_loss: 0.5113 - val_acc: 0.7422\n",
      "Epoch 479/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4808 - acc: 0.7491 - val_loss: 0.5131 - val_acc: 0.7349\n",
      "Epoch 480/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4804 - acc: 0.7523 - val_loss: 0.5139 - val_acc: 0.7301\n",
      "Epoch 481/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4799 - acc: 0.7534 - val_loss: 0.5123 - val_acc: 0.7398\n",
      "Epoch 482/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4808 - acc: 0.7528 - val_loss: 0.5133 - val_acc: 0.7349\n",
      "Epoch 483/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4809 - acc: 0.7531 - val_loss: 0.5119 - val_acc: 0.7373\n",
      "Epoch 484/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4804 - acc: 0.7515 - val_loss: 0.5137 - val_acc: 0.7301\n",
      "Epoch 485/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4805 - acc: 0.7547 - val_loss: 0.5130 - val_acc: 0.7349\n",
      "Epoch 486/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4803 - acc: 0.7512 - val_loss: 0.5144 - val_acc: 0.7325\n",
      "Epoch 487/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4804 - acc: 0.7555 - val_loss: 0.5140 - val_acc: 0.7325\n",
      "Epoch 488/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4804 - acc: 0.7507 - val_loss: 0.5143 - val_acc: 0.7325\n",
      "Epoch 489/600\n",
      "3730/3730 [==============================] - 0s 74us/step - loss: 0.4804 - acc: 0.7539 - val_loss: 0.5128 - val_acc: 0.7349\n",
      "Epoch 490/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4807 - acc: 0.7499 - val_loss: 0.5131 - val_acc: 0.7349\n",
      "Epoch 491/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4805 - acc: 0.7507 - val_loss: 0.5126 - val_acc: 0.7373\n",
      "Epoch 492/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4812 - acc: 0.7493 - val_loss: 0.5126 - val_acc: 0.7349\n",
      "Epoch 493/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4802 - acc: 0.7531 - val_loss: 0.5127 - val_acc: 0.7349\n",
      "Epoch 494/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4806 - acc: 0.7539 - val_loss: 0.5129 - val_acc: 0.7349\n",
      "Epoch 495/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4805 - acc: 0.7536 - val_loss: 0.5131 - val_acc: 0.7422\n",
      "Epoch 496/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4802 - acc: 0.7520 - val_loss: 0.5136 - val_acc: 0.7301\n",
      "Epoch 497/600\n",
      "3730/3730 [==============================] - 0s 74us/step - loss: 0.4793 - acc: 0.7523 - val_loss: 0.5137 - val_acc: 0.7301\n",
      "Epoch 498/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4816 - acc: 0.7485 - val_loss: 0.5121 - val_acc: 0.7398\n",
      "Epoch 499/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4815 - acc: 0.7520 - val_loss: 0.5133 - val_acc: 0.7349\n",
      "Epoch 500/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.4807 - acc: 0.7552 - val_loss: 0.5152 - val_acc: 0.7325\n",
      "Epoch 501/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4796 - acc: 0.7523 - val_loss: 0.5136 - val_acc: 0.7373\n",
      "Epoch 502/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4806 - acc: 0.7480 - val_loss: 0.5136 - val_acc: 0.7422\n",
      "Epoch 503/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4818 - acc: 0.7512 - val_loss: 0.5145 - val_acc: 0.7301\n",
      "Epoch 504/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4800 - acc: 0.7542 - val_loss: 0.5163 - val_acc: 0.7301\n",
      "Epoch 505/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4804 - acc: 0.7531 - val_loss: 0.5160 - val_acc: 0.7301\n",
      "Epoch 506/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4801 - acc: 0.7528 - val_loss: 0.5186 - val_acc: 0.7181\n",
      "Epoch 507/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4805 - acc: 0.7515 - val_loss: 0.5153 - val_acc: 0.7325\n",
      "Epoch 508/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4811 - acc: 0.7525 - val_loss: 0.5147 - val_acc: 0.7325\n",
      "Epoch 509/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4799 - acc: 0.7539 - val_loss: 0.5161 - val_acc: 0.7325\n",
      "Epoch 510/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4795 - acc: 0.7507 - val_loss: 0.5170 - val_acc: 0.7277\n",
      "Epoch 511/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4796 - acc: 0.7552 - val_loss: 0.5171 - val_acc: 0.7277\n",
      "Epoch 512/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4800 - acc: 0.7536 - val_loss: 0.5149 - val_acc: 0.7349\n",
      "Epoch 513/600\n",
      "3730/3730 [==============================] - 0s 74us/step - loss: 0.4803 - acc: 0.7501 - val_loss: 0.5156 - val_acc: 0.7349\n",
      "Epoch 514/600\n",
      "3730/3730 [==============================] - 0s 94us/step - loss: 0.4798 - acc: 0.7550 - val_loss: 0.5130 - val_acc: 0.7349\n",
      "Epoch 515/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4799 - acc: 0.7539 - val_loss: 0.5155 - val_acc: 0.7325\n",
      "Epoch 516/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4795 - acc: 0.7531 - val_loss: 0.5149 - val_acc: 0.7398\n",
      "Epoch 517/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4806 - acc: 0.7509 - val_loss: 0.5164 - val_acc: 0.7325\n",
      "Epoch 518/600\n",
      "3730/3730 [==============================] - 0s 74us/step - loss: 0.4796 - acc: 0.7566 - val_loss: 0.5152 - val_acc: 0.7325\n",
      "Epoch 519/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4795 - acc: 0.7542 - val_loss: 0.5125 - val_acc: 0.7373\n",
      "Epoch 520/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4809 - acc: 0.7528 - val_loss: 0.5175 - val_acc: 0.7301\n",
      "Epoch 521/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4804 - acc: 0.7517 - val_loss: 0.5165 - val_acc: 0.7325\n",
      "Epoch 522/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4792 - acc: 0.7582 - val_loss: 0.5124 - val_acc: 0.7398\n",
      "Epoch 523/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4804 - acc: 0.7485 - val_loss: 0.5156 - val_acc: 0.7277\n",
      "Epoch 524/600\n",
      "3730/3730 [==============================] - 0s 74us/step - loss: 0.4796 - acc: 0.7547 - val_loss: 0.5177 - val_acc: 0.7253\n",
      "Epoch 525/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4808 - acc: 0.7515 - val_loss: 0.5160 - val_acc: 0.7349\n",
      "Epoch 526/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4791 - acc: 0.7523 - val_loss: 0.5151 - val_acc: 0.7325\n",
      "Epoch 527/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4800 - acc: 0.7563 - val_loss: 0.5146 - val_acc: 0.7349\n",
      "Epoch 528/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4805 - acc: 0.7488 - val_loss: 0.5155 - val_acc: 0.7349\n",
      "Epoch 529/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4793 - acc: 0.7536 - val_loss: 0.5168 - val_acc: 0.7325\n",
      "Epoch 530/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4810 - acc: 0.7531 - val_loss: 0.5148 - val_acc: 0.7373\n",
      "Epoch 531/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4800 - acc: 0.7560 - val_loss: 0.5161 - val_acc: 0.7325\n",
      "Epoch 532/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4797 - acc: 0.7582 - val_loss: 0.5176 - val_acc: 0.7277\n",
      "Epoch 533/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4811 - acc: 0.7520 - val_loss: 0.5161 - val_acc: 0.7349\n",
      "Epoch 534/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4806 - acc: 0.7558 - val_loss: 0.5161 - val_acc: 0.7325\n",
      "Epoch 535/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4799 - acc: 0.7528 - val_loss: 0.5142 - val_acc: 0.7373\n",
      "Epoch 536/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4796 - acc: 0.7520 - val_loss: 0.5163 - val_acc: 0.7325\n",
      "Epoch 537/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4800 - acc: 0.7523 - val_loss: 0.5149 - val_acc: 0.7349\n",
      "Epoch 538/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4794 - acc: 0.7552 - val_loss: 0.5168 - val_acc: 0.7301\n",
      "Epoch 539/600\n",
      "3730/3730 [==============================] - 0s 89us/step - loss: 0.4801 - acc: 0.7534 - val_loss: 0.5158 - val_acc: 0.7349\n",
      "Epoch 540/600\n",
      "3730/3730 [==============================] - 0s 90us/step - loss: 0.4792 - acc: 0.7531 - val_loss: 0.5182 - val_acc: 0.7253\n",
      "Epoch 541/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4797 - acc: 0.7525 - val_loss: 0.5160 - val_acc: 0.7325\n",
      "Epoch 542/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4798 - acc: 0.7520 - val_loss: 0.5165 - val_acc: 0.7325\n",
      "Epoch 543/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4792 - acc: 0.7501 - val_loss: 0.5152 - val_acc: 0.7398\n",
      "Epoch 544/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4807 - acc: 0.7512 - val_loss: 0.5189 - val_acc: 0.7301\n",
      "Epoch 545/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4797 - acc: 0.7560 - val_loss: 0.5177 - val_acc: 0.7301\n",
      "Epoch 546/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4803 - acc: 0.7520 - val_loss: 0.5161 - val_acc: 0.7349\n",
      "Epoch 547/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.4793 - acc: 0.7536 - val_loss: 0.5164 - val_acc: 0.7325\n",
      "Epoch 548/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4791 - acc: 0.7571 - val_loss: 0.5147 - val_acc: 0.7373\n",
      "Epoch 549/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.4797 - acc: 0.7504 - val_loss: 0.5150 - val_acc: 0.7349\n",
      "Epoch 550/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4805 - acc: 0.7520 - val_loss: 0.5140 - val_acc: 0.7373\n",
      "Epoch 551/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4796 - acc: 0.7512 - val_loss: 0.5172 - val_acc: 0.7301\n",
      "Epoch 552/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4793 - acc: 0.7555 - val_loss: 0.5163 - val_acc: 0.7349\n",
      "Epoch 553/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.4802 - acc: 0.7542 - val_loss: 0.5147 - val_acc: 0.7373\n",
      "Epoch 554/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4793 - acc: 0.7536 - val_loss: 0.5175 - val_acc: 0.7325\n",
      "Epoch 555/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4799 - acc: 0.7525 - val_loss: 0.5166 - val_acc: 0.7349\n",
      "Epoch 556/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4794 - acc: 0.7485 - val_loss: 0.5188 - val_acc: 0.7301\n",
      "Epoch 557/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4793 - acc: 0.7550 - val_loss: 0.5162 - val_acc: 0.7349\n",
      "Epoch 558/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4794 - acc: 0.7528 - val_loss: 0.5176 - val_acc: 0.7301\n",
      "Epoch 559/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4798 - acc: 0.7550 - val_loss: 0.5170 - val_acc: 0.7301\n",
      "Epoch 560/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4794 - acc: 0.7528 - val_loss: 0.5152 - val_acc: 0.7373\n",
      "Epoch 561/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4807 - acc: 0.7504 - val_loss: 0.5164 - val_acc: 0.7301\n",
      "Epoch 562/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4793 - acc: 0.7517 - val_loss: 0.5173 - val_acc: 0.7301\n",
      "Epoch 563/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4793 - acc: 0.7550 - val_loss: 0.5166 - val_acc: 0.7301\n",
      "Epoch 564/600\n",
      "3730/3730 [==============================] - 0s 74us/step - loss: 0.4795 - acc: 0.7582 - val_loss: 0.5174 - val_acc: 0.7301\n",
      "Epoch 565/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4797 - acc: 0.7507 - val_loss: 0.5162 - val_acc: 0.7349\n",
      "Epoch 566/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4796 - acc: 0.7525 - val_loss: 0.5161 - val_acc: 0.7325\n",
      "Epoch 567/600\n",
      "3730/3730 [==============================] - 0s 74us/step - loss: 0.4796 - acc: 0.7547 - val_loss: 0.5174 - val_acc: 0.7349\n",
      "Epoch 568/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4789 - acc: 0.7517 - val_loss: 0.5158 - val_acc: 0.7373\n",
      "Epoch 569/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4801 - acc: 0.7531 - val_loss: 0.5155 - val_acc: 0.7373\n",
      "Epoch 570/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.4797 - acc: 0.7560 - val_loss: 0.5195 - val_acc: 0.7229\n",
      "Epoch 571/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4789 - acc: 0.7528 - val_loss: 0.5156 - val_acc: 0.7398\n",
      "Epoch 572/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4797 - acc: 0.7550 - val_loss: 0.5161 - val_acc: 0.7301\n",
      "Epoch 573/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4794 - acc: 0.7523 - val_loss: 0.5161 - val_acc: 0.7325\n",
      "Epoch 574/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4791 - acc: 0.7536 - val_loss: 0.5162 - val_acc: 0.7349\n",
      "Epoch 575/600\n",
      "3730/3730 [==============================] - 0s 94us/step - loss: 0.4786 - acc: 0.7536 - val_loss: 0.5152 - val_acc: 0.7398\n",
      "Epoch 576/600\n",
      "3730/3730 [==============================] - 0s 101us/step - loss: 0.4791 - acc: 0.7520 - val_loss: 0.5167 - val_acc: 0.7373\n",
      "Epoch 577/600\n",
      "3730/3730 [==============================] - 0s 83us/step - loss: 0.4795 - acc: 0.7539 - val_loss: 0.5172 - val_acc: 0.7373\n",
      "Epoch 578/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4795 - acc: 0.7539 - val_loss: 0.5158 - val_acc: 0.7398\n",
      "Epoch 579/600\n",
      "3730/3730 [==============================] - 0s 92us/step - loss: 0.4809 - acc: 0.7534 - val_loss: 0.5177 - val_acc: 0.7349\n",
      "Epoch 580/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4790 - acc: 0.7542 - val_loss: 0.5191 - val_acc: 0.7301\n",
      "Epoch 581/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4789 - acc: 0.7525 - val_loss: 0.5170 - val_acc: 0.7349\n",
      "Epoch 582/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4793 - acc: 0.7528 - val_loss: 0.5168 - val_acc: 0.7373\n",
      "Epoch 583/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4791 - acc: 0.7512 - val_loss: 0.5195 - val_acc: 0.7277\n",
      "Epoch 584/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4789 - acc: 0.7542 - val_loss: 0.5163 - val_acc: 0.7398\n",
      "Epoch 585/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4799 - acc: 0.7507 - val_loss: 0.5168 - val_acc: 0.7349\n",
      "Epoch 586/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4798 - acc: 0.7523 - val_loss: 0.5168 - val_acc: 0.7301\n",
      "Epoch 587/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4793 - acc: 0.7544 - val_loss: 0.5150 - val_acc: 0.7373\n",
      "Epoch 588/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4786 - acc: 0.7536 - val_loss: 0.5137 - val_acc: 0.7398\n",
      "Epoch 589/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4810 - acc: 0.7534 - val_loss: 0.5155 - val_acc: 0.7349\n",
      "Epoch 590/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4789 - acc: 0.7531 - val_loss: 0.5144 - val_acc: 0.7398\n",
      "Epoch 591/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4796 - acc: 0.7542 - val_loss: 0.5154 - val_acc: 0.7398\n",
      "Epoch 592/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4793 - acc: 0.7544 - val_loss: 0.5165 - val_acc: 0.7349\n",
      "Epoch 593/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4794 - acc: 0.7520 - val_loss: 0.5157 - val_acc: 0.7398\n",
      "Epoch 594/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4796 - acc: 0.7504 - val_loss: 0.5157 - val_acc: 0.7373\n",
      "Epoch 595/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4791 - acc: 0.7574 - val_loss: 0.5156 - val_acc: 0.7373\n",
      "Epoch 596/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4785 - acc: 0.7547 - val_loss: 0.5174 - val_acc: 0.7325\n",
      "Epoch 597/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4801 - acc: 0.7523 - val_loss: 0.5154 - val_acc: 0.7373\n",
      "Epoch 598/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4794 - acc: 0.7525 - val_loss: 0.5180 - val_acc: 0.7301\n",
      "Epoch 599/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4795 - acc: 0.7544 - val_loss: 0.5172 - val_acc: 0.7325\n",
      "Epoch 600/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.4805 - acc: 0.7547 - val_loss: 0.5155 - val_acc: 0.7349\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(8, kernel_initializer='normal', input_dim=len(X[0]), activation='relu'))\n",
    "model.add(Dense(8, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X, y.values, epochs=600, validation_split = 0.1)\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-11T19:38:39.748281Z",
     "start_time": "2019-09-11T19:35:33.809228Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3730 samples, validate on 415 samples\n",
      "Epoch 1/600\n",
      "3730/3730 [==============================] - 2s 559us/step - loss: 0.6835 - acc: 0.5330 - val_loss: 0.6715 - val_acc: 0.4892\n",
      "Epoch 2/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.6381 - acc: 0.5700 - val_loss: 0.6345 - val_acc: 0.6602\n",
      "Epoch 3/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.6079 - acc: 0.7064 - val_loss: 0.6173 - val_acc: 0.6892\n",
      "Epoch 4/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5879 - acc: 0.7220 - val_loss: 0.6123 - val_acc: 0.6916\n",
      "Epoch 5/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5761 - acc: 0.7287 - val_loss: 0.6080 - val_acc: 0.6940\n",
      "Epoch 6/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5685 - acc: 0.7298 - val_loss: 0.6016 - val_acc: 0.7036\n",
      "Epoch 7/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5616 - acc: 0.7319 - val_loss: 0.5955 - val_acc: 0.7084\n",
      "Epoch 8/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5562 - acc: 0.7300 - val_loss: 0.5836 - val_acc: 0.7157\n",
      "Epoch 9/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5518 - acc: 0.7332 - val_loss: 0.5808 - val_acc: 0.7084\n",
      "Epoch 10/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5480 - acc: 0.7354 - val_loss: 0.5766 - val_acc: 0.7133\n",
      "Epoch 11/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5451 - acc: 0.7338 - val_loss: 0.5722 - val_acc: 0.7157\n",
      "Epoch 12/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5425 - acc: 0.7381 - val_loss: 0.5718 - val_acc: 0.7229\n",
      "Epoch 13/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5399 - acc: 0.7373 - val_loss: 0.5704 - val_acc: 0.7253\n",
      "Epoch 14/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5383 - acc: 0.7365 - val_loss: 0.5649 - val_acc: 0.7325\n",
      "Epoch 15/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5369 - acc: 0.7357 - val_loss: 0.5616 - val_acc: 0.7325\n",
      "Epoch 16/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5353 - acc: 0.7386 - val_loss: 0.5622 - val_acc: 0.7349\n",
      "Epoch 17/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5341 - acc: 0.7397 - val_loss: 0.5602 - val_acc: 0.7325\n",
      "Epoch 18/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5334 - acc: 0.7365 - val_loss: 0.5582 - val_acc: 0.7349\n",
      "Epoch 19/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5317 - acc: 0.7391 - val_loss: 0.5583 - val_acc: 0.7325\n",
      "Epoch 20/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5316 - acc: 0.7383 - val_loss: 0.5548 - val_acc: 0.7373\n",
      "Epoch 21/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5305 - acc: 0.7410 - val_loss: 0.5530 - val_acc: 0.7373\n",
      "Epoch 22/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5304 - acc: 0.7386 - val_loss: 0.5529 - val_acc: 0.7373\n",
      "Epoch 23/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5296 - acc: 0.7391 - val_loss: 0.5532 - val_acc: 0.7349\n",
      "Epoch 24/600\n",
      "3730/3730 [==============================] - 0s 84us/step - loss: 0.5295 - acc: 0.7373 - val_loss: 0.5505 - val_acc: 0.7373\n",
      "Epoch 25/600\n",
      "3730/3730 [==============================] - 0s 95us/step - loss: 0.5290 - acc: 0.7373 - val_loss: 0.5486 - val_acc: 0.7398\n",
      "Epoch 26/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5287 - acc: 0.7381 - val_loss: 0.5483 - val_acc: 0.7398\n",
      "Epoch 27/600\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.5279 - acc: 0.7386 - val_loss: 0.5486 - val_acc: 0.7373\n",
      "Epoch 28/600\n",
      "3730/3730 [==============================] - 0s 87us/step - loss: 0.5275 - acc: 0.7386 - val_loss: 0.5474 - val_acc: 0.7373\n",
      "Epoch 29/600\n",
      "3730/3730 [==============================] - 0s 93us/step - loss: 0.5274 - acc: 0.7391 - val_loss: 0.5461 - val_acc: 0.7373\n",
      "Epoch 30/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5270 - acc: 0.7386 - val_loss: 0.5467 - val_acc: 0.7349\n",
      "Epoch 31/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5266 - acc: 0.7410 - val_loss: 0.5453 - val_acc: 0.7373\n",
      "Epoch 32/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5264 - acc: 0.7383 - val_loss: 0.5442 - val_acc: 0.7325\n",
      "Epoch 33/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5262 - acc: 0.7373 - val_loss: 0.5434 - val_acc: 0.7301\n",
      "Epoch 34/600\n",
      "3730/3730 [==============================] - 0s 87us/step - loss: 0.5258 - acc: 0.7375 - val_loss: 0.5436 - val_acc: 0.7373\n",
      "Epoch 35/600\n",
      "3730/3730 [==============================] - 0s 107us/step - loss: 0.5255 - acc: 0.7397 - val_loss: 0.5438 - val_acc: 0.7398\n",
      "Epoch 36/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5257 - acc: 0.7397 - val_loss: 0.5439 - val_acc: 0.7325\n",
      "Epoch 37/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5253 - acc: 0.7413 - val_loss: 0.5423 - val_acc: 0.7349\n",
      "Epoch 38/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5254 - acc: 0.7397 - val_loss: 0.5416 - val_acc: 0.7349\n",
      "Epoch 39/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5250 - acc: 0.7416 - val_loss: 0.5413 - val_acc: 0.7325\n",
      "Epoch 40/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5249 - acc: 0.7399 - val_loss: 0.5407 - val_acc: 0.7349\n",
      "Epoch 41/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5246 - acc: 0.7410 - val_loss: 0.5409 - val_acc: 0.7325\n",
      "Epoch 42/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5248 - acc: 0.7418 - val_loss: 0.5396 - val_acc: 0.7325\n",
      "Epoch 43/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5239 - acc: 0.7410 - val_loss: 0.5382 - val_acc: 0.7349\n",
      "Epoch 44/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5233 - acc: 0.7408 - val_loss: 0.5379 - val_acc: 0.7349\n",
      "Epoch 45/600\n",
      "3730/3730 [==============================] - 0s 94us/step - loss: 0.5238 - acc: 0.7410 - val_loss: 0.5384 - val_acc: 0.7325\n",
      "Epoch 46/600\n",
      "3730/3730 [==============================] - 0s 93us/step - loss: 0.5230 - acc: 0.7429 - val_loss: 0.5371 - val_acc: 0.7373\n",
      "Epoch 47/600\n",
      "3730/3730 [==============================] - 0s 93us/step - loss: 0.5224 - acc: 0.7432 - val_loss: 0.5373 - val_acc: 0.7325\n",
      "Epoch 48/600\n",
      "3730/3730 [==============================] - 0s 93us/step - loss: 0.5224 - acc: 0.7413 - val_loss: 0.5366 - val_acc: 0.7398\n",
      "Epoch 49/600\n",
      "3730/3730 [==============================] - 0s 85us/step - loss: 0.5217 - acc: 0.7442 - val_loss: 0.5378 - val_acc: 0.7349\n",
      "Epoch 50/600\n",
      "3730/3730 [==============================] - 0s 84us/step - loss: 0.5211 - acc: 0.7434 - val_loss: 0.5355 - val_acc: 0.7349\n",
      "Epoch 51/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5214 - acc: 0.7421 - val_loss: 0.5363 - val_acc: 0.7349\n",
      "Epoch 52/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5207 - acc: 0.7442 - val_loss: 0.5350 - val_acc: 0.7398\n",
      "Epoch 53/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5199 - acc: 0.7416 - val_loss: 0.5341 - val_acc: 0.7301\n",
      "Epoch 54/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5202 - acc: 0.7426 - val_loss: 0.5342 - val_acc: 0.7325\n",
      "Epoch 55/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5191 - acc: 0.7418 - val_loss: 0.5339 - val_acc: 0.7325\n",
      "Epoch 56/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5192 - acc: 0.7426 - val_loss: 0.5347 - val_acc: 0.7277\n",
      "Epoch 57/600\n",
      "3730/3730 [==============================] - 0s 93us/step - loss: 0.5185 - acc: 0.7410 - val_loss: 0.5329 - val_acc: 0.7301\n",
      "Epoch 58/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5183 - acc: 0.7426 - val_loss: 0.5331 - val_acc: 0.7253\n",
      "Epoch 59/600\n",
      "3730/3730 [==============================] - 0s 87us/step - loss: 0.5177 - acc: 0.7434 - val_loss: 0.5322 - val_acc: 0.7229\n",
      "Epoch 60/600\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.5175 - acc: 0.7418 - val_loss: 0.5321 - val_acc: 0.7229\n",
      "Epoch 61/600\n",
      "3730/3730 [==============================] - 0s 83us/step - loss: 0.5168 - acc: 0.7421 - val_loss: 0.5309 - val_acc: 0.7253\n",
      "Epoch 62/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5165 - acc: 0.7410 - val_loss: 0.5314 - val_acc: 0.7277\n",
      "Epoch 63/600\n",
      "3730/3730 [==============================] - 0s 87us/step - loss: 0.5164 - acc: 0.7424 - val_loss: 0.5307 - val_acc: 0.7229\n",
      "Epoch 64/600\n",
      "3730/3730 [==============================] - 0s 89us/step - loss: 0.5160 - acc: 0.7434 - val_loss: 0.5298 - val_acc: 0.7229\n",
      "Epoch 65/600\n",
      "3730/3730 [==============================] - 0s 85us/step - loss: 0.5158 - acc: 0.7410 - val_loss: 0.5287 - val_acc: 0.7277\n",
      "Epoch 66/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5153 - acc: 0.7429 - val_loss: 0.5289 - val_acc: 0.7253\n",
      "Epoch 67/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5151 - acc: 0.7448 - val_loss: 0.5290 - val_acc: 0.7253\n",
      "Epoch 68/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5144 - acc: 0.7421 - val_loss: 0.5283 - val_acc: 0.7301\n",
      "Epoch 69/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5141 - acc: 0.7434 - val_loss: 0.5263 - val_acc: 0.7277\n",
      "Epoch 70/600\n",
      "3730/3730 [==============================] - 0s 96us/step - loss: 0.5141 - acc: 0.7410 - val_loss: 0.5273 - val_acc: 0.7229\n",
      "Epoch 71/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5137 - acc: 0.7429 - val_loss: 0.5259 - val_acc: 0.7253\n",
      "Epoch 72/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5130 - acc: 0.7416 - val_loss: 0.5266 - val_acc: 0.7229\n",
      "Epoch 73/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5133 - acc: 0.7450 - val_loss: 0.5255 - val_acc: 0.7253\n",
      "Epoch 74/600\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.5129 - acc: 0.7416 - val_loss: 0.5247 - val_acc: 0.7253\n",
      "Epoch 75/600\n",
      "3730/3730 [==============================] - 0s 94us/step - loss: 0.5128 - acc: 0.7437 - val_loss: 0.5230 - val_acc: 0.7325\n",
      "Epoch 76/600\n",
      "3730/3730 [==============================] - 0s 87us/step - loss: 0.5121 - acc: 0.7426 - val_loss: 0.5222 - val_acc: 0.7325\n",
      "Epoch 77/600\n",
      "3730/3730 [==============================] - 0s 88us/step - loss: 0.5122 - acc: 0.7456 - val_loss: 0.5222 - val_acc: 0.7301\n",
      "Epoch 78/600\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.5121 - acc: 0.7442 - val_loss: 0.5215 - val_acc: 0.7373\n",
      "Epoch 79/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5118 - acc: 0.7421 - val_loss: 0.5221 - val_acc: 0.7325\n",
      "Epoch 80/600\n",
      "3730/3730 [==============================] - 0s 85us/step - loss: 0.5113 - acc: 0.7440 - val_loss: 0.5205 - val_acc: 0.7349\n",
      "Epoch 81/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5116 - acc: 0.7426 - val_loss: 0.5203 - val_acc: 0.7349\n",
      "Epoch 82/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5110 - acc: 0.7416 - val_loss: 0.5198 - val_acc: 0.7373\n",
      "Epoch 83/600\n",
      "3730/3730 [==============================] - 0s 88us/step - loss: 0.5111 - acc: 0.7424 - val_loss: 0.5195 - val_acc: 0.7373\n",
      "Epoch 84/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5106 - acc: 0.7418 - val_loss: 0.5186 - val_acc: 0.7398\n",
      "Epoch 85/600\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.5105 - acc: 0.7434 - val_loss: 0.5181 - val_acc: 0.7398\n",
      "Epoch 86/600\n",
      "3730/3730 [==============================] - 0s 82us/step - loss: 0.5103 - acc: 0.7434 - val_loss: 0.5184 - val_acc: 0.7373\n",
      "Epoch 87/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5100 - acc: 0.7432 - val_loss: 0.5177 - val_acc: 0.7422\n",
      "Epoch 88/600\n",
      "3730/3730 [==============================] - 0s 92us/step - loss: 0.5102 - acc: 0.7469 - val_loss: 0.5185 - val_acc: 0.7325\n",
      "Epoch 89/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5097 - acc: 0.7442 - val_loss: 0.5163 - val_acc: 0.7446\n",
      "Epoch 90/600\n",
      "3730/3730 [==============================] - 0s 74us/step - loss: 0.5094 - acc: 0.7434 - val_loss: 0.5161 - val_acc: 0.7373\n",
      "Epoch 91/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5093 - acc: 0.7421 - val_loss: 0.5158 - val_acc: 0.7422\n",
      "Epoch 92/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5092 - acc: 0.7432 - val_loss: 0.5167 - val_acc: 0.7373\n",
      "Epoch 93/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5088 - acc: 0.7416 - val_loss: 0.5166 - val_acc: 0.7349\n",
      "Epoch 94/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5084 - acc: 0.7461 - val_loss: 0.5153 - val_acc: 0.7446\n",
      "Epoch 95/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5086 - acc: 0.7442 - val_loss: 0.5162 - val_acc: 0.7398\n",
      "Epoch 96/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5086 - acc: 0.7448 - val_loss: 0.5157 - val_acc: 0.7349\n",
      "Epoch 97/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5082 - acc: 0.7442 - val_loss: 0.5153 - val_acc: 0.7398\n",
      "Epoch 98/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5084 - acc: 0.7424 - val_loss: 0.5156 - val_acc: 0.7373\n",
      "Epoch 99/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5081 - acc: 0.7413 - val_loss: 0.5152 - val_acc: 0.7349\n",
      "Epoch 100/600\n",
      "3730/3730 [==============================] - 0s 83us/step - loss: 0.5080 - acc: 0.7421 - val_loss: 0.5144 - val_acc: 0.7446\n",
      "Epoch 101/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5079 - acc: 0.7456 - val_loss: 0.5144 - val_acc: 0.7446\n",
      "Epoch 102/600\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.5078 - acc: 0.7426 - val_loss: 0.5146 - val_acc: 0.7349\n",
      "Epoch 103/600\n",
      "3730/3730 [==============================] - 0s 107us/step - loss: 0.5078 - acc: 0.7453 - val_loss: 0.5151 - val_acc: 0.7398\n",
      "Epoch 104/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5075 - acc: 0.7442 - val_loss: 0.5145 - val_acc: 0.7398\n",
      "Epoch 105/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5071 - acc: 0.7456 - val_loss: 0.5136 - val_acc: 0.7398\n",
      "Epoch 106/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5075 - acc: 0.7442 - val_loss: 0.5135 - val_acc: 0.7398\n",
      "Epoch 107/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5072 - acc: 0.7445 - val_loss: 0.5131 - val_acc: 0.7422\n",
      "Epoch 108/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5071 - acc: 0.7437 - val_loss: 0.5142 - val_acc: 0.7373\n",
      "Epoch 109/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5072 - acc: 0.7440 - val_loss: 0.5141 - val_acc: 0.7422\n",
      "Epoch 110/600\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.5072 - acc: 0.7445 - val_loss: 0.5142 - val_acc: 0.7422\n",
      "Epoch 111/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5074 - acc: 0.7458 - val_loss: 0.5151 - val_acc: 0.7398\n",
      "Epoch 112/600\n",
      "3730/3730 [==============================] - 0s 83us/step - loss: 0.5071 - acc: 0.7442 - val_loss: 0.5152 - val_acc: 0.7325\n",
      "Epoch 113/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5068 - acc: 0.7440 - val_loss: 0.5129 - val_acc: 0.7398\n",
      "Epoch 114/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5068 - acc: 0.7437 - val_loss: 0.5137 - val_acc: 0.7373\n",
      "Epoch 115/600\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.5065 - acc: 0.7445 - val_loss: 0.5128 - val_acc: 0.7373\n",
      "Epoch 116/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5065 - acc: 0.7434 - val_loss: 0.5137 - val_acc: 0.7398\n",
      "Epoch 117/600\n",
      "3730/3730 [==============================] - 0s 82us/step - loss: 0.5065 - acc: 0.7448 - val_loss: 0.5142 - val_acc: 0.7373\n",
      "Epoch 118/600\n",
      "3730/3730 [==============================] - 0s 87us/step - loss: 0.5062 - acc: 0.7426 - val_loss: 0.5134 - val_acc: 0.7349\n",
      "Epoch 119/600\n",
      "3730/3730 [==============================] - 0s 87us/step - loss: 0.5064 - acc: 0.7448 - val_loss: 0.5139 - val_acc: 0.7422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5060 - acc: 0.7426 - val_loss: 0.5136 - val_acc: 0.7422\n",
      "Epoch 121/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5059 - acc: 0.7432 - val_loss: 0.5137 - val_acc: 0.7373\n",
      "Epoch 122/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5066 - acc: 0.7429 - val_loss: 0.5131 - val_acc: 0.7325\n",
      "Epoch 123/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5066 - acc: 0.7416 - val_loss: 0.5141 - val_acc: 0.7373\n",
      "Epoch 124/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5057 - acc: 0.7424 - val_loss: 0.5135 - val_acc: 0.7325\n",
      "Epoch 125/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5059 - acc: 0.7437 - val_loss: 0.5142 - val_acc: 0.7398\n",
      "Epoch 126/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5060 - acc: 0.7429 - val_loss: 0.5129 - val_acc: 0.7373\n",
      "Epoch 127/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5057 - acc: 0.7391 - val_loss: 0.5139 - val_acc: 0.7373\n",
      "Epoch 128/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5053 - acc: 0.7410 - val_loss: 0.5154 - val_acc: 0.7373\n",
      "Epoch 129/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5057 - acc: 0.7426 - val_loss: 0.5151 - val_acc: 0.7422\n",
      "Epoch 130/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5052 - acc: 0.7429 - val_loss: 0.5139 - val_acc: 0.7398\n",
      "Epoch 131/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5053 - acc: 0.7408 - val_loss: 0.5145 - val_acc: 0.7422\n",
      "Epoch 132/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5052 - acc: 0.7426 - val_loss: 0.5144 - val_acc: 0.7349\n",
      "Epoch 133/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5048 - acc: 0.7416 - val_loss: 0.5166 - val_acc: 0.7398\n",
      "Epoch 134/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5051 - acc: 0.7424 - val_loss: 0.5149 - val_acc: 0.7373\n",
      "Epoch 135/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5049 - acc: 0.7408 - val_loss: 0.5167 - val_acc: 0.7373\n",
      "Epoch 136/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5052 - acc: 0.7416 - val_loss: 0.5157 - val_acc: 0.7373\n",
      "Epoch 137/600\n",
      "3730/3730 [==============================] - 0s 85us/step - loss: 0.5049 - acc: 0.7421 - val_loss: 0.5150 - val_acc: 0.7373\n",
      "Epoch 138/600\n",
      "3730/3730 [==============================] - 0s 91us/step - loss: 0.5051 - acc: 0.7408 - val_loss: 0.5141 - val_acc: 0.7398\n",
      "Epoch 139/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5051 - acc: 0.7410 - val_loss: 0.5151 - val_acc: 0.7349\n",
      "Epoch 140/600\n",
      "3730/3730 [==============================] - 0s 88us/step - loss: 0.5049 - acc: 0.7397 - val_loss: 0.5145 - val_acc: 0.7325\n",
      "Epoch 141/600\n",
      "3730/3730 [==============================] - 0s 99us/step - loss: 0.5046 - acc: 0.7426 - val_loss: 0.5148 - val_acc: 0.7373\n",
      "Epoch 142/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5046 - acc: 0.7402 - val_loss: 0.5146 - val_acc: 0.7398\n",
      "Epoch 143/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5048 - acc: 0.7399 - val_loss: 0.5147 - val_acc: 0.7398\n",
      "Epoch 144/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5047 - acc: 0.7421 - val_loss: 0.5141 - val_acc: 0.7398\n",
      "Epoch 145/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5043 - acc: 0.7418 - val_loss: 0.5163 - val_acc: 0.7373\n",
      "Epoch 146/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5041 - acc: 0.7402 - val_loss: 0.5162 - val_acc: 0.7422\n",
      "Epoch 147/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5045 - acc: 0.7389 - val_loss: 0.5179 - val_acc: 0.7373\n",
      "Epoch 148/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5040 - acc: 0.7378 - val_loss: 0.5180 - val_acc: 0.7349\n",
      "Epoch 149/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5041 - acc: 0.7408 - val_loss: 0.5182 - val_acc: 0.7349\n",
      "Epoch 150/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5044 - acc: 0.7370 - val_loss: 0.5170 - val_acc: 0.7325\n",
      "Epoch 151/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5037 - acc: 0.7421 - val_loss: 0.5167 - val_acc: 0.7349\n",
      "Epoch 152/600\n",
      "3730/3730 [==============================] - 0s 74us/step - loss: 0.5039 - acc: 0.7397 - val_loss: 0.5198 - val_acc: 0.7398\n",
      "Epoch 153/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5037 - acc: 0.7399 - val_loss: 0.5156 - val_acc: 0.7301\n",
      "Epoch 154/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5039 - acc: 0.7405 - val_loss: 0.5172 - val_acc: 0.7301\n",
      "Epoch 155/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5043 - acc: 0.7397 - val_loss: 0.5171 - val_acc: 0.7301\n",
      "Epoch 156/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5040 - acc: 0.7378 - val_loss: 0.5156 - val_acc: 0.7301\n",
      "Epoch 157/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5040 - acc: 0.7386 - val_loss: 0.5162 - val_acc: 0.7253\n",
      "Epoch 158/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5037 - acc: 0.7391 - val_loss: 0.5155 - val_acc: 0.7325\n",
      "Epoch 159/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5039 - acc: 0.7418 - val_loss: 0.5176 - val_acc: 0.7301\n",
      "Epoch 160/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5037 - acc: 0.7367 - val_loss: 0.5181 - val_acc: 0.7325\n",
      "Epoch 161/600\n",
      "3730/3730 [==============================] - 0s 84us/step - loss: 0.5032 - acc: 0.7381 - val_loss: 0.5177 - val_acc: 0.7325\n",
      "Epoch 162/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5036 - acc: 0.7381 - val_loss: 0.5186 - val_acc: 0.7373\n",
      "Epoch 163/600\n",
      "3730/3730 [==============================] - 0s 74us/step - loss: 0.5035 - acc: 0.7408 - val_loss: 0.5181 - val_acc: 0.7373\n",
      "Epoch 164/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5036 - acc: 0.7394 - val_loss: 0.5184 - val_acc: 0.7349\n",
      "Epoch 165/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5033 - acc: 0.7408 - val_loss: 0.5173 - val_acc: 0.7325\n",
      "Epoch 166/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5036 - acc: 0.7370 - val_loss: 0.5176 - val_acc: 0.7325\n",
      "Epoch 167/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5039 - acc: 0.7399 - val_loss: 0.5178 - val_acc: 0.7325\n",
      "Epoch 168/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5031 - acc: 0.7386 - val_loss: 0.5179 - val_acc: 0.7325\n",
      "Epoch 169/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5035 - acc: 0.7408 - val_loss: 0.5180 - val_acc: 0.7349\n",
      "Epoch 170/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5036 - acc: 0.7378 - val_loss: 0.5181 - val_acc: 0.7349\n",
      "Epoch 171/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5036 - acc: 0.7386 - val_loss: 0.5178 - val_acc: 0.7373\n",
      "Epoch 172/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5034 - acc: 0.7391 - val_loss: 0.5180 - val_acc: 0.7373\n",
      "Epoch 173/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5033 - acc: 0.7375 - val_loss: 0.5203 - val_acc: 0.7349\n",
      "Epoch 174/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5034 - acc: 0.7399 - val_loss: 0.5176 - val_acc: 0.7373\n",
      "Epoch 175/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5035 - acc: 0.7378 - val_loss: 0.5176 - val_acc: 0.7325\n",
      "Epoch 176/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5036 - acc: 0.7389 - val_loss: 0.5188 - val_acc: 0.7446\n",
      "Epoch 177/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5034 - acc: 0.7421 - val_loss: 0.5179 - val_acc: 0.7301\n",
      "Epoch 178/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5031 - acc: 0.7391 - val_loss: 0.5180 - val_acc: 0.7325\n",
      "Epoch 179/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5033 - acc: 0.7386 - val_loss: 0.5194 - val_acc: 0.7422\n",
      "Epoch 180/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5033 - acc: 0.7399 - val_loss: 0.5175 - val_acc: 0.7301\n",
      "Epoch 181/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5033 - acc: 0.7418 - val_loss: 0.5183 - val_acc: 0.7373\n",
      "Epoch 182/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5030 - acc: 0.7378 - val_loss: 0.5182 - val_acc: 0.7446\n",
      "Epoch 183/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5029 - acc: 0.7397 - val_loss: 0.5190 - val_acc: 0.7422\n",
      "Epoch 184/600\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.5027 - acc: 0.7394 - val_loss: 0.5180 - val_acc: 0.7325\n",
      "Epoch 185/600\n",
      "3730/3730 [==============================] - 0s 86us/step - loss: 0.5030 - acc: 0.7365 - val_loss: 0.5186 - val_acc: 0.7422\n",
      "Epoch 186/600\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.5030 - acc: 0.7394 - val_loss: 0.5189 - val_acc: 0.7398\n",
      "Epoch 187/600\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.5030 - acc: 0.7370 - val_loss: 0.5189 - val_acc: 0.7373\n",
      "Epoch 188/600\n",
      "3730/3730 [==============================] - 0s 85us/step - loss: 0.5032 - acc: 0.7386 - val_loss: 0.5205 - val_acc: 0.7373\n",
      "Epoch 189/600\n",
      "3730/3730 [==============================] - 0s 74us/step - loss: 0.5031 - acc: 0.7421 - val_loss: 0.5188 - val_acc: 0.7446\n",
      "Epoch 190/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5032 - acc: 0.7378 - val_loss: 0.5200 - val_acc: 0.7398\n",
      "Epoch 191/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5027 - acc: 0.7402 - val_loss: 0.5204 - val_acc: 0.7422\n",
      "Epoch 192/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5029 - acc: 0.7421 - val_loss: 0.5204 - val_acc: 0.7422\n",
      "Epoch 193/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5027 - acc: 0.7397 - val_loss: 0.5199 - val_acc: 0.7422\n",
      "Epoch 194/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5029 - acc: 0.7381 - val_loss: 0.5208 - val_acc: 0.7422\n",
      "Epoch 195/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5030 - acc: 0.7421 - val_loss: 0.5211 - val_acc: 0.7422\n",
      "Epoch 196/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5032 - acc: 0.7383 - val_loss: 0.5195 - val_acc: 0.7398\n",
      "Epoch 197/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5026 - acc: 0.7405 - val_loss: 0.5208 - val_acc: 0.7422\n",
      "Epoch 198/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5023 - acc: 0.7397 - val_loss: 0.5206 - val_acc: 0.7422\n",
      "Epoch 199/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5033 - acc: 0.7381 - val_loss: 0.5198 - val_acc: 0.7422\n",
      "Epoch 200/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5033 - acc: 0.7370 - val_loss: 0.5190 - val_acc: 0.7446\n",
      "Epoch 201/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5025 - acc: 0.7402 - val_loss: 0.5189 - val_acc: 0.7446\n",
      "Epoch 202/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5024 - acc: 0.7389 - val_loss: 0.5199 - val_acc: 0.7422\n",
      "Epoch 203/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5028 - acc: 0.7381 - val_loss: 0.5207 - val_acc: 0.7398\n",
      "Epoch 204/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5025 - acc: 0.7405 - val_loss: 0.5195 - val_acc: 0.7422\n",
      "Epoch 205/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5031 - acc: 0.7399 - val_loss: 0.5192 - val_acc: 0.7398\n",
      "Epoch 206/600\n",
      "3730/3730 [==============================] - 0s 87us/step - loss: 0.5023 - acc: 0.7373 - val_loss: 0.5208 - val_acc: 0.7398\n",
      "Epoch 207/600\n",
      "3730/3730 [==============================] - 0s 84us/step - loss: 0.5026 - acc: 0.7399 - val_loss: 0.5205 - val_acc: 0.7398\n",
      "Epoch 208/600\n",
      "3730/3730 [==============================] - 0s 85us/step - loss: 0.5022 - acc: 0.7383 - val_loss: 0.5200 - val_acc: 0.7349\n",
      "Epoch 209/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5025 - acc: 0.7383 - val_loss: 0.5219 - val_acc: 0.7349\n",
      "Epoch 210/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5026 - acc: 0.7391 - val_loss: 0.5212 - val_acc: 0.7398\n",
      "Epoch 211/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5026 - acc: 0.7397 - val_loss: 0.5206 - val_acc: 0.7422\n",
      "Epoch 212/600\n",
      "3730/3730 [==============================] - 0s 89us/step - loss: 0.5022 - acc: 0.7405 - val_loss: 0.5201 - val_acc: 0.7373\n",
      "Epoch 213/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5026 - acc: 0.7391 - val_loss: 0.5194 - val_acc: 0.7398\n",
      "Epoch 214/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5026 - acc: 0.7394 - val_loss: 0.5199 - val_acc: 0.7398\n",
      "Epoch 215/600\n",
      "3730/3730 [==============================] - 0s 94us/step - loss: 0.5028 - acc: 0.7410 - val_loss: 0.5194 - val_acc: 0.7373\n",
      "Epoch 216/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5024 - acc: 0.7381 - val_loss: 0.5204 - val_acc: 0.7349\n",
      "Epoch 217/600\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.5023 - acc: 0.7391 - val_loss: 0.5198 - val_acc: 0.7398\n",
      "Epoch 218/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5022 - acc: 0.7389 - val_loss: 0.5206 - val_acc: 0.7398\n",
      "Epoch 219/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5022 - acc: 0.7397 - val_loss: 0.5226 - val_acc: 0.7373\n",
      "Epoch 220/600\n",
      "3730/3730 [==============================] - 0s 86us/step - loss: 0.5024 - acc: 0.7399 - val_loss: 0.5235 - val_acc: 0.7325\n",
      "Epoch 221/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5026 - acc: 0.7394 - val_loss: 0.5222 - val_acc: 0.7398\n",
      "Epoch 222/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5024 - acc: 0.7391 - val_loss: 0.5215 - val_acc: 0.7422\n",
      "Epoch 223/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5024 - acc: 0.7397 - val_loss: 0.5218 - val_acc: 0.7398\n",
      "Epoch 224/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5025 - acc: 0.7375 - val_loss: 0.5215 - val_acc: 0.7398\n",
      "Epoch 225/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5024 - acc: 0.7375 - val_loss: 0.5219 - val_acc: 0.7373\n",
      "Epoch 226/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5024 - acc: 0.7418 - val_loss: 0.5201 - val_acc: 0.7349\n",
      "Epoch 227/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5026 - acc: 0.7383 - val_loss: 0.5203 - val_acc: 0.7398\n",
      "Epoch 228/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5025 - acc: 0.7389 - val_loss: 0.5206 - val_acc: 0.7349\n",
      "Epoch 229/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5028 - acc: 0.7389 - val_loss: 0.5210 - val_acc: 0.7398\n",
      "Epoch 230/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5027 - acc: 0.7426 - val_loss: 0.5216 - val_acc: 0.7325\n",
      "Epoch 231/600\n",
      "3730/3730 [==============================] - 0s 74us/step - loss: 0.5027 - acc: 0.7373 - val_loss: 0.5210 - val_acc: 0.7398\n",
      "Epoch 232/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5024 - acc: 0.7410 - val_loss: 0.5206 - val_acc: 0.7373\n",
      "Epoch 233/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5020 - acc: 0.7413 - val_loss: 0.5238 - val_acc: 0.7325\n",
      "Epoch 234/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5026 - acc: 0.7399 - val_loss: 0.5213 - val_acc: 0.7349\n",
      "Epoch 235/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5026 - acc: 0.7410 - val_loss: 0.5221 - val_acc: 0.7349\n",
      "Epoch 236/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5029 - acc: 0.7391 - val_loss: 0.5208 - val_acc: 0.7398\n",
      "Epoch 237/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5020 - acc: 0.7413 - val_loss: 0.5225 - val_acc: 0.7325\n",
      "Epoch 238/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5028 - acc: 0.7386 - val_loss: 0.5208 - val_acc: 0.7398\n",
      "Epoch 239/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5022 - acc: 0.7391 - val_loss: 0.5214 - val_acc: 0.7398\n",
      "Epoch 240/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5025 - acc: 0.7402 - val_loss: 0.5204 - val_acc: 0.7373\n",
      "Epoch 241/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5026 - acc: 0.7391 - val_loss: 0.5205 - val_acc: 0.7373\n",
      "Epoch 242/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5022 - acc: 0.7394 - val_loss: 0.5210 - val_acc: 0.7422\n",
      "Epoch 243/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5024 - acc: 0.7391 - val_loss: 0.5209 - val_acc: 0.7398\n",
      "Epoch 244/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5025 - acc: 0.7391 - val_loss: 0.5223 - val_acc: 0.7349\n",
      "Epoch 245/600\n",
      "3730/3730 [==============================] - 0s 85us/step - loss: 0.5023 - acc: 0.7375 - val_loss: 0.5213 - val_acc: 0.7373\n",
      "Epoch 246/600\n",
      "3730/3730 [==============================] - 0s 89us/step - loss: 0.5019 - acc: 0.7397 - val_loss: 0.5228 - val_acc: 0.7349\n",
      "Epoch 247/600\n",
      "3730/3730 [==============================] - 0s 98us/step - loss: 0.5028 - acc: 0.7418 - val_loss: 0.5228 - val_acc: 0.7325\n",
      "Epoch 248/600\n",
      "3730/3730 [==============================] - 0s 82us/step - loss: 0.5021 - acc: 0.7383 - val_loss: 0.5206 - val_acc: 0.7349\n",
      "Epoch 249/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5022 - acc: 0.7402 - val_loss: 0.5201 - val_acc: 0.7373\n",
      "Epoch 250/600\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.5021 - acc: 0.7394 - val_loss: 0.5205 - val_acc: 0.7325\n",
      "Epoch 251/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5025 - acc: 0.7383 - val_loss: 0.5218 - val_acc: 0.7398\n",
      "Epoch 252/600\n",
      "3730/3730 [==============================] - 0s 90us/step - loss: 0.5027 - acc: 0.7389 - val_loss: 0.5223 - val_acc: 0.7301\n",
      "Epoch 253/600\n",
      "3730/3730 [==============================] - 0s 86us/step - loss: 0.5021 - acc: 0.7402 - val_loss: 0.5213 - val_acc: 0.7373\n",
      "Epoch 254/600\n",
      "3730/3730 [==============================] - 0s 82us/step - loss: 0.5024 - acc: 0.7394 - val_loss: 0.5202 - val_acc: 0.7277\n",
      "Epoch 255/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5025 - acc: 0.7389 - val_loss: 0.5203 - val_acc: 0.7349\n",
      "Epoch 256/600\n",
      "3730/3730 [==============================] - 0s 93us/step - loss: 0.5020 - acc: 0.7399 - val_loss: 0.5220 - val_acc: 0.7301\n",
      "Epoch 257/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5029 - acc: 0.7413 - val_loss: 0.5200 - val_acc: 0.7373\n",
      "Epoch 258/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5026 - acc: 0.7394 - val_loss: 0.5224 - val_acc: 0.7349\n",
      "Epoch 259/600\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.5027 - acc: 0.7394 - val_loss: 0.5208 - val_acc: 0.7325\n",
      "Epoch 260/600\n",
      "3730/3730 [==============================] - 0s 92us/step - loss: 0.5028 - acc: 0.7397 - val_loss: 0.5229 - val_acc: 0.7349\n",
      "Epoch 261/600\n",
      "3730/3730 [==============================] - 0s 83us/step - loss: 0.5022 - acc: 0.7375 - val_loss: 0.5212 - val_acc: 0.7373\n",
      "Epoch 262/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5022 - acc: 0.7383 - val_loss: 0.5231 - val_acc: 0.7325\n",
      "Epoch 263/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5021 - acc: 0.7402 - val_loss: 0.5219 - val_acc: 0.7398\n",
      "Epoch 264/600\n",
      "3730/3730 [==============================] - 0s 85us/step - loss: 0.5028 - acc: 0.7370 - val_loss: 0.5219 - val_acc: 0.7349\n",
      "Epoch 265/600\n",
      "3730/3730 [==============================] - 0s 96us/step - loss: 0.5023 - acc: 0.7418 - val_loss: 0.5208 - val_acc: 0.7373\n",
      "Epoch 266/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5021 - acc: 0.7394 - val_loss: 0.5205 - val_acc: 0.7325\n",
      "Epoch 267/600\n",
      "3730/3730 [==============================] - 0s 92us/step - loss: 0.5025 - acc: 0.7394 - val_loss: 0.5216 - val_acc: 0.7373\n",
      "Epoch 268/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5022 - acc: 0.7386 - val_loss: 0.5211 - val_acc: 0.7349\n",
      "Epoch 269/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5027 - acc: 0.7381 - val_loss: 0.5214 - val_acc: 0.7349\n",
      "Epoch 270/600\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.5023 - acc: 0.7399 - val_loss: 0.5208 - val_acc: 0.7373\n",
      "Epoch 271/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5026 - acc: 0.7389 - val_loss: 0.5211 - val_acc: 0.7349\n",
      "Epoch 272/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5023 - acc: 0.7402 - val_loss: 0.5213 - val_acc: 0.7373\n",
      "Epoch 273/600\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.5021 - acc: 0.7397 - val_loss: 0.5196 - val_acc: 0.7301\n",
      "Epoch 274/600\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.5019 - acc: 0.7370 - val_loss: 0.5220 - val_acc: 0.7373\n",
      "Epoch 275/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5024 - acc: 0.7381 - val_loss: 0.5208 - val_acc: 0.7349\n",
      "Epoch 276/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5022 - acc: 0.7416 - val_loss: 0.5205 - val_acc: 0.7349\n",
      "Epoch 277/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5016 - acc: 0.7405 - val_loss: 0.5211 - val_acc: 0.7373\n",
      "Epoch 278/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5020 - acc: 0.7408 - val_loss: 0.5207 - val_acc: 0.7349\n",
      "Epoch 279/600\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.5024 - acc: 0.7394 - val_loss: 0.5212 - val_acc: 0.7398\n",
      "Epoch 280/600\n",
      "3730/3730 [==============================] - 0s 98us/step - loss: 0.5021 - acc: 0.7394 - val_loss: 0.5227 - val_acc: 0.7349\n",
      "Epoch 281/600\n",
      "3730/3730 [==============================] - 0s 98us/step - loss: 0.5019 - acc: 0.7402 - val_loss: 0.5216 - val_acc: 0.7325\n",
      "Epoch 282/600\n",
      "3730/3730 [==============================] - 0s 95us/step - loss: 0.5020 - acc: 0.7386 - val_loss: 0.5239 - val_acc: 0.7277\n",
      "Epoch 283/600\n",
      "3730/3730 [==============================] - 0s 86us/step - loss: 0.5019 - acc: 0.7391 - val_loss: 0.5220 - val_acc: 0.7373\n",
      "Epoch 284/600\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.5024 - acc: 0.7405 - val_loss: 0.5226 - val_acc: 0.7301\n",
      "Epoch 285/600\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.5023 - acc: 0.7408 - val_loss: 0.5217 - val_acc: 0.7349\n",
      "Epoch 286/600\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.5022 - acc: 0.7383 - val_loss: 0.5237 - val_acc: 0.7301\n",
      "Epoch 287/600\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.5023 - acc: 0.7410 - val_loss: 0.5207 - val_acc: 0.7325\n",
      "Epoch 288/600\n",
      "3730/3730 [==============================] - 0s 82us/step - loss: 0.5020 - acc: 0.7413 - val_loss: 0.5227 - val_acc: 0.7325\n",
      "Epoch 289/600\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.5022 - acc: 0.7421 - val_loss: 0.5216 - val_acc: 0.7349\n",
      "Epoch 290/600\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.5019 - acc: 0.7394 - val_loss: 0.5221 - val_acc: 0.7325\n",
      "Epoch 291/600\n",
      "3730/3730 [==============================] - 0s 87us/step - loss: 0.5019 - acc: 0.7408 - val_loss: 0.5225 - val_acc: 0.7373\n",
      "Epoch 292/600\n",
      "3730/3730 [==============================] - 0s 83us/step - loss: 0.5026 - acc: 0.7429 - val_loss: 0.5220 - val_acc: 0.7325\n",
      "Epoch 293/600\n",
      "3730/3730 [==============================] - 0s 83us/step - loss: 0.5020 - acc: 0.7397 - val_loss: 0.5221 - val_acc: 0.7349\n",
      "Epoch 294/600\n",
      "3730/3730 [==============================] - 0s 91us/step - loss: 0.5020 - acc: 0.7410 - val_loss: 0.5203 - val_acc: 0.7373\n",
      "Epoch 295/600\n",
      "3730/3730 [==============================] - 0s 85us/step - loss: 0.5023 - acc: 0.7370 - val_loss: 0.5223 - val_acc: 0.7325\n",
      "Epoch 296/600\n",
      "3730/3730 [==============================] - 0s 84us/step - loss: 0.5023 - acc: 0.7421 - val_loss: 0.5204 - val_acc: 0.7349\n",
      "Epoch 297/600\n",
      "3730/3730 [==============================] - 0s 93us/step - loss: 0.5019 - acc: 0.7405 - val_loss: 0.5220 - val_acc: 0.7373\n",
      "Epoch 298/600\n",
      "3730/3730 [==============================] - 0s 84us/step - loss: 0.5023 - acc: 0.7375 - val_loss: 0.5219 - val_acc: 0.7373\n",
      "Epoch 299/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5014 - acc: 0.7397 - val_loss: 0.5219 - val_acc: 0.7277\n",
      "Epoch 300/600\n",
      "3730/3730 [==============================] - 0s 88us/step - loss: 0.5024 - acc: 0.7378 - val_loss: 0.5211 - val_acc: 0.7325\n",
      "Epoch 301/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5021 - acc: 0.7397 - val_loss: 0.5213 - val_acc: 0.7325\n",
      "Epoch 302/600\n",
      "3730/3730 [==============================] - 0s 95us/step - loss: 0.5021 - acc: 0.7413 - val_loss: 0.5227 - val_acc: 0.7301\n",
      "Epoch 303/600\n",
      "3730/3730 [==============================] - 0s 102us/step - loss: 0.5021 - acc: 0.7378 - val_loss: 0.5236 - val_acc: 0.7277\n",
      "Epoch 304/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5026 - acc: 0.7399 - val_loss: 0.5242 - val_acc: 0.7277\n",
      "Epoch 305/600\n",
      "3730/3730 [==============================] - 0s 90us/step - loss: 0.5020 - acc: 0.7399 - val_loss: 0.5220 - val_acc: 0.7325\n",
      "Epoch 306/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5021 - acc: 0.7405 - val_loss: 0.5214 - val_acc: 0.7349\n",
      "Epoch 307/600\n",
      "3730/3730 [==============================] - 0s 85us/step - loss: 0.5023 - acc: 0.7397 - val_loss: 0.5202 - val_acc: 0.7373\n",
      "Epoch 308/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5023 - acc: 0.7397 - val_loss: 0.5226 - val_acc: 0.7325\n",
      "Epoch 309/600\n",
      "3730/3730 [==============================] - 0s 91us/step - loss: 0.5020 - acc: 0.7426 - val_loss: 0.5212 - val_acc: 0.7325\n",
      "Epoch 310/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5023 - acc: 0.7378 - val_loss: 0.5223 - val_acc: 0.7373\n",
      "Epoch 311/600\n",
      "3730/3730 [==============================] - 0s 91us/step - loss: 0.5025 - acc: 0.7397 - val_loss: 0.5219 - val_acc: 0.7398\n",
      "Epoch 312/600\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.5017 - acc: 0.7399 - val_loss: 0.5234 - val_acc: 0.7301\n",
      "Epoch 313/600\n",
      "3730/3730 [==============================] - 0s 99us/step - loss: 0.5021 - acc: 0.7378 - val_loss: 0.5231 - val_acc: 0.7277\n",
      "Epoch 314/600\n",
      "3730/3730 [==============================] - 0s 82us/step - loss: 0.5020 - acc: 0.7389 - val_loss: 0.5228 - val_acc: 0.7301\n",
      "Epoch 315/600\n",
      "3730/3730 [==============================] - 0s 96us/step - loss: 0.5020 - acc: 0.7402 - val_loss: 0.5219 - val_acc: 0.7349\n",
      "Epoch 316/600\n",
      "3730/3730 [==============================] - 0s 84us/step - loss: 0.5022 - acc: 0.7391 - val_loss: 0.5208 - val_acc: 0.7301\n",
      "Epoch 317/600\n",
      "3730/3730 [==============================] - 0s 99us/step - loss: 0.5018 - acc: 0.7399 - val_loss: 0.5239 - val_acc: 0.7301\n",
      "Epoch 318/600\n",
      "3730/3730 [==============================] - 0s 83us/step - loss: 0.5029 - acc: 0.7378 - val_loss: 0.5201 - val_acc: 0.7398\n",
      "Epoch 319/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5020 - acc: 0.7405 - val_loss: 0.5214 - val_acc: 0.7325\n",
      "Epoch 320/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5020 - acc: 0.7383 - val_loss: 0.5215 - val_acc: 0.7301\n",
      "Epoch 321/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5020 - acc: 0.7408 - val_loss: 0.5202 - val_acc: 0.7373\n",
      "Epoch 322/600\n",
      "3730/3730 [==============================] - 0s 86us/step - loss: 0.5024 - acc: 0.7391 - val_loss: 0.5207 - val_acc: 0.7349\n",
      "Epoch 323/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5019 - acc: 0.7391 - val_loss: 0.5216 - val_acc: 0.7301\n",
      "Epoch 324/600\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.5018 - acc: 0.7418 - val_loss: 0.5196 - val_acc: 0.7301\n",
      "Epoch 325/600\n",
      "3730/3730 [==============================] - 0s 97us/step - loss: 0.5022 - acc: 0.7399 - val_loss: 0.5212 - val_acc: 0.7325\n",
      "Epoch 326/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5021 - acc: 0.7408 - val_loss: 0.5195 - val_acc: 0.7373\n",
      "Epoch 327/600\n",
      "3730/3730 [==============================] - 0s 84us/step - loss: 0.5026 - acc: 0.7416 - val_loss: 0.5207 - val_acc: 0.7373\n",
      "Epoch 328/600\n",
      "3730/3730 [==============================] - 0s 91us/step - loss: 0.5022 - acc: 0.7391 - val_loss: 0.5213 - val_acc: 0.7373\n",
      "Epoch 329/600\n",
      "3730/3730 [==============================] - 0s 86us/step - loss: 0.5018 - acc: 0.7405 - val_loss: 0.5212 - val_acc: 0.7325\n",
      "Epoch 330/600\n",
      "3730/3730 [==============================] - 0s 87us/step - loss: 0.5025 - acc: 0.7397 - val_loss: 0.5219 - val_acc: 0.7325\n",
      "Epoch 331/600\n",
      "3730/3730 [==============================] - 0s 92us/step - loss: 0.5020 - acc: 0.7408 - val_loss: 0.5216 - val_acc: 0.7349\n",
      "Epoch 332/600\n",
      "3730/3730 [==============================] - 0s 93us/step - loss: 0.5017 - acc: 0.7413 - val_loss: 0.5216 - val_acc: 0.7349\n",
      "Epoch 333/600\n",
      "3730/3730 [==============================] - 0s 96us/step - loss: 0.5020 - acc: 0.7413 - val_loss: 0.5197 - val_acc: 0.7301\n",
      "Epoch 334/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5021 - acc: 0.7397 - val_loss: 0.5201 - val_acc: 0.7373\n",
      "Epoch 335/600\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.5022 - acc: 0.7405 - val_loss: 0.5210 - val_acc: 0.7373\n",
      "Epoch 336/600\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.5017 - acc: 0.7394 - val_loss: 0.5206 - val_acc: 0.7373\n",
      "Epoch 337/600\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.5022 - acc: 0.7408 - val_loss: 0.5206 - val_acc: 0.7373\n",
      "Epoch 338/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5020 - acc: 0.7405 - val_loss: 0.5194 - val_acc: 0.7349\n",
      "Epoch 339/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5020 - acc: 0.7402 - val_loss: 0.5200 - val_acc: 0.7325\n",
      "Epoch 340/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5019 - acc: 0.7402 - val_loss: 0.5208 - val_acc: 0.7373\n",
      "Epoch 341/600\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.5021 - acc: 0.7416 - val_loss: 0.5225 - val_acc: 0.7301\n",
      "Epoch 342/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5020 - acc: 0.7418 - val_loss: 0.5199 - val_acc: 0.7349\n",
      "Epoch 343/600\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.5020 - acc: 0.7389 - val_loss: 0.5215 - val_acc: 0.7349\n",
      "Epoch 344/600\n",
      "3730/3730 [==============================] - 0s 91us/step - loss: 0.5022 - acc: 0.7408 - val_loss: 0.5200 - val_acc: 0.7398\n",
      "Epoch 345/600\n",
      "3730/3730 [==============================] - 0s 87us/step - loss: 0.5011 - acc: 0.7421 - val_loss: 0.5196 - val_acc: 0.7325\n",
      "Epoch 346/600\n",
      "3730/3730 [==============================] - 0s 88us/step - loss: 0.5020 - acc: 0.7397 - val_loss: 0.5196 - val_acc: 0.7373\n",
      "Epoch 347/600\n",
      "3730/3730 [==============================] - 0s 84us/step - loss: 0.5024 - acc: 0.7416 - val_loss: 0.5223 - val_acc: 0.7325\n",
      "Epoch 348/600\n",
      "3730/3730 [==============================] - 0s 86us/step - loss: 0.5020 - acc: 0.7391 - val_loss: 0.5219 - val_acc: 0.7325\n",
      "Epoch 349/600\n",
      "3730/3730 [==============================] - 0s 86us/step - loss: 0.5017 - acc: 0.7397 - val_loss: 0.5226 - val_acc: 0.7373\n",
      "Epoch 350/600\n",
      "3730/3730 [==============================] - 0s 86us/step - loss: 0.5021 - acc: 0.7399 - val_loss: 0.5220 - val_acc: 0.7349\n",
      "Epoch 351/600\n",
      "3730/3730 [==============================] - 0s 85us/step - loss: 0.5024 - acc: 0.7381 - val_loss: 0.5218 - val_acc: 0.7373\n",
      "Epoch 352/600\n",
      "3730/3730 [==============================] - 0s 86us/step - loss: 0.5022 - acc: 0.7418 - val_loss: 0.5208 - val_acc: 0.7325\n",
      "Epoch 353/600\n",
      "3730/3730 [==============================] - 0s 85us/step - loss: 0.5020 - acc: 0.7413 - val_loss: 0.5198 - val_acc: 0.7373\n",
      "Epoch 354/600\n",
      "3730/3730 [==============================] - 0s 83us/step - loss: 0.5019 - acc: 0.7399 - val_loss: 0.5208 - val_acc: 0.7325\n",
      "Epoch 355/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5018 - acc: 0.7408 - val_loss: 0.5218 - val_acc: 0.7325\n",
      "Epoch 356/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3730/3730 [==============================] - 0s 87us/step - loss: 0.5022 - acc: 0.7399 - val_loss: 0.5213 - val_acc: 0.7325\n",
      "Epoch 357/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5021 - acc: 0.7405 - val_loss: 0.5229 - val_acc: 0.7349\n",
      "Epoch 358/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5024 - acc: 0.7402 - val_loss: 0.5228 - val_acc: 0.7325\n",
      "Epoch 359/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5027 - acc: 0.7383 - val_loss: 0.5224 - val_acc: 0.7325\n",
      "Epoch 360/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5019 - acc: 0.7413 - val_loss: 0.5224 - val_acc: 0.7373\n",
      "Epoch 361/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5015 - acc: 0.7378 - val_loss: 0.5248 - val_acc: 0.7277\n",
      "Epoch 362/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5018 - acc: 0.7413 - val_loss: 0.5228 - val_acc: 0.7349\n",
      "Epoch 363/600\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.5025 - acc: 0.7399 - val_loss: 0.5223 - val_acc: 0.7325\n",
      "Epoch 364/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5025 - acc: 0.7381 - val_loss: 0.5235 - val_acc: 0.7277\n",
      "Epoch 365/600\n",
      "3730/3730 [==============================] - 0s 92us/step - loss: 0.5026 - acc: 0.7399 - val_loss: 0.5212 - val_acc: 0.7349\n",
      "Epoch 366/600\n",
      "3730/3730 [==============================] - 0s 86us/step - loss: 0.5020 - acc: 0.7429 - val_loss: 0.5240 - val_acc: 0.7301\n",
      "Epoch 367/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5018 - acc: 0.7408 - val_loss: 0.5233 - val_acc: 0.7349\n",
      "Epoch 368/600\n",
      "3730/3730 [==============================] - 0s 85us/step - loss: 0.5022 - acc: 0.7386 - val_loss: 0.5228 - val_acc: 0.7349\n",
      "Epoch 369/600\n",
      "3730/3730 [==============================] - 0s 90us/step - loss: 0.5021 - acc: 0.7375 - val_loss: 0.5223 - val_acc: 0.7349\n",
      "Epoch 370/600\n",
      "3730/3730 [==============================] - 0s 84us/step - loss: 0.5022 - acc: 0.7413 - val_loss: 0.5242 - val_acc: 0.7325\n",
      "Epoch 371/600\n",
      "3730/3730 [==============================] - 0s 83us/step - loss: 0.5022 - acc: 0.7399 - val_loss: 0.5222 - val_acc: 0.7325\n",
      "Epoch 372/600\n",
      "3730/3730 [==============================] - 0s 90us/step - loss: 0.5017 - acc: 0.7413 - val_loss: 0.5213 - val_acc: 0.7349\n",
      "Epoch 373/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5019 - acc: 0.7426 - val_loss: 0.5214 - val_acc: 0.7349\n",
      "Epoch 374/600\n",
      "3730/3730 [==============================] - 0s 90us/step - loss: 0.5018 - acc: 0.7391 - val_loss: 0.5228 - val_acc: 0.7325\n",
      "Epoch 375/600\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.5018 - acc: 0.7394 - val_loss: 0.5210 - val_acc: 0.7373\n",
      "Epoch 376/600\n",
      "3730/3730 [==============================] - 0s 85us/step - loss: 0.5021 - acc: 0.7399 - val_loss: 0.5214 - val_acc: 0.7349\n",
      "Epoch 377/600\n",
      "3730/3730 [==============================] - 0s 87us/step - loss: 0.5016 - acc: 0.7383 - val_loss: 0.5238 - val_acc: 0.7349\n",
      "Epoch 378/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5018 - acc: 0.7391 - val_loss: 0.5228 - val_acc: 0.7373\n",
      "Epoch 379/600\n",
      "3730/3730 [==============================] - 0s 85us/step - loss: 0.5019 - acc: 0.7386 - val_loss: 0.5224 - val_acc: 0.7373\n",
      "Epoch 380/600\n",
      "3730/3730 [==============================] - 0s 85us/step - loss: 0.5019 - acc: 0.7408 - val_loss: 0.5212 - val_acc: 0.7349\n",
      "Epoch 381/600\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.5018 - acc: 0.7410 - val_loss: 0.5204 - val_acc: 0.7325\n",
      "Epoch 382/600\n",
      "3730/3730 [==============================] - 0s 92us/step - loss: 0.5022 - acc: 0.7410 - val_loss: 0.5247 - val_acc: 0.7253\n",
      "Epoch 383/600\n",
      "3730/3730 [==============================] - 0s 88us/step - loss: 0.5018 - acc: 0.7424 - val_loss: 0.5215 - val_acc: 0.7301\n",
      "Epoch 384/600\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.5023 - acc: 0.7442 - val_loss: 0.5218 - val_acc: 0.7253\n",
      "Epoch 385/600\n",
      "3730/3730 [==============================] - 0s 85us/step - loss: 0.5019 - acc: 0.7399 - val_loss: 0.5213 - val_acc: 0.7277\n",
      "Epoch 386/600\n",
      "3730/3730 [==============================] - 0s 92us/step - loss: 0.5015 - acc: 0.7416 - val_loss: 0.5227 - val_acc: 0.7301\n",
      "Epoch 387/600\n",
      "3730/3730 [==============================] - 0s 91us/step - loss: 0.5017 - acc: 0.7408 - val_loss: 0.5244 - val_acc: 0.7349\n",
      "Epoch 388/600\n",
      "3730/3730 [==============================] - 0s 82us/step - loss: 0.5021 - acc: 0.7405 - val_loss: 0.5247 - val_acc: 0.7301\n",
      "Epoch 389/600\n",
      "3730/3730 [==============================] - 0s 84us/step - loss: 0.5017 - acc: 0.7394 - val_loss: 0.5252 - val_acc: 0.7325\n",
      "Epoch 390/600\n",
      "3730/3730 [==============================] - 0s 87us/step - loss: 0.5018 - acc: 0.7389 - val_loss: 0.5245 - val_acc: 0.7349\n",
      "Epoch 391/600\n",
      "3730/3730 [==============================] - 0s 91us/step - loss: 0.5019 - acc: 0.7416 - val_loss: 0.5227 - val_acc: 0.7277\n",
      "Epoch 392/600\n",
      "3730/3730 [==============================] - 0s 90us/step - loss: 0.5016 - acc: 0.7381 - val_loss: 0.5250 - val_acc: 0.7325\n",
      "Epoch 393/600\n",
      "3730/3730 [==============================] - 0s 85us/step - loss: 0.5021 - acc: 0.7381 - val_loss: 0.5269 - val_acc: 0.7229\n",
      "Epoch 394/600\n",
      "3730/3730 [==============================] - 0s 83us/step - loss: 0.5014 - acc: 0.7394 - val_loss: 0.5267 - val_acc: 0.7205\n",
      "Epoch 395/600\n",
      "3730/3730 [==============================] - 0s 85us/step - loss: 0.5018 - acc: 0.7405 - val_loss: 0.5272 - val_acc: 0.7229\n",
      "Epoch 396/600\n",
      "3730/3730 [==============================] - 0s 90us/step - loss: 0.5019 - acc: 0.7405 - val_loss: 0.5246 - val_acc: 0.7277\n",
      "Epoch 397/600\n",
      "3730/3730 [==============================] - 0s 87us/step - loss: 0.5018 - acc: 0.7402 - val_loss: 0.5265 - val_acc: 0.7277\n",
      "Epoch 398/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5016 - acc: 0.7416 - val_loss: 0.5253 - val_acc: 0.7277\n",
      "Epoch 399/600\n",
      "3730/3730 [==============================] - 0s 93us/step - loss: 0.5016 - acc: 0.7432 - val_loss: 0.5248 - val_acc: 0.7253\n",
      "Epoch 400/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5015 - acc: 0.7397 - val_loss: 0.5257 - val_acc: 0.7205\n",
      "Epoch 401/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5014 - acc: 0.7386 - val_loss: 0.5240 - val_acc: 0.7301\n",
      "Epoch 402/600\n",
      "3730/3730 [==============================] - 0s 91us/step - loss: 0.5016 - acc: 0.7381 - val_loss: 0.5279 - val_acc: 0.7205\n",
      "Epoch 403/600\n",
      "3730/3730 [==============================] - 0s 84us/step - loss: 0.5019 - acc: 0.7402 - val_loss: 0.5252 - val_acc: 0.7253\n",
      "Epoch 404/600\n",
      "3730/3730 [==============================] - 0s 87us/step - loss: 0.5016 - acc: 0.7399 - val_loss: 0.5258 - val_acc: 0.7229\n",
      "Epoch 405/600\n",
      "3730/3730 [==============================] - 0s 83us/step - loss: 0.5012 - acc: 0.7408 - val_loss: 0.5223 - val_acc: 0.7277\n",
      "Epoch 406/600\n",
      "3730/3730 [==============================] - 0s 83us/step - loss: 0.5026 - acc: 0.7413 - val_loss: 0.5274 - val_acc: 0.7205\n",
      "Epoch 407/600\n",
      "3730/3730 [==============================] - 0s 88us/step - loss: 0.5016 - acc: 0.7402 - val_loss: 0.5257 - val_acc: 0.7229\n",
      "Epoch 408/600\n",
      "3730/3730 [==============================] - 0s 85us/step - loss: 0.5016 - acc: 0.7405 - val_loss: 0.5243 - val_acc: 0.7349\n",
      "Epoch 409/600\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.5016 - acc: 0.7394 - val_loss: 0.5254 - val_acc: 0.7253\n",
      "Epoch 410/600\n",
      "3730/3730 [==============================] - 0s 86us/step - loss: 0.5015 - acc: 0.7399 - val_loss: 0.5262 - val_acc: 0.7205\n",
      "Epoch 411/600\n",
      "3730/3730 [==============================] - 0s 92us/step - loss: 0.5018 - acc: 0.7402 - val_loss: 0.5267 - val_acc: 0.7205\n",
      "Epoch 412/600\n",
      "3730/3730 [==============================] - 0s 90us/step - loss: 0.5016 - acc: 0.7408 - val_loss: 0.5272 - val_acc: 0.7205\n",
      "Epoch 413/600\n",
      "3730/3730 [==============================] - 0s 88us/step - loss: 0.5015 - acc: 0.7405 - val_loss: 0.5250 - val_acc: 0.7253\n",
      "Epoch 414/600\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.5015 - acc: 0.7410 - val_loss: 0.5240 - val_acc: 0.7301\n",
      "Epoch 415/600\n",
      "3730/3730 [==============================] - 0s 90us/step - loss: 0.5016 - acc: 0.7394 - val_loss: 0.5231 - val_acc: 0.7277\n",
      "Epoch 416/600\n",
      "3730/3730 [==============================] - 0s 90us/step - loss: 0.5018 - acc: 0.7386 - val_loss: 0.5244 - val_acc: 0.7325\n",
      "Epoch 417/600\n",
      "3730/3730 [==============================] - 0s 87us/step - loss: 0.5015 - acc: 0.7394 - val_loss: 0.5255 - val_acc: 0.7253\n",
      "Epoch 418/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5016 - acc: 0.7394 - val_loss: 0.5255 - val_acc: 0.7205\n",
      "Epoch 419/600\n",
      "3730/3730 [==============================] - 0s 84us/step - loss: 0.5016 - acc: 0.7421 - val_loss: 0.5254 - val_acc: 0.7229\n",
      "Epoch 420/600\n",
      "3730/3730 [==============================] - 0s 86us/step - loss: 0.5017 - acc: 0.7397 - val_loss: 0.5224 - val_acc: 0.7277\n",
      "Epoch 421/600\n",
      "3730/3730 [==============================] - 0s 84us/step - loss: 0.5019 - acc: 0.7394 - val_loss: 0.5251 - val_acc: 0.7301\n",
      "Epoch 422/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5018 - acc: 0.7375 - val_loss: 0.5270 - val_acc: 0.7229\n",
      "Epoch 423/600\n",
      "3730/3730 [==============================] - 0s 91us/step - loss: 0.5016 - acc: 0.7391 - val_loss: 0.5268 - val_acc: 0.7229\n",
      "Epoch 424/600\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.5018 - acc: 0.7389 - val_loss: 0.5240 - val_acc: 0.7301\n",
      "Epoch 425/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5014 - acc: 0.7416 - val_loss: 0.5268 - val_acc: 0.7229\n",
      "Epoch 426/600\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.5017 - acc: 0.7391 - val_loss: 0.5253 - val_acc: 0.7277\n",
      "Epoch 427/600\n",
      "3730/3730 [==============================] - 0s 82us/step - loss: 0.5016 - acc: 0.7394 - val_loss: 0.5239 - val_acc: 0.7325\n",
      "Epoch 428/600\n",
      "3730/3730 [==============================] - 0s 97us/step - loss: 0.5014 - acc: 0.7394 - val_loss: 0.5261 - val_acc: 0.7229\n",
      "Epoch 429/600\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.5017 - acc: 0.7408 - val_loss: 0.5242 - val_acc: 0.7277\n",
      "Epoch 430/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5016 - acc: 0.7386 - val_loss: 0.5275 - val_acc: 0.7157\n",
      "Epoch 431/600\n",
      "3730/3730 [==============================] - 0s 106us/step - loss: 0.5019 - acc: 0.7394 - val_loss: 0.5266 - val_acc: 0.7229\n",
      "Epoch 432/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5016 - acc: 0.7397 - val_loss: 0.5263 - val_acc: 0.7205\n",
      "Epoch 433/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5013 - acc: 0.7402 - val_loss: 0.5251 - val_acc: 0.7277\n",
      "Epoch 434/600\n",
      "3730/3730 [==============================] - 0s 96us/step - loss: 0.5020 - acc: 0.7397 - val_loss: 0.5243 - val_acc: 0.7229\n",
      "Epoch 435/600\n",
      "3730/3730 [==============================] - 0s 83us/step - loss: 0.5020 - acc: 0.7386 - val_loss: 0.5244 - val_acc: 0.7277\n",
      "Epoch 436/600\n",
      "3730/3730 [==============================] - 0s 87us/step - loss: 0.5019 - acc: 0.7399 - val_loss: 0.5260 - val_acc: 0.7229\n",
      "Epoch 437/600\n",
      "3730/3730 [==============================] - 0s 91us/step - loss: 0.5019 - acc: 0.7373 - val_loss: 0.5254 - val_acc: 0.7277\n",
      "Epoch 438/600\n",
      "3730/3730 [==============================] - 0s 86us/step - loss: 0.5018 - acc: 0.7397 - val_loss: 0.5251 - val_acc: 0.7253\n",
      "Epoch 439/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5013 - acc: 0.7381 - val_loss: 0.5270 - val_acc: 0.7133\n",
      "Epoch 440/600\n",
      "3730/3730 [==============================] - 0s 86us/step - loss: 0.5021 - acc: 0.7373 - val_loss: 0.5265 - val_acc: 0.7181\n",
      "Epoch 441/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5016 - acc: 0.7402 - val_loss: 0.5267 - val_acc: 0.7157\n",
      "Epoch 442/600\n",
      "3730/3730 [==============================] - 0s 91us/step - loss: 0.5012 - acc: 0.7418 - val_loss: 0.5240 - val_acc: 0.7277\n",
      "Epoch 443/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5015 - acc: 0.7394 - val_loss: 0.5266 - val_acc: 0.7253\n",
      "Epoch 444/600\n",
      "3730/3730 [==============================] - 0s 82us/step - loss: 0.5012 - acc: 0.7397 - val_loss: 0.5281 - val_acc: 0.7133\n",
      "Epoch 445/600\n",
      "3730/3730 [==============================] - 0s 82us/step - loss: 0.5013 - acc: 0.7440 - val_loss: 0.5240 - val_acc: 0.7277\n",
      "Epoch 446/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5019 - acc: 0.7405 - val_loss: 0.5250 - val_acc: 0.7301\n",
      "Epoch 447/600\n",
      "3730/3730 [==============================] - 0s 90us/step - loss: 0.5014 - acc: 0.7410 - val_loss: 0.5265 - val_acc: 0.7277\n",
      "Epoch 448/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5013 - acc: 0.7389 - val_loss: 0.5255 - val_acc: 0.7253\n",
      "Epoch 449/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5012 - acc: 0.7391 - val_loss: 0.5300 - val_acc: 0.7133\n",
      "Epoch 450/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5016 - acc: 0.7394 - val_loss: 0.5303 - val_acc: 0.7157\n",
      "Epoch 451/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5014 - acc: 0.7375 - val_loss: 0.5262 - val_acc: 0.7325\n",
      "Epoch 452/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5013 - acc: 0.7416 - val_loss: 0.5290 - val_acc: 0.7108\n",
      "Epoch 453/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5014 - acc: 0.7373 - val_loss: 0.5288 - val_acc: 0.7108\n",
      "Epoch 454/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5013 - acc: 0.7432 - val_loss: 0.5262 - val_acc: 0.7205\n",
      "Epoch 455/600\n",
      "3730/3730 [==============================] - 0s 88us/step - loss: 0.5016 - acc: 0.7383 - val_loss: 0.5286 - val_acc: 0.7181\n",
      "Epoch 456/600\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.5014 - acc: 0.7367 - val_loss: 0.5282 - val_acc: 0.7157\n",
      "Epoch 457/600\n",
      "3730/3730 [==============================] - 0s 94us/step - loss: 0.5014 - acc: 0.7413 - val_loss: 0.5276 - val_acc: 0.7277\n",
      "Epoch 458/600\n",
      "3730/3730 [==============================] - 0s 92us/step - loss: 0.5018 - acc: 0.7397 - val_loss: 0.5261 - val_acc: 0.7253\n",
      "Epoch 459/600\n",
      "3730/3730 [==============================] - 0s 83us/step - loss: 0.5013 - acc: 0.7402 - val_loss: 0.5281 - val_acc: 0.7205\n",
      "Epoch 460/600\n",
      "3730/3730 [==============================] - 0s 85us/step - loss: 0.5014 - acc: 0.7373 - val_loss: 0.5277 - val_acc: 0.7157\n",
      "Epoch 461/600\n",
      "3730/3730 [==============================] - 0s 87us/step - loss: 0.5014 - acc: 0.7381 - val_loss: 0.5284 - val_acc: 0.7181\n",
      "Epoch 462/600\n",
      "3730/3730 [==============================] - 0s 101us/step - loss: 0.5017 - acc: 0.7391 - val_loss: 0.5282 - val_acc: 0.7181\n",
      "Epoch 463/600\n",
      "3730/3730 [==============================] - 0s 90us/step - loss: 0.5011 - acc: 0.7410 - val_loss: 0.5269 - val_acc: 0.7253\n",
      "Epoch 464/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5014 - acc: 0.7373 - val_loss: 0.5298 - val_acc: 0.7181\n",
      "Epoch 465/600\n",
      "3730/3730 [==============================] - 0s 93us/step - loss: 0.5017 - acc: 0.7386 - val_loss: 0.5281 - val_acc: 0.7253\n",
      "Epoch 466/600\n",
      "3730/3730 [==============================] - 0s 123us/step - loss: 0.5013 - acc: 0.7394 - val_loss: 0.5272 - val_acc: 0.7253\n",
      "Epoch 467/600\n",
      "3730/3730 [==============================] - 0s 102us/step - loss: 0.5014 - acc: 0.7370 - val_loss: 0.5281 - val_acc: 0.7205\n",
      "Epoch 468/600\n",
      "3730/3730 [==============================] - 0s 83us/step - loss: 0.5013 - acc: 0.7394 - val_loss: 0.5308 - val_acc: 0.7157\n",
      "Epoch 469/600\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.5013 - acc: 0.7389 - val_loss: 0.5285 - val_acc: 0.7133\n",
      "Epoch 470/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5011 - acc: 0.7399 - val_loss: 0.5303 - val_acc: 0.7133\n",
      "Epoch 471/600\n",
      "3730/3730 [==============================] - 0s 90us/step - loss: 0.5011 - acc: 0.7373 - val_loss: 0.5271 - val_acc: 0.7181\n",
      "Epoch 472/600\n",
      "3730/3730 [==============================] - 0s 85us/step - loss: 0.5011 - acc: 0.7397 - val_loss: 0.5328 - val_acc: 0.7157\n",
      "Epoch 473/600\n",
      "3730/3730 [==============================] - 0s 85us/step - loss: 0.5012 - acc: 0.7440 - val_loss: 0.5289 - val_acc: 0.7133\n",
      "Epoch 474/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3730/3730 [==============================] - ETA: 0s - loss: 0.4982 - acc: 0.741 - 0s 82us/step - loss: 0.5016 - acc: 0.7383 - val_loss: 0.5299 - val_acc: 0.7108\n",
      "Epoch 475/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5017 - acc: 0.7386 - val_loss: 0.5315 - val_acc: 0.7157\n",
      "Epoch 476/600\n",
      "3730/3730 [==============================] - 0s 95us/step - loss: 0.5010 - acc: 0.7405 - val_loss: 0.5287 - val_acc: 0.7181\n",
      "Epoch 477/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5013 - acc: 0.7381 - val_loss: 0.5302 - val_acc: 0.7084\n",
      "Epoch 478/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5010 - acc: 0.7381 - val_loss: 0.5306 - val_acc: 0.7108\n",
      "Epoch 479/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5009 - acc: 0.7383 - val_loss: 0.5331 - val_acc: 0.7133\n",
      "Epoch 480/600\n",
      "3730/3730 [==============================] - 0s 82us/step - loss: 0.5013 - acc: 0.7394 - val_loss: 0.5314 - val_acc: 0.7084\n",
      "Epoch 481/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5012 - acc: 0.7416 - val_loss: 0.5313 - val_acc: 0.7133\n",
      "Epoch 482/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5012 - acc: 0.7375 - val_loss: 0.5344 - val_acc: 0.7108\n",
      "Epoch 483/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5011 - acc: 0.7375 - val_loss: 0.5339 - val_acc: 0.7084\n",
      "Epoch 484/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5014 - acc: 0.7378 - val_loss: 0.5357 - val_acc: 0.7181\n",
      "Epoch 485/600\n",
      "3730/3730 [==============================] - 0s 90us/step - loss: 0.5014 - acc: 0.7362 - val_loss: 0.5331 - val_acc: 0.7133\n",
      "Epoch 486/600\n",
      "3730/3730 [==============================] - 0s 82us/step - loss: 0.5011 - acc: 0.7370 - val_loss: 0.5343 - val_acc: 0.7133\n",
      "Epoch 487/600\n",
      "3730/3730 [==============================] - 0s 105us/step - loss: 0.5012 - acc: 0.7405 - val_loss: 0.5327 - val_acc: 0.7084\n",
      "Epoch 488/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5008 - acc: 0.7399 - val_loss: 0.5306 - val_acc: 0.7157\n",
      "Epoch 489/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5009 - acc: 0.7381 - val_loss: 0.5331 - val_acc: 0.7084\n",
      "Epoch 490/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5015 - acc: 0.7381 - val_loss: 0.5348 - val_acc: 0.7108\n",
      "Epoch 491/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5015 - acc: 0.7381 - val_loss: 0.5361 - val_acc: 0.7181\n",
      "Epoch 492/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5009 - acc: 0.7378 - val_loss: 0.5367 - val_acc: 0.7157\n",
      "Epoch 493/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5011 - acc: 0.7405 - val_loss: 0.5360 - val_acc: 0.7157\n",
      "Epoch 494/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5013 - acc: 0.7381 - val_loss: 0.5347 - val_acc: 0.7133\n",
      "Epoch 495/600\n",
      "3730/3730 [==============================] - 0s 99us/step - loss: 0.5011 - acc: 0.7378 - val_loss: 0.5316 - val_acc: 0.7108\n",
      "Epoch 496/600\n",
      "3730/3730 [==============================] - 0s 95us/step - loss: 0.5008 - acc: 0.7383 - val_loss: 0.5344 - val_acc: 0.7084\n",
      "Epoch 497/600\n",
      "3730/3730 [==============================] - 0s 83us/step - loss: 0.5008 - acc: 0.7391 - val_loss: 0.5357 - val_acc: 0.7157\n",
      "Epoch 498/600\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.5009 - acc: 0.7402 - val_loss: 0.5331 - val_acc: 0.7084\n",
      "Epoch 499/600\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.5010 - acc: 0.7367 - val_loss: 0.5292 - val_acc: 0.7157\n",
      "Epoch 500/600\n",
      "3730/3730 [==============================] - 0s 82us/step - loss: 0.5008 - acc: 0.7365 - val_loss: 0.5340 - val_acc: 0.7133\n",
      "Epoch 501/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5013 - acc: 0.7408 - val_loss: 0.5336 - val_acc: 0.7108\n",
      "Epoch 502/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5007 - acc: 0.7399 - val_loss: 0.5324 - val_acc: 0.7108\n",
      "Epoch 503/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5006 - acc: 0.7386 - val_loss: 0.5318 - val_acc: 0.7108\n",
      "Epoch 504/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5003 - acc: 0.7399 - val_loss: 0.5389 - val_acc: 0.7181\n",
      "Epoch 505/600\n",
      "3730/3730 [==============================] - 0s 90us/step - loss: 0.5013 - acc: 0.7416 - val_loss: 0.5364 - val_acc: 0.7108\n",
      "Epoch 506/600\n",
      "3730/3730 [==============================] - 0s 85us/step - loss: 0.5005 - acc: 0.7394 - val_loss: 0.5317 - val_acc: 0.7157\n",
      "Epoch 507/600\n",
      "3730/3730 [==============================] - 0s 85us/step - loss: 0.5009 - acc: 0.7362 - val_loss: 0.5331 - val_acc: 0.7084\n",
      "Epoch 508/600\n",
      "3730/3730 [==============================] - 0s 98us/step - loss: 0.5007 - acc: 0.7391 - val_loss: 0.5345 - val_acc: 0.7108\n",
      "Epoch 509/600\n",
      "3730/3730 [==============================] - 0s 74us/step - loss: 0.5007 - acc: 0.7416 - val_loss: 0.5371 - val_acc: 0.7133\n",
      "Epoch 510/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5009 - acc: 0.7416 - val_loss: 0.5353 - val_acc: 0.7133\n",
      "Epoch 511/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5007 - acc: 0.7397 - val_loss: 0.5352 - val_acc: 0.7084\n",
      "Epoch 512/600\n",
      "3730/3730 [==============================] - 0s 90us/step - loss: 0.5008 - acc: 0.7402 - val_loss: 0.5334 - val_acc: 0.7084\n",
      "Epoch 513/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5010 - acc: 0.7410 - val_loss: 0.5342 - val_acc: 0.7084\n",
      "Epoch 514/600\n",
      "3730/3730 [==============================] - 0s 74us/step - loss: 0.5011 - acc: 0.7408 - val_loss: 0.5340 - val_acc: 0.7060\n",
      "Epoch 515/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5007 - acc: 0.7399 - val_loss: 0.5356 - val_acc: 0.7108\n",
      "Epoch 516/600\n",
      "3730/3730 [==============================] - 0s 87us/step - loss: 0.5012 - acc: 0.7402 - val_loss: 0.5350 - val_acc: 0.7108\n",
      "Epoch 517/600\n",
      "3730/3730 [==============================] - 0s 84us/step - loss: 0.5005 - acc: 0.7402 - val_loss: 0.5337 - val_acc: 0.7084\n",
      "Epoch 518/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5013 - acc: 0.7389 - val_loss: 0.5339 - val_acc: 0.7060\n",
      "Epoch 519/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5006 - acc: 0.7383 - val_loss: 0.5346 - val_acc: 0.7108\n",
      "Epoch 520/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5004 - acc: 0.7370 - val_loss: 0.5368 - val_acc: 0.7084\n",
      "Epoch 521/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5013 - acc: 0.7402 - val_loss: 0.5346 - val_acc: 0.7084\n",
      "Epoch 522/600\n",
      "3730/3730 [==============================] - 0s 90us/step - loss: 0.5007 - acc: 0.7402 - val_loss: 0.5347 - val_acc: 0.7108\n",
      "Epoch 523/600\n",
      "3730/3730 [==============================] - 0s 74us/step - loss: 0.5012 - acc: 0.7408 - val_loss: 0.5376 - val_acc: 0.7133\n",
      "Epoch 524/600\n",
      "3730/3730 [==============================] - 0s 90us/step - loss: 0.5007 - acc: 0.7402 - val_loss: 0.5381 - val_acc: 0.7108\n",
      "Epoch 525/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5011 - acc: 0.7399 - val_loss: 0.5336 - val_acc: 0.7108\n",
      "Epoch 526/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5009 - acc: 0.7405 - val_loss: 0.5362 - val_acc: 0.7108\n",
      "Epoch 527/600\n",
      "3730/3730 [==============================] - 0s 96us/step - loss: 0.5009 - acc: 0.7402 - val_loss: 0.5365 - val_acc: 0.7133\n",
      "Epoch 528/600\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.5007 - acc: 0.7413 - val_loss: 0.5360 - val_acc: 0.7133\n",
      "Epoch 529/600\n",
      "3730/3730 [==============================] - 0s 86us/step - loss: 0.5007 - acc: 0.7391 - val_loss: 0.5391 - val_acc: 0.7157\n",
      "Epoch 530/600\n",
      "3730/3730 [==============================] - 0s 85us/step - loss: 0.5006 - acc: 0.7386 - val_loss: 0.5365 - val_acc: 0.7157\n",
      "Epoch 531/600\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.5004 - acc: 0.7413 - val_loss: 0.5378 - val_acc: 0.7133\n",
      "Epoch 532/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5009 - acc: 0.7367 - val_loss: 0.5359 - val_acc: 0.7133\n",
      "Epoch 533/600\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.5006 - acc: 0.7394 - val_loss: 0.5369 - val_acc: 0.7108\n",
      "Epoch 534/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5007 - acc: 0.7386 - val_loss: 0.5338 - val_acc: 0.7084\n",
      "Epoch 535/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5009 - acc: 0.7389 - val_loss: 0.5326 - val_acc: 0.7108\n",
      "Epoch 536/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5009 - acc: 0.7391 - val_loss: 0.5375 - val_acc: 0.7181\n",
      "Epoch 537/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5009 - acc: 0.7386 - val_loss: 0.5356 - val_acc: 0.7084\n",
      "Epoch 538/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5005 - acc: 0.7405 - val_loss: 0.5370 - val_acc: 0.7157\n",
      "Epoch 539/600\n",
      "3730/3730 [==============================] - 0s 86us/step - loss: 0.5004 - acc: 0.7413 - val_loss: 0.5393 - val_acc: 0.7181\n",
      "Epoch 540/600\n",
      "3730/3730 [==============================] - 0s 85us/step - loss: 0.5006 - acc: 0.7402 - val_loss: 0.5376 - val_acc: 0.7157\n",
      "Epoch 541/600\n",
      "3730/3730 [==============================] - 0s 87us/step - loss: 0.5007 - acc: 0.7410 - val_loss: 0.5377 - val_acc: 0.7181\n",
      "Epoch 542/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5003 - acc: 0.7402 - val_loss: 0.5365 - val_acc: 0.7133\n",
      "Epoch 543/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5001 - acc: 0.7399 - val_loss: 0.5357 - val_acc: 0.7060\n",
      "Epoch 544/600\n",
      "3730/3730 [==============================] - 0s 74us/step - loss: 0.5008 - acc: 0.7405 - val_loss: 0.5408 - val_acc: 0.7181\n",
      "Epoch 545/600\n",
      "3730/3730 [==============================] - 0s 89us/step - loss: 0.5003 - acc: 0.7413 - val_loss: 0.5369 - val_acc: 0.7133\n",
      "Epoch 546/600\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.5002 - acc: 0.7410 - val_loss: 0.5417 - val_acc: 0.7157\n",
      "Epoch 547/600\n",
      "3730/3730 [==============================] - 0s 98us/step - loss: 0.5003 - acc: 0.7399 - val_loss: 0.5392 - val_acc: 0.7157\n",
      "Epoch 548/600\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.5005 - acc: 0.7418 - val_loss: 0.5397 - val_acc: 0.7157\n",
      "Epoch 549/600\n",
      "3730/3730 [==============================] - 0s 74us/step - loss: 0.5008 - acc: 0.7416 - val_loss: 0.5392 - val_acc: 0.7181\n",
      "Epoch 550/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5002 - acc: 0.7386 - val_loss: 0.5398 - val_acc: 0.7133\n",
      "Epoch 551/600\n",
      "3730/3730 [==============================] - 0s 90us/step - loss: 0.5005 - acc: 0.7391 - val_loss: 0.5415 - val_acc: 0.7157\n",
      "Epoch 552/600\n",
      "3730/3730 [==============================] - 0s 91us/step - loss: 0.5006 - acc: 0.7399 - val_loss: 0.5362 - val_acc: 0.7108\n",
      "Epoch 553/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5007 - acc: 0.7394 - val_loss: 0.5379 - val_acc: 0.7181\n",
      "Epoch 554/600\n",
      "3730/3730 [==============================] - 0s 82us/step - loss: 0.5005 - acc: 0.7413 - val_loss: 0.5415 - val_acc: 0.7229\n",
      "Epoch 555/600\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.5003 - acc: 0.7418 - val_loss: 0.5399 - val_acc: 0.7157\n",
      "Epoch 556/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5005 - acc: 0.7426 - val_loss: 0.5372 - val_acc: 0.7157\n",
      "Epoch 557/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5009 - acc: 0.7354 - val_loss: 0.5422 - val_acc: 0.7157\n",
      "Epoch 558/600\n",
      "3730/3730 [==============================] - 0s 84us/step - loss: 0.5005 - acc: 0.7421 - val_loss: 0.5356 - val_acc: 0.7108\n",
      "Epoch 559/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5006 - acc: 0.7370 - val_loss: 0.5395 - val_acc: 0.7205\n",
      "Epoch 560/600\n",
      "3730/3730 [==============================] - 0s 74us/step - loss: 0.5003 - acc: 0.7405 - val_loss: 0.5363 - val_acc: 0.7133\n",
      "Epoch 561/600\n",
      "3730/3730 [==============================] - 0s 82us/step - loss: 0.5004 - acc: 0.7408 - val_loss: 0.5369 - val_acc: 0.7157\n",
      "Epoch 562/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5005 - acc: 0.7394 - val_loss: 0.5387 - val_acc: 0.7181\n",
      "Epoch 563/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5002 - acc: 0.7408 - val_loss: 0.5380 - val_acc: 0.7157\n",
      "Epoch 564/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5003 - acc: 0.7402 - val_loss: 0.5388 - val_acc: 0.7133\n",
      "Epoch 565/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5009 - acc: 0.7410 - val_loss: 0.5397 - val_acc: 0.7157\n",
      "Epoch 566/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5004 - acc: 0.7389 - val_loss: 0.5400 - val_acc: 0.7157\n",
      "Epoch 567/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5006 - acc: 0.7421 - val_loss: 0.5429 - val_acc: 0.7157\n",
      "Epoch 568/600\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.5005 - acc: 0.7402 - val_loss: 0.5396 - val_acc: 0.7133\n",
      "Epoch 569/600\n",
      "3730/3730 [==============================] - 0s 106us/step - loss: 0.5004 - acc: 0.7432 - val_loss: 0.5402 - val_acc: 0.7157\n",
      "Epoch 570/600\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.5000 - acc: 0.7381 - val_loss: 0.5421 - val_acc: 0.7133\n",
      "Epoch 571/600\n",
      "3730/3730 [==============================] - 0s 84us/step - loss: 0.5009 - acc: 0.7386 - val_loss: 0.5402 - val_acc: 0.7181\n",
      "Epoch 572/600\n",
      "3730/3730 [==============================] - 0s 92us/step - loss: 0.5004 - acc: 0.7402 - val_loss: 0.5419 - val_acc: 0.7157\n",
      "Epoch 573/600\n",
      "3730/3730 [==============================] - 0s 92us/step - loss: 0.5004 - acc: 0.7399 - val_loss: 0.5420 - val_acc: 0.7157\n",
      "Epoch 574/600\n",
      "3730/3730 [==============================] - 0s 84us/step - loss: 0.5006 - acc: 0.7405 - val_loss: 0.5411 - val_acc: 0.7133\n",
      "Epoch 575/600\n",
      "3730/3730 [==============================] - 0s 90us/step - loss: 0.5005 - acc: 0.7397 - val_loss: 0.5449 - val_acc: 0.7157\n",
      "Epoch 576/600\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.5003 - acc: 0.7402 - val_loss: 0.5409 - val_acc: 0.7181\n",
      "Epoch 577/600\n",
      "3730/3730 [==============================] - 0s 86us/step - loss: 0.5005 - acc: 0.7405 - val_loss: 0.5424 - val_acc: 0.7157\n",
      "Epoch 578/600\n",
      "3730/3730 [==============================] - 0s 85us/step - loss: 0.5003 - acc: 0.7402 - val_loss: 0.5461 - val_acc: 0.7157\n",
      "Epoch 579/600\n",
      "3730/3730 [==============================] - 0s 91us/step - loss: 0.5003 - acc: 0.7413 - val_loss: 0.5450 - val_acc: 0.7157\n",
      "Epoch 580/600\n",
      "3730/3730 [==============================] - 0s 90us/step - loss: 0.5005 - acc: 0.7408 - val_loss: 0.5399 - val_acc: 0.7133\n",
      "Epoch 581/600\n",
      "3730/3730 [==============================] - 0s 92us/step - loss: 0.5004 - acc: 0.7397 - val_loss: 0.5397 - val_acc: 0.7181\n",
      "Epoch 582/600\n",
      "3730/3730 [==============================] - 0s 89us/step - loss: 0.5002 - acc: 0.7429 - val_loss: 0.5389 - val_acc: 0.7133\n",
      "Epoch 583/600\n",
      "3730/3730 [==============================] - 0s 86us/step - loss: 0.5003 - acc: 0.7418 - val_loss: 0.5398 - val_acc: 0.7181\n",
      "Epoch 584/600\n",
      "3730/3730 [==============================] - 0s 83us/step - loss: 0.5003 - acc: 0.7391 - val_loss: 0.5411 - val_acc: 0.7157\n",
      "Epoch 585/600\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.5002 - acc: 0.7391 - val_loss: 0.5402 - val_acc: 0.7133\n",
      "Epoch 586/600\n",
      "3730/3730 [==============================] - 0s 87us/step - loss: 0.5006 - acc: 0.7389 - val_loss: 0.5376 - val_acc: 0.7133\n",
      "Epoch 587/600\n",
      "3730/3730 [==============================] - 0s 88us/step - loss: 0.5007 - acc: 0.7391 - val_loss: 0.5406 - val_acc: 0.7181\n",
      "Epoch 588/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5003 - acc: 0.7381 - val_loss: 0.5412 - val_acc: 0.7157\n",
      "Epoch 589/600\n",
      "3730/3730 [==============================] - 0s 86us/step - loss: 0.5006 - acc: 0.7386 - val_loss: 0.5405 - val_acc: 0.7133\n",
      "Epoch 590/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5002 - acc: 0.7394 - val_loss: 0.5422 - val_acc: 0.7181\n",
      "Epoch 591/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5007 - acc: 0.7413 - val_loss: 0.5440 - val_acc: 0.7181\n",
      "Epoch 592/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5004 - acc: 0.7402 - val_loss: 0.5396 - val_acc: 0.7157\n",
      "Epoch 593/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5003 - acc: 0.7397 - val_loss: 0.5415 - val_acc: 0.7181\n",
      "Epoch 594/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5002 - acc: 0.7389 - val_loss: 0.5388 - val_acc: 0.7108\n",
      "Epoch 595/600\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.5007 - acc: 0.7408 - val_loss: 0.5438 - val_acc: 0.7133\n",
      "Epoch 596/600\n",
      "3730/3730 [==============================] - 0s 86us/step - loss: 0.5008 - acc: 0.7399 - val_loss: 0.5448 - val_acc: 0.7157\n",
      "Epoch 597/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5000 - acc: 0.7429 - val_loss: 0.5441 - val_acc: 0.7181\n",
      "Epoch 598/600\n",
      "3730/3730 [==============================] - 0s 91us/step - loss: 0.5001 - acc: 0.7405 - val_loss: 0.5462 - val_acc: 0.7157\n",
      "Epoch 599/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5002 - acc: 0.7399 - val_loss: 0.5419 - val_acc: 0.7133\n",
      "Epoch 600/600\n",
      "3730/3730 [==============================] - 0s 89us/step - loss: 0.5001 - acc: 0.7408 - val_loss: 0.5420 - val_acc: 0.7133\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(4, kernel_initializer='normal', input_dim=len(X[0]), activation='relu'))\n",
    "model.add(Dense(4, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X, y.values, epochs=600, validation_split = 0.1)\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-11T19:32:19.021540Z",
     "start_time": "2019-09-11T19:29:17.938441Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3730 samples, validate on 415 samples\n",
      "Epoch 1/600\n",
      "3730/3730 [==============================] - 2s 549us/step - loss: 0.6837 - acc: 0.6346 - val_loss: 0.6620 - val_acc: 0.6819\n",
      "Epoch 2/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.6399 - acc: 0.6938 - val_loss: 0.6103 - val_acc: 0.6867\n",
      "Epoch 3/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5952 - acc: 0.7113 - val_loss: 0.5763 - val_acc: 0.6723\n",
      "Epoch 4/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5686 - acc: 0.7225 - val_loss: 0.5628 - val_acc: 0.6771\n",
      "Epoch 5/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5556 - acc: 0.7241 - val_loss: 0.5548 - val_acc: 0.6795\n",
      "Epoch 6/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5485 - acc: 0.7228 - val_loss: 0.5507 - val_acc: 0.6916\n",
      "Epoch 7/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5442 - acc: 0.7252 - val_loss: 0.5490 - val_acc: 0.6843\n",
      "Epoch 8/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.5416 - acc: 0.7249 - val_loss: 0.5458 - val_acc: 0.6916\n",
      "Epoch 9/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5391 - acc: 0.7249 - val_loss: 0.5430 - val_acc: 0.6940\n",
      "Epoch 10/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5375 - acc: 0.7265 - val_loss: 0.5412 - val_acc: 0.6916\n",
      "Epoch 11/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5363 - acc: 0.7265 - val_loss: 0.5418 - val_acc: 0.6916\n",
      "Epoch 12/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5350 - acc: 0.7273 - val_loss: 0.5378 - val_acc: 0.6940\n",
      "Epoch 13/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5331 - acc: 0.7276 - val_loss: 0.5364 - val_acc: 0.6916\n",
      "Epoch 14/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5317 - acc: 0.7298 - val_loss: 0.5413 - val_acc: 0.6819\n",
      "Epoch 15/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5306 - acc: 0.7290 - val_loss: 0.5374 - val_acc: 0.6892\n",
      "Epoch 16/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5294 - acc: 0.7311 - val_loss: 0.5354 - val_acc: 0.6867\n",
      "Epoch 17/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5287 - acc: 0.7324 - val_loss: 0.5356 - val_acc: 0.6867\n",
      "Epoch 18/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5281 - acc: 0.7319 - val_loss: 0.5359 - val_acc: 0.6867\n",
      "Epoch 19/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5273 - acc: 0.7314 - val_loss: 0.5332 - val_acc: 0.6867\n",
      "Epoch 20/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5266 - acc: 0.7316 - val_loss: 0.5349 - val_acc: 0.6892\n",
      "Epoch 21/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5258 - acc: 0.7327 - val_loss: 0.5316 - val_acc: 0.6964\n",
      "Epoch 22/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5254 - acc: 0.7327 - val_loss: 0.5324 - val_acc: 0.6940\n",
      "Epoch 23/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5244 - acc: 0.7308 - val_loss: 0.5312 - val_acc: 0.6916\n",
      "Epoch 24/600\n",
      "3730/3730 [==============================] - 0s 104us/step - loss: 0.5238 - acc: 0.7335 - val_loss: 0.5278 - val_acc: 0.6964\n",
      "Epoch 25/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5229 - acc: 0.7349 - val_loss: 0.5281 - val_acc: 0.6940\n",
      "Epoch 26/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5221 - acc: 0.7354 - val_loss: 0.5273 - val_acc: 0.6940\n",
      "Epoch 27/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5214 - acc: 0.7346 - val_loss: 0.5251 - val_acc: 0.6964\n",
      "Epoch 28/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5207 - acc: 0.7359 - val_loss: 0.5248 - val_acc: 0.6964\n",
      "Epoch 29/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5201 - acc: 0.7346 - val_loss: 0.5245 - val_acc: 0.6964\n",
      "Epoch 30/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5192 - acc: 0.7365 - val_loss: 0.5226 - val_acc: 0.6988\n",
      "Epoch 31/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5186 - acc: 0.7351 - val_loss: 0.5231 - val_acc: 0.6940\n",
      "Epoch 32/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5181 - acc: 0.7365 - val_loss: 0.5212 - val_acc: 0.6988\n",
      "Epoch 33/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5171 - acc: 0.7367 - val_loss: 0.5202 - val_acc: 0.6988\n",
      "Epoch 34/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5166 - acc: 0.7359 - val_loss: 0.5215 - val_acc: 0.6940\n",
      "Epoch 35/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5160 - acc: 0.7365 - val_loss: 0.5189 - val_acc: 0.7012\n",
      "Epoch 36/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5158 - acc: 0.7346 - val_loss: 0.5193 - val_acc: 0.7012\n",
      "Epoch 37/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5151 - acc: 0.7365 - val_loss: 0.5195 - val_acc: 0.7012\n",
      "Epoch 38/600\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.5149 - acc: 0.7349 - val_loss: 0.5182 - val_acc: 0.6964\n",
      "Epoch 39/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5144 - acc: 0.7373 - val_loss: 0.5170 - val_acc: 0.6988\n",
      "Epoch 40/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5139 - acc: 0.7370 - val_loss: 0.5156 - val_acc: 0.7060\n",
      "Epoch 41/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5136 - acc: 0.7359 - val_loss: 0.5154 - val_acc: 0.7012\n",
      "Epoch 42/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5132 - acc: 0.7362 - val_loss: 0.5143 - val_acc: 0.7036\n",
      "Epoch 43/600\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.5127 - acc: 0.7383 - val_loss: 0.5137 - val_acc: 0.7060\n",
      "Epoch 44/600\n",
      "3730/3730 [==============================] - 0s 83us/step - loss: 0.5127 - acc: 0.7386 - val_loss: 0.5126 - val_acc: 0.7036\n",
      "Epoch 45/600\n",
      "3730/3730 [==============================] - 0s 82us/step - loss: 0.5124 - acc: 0.7386 - val_loss: 0.5130 - val_acc: 0.7060\n",
      "Epoch 46/600\n",
      "3730/3730 [==============================] - 0s 93us/step - loss: 0.5119 - acc: 0.7413 - val_loss: 0.5119 - val_acc: 0.7108\n",
      "Epoch 47/600\n",
      "3730/3730 [==============================] - 1s 165us/step - loss: 0.5119 - acc: 0.7405 - val_loss: 0.5125 - val_acc: 0.7084\n",
      "Epoch 48/600\n",
      "3730/3730 [==============================] - 1s 181us/step - loss: 0.5114 - acc: 0.7399 - val_loss: 0.5141 - val_acc: 0.7036\n",
      "Epoch 49/600\n",
      "3730/3730 [==============================] - 1s 144us/step - loss: 0.5113 - acc: 0.7375 - val_loss: 0.5116 - val_acc: 0.7108\n",
      "Epoch 50/600\n",
      "3730/3730 [==============================] - 0s 121us/step - loss: 0.5113 - acc: 0.7375 - val_loss: 0.5111 - val_acc: 0.7108\n",
      "Epoch 51/600\n",
      "3730/3730 [==============================] - 0s 91us/step - loss: 0.5108 - acc: 0.7367 - val_loss: 0.5108 - val_acc: 0.7108\n",
      "Epoch 52/600\n",
      "3730/3730 [==============================] - 0s 87us/step - loss: 0.5107 - acc: 0.7383 - val_loss: 0.5102 - val_acc: 0.7084\n",
      "Epoch 53/600\n",
      "3730/3730 [==============================] - 0s 97us/step - loss: 0.5105 - acc: 0.7359 - val_loss: 0.5118 - val_acc: 0.7108\n",
      "Epoch 54/600\n",
      "3730/3730 [==============================] - 0s 83us/step - loss: 0.5104 - acc: 0.7367 - val_loss: 0.5103 - val_acc: 0.7133\n",
      "Epoch 55/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5100 - acc: 0.7370 - val_loss: 0.5112 - val_acc: 0.7157\n",
      "Epoch 56/600\n",
      "3730/3730 [==============================] - 0s 112us/step - loss: 0.5103 - acc: 0.7365 - val_loss: 0.5101 - val_acc: 0.7133\n",
      "Epoch 57/600\n",
      "3730/3730 [==============================] - 0s 110us/step - loss: 0.5099 - acc: 0.7365 - val_loss: 0.5102 - val_acc: 0.7157\n",
      "Epoch 58/600\n",
      "3730/3730 [==============================] - 0s 101us/step - loss: 0.5098 - acc: 0.7378 - val_loss: 0.5100 - val_acc: 0.7181\n",
      "Epoch 59/600\n",
      "3730/3730 [==============================] - 0s 92us/step - loss: 0.5094 - acc: 0.7354 - val_loss: 0.5089 - val_acc: 0.7157\n",
      "Epoch 60/600\n",
      "3730/3730 [==============================] - 0s 85us/step - loss: 0.5093 - acc: 0.7365 - val_loss: 0.5089 - val_acc: 0.7157\n",
      "Epoch 61/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5093 - acc: 0.7359 - val_loss: 0.5094 - val_acc: 0.7181\n",
      "Epoch 62/600\n",
      "3730/3730 [==============================] - 0s 91us/step - loss: 0.5090 - acc: 0.7359 - val_loss: 0.5093 - val_acc: 0.7157\n",
      "Epoch 63/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5091 - acc: 0.7340 - val_loss: 0.5099 - val_acc: 0.7181\n",
      "Epoch 64/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5087 - acc: 0.7332 - val_loss: 0.5094 - val_acc: 0.7181\n",
      "Epoch 65/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5086 - acc: 0.7346 - val_loss: 0.5083 - val_acc: 0.7157\n",
      "Epoch 66/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5087 - acc: 0.7327 - val_loss: 0.5084 - val_acc: 0.7157\n",
      "Epoch 67/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5088 - acc: 0.7324 - val_loss: 0.5079 - val_acc: 0.7181\n",
      "Epoch 68/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5080 - acc: 0.7330 - val_loss: 0.5083 - val_acc: 0.7181\n",
      "Epoch 69/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5082 - acc: 0.7346 - val_loss: 0.5085 - val_acc: 0.7157\n",
      "Epoch 70/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5079 - acc: 0.7340 - val_loss: 0.5089 - val_acc: 0.7157\n",
      "Epoch 71/600\n",
      "3730/3730 [==============================] - 0s 74us/step - loss: 0.5080 - acc: 0.7324 - val_loss: 0.5089 - val_acc: 0.7181\n",
      "Epoch 72/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5074 - acc: 0.7324 - val_loss: 0.5089 - val_acc: 0.7181\n",
      "Epoch 73/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5075 - acc: 0.7324 - val_loss: 0.5091 - val_acc: 0.7157\n",
      "Epoch 74/600\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.5076 - acc: 0.7338 - val_loss: 0.5081 - val_acc: 0.7181\n",
      "Epoch 75/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5074 - acc: 0.7338 - val_loss: 0.5073 - val_acc: 0.7157\n",
      "Epoch 76/600\n",
      "3730/3730 [==============================] - 0s 85us/step - loss: 0.5070 - acc: 0.7338 - val_loss: 0.5071 - val_acc: 0.7157\n",
      "Epoch 77/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5068 - acc: 0.7335 - val_loss: 0.5085 - val_acc: 0.7181\n",
      "Epoch 78/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5073 - acc: 0.7284 - val_loss: 0.5069 - val_acc: 0.7181\n",
      "Epoch 79/600\n",
      "3730/3730 [==============================] - 0s 86us/step - loss: 0.5070 - acc: 0.7298 - val_loss: 0.5055 - val_acc: 0.7133\n",
      "Epoch 80/600\n",
      "3730/3730 [==============================] - 0s 94us/step - loss: 0.5071 - acc: 0.7327 - val_loss: 0.5060 - val_acc: 0.7181\n",
      "Epoch 81/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5068 - acc: 0.7316 - val_loss: 0.5044 - val_acc: 0.7133\n",
      "Epoch 82/600\n",
      "3730/3730 [==============================] - 0s 113us/step - loss: 0.5066 - acc: 0.7330 - val_loss: 0.5055 - val_acc: 0.7157\n",
      "Epoch 83/600\n",
      "3730/3730 [==============================] - 0s 101us/step - loss: 0.5063 - acc: 0.7332 - val_loss: 0.5040 - val_acc: 0.7157\n",
      "Epoch 84/600\n",
      "3730/3730 [==============================] - 0s 84us/step - loss: 0.5066 - acc: 0.7322 - val_loss: 0.5033 - val_acc: 0.7133\n",
      "Epoch 85/600\n",
      "3730/3730 [==============================] - 0s 74us/step - loss: 0.5065 - acc: 0.7332 - val_loss: 0.5039 - val_acc: 0.7181\n",
      "Epoch 86/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5061 - acc: 0.7308 - val_loss: 0.5031 - val_acc: 0.7181\n",
      "Epoch 87/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5060 - acc: 0.7308 - val_loss: 0.5032 - val_acc: 0.7133\n",
      "Epoch 88/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5057 - acc: 0.7338 - val_loss: 0.5025 - val_acc: 0.7157\n",
      "Epoch 89/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5056 - acc: 0.7314 - val_loss: 0.5005 - val_acc: 0.7325\n",
      "Epoch 90/600\n",
      "3730/3730 [==============================] - 0s 74us/step - loss: 0.5055 - acc: 0.7370 - val_loss: 0.5009 - val_acc: 0.7133\n",
      "Epoch 91/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.5054 - acc: 0.7332 - val_loss: 0.5016 - val_acc: 0.7205\n",
      "Epoch 92/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5056 - acc: 0.7314 - val_loss: 0.5007 - val_acc: 0.7181\n",
      "Epoch 93/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5054 - acc: 0.7338 - val_loss: 0.5003 - val_acc: 0.7181\n",
      "Epoch 94/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5052 - acc: 0.7330 - val_loss: 0.4998 - val_acc: 0.7181\n",
      "Epoch 95/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5049 - acc: 0.7338 - val_loss: 0.5001 - val_acc: 0.7157\n",
      "Epoch 96/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5048 - acc: 0.7332 - val_loss: 0.5003 - val_acc: 0.7205\n",
      "Epoch 97/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.5047 - acc: 0.7354 - val_loss: 0.4991 - val_acc: 0.7157\n",
      "Epoch 98/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5049 - acc: 0.7370 - val_loss: 0.4987 - val_acc: 0.7133\n",
      "Epoch 99/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5045 - acc: 0.7338 - val_loss: 0.4983 - val_acc: 0.7181\n",
      "Epoch 100/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5047 - acc: 0.7340 - val_loss: 0.4981 - val_acc: 0.7229\n",
      "Epoch 101/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5047 - acc: 0.7354 - val_loss: 0.4978 - val_acc: 0.7229\n",
      "Epoch 102/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5043 - acc: 0.7351 - val_loss: 0.4969 - val_acc: 0.7181\n",
      "Epoch 103/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5045 - acc: 0.7375 - val_loss: 0.4969 - val_acc: 0.7181\n",
      "Epoch 104/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5043 - acc: 0.7362 - val_loss: 0.4974 - val_acc: 0.7229\n",
      "Epoch 105/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5043 - acc: 0.7359 - val_loss: 0.4976 - val_acc: 0.7205\n",
      "Epoch 106/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5044 - acc: 0.7362 - val_loss: 0.4967 - val_acc: 0.7205\n",
      "Epoch 107/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5043 - acc: 0.7359 - val_loss: 0.4967 - val_acc: 0.7181\n",
      "Epoch 108/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5042 - acc: 0.7346 - val_loss: 0.4963 - val_acc: 0.7229\n",
      "Epoch 109/600\n",
      "3730/3730 [==============================] - 0s 74us/step - loss: 0.5043 - acc: 0.7343 - val_loss: 0.4969 - val_acc: 0.7253\n",
      "Epoch 110/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5044 - acc: 0.7343 - val_loss: 0.4957 - val_acc: 0.7181\n",
      "Epoch 111/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5040 - acc: 0.7346 - val_loss: 0.4957 - val_acc: 0.7205\n",
      "Epoch 112/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5040 - acc: 0.7338 - val_loss: 0.4960 - val_acc: 0.7205\n",
      "Epoch 113/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5040 - acc: 0.7359 - val_loss: 0.4963 - val_acc: 0.7253\n",
      "Epoch 114/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5040 - acc: 0.7362 - val_loss: 0.4956 - val_acc: 0.7205\n",
      "Epoch 115/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5038 - acc: 0.7354 - val_loss: 0.4958 - val_acc: 0.7229\n",
      "Epoch 116/600\n",
      "3730/3730 [==============================] - 0s 74us/step - loss: 0.5040 - acc: 0.7330 - val_loss: 0.4956 - val_acc: 0.7253\n",
      "Epoch 117/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5039 - acc: 0.7349 - val_loss: 0.4955 - val_acc: 0.7181\n",
      "Epoch 118/600\n",
      "3730/3730 [==============================] - 0s 92us/step - loss: 0.5039 - acc: 0.7332 - val_loss: 0.4952 - val_acc: 0.7205\n",
      "Epoch 119/600\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.5036 - acc: 0.7357 - val_loss: 0.4951 - val_acc: 0.7181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/600\n",
      "3730/3730 [==============================] - 0s 95us/step - loss: 0.5035 - acc: 0.7349 - val_loss: 0.4950 - val_acc: 0.7205\n",
      "Epoch 121/600\n",
      "3730/3730 [==============================] - 0s 107us/step - loss: 0.5036 - acc: 0.7351 - val_loss: 0.4957 - val_acc: 0.7229\n",
      "Epoch 122/600\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.5035 - acc: 0.7338 - val_loss: 0.4956 - val_acc: 0.7229\n",
      "Epoch 123/600\n",
      "3730/3730 [==============================] - 0s 87us/step - loss: 0.5035 - acc: 0.7354 - val_loss: 0.4950 - val_acc: 0.7157\n",
      "Epoch 124/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5034 - acc: 0.7346 - val_loss: 0.4953 - val_acc: 0.7181\n",
      "Epoch 125/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5036 - acc: 0.7354 - val_loss: 0.4953 - val_acc: 0.7229\n",
      "Epoch 126/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5034 - acc: 0.7362 - val_loss: 0.4950 - val_acc: 0.7181\n",
      "Epoch 127/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5039 - acc: 0.7367 - val_loss: 0.4947 - val_acc: 0.7181\n",
      "Epoch 128/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5037 - acc: 0.7340 - val_loss: 0.4948 - val_acc: 0.7157\n",
      "Epoch 129/600\n",
      "3730/3730 [==============================] - 0s 115us/step - loss: 0.5036 - acc: 0.7338 - val_loss: 0.4949 - val_acc: 0.7181\n",
      "Epoch 130/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5033 - acc: 0.7343 - val_loss: 0.4952 - val_acc: 0.7181\n",
      "Epoch 131/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5034 - acc: 0.7324 - val_loss: 0.4946 - val_acc: 0.7133\n",
      "Epoch 132/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5036 - acc: 0.7349 - val_loss: 0.4953 - val_acc: 0.7133\n",
      "Epoch 133/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5033 - acc: 0.7338 - val_loss: 0.4952 - val_acc: 0.7133\n",
      "Epoch 134/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5034 - acc: 0.7330 - val_loss: 0.4949 - val_acc: 0.7157\n",
      "Epoch 135/600\n",
      "3730/3730 [==============================] - 0s 86us/step - loss: 0.5033 - acc: 0.7357 - val_loss: 0.4946 - val_acc: 0.7181\n",
      "Epoch 136/600\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.5032 - acc: 0.7367 - val_loss: 0.4957 - val_acc: 0.7133\n",
      "Epoch 137/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5030 - acc: 0.7338 - val_loss: 0.4947 - val_acc: 0.7181\n",
      "Epoch 138/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5033 - acc: 0.7359 - val_loss: 0.4947 - val_acc: 0.7181\n",
      "Epoch 139/600\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.5032 - acc: 0.7340 - val_loss: 0.4949 - val_acc: 0.7157\n",
      "Epoch 140/600\n",
      "3730/3730 [==============================] - 0s 84us/step - loss: 0.5031 - acc: 0.7346 - val_loss: 0.4947 - val_acc: 0.7133\n",
      "Epoch 141/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.5030 - acc: 0.7354 - val_loss: 0.4949 - val_acc: 0.7157\n",
      "Epoch 142/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5030 - acc: 0.7359 - val_loss: 0.4943 - val_acc: 0.7181\n",
      "Epoch 143/600\n",
      "3730/3730 [==============================] - 0s 82us/step - loss: 0.5029 - acc: 0.7362 - val_loss: 0.4944 - val_acc: 0.7157\n",
      "Epoch 144/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5029 - acc: 0.7354 - val_loss: 0.4952 - val_acc: 0.7157\n",
      "Epoch 145/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.5030 - acc: 0.7351 - val_loss: 0.4947 - val_acc: 0.7205\n",
      "Epoch 146/600\n",
      "3730/3730 [==============================] - 0s 91us/step - loss: 0.5030 - acc: 0.7351 - val_loss: 0.4947 - val_acc: 0.7181\n",
      "Epoch 147/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5032 - acc: 0.7332 - val_loss: 0.4947 - val_acc: 0.7181\n",
      "Epoch 148/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5029 - acc: 0.7343 - val_loss: 0.4948 - val_acc: 0.7205\n",
      "Epoch 149/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.5029 - acc: 0.7351 - val_loss: 0.4946 - val_acc: 0.7229\n",
      "Epoch 150/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5028 - acc: 0.7357 - val_loss: 0.4951 - val_acc: 0.7181\n",
      "Epoch 151/600\n",
      "3730/3730 [==============================] - 0s 87us/step - loss: 0.5028 - acc: 0.7351 - val_loss: 0.4949 - val_acc: 0.7205\n",
      "Epoch 152/600\n",
      "3730/3730 [==============================] - 0s 88us/step - loss: 0.5027 - acc: 0.7362 - val_loss: 0.4949 - val_acc: 0.7205\n",
      "Epoch 153/600\n",
      "3730/3730 [==============================] - 0s 86us/step - loss: 0.5030 - acc: 0.7357 - val_loss: 0.4945 - val_acc: 0.7205\n",
      "Epoch 154/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5027 - acc: 0.7354 - val_loss: 0.4953 - val_acc: 0.7181\n",
      "Epoch 155/600\n",
      "3730/3730 [==============================] - 0s 94us/step - loss: 0.5028 - acc: 0.7375 - val_loss: 0.4948 - val_acc: 0.7205\n",
      "Epoch 156/600\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.5031 - acc: 0.7362 - val_loss: 0.4943 - val_acc: 0.7157\n",
      "Epoch 157/600\n",
      "3730/3730 [==============================] - 0s 97us/step - loss: 0.5027 - acc: 0.7346 - val_loss: 0.4948 - val_acc: 0.7181\n",
      "Epoch 158/600\n",
      "3730/3730 [==============================] - 0s 86us/step - loss: 0.5027 - acc: 0.7351 - val_loss: 0.4947 - val_acc: 0.7157\n",
      "Epoch 159/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5027 - acc: 0.7343 - val_loss: 0.4950 - val_acc: 0.7205\n",
      "Epoch 160/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5031 - acc: 0.7351 - val_loss: 0.4948 - val_acc: 0.7205\n",
      "Epoch 161/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.5027 - acc: 0.7338 - val_loss: 0.4945 - val_acc: 0.7205\n",
      "Epoch 162/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5028 - acc: 0.7349 - val_loss: 0.4949 - val_acc: 0.7181\n",
      "Epoch 163/600\n",
      "3730/3730 [==============================] - 0s 84us/step - loss: 0.5025 - acc: 0.7365 - val_loss: 0.4947 - val_acc: 0.7205\n",
      "Epoch 164/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5028 - acc: 0.7354 - val_loss: 0.4941 - val_acc: 0.7205\n",
      "Epoch 165/600\n",
      "3730/3730 [==============================] - 0s 82us/step - loss: 0.5028 - acc: 0.7354 - val_loss: 0.4944 - val_acc: 0.7157\n",
      "Epoch 166/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5027 - acc: 0.7359 - val_loss: 0.4944 - val_acc: 0.7181\n",
      "Epoch 167/600\n",
      "3730/3730 [==============================] - 0s 98us/step - loss: 0.5029 - acc: 0.7316 - val_loss: 0.4944 - val_acc: 0.7205\n",
      "Epoch 168/600\n",
      "3730/3730 [==============================] - 0s 100us/step - loss: 0.5028 - acc: 0.7359 - val_loss: 0.4948 - val_acc: 0.7205\n",
      "Epoch 169/600\n",
      "3730/3730 [==============================] - 0s 125us/step - loss: 0.5032 - acc: 0.7378 - val_loss: 0.4949 - val_acc: 0.7205\n",
      "Epoch 170/600\n",
      "3730/3730 [==============================] - 0s 100us/step - loss: 0.5027 - acc: 0.7359 - val_loss: 0.4942 - val_acc: 0.7181\n",
      "Epoch 171/600\n",
      "3730/3730 [==============================] - 0s 111us/step - loss: 0.5028 - acc: 0.7343 - val_loss: 0.4944 - val_acc: 0.7157\n",
      "Epoch 172/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5025 - acc: 0.7354 - val_loss: 0.4946 - val_acc: 0.7157\n",
      "Epoch 173/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.5026 - acc: 0.7383 - val_loss: 0.4946 - val_acc: 0.7133\n",
      "Epoch 174/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5026 - acc: 0.7357 - val_loss: 0.4946 - val_acc: 0.7157\n",
      "Epoch 175/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5023 - acc: 0.7378 - val_loss: 0.4950 - val_acc: 0.7181\n",
      "Epoch 176/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5025 - acc: 0.7373 - val_loss: 0.4943 - val_acc: 0.7133\n",
      "Epoch 177/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5026 - acc: 0.7349 - val_loss: 0.4945 - val_acc: 0.7205\n",
      "Epoch 178/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5023 - acc: 0.7346 - val_loss: 0.4950 - val_acc: 0.7205\n",
      "Epoch 179/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5028 - acc: 0.7351 - val_loss: 0.4943 - val_acc: 0.7205\n",
      "Epoch 180/600\n",
      "3730/3730 [==============================] - 0s 70us/step - loss: 0.5027 - acc: 0.7381 - val_loss: 0.4942 - val_acc: 0.7181\n",
      "Epoch 181/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.5023 - acc: 0.7362 - val_loss: 0.4945 - val_acc: 0.7205\n",
      "Epoch 182/600\n",
      "3730/3730 [==============================] - 0s 85us/step - loss: 0.5024 - acc: 0.7351 - val_loss: 0.4941 - val_acc: 0.7205\n",
      "Epoch 183/600\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.5022 - acc: 0.7375 - val_loss: 0.4941 - val_acc: 0.7205\n",
      "Epoch 184/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5025 - acc: 0.7349 - val_loss: 0.4944 - val_acc: 0.7205\n",
      "Epoch 185/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5026 - acc: 0.7359 - val_loss: 0.4944 - val_acc: 0.7205\n",
      "Epoch 186/600\n",
      "3730/3730 [==============================] - 0s 114us/step - loss: 0.5022 - acc: 0.7343 - val_loss: 0.4943 - val_acc: 0.7205\n",
      "Epoch 187/600\n",
      "3730/3730 [==============================] - 0s 95us/step - loss: 0.5025 - acc: 0.7354 - val_loss: 0.4941 - val_acc: 0.7181\n",
      "Epoch 188/600\n",
      "3730/3730 [==============================] - 0s 129us/step - loss: 0.5026 - acc: 0.7354 - val_loss: 0.4939 - val_acc: 0.7181\n",
      "Epoch 189/600\n",
      "3730/3730 [==============================] - 0s 107us/step - loss: 0.5026 - acc: 0.7365 - val_loss: 0.4947 - val_acc: 0.7205\n",
      "Epoch 190/600\n",
      "3730/3730 [==============================] - 0s 100us/step - loss: 0.5022 - acc: 0.7359 - val_loss: 0.4945 - val_acc: 0.7205\n",
      "Epoch 191/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5025 - acc: 0.7343 - val_loss: 0.4943 - val_acc: 0.7157\n",
      "Epoch 192/600\n",
      "3730/3730 [==============================] - 0s 89us/step - loss: 0.5022 - acc: 0.7367 - val_loss: 0.4944 - val_acc: 0.7205\n",
      "Epoch 193/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5024 - acc: 0.7386 - val_loss: 0.4941 - val_acc: 0.7157\n",
      "Epoch 194/600\n",
      "3730/3730 [==============================] - 0s 82us/step - loss: 0.5024 - acc: 0.7365 - val_loss: 0.4941 - val_acc: 0.7181\n",
      "Epoch 195/600\n",
      "3730/3730 [==============================] - 0s 83us/step - loss: 0.5023 - acc: 0.7381 - val_loss: 0.4944 - val_acc: 0.7205\n",
      "Epoch 196/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5020 - acc: 0.7354 - val_loss: 0.4941 - val_acc: 0.7205\n",
      "Epoch 197/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5023 - acc: 0.7354 - val_loss: 0.4941 - val_acc: 0.7205\n",
      "Epoch 198/600\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.5025 - acc: 0.7370 - val_loss: 0.4941 - val_acc: 0.7181\n",
      "Epoch 199/600\n",
      "3730/3730 [==============================] - 0s 83us/step - loss: 0.5024 - acc: 0.7375 - val_loss: 0.4939 - val_acc: 0.7181\n",
      "Epoch 200/600\n",
      "3730/3730 [==============================] - 0s 95us/step - loss: 0.5022 - acc: 0.7381 - val_loss: 0.4942 - val_acc: 0.7205\n",
      "Epoch 201/600\n",
      "3730/3730 [==============================] - 0s 98us/step - loss: 0.5021 - acc: 0.7367 - val_loss: 0.4940 - val_acc: 0.7181\n",
      "Epoch 202/600\n",
      "3730/3730 [==============================] - 0s 111us/step - loss: 0.5021 - acc: 0.7383 - val_loss: 0.4940 - val_acc: 0.7181\n",
      "Epoch 203/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5020 - acc: 0.7370 - val_loss: 0.4941 - val_acc: 0.7205\n",
      "Epoch 204/600\n",
      "3730/3730 [==============================] - 0s 113us/step - loss: 0.5023 - acc: 0.7365 - val_loss: 0.4943 - val_acc: 0.7205\n",
      "Epoch 205/600\n",
      "3730/3730 [==============================] - 0s 108us/step - loss: 0.5019 - acc: 0.7373 - val_loss: 0.4940 - val_acc: 0.7181\n",
      "Epoch 206/600\n",
      "3730/3730 [==============================] - 0s 92us/step - loss: 0.5023 - acc: 0.7362 - val_loss: 0.4940 - val_acc: 0.7205\n",
      "Epoch 207/600\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.5018 - acc: 0.7373 - val_loss: 0.4940 - val_acc: 0.7181\n",
      "Epoch 208/600\n",
      "3730/3730 [==============================] - 0s 82us/step - loss: 0.5020 - acc: 0.7370 - val_loss: 0.4940 - val_acc: 0.7205\n",
      "Epoch 209/600\n",
      "3730/3730 [==============================] - 0s 109us/step - loss: 0.5021 - acc: 0.7370 - val_loss: 0.4937 - val_acc: 0.7205\n",
      "Epoch 210/600\n",
      "3730/3730 [==============================] - 0s 115us/step - loss: 0.5021 - acc: 0.7354 - val_loss: 0.4937 - val_acc: 0.7205\n",
      "Epoch 211/600\n",
      "3730/3730 [==============================] - 1s 139us/step - loss: 0.5024 - acc: 0.7365 - val_loss: 0.4940 - val_acc: 0.7205\n",
      "Epoch 212/600\n",
      "3730/3730 [==============================] - 0s 128us/step - loss: 0.5018 - acc: 0.7373 - val_loss: 0.4936 - val_acc: 0.7205\n",
      "Epoch 213/600\n",
      "3730/3730 [==============================] - 0s 87us/step - loss: 0.5019 - acc: 0.7367 - val_loss: 0.4937 - val_acc: 0.7205\n",
      "Epoch 214/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5019 - acc: 0.7370 - val_loss: 0.4939 - val_acc: 0.7205\n",
      "Epoch 215/600\n",
      "3730/3730 [==============================] - 0s 90us/step - loss: 0.5018 - acc: 0.7391 - val_loss: 0.4939 - val_acc: 0.7205\n",
      "Epoch 216/600\n",
      "3730/3730 [==============================] - 0s 92us/step - loss: 0.5019 - acc: 0.7362 - val_loss: 0.4942 - val_acc: 0.7205\n",
      "Epoch 217/600\n",
      "3730/3730 [==============================] - 0s 113us/step - loss: 0.5016 - acc: 0.7367 - val_loss: 0.4940 - val_acc: 0.7229\n",
      "Epoch 218/600\n",
      "3730/3730 [==============================] - 0s 91us/step - loss: 0.5019 - acc: 0.7354 - val_loss: 0.4939 - val_acc: 0.7229\n",
      "Epoch 219/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5018 - acc: 0.7399 - val_loss: 0.4941 - val_acc: 0.7205\n",
      "Epoch 220/600\n",
      "3730/3730 [==============================] - 0s 91us/step - loss: 0.5020 - acc: 0.7383 - val_loss: 0.4943 - val_acc: 0.7205\n",
      "Epoch 221/600\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.5019 - acc: 0.7378 - val_loss: 0.4940 - val_acc: 0.7205\n",
      "Epoch 222/600\n",
      "3730/3730 [==============================] - 0s 82us/step - loss: 0.5019 - acc: 0.7362 - val_loss: 0.4942 - val_acc: 0.7229\n",
      "Epoch 223/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5018 - acc: 0.7359 - val_loss: 0.4943 - val_acc: 0.7229\n",
      "Epoch 224/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5016 - acc: 0.7375 - val_loss: 0.4940 - val_acc: 0.7181\n",
      "Epoch 225/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5017 - acc: 0.7351 - val_loss: 0.4943 - val_acc: 0.7229\n",
      "Epoch 226/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5020 - acc: 0.7362 - val_loss: 0.4940 - val_acc: 0.7229\n",
      "Epoch 227/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5019 - acc: 0.7365 - val_loss: 0.4939 - val_acc: 0.7181\n",
      "Epoch 228/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5019 - acc: 0.7370 - val_loss: 0.4940 - val_acc: 0.7229\n",
      "Epoch 229/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5015 - acc: 0.7370 - val_loss: 0.4938 - val_acc: 0.7181\n",
      "Epoch 230/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5013 - acc: 0.7359 - val_loss: 0.4941 - val_acc: 0.7229\n",
      "Epoch 231/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5019 - acc: 0.7373 - val_loss: 0.4942 - val_acc: 0.7181\n",
      "Epoch 232/600\n",
      "3730/3730 [==============================] - 0s 85us/step - loss: 0.5015 - acc: 0.7383 - val_loss: 0.4940 - val_acc: 0.7229\n",
      "Epoch 233/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5016 - acc: 0.7370 - val_loss: 0.4943 - val_acc: 0.7181\n",
      "Epoch 234/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5020 - acc: 0.7359 - val_loss: 0.4940 - val_acc: 0.7205\n",
      "Epoch 235/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5016 - acc: 0.7386 - val_loss: 0.4941 - val_acc: 0.7205\n",
      "Epoch 236/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5017 - acc: 0.7375 - val_loss: 0.4941 - val_acc: 0.7205\n",
      "Epoch 237/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5017 - acc: 0.7365 - val_loss: 0.4940 - val_acc: 0.7205\n",
      "Epoch 238/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5014 - acc: 0.7389 - val_loss: 0.4946 - val_acc: 0.7205\n",
      "Epoch 239/600\n",
      "3730/3730 [==============================] - 0s 83us/step - loss: 0.5016 - acc: 0.7399 - val_loss: 0.4942 - val_acc: 0.7181\n",
      "Epoch 240/600\n",
      "3730/3730 [==============================] - 0s 94us/step - loss: 0.5016 - acc: 0.7375 - val_loss: 0.4942 - val_acc: 0.7181\n",
      "Epoch 241/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5017 - acc: 0.7381 - val_loss: 0.4943 - val_acc: 0.7205\n",
      "Epoch 242/600\n",
      "3730/3730 [==============================] - 0s 85us/step - loss: 0.5017 - acc: 0.7383 - val_loss: 0.4943 - val_acc: 0.7205\n",
      "Epoch 243/600\n",
      "3730/3730 [==============================] - 0s 92us/step - loss: 0.5016 - acc: 0.7381 - val_loss: 0.4944 - val_acc: 0.7205\n",
      "Epoch 244/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5014 - acc: 0.7389 - val_loss: 0.4941 - val_acc: 0.7181\n",
      "Epoch 245/600\n",
      "3730/3730 [==============================] - 0s 85us/step - loss: 0.5016 - acc: 0.7394 - val_loss: 0.4942 - val_acc: 0.7157\n",
      "Epoch 246/600\n",
      "3730/3730 [==============================] - 0s 92us/step - loss: 0.5012 - acc: 0.7397 - val_loss: 0.4941 - val_acc: 0.7181\n",
      "Epoch 247/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5018 - acc: 0.7386 - val_loss: 0.4944 - val_acc: 0.7157\n",
      "Epoch 248/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5014 - acc: 0.7405 - val_loss: 0.4945 - val_acc: 0.7205\n",
      "Epoch 249/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5014 - acc: 0.7402 - val_loss: 0.4945 - val_acc: 0.7157\n",
      "Epoch 250/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5012 - acc: 0.7389 - val_loss: 0.4944 - val_acc: 0.7181\n",
      "Epoch 251/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5013 - acc: 0.7389 - val_loss: 0.4943 - val_acc: 0.7157\n",
      "Epoch 252/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5012 - acc: 0.7391 - val_loss: 0.4942 - val_acc: 0.7157\n",
      "Epoch 253/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5013 - acc: 0.7397 - val_loss: 0.4946 - val_acc: 0.7181\n",
      "Epoch 254/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5014 - acc: 0.7394 - val_loss: 0.4947 - val_acc: 0.7157\n",
      "Epoch 255/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5012 - acc: 0.7381 - val_loss: 0.4944 - val_acc: 0.7157\n",
      "Epoch 256/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5012 - acc: 0.7381 - val_loss: 0.4946 - val_acc: 0.7181\n",
      "Epoch 257/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5013 - acc: 0.7402 - val_loss: 0.4945 - val_acc: 0.7181\n",
      "Epoch 258/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5012 - acc: 0.7402 - val_loss: 0.4945 - val_acc: 0.7181\n",
      "Epoch 259/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5012 - acc: 0.7375 - val_loss: 0.4948 - val_acc: 0.7181\n",
      "Epoch 260/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5012 - acc: 0.7389 - val_loss: 0.4944 - val_acc: 0.7133\n",
      "Epoch 261/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5012 - acc: 0.7381 - val_loss: 0.4947 - val_acc: 0.7157\n",
      "Epoch 262/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5016 - acc: 0.7378 - val_loss: 0.4944 - val_acc: 0.7157\n",
      "Epoch 263/600\n",
      "3730/3730 [==============================] - 0s 74us/step - loss: 0.5011 - acc: 0.7373 - val_loss: 0.4945 - val_acc: 0.7157\n",
      "Epoch 264/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5012 - acc: 0.7416 - val_loss: 0.4944 - val_acc: 0.7205\n",
      "Epoch 265/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5014 - acc: 0.7402 - val_loss: 0.4944 - val_acc: 0.7157\n",
      "Epoch 266/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5009 - acc: 0.7408 - val_loss: 0.4943 - val_acc: 0.7181\n",
      "Epoch 267/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5013 - acc: 0.7397 - val_loss: 0.4946 - val_acc: 0.7205\n",
      "Epoch 268/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5015 - acc: 0.7370 - val_loss: 0.4945 - val_acc: 0.7205\n",
      "Epoch 269/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5007 - acc: 0.7399 - val_loss: 0.4946 - val_acc: 0.7157\n",
      "Epoch 270/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5014 - acc: 0.7370 - val_loss: 0.4944 - val_acc: 0.7205\n",
      "Epoch 271/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5011 - acc: 0.7389 - val_loss: 0.4947 - val_acc: 0.7181\n",
      "Epoch 272/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5007 - acc: 0.7410 - val_loss: 0.4945 - val_acc: 0.7157\n",
      "Epoch 273/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5012 - acc: 0.7391 - val_loss: 0.4946 - val_acc: 0.7157\n",
      "Epoch 274/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5012 - acc: 0.7394 - val_loss: 0.4946 - val_acc: 0.7133\n",
      "Epoch 275/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5011 - acc: 0.7389 - val_loss: 0.4943 - val_acc: 0.7181\n",
      "Epoch 276/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5010 - acc: 0.7399 - val_loss: 0.4944 - val_acc: 0.7157\n",
      "Epoch 277/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5016 - acc: 0.7410 - val_loss: 0.4947 - val_acc: 0.7181\n",
      "Epoch 278/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5014 - acc: 0.7365 - val_loss: 0.4942 - val_acc: 0.7181\n",
      "Epoch 279/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5013 - acc: 0.7410 - val_loss: 0.4943 - val_acc: 0.7205\n",
      "Epoch 280/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5013 - acc: 0.7421 - val_loss: 0.4946 - val_acc: 0.7205\n",
      "Epoch 281/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5010 - acc: 0.7381 - val_loss: 0.4947 - val_acc: 0.7157\n",
      "Epoch 282/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5010 - acc: 0.7405 - val_loss: 0.4945 - val_acc: 0.7181\n",
      "Epoch 283/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5012 - acc: 0.7370 - val_loss: 0.4945 - val_acc: 0.7205\n",
      "Epoch 284/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5010 - acc: 0.7399 - val_loss: 0.4945 - val_acc: 0.7181\n",
      "Epoch 285/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5011 - acc: 0.7410 - val_loss: 0.4944 - val_acc: 0.7181\n",
      "Epoch 286/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5010 - acc: 0.7394 - val_loss: 0.4948 - val_acc: 0.7205\n",
      "Epoch 287/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5008 - acc: 0.7391 - val_loss: 0.4946 - val_acc: 0.7157\n",
      "Epoch 288/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5011 - acc: 0.7424 - val_loss: 0.4944 - val_acc: 0.7181\n",
      "Epoch 289/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5008 - acc: 0.7381 - val_loss: 0.4944 - val_acc: 0.7205\n",
      "Epoch 290/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5010 - acc: 0.7408 - val_loss: 0.4945 - val_acc: 0.7205\n",
      "Epoch 291/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5009 - acc: 0.7410 - val_loss: 0.4944 - val_acc: 0.7205\n",
      "Epoch 292/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5003 - acc: 0.7391 - val_loss: 0.4948 - val_acc: 0.7181\n",
      "Epoch 293/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5015 - acc: 0.7383 - val_loss: 0.4943 - val_acc: 0.7133\n",
      "Epoch 294/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5011 - acc: 0.7381 - val_loss: 0.4940 - val_acc: 0.7181\n",
      "Epoch 295/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5007 - acc: 0.7399 - val_loss: 0.4942 - val_acc: 0.7181\n",
      "Epoch 296/600\n",
      "3730/3730 [==============================] - 0s 74us/step - loss: 0.5009 - acc: 0.7386 - val_loss: 0.4946 - val_acc: 0.7157\n",
      "Epoch 297/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5010 - acc: 0.7440 - val_loss: 0.4945 - val_acc: 0.7133\n",
      "Epoch 298/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5009 - acc: 0.7416 - val_loss: 0.4942 - val_acc: 0.7181\n",
      "Epoch 299/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5009 - acc: 0.7408 - val_loss: 0.4943 - val_acc: 0.7205\n",
      "Epoch 300/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5008 - acc: 0.7413 - val_loss: 0.4946 - val_acc: 0.7181\n",
      "Epoch 301/600\n",
      "3730/3730 [==============================] - 0s 74us/step - loss: 0.5011 - acc: 0.7399 - val_loss: 0.4945 - val_acc: 0.7181\n",
      "Epoch 302/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5010 - acc: 0.7405 - val_loss: 0.4946 - val_acc: 0.7229\n",
      "Epoch 303/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5006 - acc: 0.7386 - val_loss: 0.4946 - val_acc: 0.7181\n",
      "Epoch 304/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5009 - acc: 0.7397 - val_loss: 0.4949 - val_acc: 0.7157\n",
      "Epoch 305/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5012 - acc: 0.7394 - val_loss: 0.4947 - val_acc: 0.7133\n",
      "Epoch 306/600\n",
      "3730/3730 [==============================] - 0s 66us/step - loss: 0.5009 - acc: 0.7370 - val_loss: 0.4945 - val_acc: 0.7181\n",
      "Epoch 307/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5006 - acc: 0.7397 - val_loss: 0.4946 - val_acc: 0.7157\n",
      "Epoch 308/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5007 - acc: 0.7410 - val_loss: 0.4946 - val_acc: 0.7157\n",
      "Epoch 309/600\n",
      "3730/3730 [==============================] - 0s 84us/step - loss: 0.5007 - acc: 0.7402 - val_loss: 0.4946 - val_acc: 0.7157\n",
      "Epoch 310/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5007 - acc: 0.7381 - val_loss: 0.4948 - val_acc: 0.7157\n",
      "Epoch 311/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5009 - acc: 0.7408 - val_loss: 0.4946 - val_acc: 0.7205\n",
      "Epoch 312/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5008 - acc: 0.7405 - val_loss: 0.4945 - val_acc: 0.7205\n",
      "Epoch 313/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5007 - acc: 0.7413 - val_loss: 0.4944 - val_acc: 0.7181\n",
      "Epoch 314/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5009 - acc: 0.7405 - val_loss: 0.4944 - val_acc: 0.7181\n",
      "Epoch 315/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5006 - acc: 0.7399 - val_loss: 0.4944 - val_acc: 0.7157\n",
      "Epoch 316/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5009 - acc: 0.7397 - val_loss: 0.4947 - val_acc: 0.7133\n",
      "Epoch 317/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5007 - acc: 0.7416 - val_loss: 0.4947 - val_acc: 0.7133\n",
      "Epoch 318/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5011 - acc: 0.7408 - val_loss: 0.4942 - val_acc: 0.7157\n",
      "Epoch 319/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5009 - acc: 0.7405 - val_loss: 0.4947 - val_acc: 0.7157\n",
      "Epoch 320/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5007 - acc: 0.7410 - val_loss: 0.4946 - val_acc: 0.7133\n",
      "Epoch 321/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5007 - acc: 0.7416 - val_loss: 0.4943 - val_acc: 0.7157\n",
      "Epoch 322/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5006 - acc: 0.7391 - val_loss: 0.4945 - val_acc: 0.7157\n",
      "Epoch 323/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5007 - acc: 0.7402 - val_loss: 0.4947 - val_acc: 0.7181\n",
      "Epoch 324/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5008 - acc: 0.7397 - val_loss: 0.4947 - val_acc: 0.7181\n",
      "Epoch 325/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5008 - acc: 0.7389 - val_loss: 0.4948 - val_acc: 0.7181\n",
      "Epoch 326/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5008 - acc: 0.7394 - val_loss: 0.4949 - val_acc: 0.7133\n",
      "Epoch 327/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5009 - acc: 0.7402 - val_loss: 0.4948 - val_acc: 0.7157\n",
      "Epoch 328/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5006 - acc: 0.7383 - val_loss: 0.4949 - val_acc: 0.7205\n",
      "Epoch 329/600\n",
      "3730/3730 [==============================] - 0s 85us/step - loss: 0.5011 - acc: 0.7386 - val_loss: 0.4949 - val_acc: 0.7205\n",
      "Epoch 330/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5006 - acc: 0.7383 - val_loss: 0.4949 - val_acc: 0.7205\n",
      "Epoch 331/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5010 - acc: 0.7378 - val_loss: 0.4948 - val_acc: 0.7157\n",
      "Epoch 332/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5011 - acc: 0.7383 - val_loss: 0.4949 - val_acc: 0.7157\n",
      "Epoch 333/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5005 - acc: 0.7402 - val_loss: 0.4948 - val_acc: 0.7157\n",
      "Epoch 334/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5007 - acc: 0.7405 - val_loss: 0.4949 - val_acc: 0.7133\n",
      "Epoch 335/600\n",
      "3730/3730 [==============================] - 0s 84us/step - loss: 0.5008 - acc: 0.7375 - val_loss: 0.4950 - val_acc: 0.7133\n",
      "Epoch 336/600\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.5006 - acc: 0.7410 - val_loss: 0.4949 - val_acc: 0.7133\n",
      "Epoch 337/600\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.5008 - acc: 0.7405 - val_loss: 0.4946 - val_acc: 0.7181\n",
      "Epoch 338/600\n",
      "3730/3730 [==============================] - 0s 84us/step - loss: 0.5005 - acc: 0.7383 - val_loss: 0.4946 - val_acc: 0.7181\n",
      "Epoch 339/600\n",
      "3730/3730 [==============================] - 0s 116us/step - loss: 0.5006 - acc: 0.7402 - val_loss: 0.4947 - val_acc: 0.7181\n",
      "Epoch 340/600\n",
      "3730/3730 [==============================] - 0s 87us/step - loss: 0.5008 - acc: 0.7402 - val_loss: 0.4944 - val_acc: 0.7181\n",
      "Epoch 341/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5005 - acc: 0.7397 - val_loss: 0.4947 - val_acc: 0.7133\n",
      "Epoch 342/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5008 - acc: 0.7397 - val_loss: 0.4947 - val_acc: 0.7133\n",
      "Epoch 343/600\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.5005 - acc: 0.7383 - val_loss: 0.4947 - val_acc: 0.7157\n",
      "Epoch 344/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5005 - acc: 0.7397 - val_loss: 0.4946 - val_acc: 0.7181\n",
      "Epoch 345/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5006 - acc: 0.7394 - val_loss: 0.4946 - val_acc: 0.7205\n",
      "Epoch 346/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5008 - acc: 0.7386 - val_loss: 0.4945 - val_acc: 0.7157\n",
      "Epoch 347/600\n",
      "3730/3730 [==============================] - 0s 95us/step - loss: 0.5006 - acc: 0.7383 - val_loss: 0.4947 - val_acc: 0.7157\n",
      "Epoch 348/600\n",
      "3730/3730 [==============================] - 0s 108us/step - loss: 0.5006 - acc: 0.7399 - val_loss: 0.4947 - val_acc: 0.7157\n",
      "Epoch 349/600\n",
      "3730/3730 [==============================] - 0s 82us/step - loss: 0.5005 - acc: 0.7378 - val_loss: 0.4947 - val_acc: 0.7157\n",
      "Epoch 350/600\n",
      "3730/3730 [==============================] - 0s 111us/step - loss: 0.5006 - acc: 0.7402 - val_loss: 0.4947 - val_acc: 0.7229\n",
      "Epoch 351/600\n",
      "3730/3730 [==============================] - 0s 116us/step - loss: 0.5010 - acc: 0.7375 - val_loss: 0.4946 - val_acc: 0.7181\n",
      "Epoch 352/600\n",
      "3730/3730 [==============================] - 0s 87us/step - loss: 0.5007 - acc: 0.7402 - val_loss: 0.4947 - val_acc: 0.7133\n",
      "Epoch 353/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5007 - acc: 0.7391 - val_loss: 0.4948 - val_acc: 0.7157\n",
      "Epoch 354/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5003 - acc: 0.7389 - val_loss: 0.4947 - val_acc: 0.7157\n",
      "Epoch 355/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5010 - acc: 0.7381 - val_loss: 0.4950 - val_acc: 0.7181\n",
      "Epoch 356/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5005 - acc: 0.7362 - val_loss: 0.4951 - val_acc: 0.7181\n",
      "Epoch 357/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5004 - acc: 0.7413 - val_loss: 0.4949 - val_acc: 0.7181\n",
      "Epoch 358/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5005 - acc: 0.7399 - val_loss: 0.4949 - val_acc: 0.7133\n",
      "Epoch 359/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5007 - acc: 0.7378 - val_loss: 0.4949 - val_acc: 0.7157\n",
      "Epoch 360/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5004 - acc: 0.7386 - val_loss: 0.4951 - val_acc: 0.7157\n",
      "Epoch 361/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5005 - acc: 0.7391 - val_loss: 0.4950 - val_acc: 0.7157\n",
      "Epoch 362/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5004 - acc: 0.7389 - val_loss: 0.4951 - val_acc: 0.7157\n",
      "Epoch 363/600\n",
      "3730/3730 [==============================] - 0s 74us/step - loss: 0.5004 - acc: 0.7394 - val_loss: 0.4949 - val_acc: 0.7157\n",
      "Epoch 364/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5008 - acc: 0.7386 - val_loss: 0.4948 - val_acc: 0.7181\n",
      "Epoch 365/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5004 - acc: 0.7394 - val_loss: 0.4952 - val_acc: 0.7157\n",
      "Epoch 366/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5005 - acc: 0.7375 - val_loss: 0.4950 - val_acc: 0.7157\n",
      "Epoch 367/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5009 - acc: 0.7370 - val_loss: 0.4949 - val_acc: 0.7181\n",
      "Epoch 368/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5005 - acc: 0.7389 - val_loss: 0.4953 - val_acc: 0.7157\n",
      "Epoch 369/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5005 - acc: 0.7397 - val_loss: 0.4950 - val_acc: 0.7157\n",
      "Epoch 370/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5003 - acc: 0.7391 - val_loss: 0.4951 - val_acc: 0.7157\n",
      "Epoch 371/600\n",
      "3730/3730 [==============================] - 0s 85us/step - loss: 0.5003 - acc: 0.7402 - val_loss: 0.4951 - val_acc: 0.7157\n",
      "Epoch 372/600\n",
      "3730/3730 [==============================] - 0s 82us/step - loss: 0.5005 - acc: 0.7381 - val_loss: 0.4952 - val_acc: 0.7157\n",
      "Epoch 373/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5005 - acc: 0.7397 - val_loss: 0.4950 - val_acc: 0.7157\n",
      "Epoch 374/600\n",
      "3730/3730 [==============================] - 0s 88us/step - loss: 0.4997 - acc: 0.7391 - val_loss: 0.4951 - val_acc: 0.7181\n",
      "Epoch 375/600\n",
      "3730/3730 [==============================] - 1s 152us/step - loss: 0.5005 - acc: 0.7383 - val_loss: 0.4952 - val_acc: 0.7157\n",
      "Epoch 376/600\n",
      "3730/3730 [==============================] - 0s 94us/step - loss: 0.5004 - acc: 0.7381 - val_loss: 0.4950 - val_acc: 0.7133\n",
      "Epoch 377/600\n",
      "3730/3730 [==============================] - 0s 82us/step - loss: 0.5006 - acc: 0.7394 - val_loss: 0.4950 - val_acc: 0.7157\n",
      "Epoch 378/600\n",
      "3730/3730 [==============================] - 0s 99us/step - loss: 0.5004 - acc: 0.7389 - val_loss: 0.4950 - val_acc: 0.7157\n",
      "Epoch 379/600\n",
      "3730/3730 [==============================] - 0s 90us/step - loss: 0.5004 - acc: 0.7391 - val_loss: 0.4949 - val_acc: 0.7157\n",
      "Epoch 380/600\n",
      "3730/3730 [==============================] - 0s 87us/step - loss: 0.5002 - acc: 0.7421 - val_loss: 0.4954 - val_acc: 0.7157\n",
      "Epoch 381/600\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.5006 - acc: 0.7391 - val_loss: 0.4955 - val_acc: 0.7157\n",
      "Epoch 382/600\n",
      "3730/3730 [==============================] - 0s 94us/step - loss: 0.5005 - acc: 0.7383 - val_loss: 0.4951 - val_acc: 0.7157\n",
      "Epoch 383/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5003 - acc: 0.7405 - val_loss: 0.4950 - val_acc: 0.7181\n",
      "Epoch 384/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5006 - acc: 0.7383 - val_loss: 0.4949 - val_acc: 0.7157\n",
      "Epoch 385/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5001 - acc: 0.7397 - val_loss: 0.4949 - val_acc: 0.7157\n",
      "Epoch 386/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5002 - acc: 0.7391 - val_loss: 0.4955 - val_acc: 0.7157\n",
      "Epoch 387/600\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.5003 - acc: 0.7402 - val_loss: 0.4950 - val_acc: 0.7205\n",
      "Epoch 388/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5008 - acc: 0.7373 - val_loss: 0.4949 - val_acc: 0.7157\n",
      "Epoch 389/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5004 - acc: 0.7408 - val_loss: 0.4952 - val_acc: 0.7157\n",
      "Epoch 390/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5003 - acc: 0.7397 - val_loss: 0.4951 - val_acc: 0.7157\n",
      "Epoch 391/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5003 - acc: 0.7405 - val_loss: 0.4951 - val_acc: 0.7181\n",
      "Epoch 392/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5004 - acc: 0.7386 - val_loss: 0.4952 - val_acc: 0.7157\n",
      "Epoch 393/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.5004 - acc: 0.7389 - val_loss: 0.4953 - val_acc: 0.7157\n",
      "Epoch 394/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5004 - acc: 0.7394 - val_loss: 0.4950 - val_acc: 0.7181\n",
      "Epoch 395/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5004 - acc: 0.7391 - val_loss: 0.4952 - val_acc: 0.7157\n",
      "Epoch 396/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5004 - acc: 0.7399 - val_loss: 0.4955 - val_acc: 0.7157\n",
      "Epoch 397/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5005 - acc: 0.7375 - val_loss: 0.4954 - val_acc: 0.7181\n",
      "Epoch 398/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5003 - acc: 0.7397 - val_loss: 0.4956 - val_acc: 0.7181\n",
      "Epoch 399/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5005 - acc: 0.7418 - val_loss: 0.4953 - val_acc: 0.7157\n",
      "Epoch 400/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5003 - acc: 0.7391 - val_loss: 0.4953 - val_acc: 0.7157\n",
      "Epoch 401/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5007 - acc: 0.7394 - val_loss: 0.4954 - val_acc: 0.7205\n",
      "Epoch 402/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5002 - acc: 0.7408 - val_loss: 0.4955 - val_acc: 0.7157\n",
      "Epoch 403/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5006 - acc: 0.7389 - val_loss: 0.4954 - val_acc: 0.7181\n",
      "Epoch 404/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5005 - acc: 0.7391 - val_loss: 0.4952 - val_acc: 0.7133\n",
      "Epoch 405/600\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.5003 - acc: 0.7370 - val_loss: 0.4953 - val_acc: 0.7133\n",
      "Epoch 406/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5004 - acc: 0.7383 - val_loss: 0.4955 - val_acc: 0.7181\n",
      "Epoch 407/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5002 - acc: 0.7402 - val_loss: 0.4952 - val_acc: 0.7157\n",
      "Epoch 408/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5002 - acc: 0.7373 - val_loss: 0.4951 - val_acc: 0.7181\n",
      "Epoch 409/600\n",
      "3730/3730 [==============================] - 0s 82us/step - loss: 0.5005 - acc: 0.7394 - val_loss: 0.4953 - val_acc: 0.7157\n",
      "Epoch 410/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.5003 - acc: 0.7373 - val_loss: 0.4950 - val_acc: 0.7205\n",
      "Epoch 411/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5002 - acc: 0.7375 - val_loss: 0.4951 - val_acc: 0.7181\n",
      "Epoch 412/600\n",
      "3730/3730 [==============================] - 0s 86us/step - loss: 0.5003 - acc: 0.7383 - val_loss: 0.4954 - val_acc: 0.7157\n",
      "Epoch 413/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5002 - acc: 0.7410 - val_loss: 0.4950 - val_acc: 0.7205\n",
      "Epoch 414/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5002 - acc: 0.7381 - val_loss: 0.4952 - val_acc: 0.7181\n",
      "Epoch 415/600\n",
      "3730/3730 [==============================] - 0s 86us/step - loss: 0.5002 - acc: 0.7381 - val_loss: 0.4953 - val_acc: 0.7181\n",
      "Epoch 416/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5001 - acc: 0.7394 - val_loss: 0.4951 - val_acc: 0.7181\n",
      "Epoch 417/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.5000 - acc: 0.7402 - val_loss: 0.4954 - val_acc: 0.7133\n",
      "Epoch 418/600\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.5004 - acc: 0.7367 - val_loss: 0.4954 - val_acc: 0.7157\n",
      "Epoch 419/600\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.5000 - acc: 0.7391 - val_loss: 0.4953 - val_acc: 0.7157\n",
      "Epoch 420/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5002 - acc: 0.7389 - val_loss: 0.4956 - val_acc: 0.7157\n",
      "Epoch 421/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5001 - acc: 0.7405 - val_loss: 0.4955 - val_acc: 0.7157\n",
      "Epoch 422/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5004 - acc: 0.7386 - val_loss: 0.4953 - val_acc: 0.7157\n",
      "Epoch 423/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4998 - acc: 0.7378 - val_loss: 0.4957 - val_acc: 0.7157\n",
      "Epoch 424/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5003 - acc: 0.7386 - val_loss: 0.4953 - val_acc: 0.7205\n",
      "Epoch 425/600\n",
      "3730/3730 [==============================] - 0s 88us/step - loss: 0.5005 - acc: 0.7386 - val_loss: 0.4954 - val_acc: 0.7157\n",
      "Epoch 426/600\n",
      "3730/3730 [==============================] - 0s 90us/step - loss: 0.5005 - acc: 0.7381 - val_loss: 0.4952 - val_acc: 0.7181\n",
      "Epoch 427/600\n",
      "3730/3730 [==============================] - 0s 90us/step - loss: 0.5003 - acc: 0.7397 - val_loss: 0.4952 - val_acc: 0.7133\n",
      "Epoch 428/600\n",
      "3730/3730 [==============================] - 0s 88us/step - loss: 0.5006 - acc: 0.7381 - val_loss: 0.4957 - val_acc: 0.7157\n",
      "Epoch 429/600\n",
      "3730/3730 [==============================] - 0s 87us/step - loss: 0.5003 - acc: 0.7394 - val_loss: 0.4956 - val_acc: 0.7133\n",
      "Epoch 430/600\n",
      "3730/3730 [==============================] - 0s 84us/step - loss: 0.5002 - acc: 0.7391 - val_loss: 0.4955 - val_acc: 0.7181\n",
      "Epoch 431/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5002 - acc: 0.7410 - val_loss: 0.4956 - val_acc: 0.7181\n",
      "Epoch 432/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.5005 - acc: 0.7391 - val_loss: 0.4955 - val_acc: 0.7133\n",
      "Epoch 433/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5001 - acc: 0.7399 - val_loss: 0.4952 - val_acc: 0.7205\n",
      "Epoch 434/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.5001 - acc: 0.7381 - val_loss: 0.4952 - val_acc: 0.7157\n",
      "Epoch 435/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5000 - acc: 0.7367 - val_loss: 0.4956 - val_acc: 0.7157\n",
      "Epoch 436/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5001 - acc: 0.7413 - val_loss: 0.4954 - val_acc: 0.7133\n",
      "Epoch 437/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5001 - acc: 0.7402 - val_loss: 0.4955 - val_acc: 0.7181\n",
      "Epoch 438/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5005 - acc: 0.7381 - val_loss: 0.4955 - val_acc: 0.7133\n",
      "Epoch 439/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5001 - acc: 0.7391 - val_loss: 0.4956 - val_acc: 0.7157\n",
      "Epoch 440/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5005 - acc: 0.7397 - val_loss: 0.4952 - val_acc: 0.7181\n",
      "Epoch 441/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5000 - acc: 0.7394 - val_loss: 0.4956 - val_acc: 0.7181\n",
      "Epoch 442/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4999 - acc: 0.7410 - val_loss: 0.4956 - val_acc: 0.7133\n",
      "Epoch 443/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5003 - acc: 0.7399 - val_loss: 0.4957 - val_acc: 0.7133\n",
      "Epoch 444/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5002 - acc: 0.7370 - val_loss: 0.4957 - val_acc: 0.7157\n",
      "Epoch 445/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5001 - acc: 0.7397 - val_loss: 0.4955 - val_acc: 0.7205\n",
      "Epoch 446/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5005 - acc: 0.7408 - val_loss: 0.4957 - val_acc: 0.7157\n",
      "Epoch 447/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.5006 - acc: 0.7383 - val_loss: 0.4956 - val_acc: 0.7181\n",
      "Epoch 448/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5003 - acc: 0.7416 - val_loss: 0.4955 - val_acc: 0.7181\n",
      "Epoch 449/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5004 - acc: 0.7391 - val_loss: 0.4957 - val_acc: 0.7181\n",
      "Epoch 450/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5000 - acc: 0.7373 - val_loss: 0.4957 - val_acc: 0.7181\n",
      "Epoch 451/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.5001 - acc: 0.7386 - val_loss: 0.4958 - val_acc: 0.7133\n",
      "Epoch 452/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5002 - acc: 0.7386 - val_loss: 0.4956 - val_acc: 0.7157\n",
      "Epoch 453/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4999 - acc: 0.7391 - val_loss: 0.4959 - val_acc: 0.7133\n",
      "Epoch 454/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.5000 - acc: 0.7410 - val_loss: 0.4954 - val_acc: 0.7181\n",
      "Epoch 455/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5001 - acc: 0.7394 - val_loss: 0.4956 - val_acc: 0.7181\n",
      "Epoch 456/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.5000 - acc: 0.7410 - val_loss: 0.4959 - val_acc: 0.7157\n",
      "Epoch 457/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5000 - acc: 0.7394 - val_loss: 0.4958 - val_acc: 0.7133\n",
      "Epoch 458/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5000 - acc: 0.7389 - val_loss: 0.4957 - val_acc: 0.7157\n",
      "Epoch 459/600\n",
      "3730/3730 [==============================] - 0s 99us/step - loss: 0.5001 - acc: 0.7405 - val_loss: 0.4956 - val_acc: 0.7181\n",
      "Epoch 460/600\n",
      "3730/3730 [==============================] - 0s 120us/step - loss: 0.4998 - acc: 0.7399 - val_loss: 0.4956 - val_acc: 0.7133\n",
      "Epoch 461/600\n",
      "3730/3730 [==============================] - 0s 99us/step - loss: 0.5001 - acc: 0.7389 - val_loss: 0.4955 - val_acc: 0.7157\n",
      "Epoch 462/600\n",
      "3730/3730 [==============================] - 0s 112us/step - loss: 0.4999 - acc: 0.7389 - val_loss: 0.4955 - val_acc: 0.7133\n",
      "Epoch 463/600\n",
      "3730/3730 [==============================] - 0s 125us/step - loss: 0.5002 - acc: 0.7399 - val_loss: 0.4956 - val_acc: 0.7157\n",
      "Epoch 464/600\n",
      "3730/3730 [==============================] - 0s 118us/step - loss: 0.4999 - acc: 0.7383 - val_loss: 0.4955 - val_acc: 0.7133\n",
      "Epoch 465/600\n",
      "3730/3730 [==============================] - 0s 116us/step - loss: 0.5001 - acc: 0.7405 - val_loss: 0.4956 - val_acc: 0.7157\n",
      "Epoch 466/600\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4999 - acc: 0.7391 - val_loss: 0.4956 - val_acc: 0.7157\n",
      "Epoch 467/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5002 - acc: 0.7375 - val_loss: 0.4956 - val_acc: 0.7181\n",
      "Epoch 468/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5001 - acc: 0.7391 - val_loss: 0.4957 - val_acc: 0.7181\n",
      "Epoch 469/600\n",
      "3730/3730 [==============================] - 0s 82us/step - loss: 0.5001 - acc: 0.7397 - val_loss: 0.4955 - val_acc: 0.7133\n",
      "Epoch 470/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5002 - acc: 0.7399 - val_loss: 0.4956 - val_acc: 0.7157\n",
      "Epoch 471/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4999 - acc: 0.7391 - val_loss: 0.4958 - val_acc: 0.7157\n",
      "Epoch 472/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4999 - acc: 0.7408 - val_loss: 0.4957 - val_acc: 0.7181\n",
      "Epoch 473/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5001 - acc: 0.7359 - val_loss: 0.4958 - val_acc: 0.7181\n",
      "Epoch 474/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5000 - acc: 0.7391 - val_loss: 0.4958 - val_acc: 0.7181\n",
      "Epoch 475/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.5001 - acc: 0.7402 - val_loss: 0.4958 - val_acc: 0.7157\n",
      "Epoch 476/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.4997 - acc: 0.7373 - val_loss: 0.4957 - val_acc: 0.7181\n",
      "Epoch 477/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4999 - acc: 0.7383 - val_loss: 0.4956 - val_acc: 0.7181\n",
      "Epoch 478/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5000 - acc: 0.7391 - val_loss: 0.4956 - val_acc: 0.7157\n",
      "Epoch 479/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5000 - acc: 0.7408 - val_loss: 0.4958 - val_acc: 0.7157\n",
      "Epoch 480/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4999 - acc: 0.7397 - val_loss: 0.4955 - val_acc: 0.7133\n",
      "Epoch 481/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4998 - acc: 0.7405 - val_loss: 0.4958 - val_acc: 0.7157\n",
      "Epoch 482/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5001 - acc: 0.7362 - val_loss: 0.4955 - val_acc: 0.7157\n",
      "Epoch 483/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.4999 - acc: 0.7375 - val_loss: 0.4955 - val_acc: 0.7133\n",
      "Epoch 484/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.5001 - acc: 0.7391 - val_loss: 0.4956 - val_acc: 0.7181\n",
      "Epoch 485/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4999 - acc: 0.7365 - val_loss: 0.4957 - val_acc: 0.7181\n",
      "Epoch 486/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4999 - acc: 0.7397 - val_loss: 0.4955 - val_acc: 0.7133\n",
      "Epoch 487/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.4999 - acc: 0.7413 - val_loss: 0.4957 - val_acc: 0.7157\n",
      "Epoch 488/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4997 - acc: 0.7410 - val_loss: 0.4956 - val_acc: 0.7157\n",
      "Epoch 489/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4999 - acc: 0.7394 - val_loss: 0.4958 - val_acc: 0.7157\n",
      "Epoch 490/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.5000 - acc: 0.7386 - val_loss: 0.4960 - val_acc: 0.7181\n",
      "Epoch 491/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.4997 - acc: 0.7402 - val_loss: 0.4956 - val_acc: 0.7133\n",
      "Epoch 492/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5002 - acc: 0.7386 - val_loss: 0.4954 - val_acc: 0.7157\n",
      "Epoch 493/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5003 - acc: 0.7381 - val_loss: 0.4959 - val_acc: 0.7181\n",
      "Epoch 494/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.5002 - acc: 0.7394 - val_loss: 0.4960 - val_acc: 0.7133\n",
      "Epoch 495/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5000 - acc: 0.7386 - val_loss: 0.4958 - val_acc: 0.7181\n",
      "Epoch 496/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.5000 - acc: 0.7394 - val_loss: 0.4956 - val_acc: 0.7181\n",
      "Epoch 497/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.5001 - acc: 0.7381 - val_loss: 0.4959 - val_acc: 0.7157\n",
      "Epoch 498/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.5002 - acc: 0.7389 - val_loss: 0.4960 - val_acc: 0.7157\n",
      "Epoch 499/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5001 - acc: 0.7397 - val_loss: 0.4957 - val_acc: 0.7157\n",
      "Epoch 500/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4999 - acc: 0.7378 - val_loss: 0.4957 - val_acc: 0.7157\n",
      "Epoch 501/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4998 - acc: 0.7402 - val_loss: 0.4959 - val_acc: 0.7181\n",
      "Epoch 502/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4999 - acc: 0.7373 - val_loss: 0.4959 - val_acc: 0.7181\n",
      "Epoch 503/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4999 - acc: 0.7383 - val_loss: 0.4960 - val_acc: 0.7205\n",
      "Epoch 504/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5003 - acc: 0.7362 - val_loss: 0.4963 - val_acc: 0.7181\n",
      "Epoch 505/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.5001 - acc: 0.7381 - val_loss: 0.4959 - val_acc: 0.7181\n",
      "Epoch 506/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4998 - acc: 0.7408 - val_loss: 0.4956 - val_acc: 0.7181\n",
      "Epoch 507/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4999 - acc: 0.7383 - val_loss: 0.4956 - val_acc: 0.7157\n",
      "Epoch 508/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5001 - acc: 0.7386 - val_loss: 0.4957 - val_acc: 0.7181\n",
      "Epoch 509/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.4997 - acc: 0.7399 - val_loss: 0.4958 - val_acc: 0.7157\n",
      "Epoch 510/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5001 - acc: 0.7399 - val_loss: 0.4955 - val_acc: 0.7157\n",
      "Epoch 511/600\n",
      "3730/3730 [==============================] - 0s 74us/step - loss: 0.5002 - acc: 0.7394 - val_loss: 0.4959 - val_acc: 0.7133\n",
      "Epoch 512/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4998 - acc: 0.7399 - val_loss: 0.4960 - val_acc: 0.7157\n",
      "Epoch 513/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5001 - acc: 0.7378 - val_loss: 0.4959 - val_acc: 0.7133\n",
      "Epoch 514/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4997 - acc: 0.7389 - val_loss: 0.4959 - val_acc: 0.7133\n",
      "Epoch 515/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5001 - acc: 0.7383 - val_loss: 0.4955 - val_acc: 0.7157\n",
      "Epoch 516/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4999 - acc: 0.7389 - val_loss: 0.4957 - val_acc: 0.7157\n",
      "Epoch 517/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5001 - acc: 0.7389 - val_loss: 0.4959 - val_acc: 0.7157\n",
      "Epoch 518/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5002 - acc: 0.7394 - val_loss: 0.4955 - val_acc: 0.7157\n",
      "Epoch 519/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5000 - acc: 0.7391 - val_loss: 0.4958 - val_acc: 0.7181\n",
      "Epoch 520/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4997 - acc: 0.7375 - val_loss: 0.4959 - val_acc: 0.7157\n",
      "Epoch 521/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5001 - acc: 0.7389 - val_loss: 0.4960 - val_acc: 0.7181\n",
      "Epoch 522/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5005 - acc: 0.7367 - val_loss: 0.4957 - val_acc: 0.7157\n",
      "Epoch 523/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5001 - acc: 0.7394 - val_loss: 0.4955 - val_acc: 0.7133\n",
      "Epoch 524/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.4996 - acc: 0.7394 - val_loss: 0.4953 - val_acc: 0.7157\n",
      "Epoch 525/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5001 - acc: 0.7373 - val_loss: 0.4955 - val_acc: 0.7133\n",
      "Epoch 526/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5000 - acc: 0.7389 - val_loss: 0.4955 - val_acc: 0.7157\n",
      "Epoch 527/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4998 - acc: 0.7421 - val_loss: 0.4955 - val_acc: 0.7181\n",
      "Epoch 528/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.5000 - acc: 0.7391 - val_loss: 0.4957 - val_acc: 0.7157\n",
      "Epoch 529/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5001 - acc: 0.7408 - val_loss: 0.4956 - val_acc: 0.7133\n",
      "Epoch 530/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5001 - acc: 0.7386 - val_loss: 0.4959 - val_acc: 0.7157\n",
      "Epoch 531/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.5001 - acc: 0.7386 - val_loss: 0.4960 - val_acc: 0.7157\n",
      "Epoch 532/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5002 - acc: 0.7370 - val_loss: 0.4958 - val_acc: 0.7133\n",
      "Epoch 533/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4999 - acc: 0.7418 - val_loss: 0.4959 - val_acc: 0.7181\n",
      "Epoch 534/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4998 - acc: 0.7402 - val_loss: 0.4959 - val_acc: 0.7181\n",
      "Epoch 535/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.4997 - acc: 0.7365 - val_loss: 0.4958 - val_acc: 0.7157\n",
      "Epoch 536/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.5000 - acc: 0.7386 - val_loss: 0.4957 - val_acc: 0.7181\n",
      "Epoch 537/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4998 - acc: 0.7386 - val_loss: 0.4959 - val_acc: 0.7157\n",
      "Epoch 538/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.4998 - acc: 0.7405 - val_loss: 0.4957 - val_acc: 0.7181\n",
      "Epoch 539/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.5002 - acc: 0.7402 - val_loss: 0.4954 - val_acc: 0.7181\n",
      "Epoch 540/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.4997 - acc: 0.7391 - val_loss: 0.4958 - val_acc: 0.7181\n",
      "Epoch 541/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4999 - acc: 0.7413 - val_loss: 0.4956 - val_acc: 0.7205\n",
      "Epoch 542/600\n",
      "3730/3730 [==============================] - 0s 70us/step - loss: 0.4997 - acc: 0.7399 - val_loss: 0.4956 - val_acc: 0.7133\n",
      "Epoch 543/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.5004 - acc: 0.7405 - val_loss: 0.4954 - val_acc: 0.7157\n",
      "Epoch 544/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.5001 - acc: 0.7381 - val_loss: 0.4957 - val_acc: 0.7157\n",
      "Epoch 545/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4999 - acc: 0.7413 - val_loss: 0.4955 - val_acc: 0.7181\n",
      "Epoch 546/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4998 - acc: 0.7399 - val_loss: 0.4956 - val_acc: 0.7157\n",
      "Epoch 547/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4996 - acc: 0.7375 - val_loss: 0.4958 - val_acc: 0.7157\n",
      "Epoch 548/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4996 - acc: 0.7399 - val_loss: 0.4958 - val_acc: 0.7181\n",
      "Epoch 549/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.5001 - acc: 0.7386 - val_loss: 0.4958 - val_acc: 0.7157\n",
      "Epoch 550/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.4995 - acc: 0.7386 - val_loss: 0.4956 - val_acc: 0.7157\n",
      "Epoch 551/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4998 - acc: 0.7394 - val_loss: 0.4958 - val_acc: 0.7181\n",
      "Epoch 552/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5000 - acc: 0.7370 - val_loss: 0.4958 - val_acc: 0.7157\n",
      "Epoch 553/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5001 - acc: 0.7397 - val_loss: 0.4958 - val_acc: 0.7157\n",
      "Epoch 554/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4999 - acc: 0.7386 - val_loss: 0.4958 - val_acc: 0.7181\n",
      "Epoch 555/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4998 - acc: 0.7383 - val_loss: 0.4955 - val_acc: 0.7157\n",
      "Epoch 556/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.5002 - acc: 0.7381 - val_loss: 0.4958 - val_acc: 0.7205\n",
      "Epoch 557/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4999 - acc: 0.7389 - val_loss: 0.4956 - val_acc: 0.7157\n",
      "Epoch 558/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4996 - acc: 0.7383 - val_loss: 0.4957 - val_acc: 0.7181\n",
      "Epoch 559/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4998 - acc: 0.7410 - val_loss: 0.4956 - val_acc: 0.7133\n",
      "Epoch 560/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.5000 - acc: 0.7405 - val_loss: 0.4958 - val_acc: 0.7205\n",
      "Epoch 561/600\n",
      "3730/3730 [==============================] - 0s 74us/step - loss: 0.4999 - acc: 0.7408 - val_loss: 0.4955 - val_acc: 0.7181\n",
      "Epoch 562/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5001 - acc: 0.7378 - val_loss: 0.4957 - val_acc: 0.7157\n",
      "Epoch 563/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4997 - acc: 0.7394 - val_loss: 0.4956 - val_acc: 0.7181\n",
      "Epoch 564/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4998 - acc: 0.7405 - val_loss: 0.4958 - val_acc: 0.7181\n",
      "Epoch 565/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5000 - acc: 0.7391 - val_loss: 0.4958 - val_acc: 0.7157\n",
      "Epoch 566/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5002 - acc: 0.7391 - val_loss: 0.4958 - val_acc: 0.7133\n",
      "Epoch 567/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4997 - acc: 0.7405 - val_loss: 0.4962 - val_acc: 0.7157\n",
      "Epoch 568/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5002 - acc: 0.7381 - val_loss: 0.4962 - val_acc: 0.7157\n",
      "Epoch 569/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4998 - acc: 0.7399 - val_loss: 0.4957 - val_acc: 0.7205\n",
      "Epoch 570/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5002 - acc: 0.7365 - val_loss: 0.4959 - val_acc: 0.7133\n",
      "Epoch 571/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5000 - acc: 0.7375 - val_loss: 0.4959 - val_acc: 0.7157\n",
      "Epoch 572/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4997 - acc: 0.7394 - val_loss: 0.4960 - val_acc: 0.7157\n",
      "Epoch 573/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4998 - acc: 0.7399 - val_loss: 0.4959 - val_acc: 0.7157\n",
      "Epoch 574/600\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.4996 - acc: 0.7402 - val_loss: 0.4959 - val_acc: 0.7157\n",
      "Epoch 575/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5000 - acc: 0.7383 - val_loss: 0.4957 - val_acc: 0.7157\n",
      "Epoch 576/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4996 - acc: 0.7399 - val_loss: 0.4959 - val_acc: 0.7157\n",
      "Epoch 577/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4999 - acc: 0.7381 - val_loss: 0.4959 - val_acc: 0.7157\n",
      "Epoch 578/600\n",
      "3730/3730 [==============================] - 0s 90us/step - loss: 0.4994 - acc: 0.7394 - val_loss: 0.4963 - val_acc: 0.7157\n",
      "Epoch 579/600\n",
      "3730/3730 [==============================] - 0s 114us/step - loss: 0.4997 - acc: 0.7391 - val_loss: 0.4956 - val_acc: 0.7181\n",
      "Epoch 580/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4998 - acc: 0.7405 - val_loss: 0.4959 - val_acc: 0.7157\n",
      "Epoch 581/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.4997 - acc: 0.7381 - val_loss: 0.4958 - val_acc: 0.7157\n",
      "Epoch 582/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4997 - acc: 0.7391 - val_loss: 0.4961 - val_acc: 0.7133\n",
      "Epoch 583/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5002 - acc: 0.7394 - val_loss: 0.4960 - val_acc: 0.7133\n",
      "Epoch 584/600\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.4998 - acc: 0.7367 - val_loss: 0.4962 - val_acc: 0.7157\n",
      "Epoch 585/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4998 - acc: 0.7381 - val_loss: 0.4960 - val_acc: 0.7181\n",
      "Epoch 586/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.5000 - acc: 0.7378 - val_loss: 0.4959 - val_acc: 0.7205\n",
      "Epoch 587/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.5001 - acc: 0.7402 - val_loss: 0.4960 - val_acc: 0.7181\n",
      "Epoch 588/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4999 - acc: 0.7397 - val_loss: 0.4960 - val_acc: 0.7157\n",
      "Epoch 589/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4999 - acc: 0.7386 - val_loss: 0.4959 - val_acc: 0.7205\n",
      "Epoch 590/600\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4997 - acc: 0.7383 - val_loss: 0.4961 - val_acc: 0.7157\n",
      "Epoch 591/600\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.5000 - acc: 0.7367 - val_loss: 0.4962 - val_acc: 0.7157\n",
      "Epoch 592/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4996 - acc: 0.7394 - val_loss: 0.4961 - val_acc: 0.7181\n",
      "Epoch 593/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.4998 - acc: 0.7408 - val_loss: 0.4960 - val_acc: 0.7181\n",
      "Epoch 594/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4998 - acc: 0.7421 - val_loss: 0.4961 - val_acc: 0.7181\n",
      "Epoch 595/600\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4999 - acc: 0.7381 - val_loss: 0.4962 - val_acc: 0.7157\n",
      "Epoch 596/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.4999 - acc: 0.7373 - val_loss: 0.4960 - val_acc: 0.7157\n",
      "Epoch 597/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.4998 - acc: 0.7389 - val_loss: 0.4960 - val_acc: 0.7205\n",
      "Epoch 598/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.5000 - acc: 0.7391 - val_loss: 0.4960 - val_acc: 0.7181\n",
      "Epoch 599/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.4995 - acc: 0.7386 - val_loss: 0.4961 - val_acc: 0.7157\n",
      "Epoch 600/600\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.4996 - acc: 0.7386 - val_loss: 0.4960 - val_acc: 0.7181\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(4, kernel_initializer='normal', input_dim=len(X[0]), activation='relu'))\n",
    "model.add(Dense(4, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adamax',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X, y.values, epochs=600, validation_split = 0.1)\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prever relação do AJUSTE ATUAL com o AJUSTE ANTERIOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T18:06:26.317417Z",
     "start_time": "2019-09-13T18:06:26.255453Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Número Negócios</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Var pontos</th>\n",
       "      <th>Dif_contratos</th>\n",
       "      <th>Dif_minmax</th>\n",
       "      <th>Dif_abert_ultimo</th>\n",
       "      <th>Dif_abert_ajuste</th>\n",
       "      <th>Dif_abert_min</th>\n",
       "      <th>Dif_abert_max</th>\n",
       "      <th>Dif_abert_medio</th>\n",
       "      <th>Dif_ajuste_ultimo</th>\n",
       "      <th>Dif_ajuste_medio</th>\n",
       "      <th>Dif_ultimacomp_ultimavend</th>\n",
       "      <th>Média</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29/07/2019</td>\n",
       "      <td>271.92</td>\n",
       "      <td>42.939771</td>\n",
       "      <td>145520</td>\n",
       "      <td>132520</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>7.5</td>\n",
       "      <td>-16.5</td>\n",
       "      <td>-4.499</td>\n",
       "      <td>2.797</td>\n",
       "      <td>-4.702</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.785600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26/07/2019</td>\n",
       "      <td>321.28</td>\n",
       "      <td>58.414828</td>\n",
       "      <td>125890</td>\n",
       "      <td>23510</td>\n",
       "      <td>34.5</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-9.755</td>\n",
       "      <td>19.0</td>\n",
       "      <td>-15.5</td>\n",
       "      <td>4.970</td>\n",
       "      <td>-5.755</td>\n",
       "      <td>-4.785</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.776534</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25/07/2019</td>\n",
       "      <td>416.51</td>\n",
       "      <td>72.105906</td>\n",
       "      <td>129780</td>\n",
       "      <td>15894</td>\n",
       "      <td>50.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>14.834</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-39.0</td>\n",
       "      <td>-16.490</td>\n",
       "      <td>3.334</td>\n",
       "      <td>-1.656</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.779853</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24/07/2019</td>\n",
       "      <td>261.37</td>\n",
       "      <td>50.725253</td>\n",
       "      <td>31160</td>\n",
       "      <td>-7529</td>\n",
       "      <td>25.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.356</td>\n",
       "      <td>13.5</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>4.779</td>\n",
       "      <td>-3.644</td>\n",
       "      <td>7.135</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.769510</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23/07/2019</td>\n",
       "      <td>335.86</td>\n",
       "      <td>59.121713</td>\n",
       "      <td>356000</td>\n",
       "      <td>-2908</td>\n",
       "      <td>39.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>27.972</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>-22.634</td>\n",
       "      <td>-2.028</td>\n",
       "      <td>5.338</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.767201</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Data  Número Negócios     Volume  Var pontos  Dif_contratos  \\\n",
       "0  29/07/2019           271.92  42.939771      145520         132520   \n",
       "1  26/07/2019           321.28  58.414828      125890          23510   \n",
       "2  25/07/2019           416.51  72.105906      129780          15894   \n",
       "3  24/07/2019           261.37  50.725253       31160          -7529   \n",
       "4  23/07/2019           335.86  59.121713      356000          -2908   \n",
       "\n",
       "   Dif_minmax  Dif_abert_ultimo  Dif_abert_ajuste  Dif_abert_min  \\\n",
       "0        24.0              -3.0            -0.203            7.5   \n",
       "1        34.5              -4.0            -9.755           19.0   \n",
       "2        50.0              11.5            14.834           11.0   \n",
       "3        25.5               6.0             2.356           13.5   \n",
       "4        39.0              30.0            27.972            2.0   \n",
       "\n",
       "   Dif_abert_max  Dif_abert_medio  Dif_ajuste_ultimo  Dif_ajuste_medio  \\\n",
       "0          -16.5           -4.499              2.797            -4.702   \n",
       "1          -15.5            4.970             -5.755            -4.785   \n",
       "2          -39.0          -16.490              3.334            -1.656   \n",
       "3          -12.0            4.779             -3.644             7.135   \n",
       "4          -37.0          -22.634             -2.028             5.338   \n",
       "\n",
       "   Dif_ultimacomp_ultimavend     Média  target  \n",
       "0                        0.5  3.785600       0  \n",
       "1                        1.5  3.776534       1  \n",
       "2                        1.0  3.779853       0  \n",
       "3                        2.0  3.769510       1  \n",
       "4                        2.0  3.767201       0  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Aqui eu posso pensar em colocar uma camada a mais. Ver primeiro de o ajuste será maior depois ver \n",
    "se a abertura tá menor que o ajuste anterior '''\n",
    "\n",
    "df_abert_old = df.copy()\n",
    "\n",
    "#1 se o Ajuste Atual for maior que o Ajuste Anterior\n",
    "\n",
    "\n",
    "df_abert_old['target'] = df_abert_old.Ajuste.shift(-1) - df_abert_old['Ajuste']\n",
    "df_abert_old['target'] = df_abert_old['target'].apply(lambda x: 1 if x > 0 else 0)\n",
    "df_abert_old = df_abert_old.drop(len(df_abert_old)-1)\n",
    "\n",
    "df_abert_old['Média'] = (df_abert_old['Último Preço'] + df_abert_old['Abertura'] + df_abert_old['Máximo'] + df_abert_old['Mínimo'] + df_abert_old['Médio'] + df_abert_old['Ajuste'] + df_abert_old['Última oferta de compra']+ df_abert_old['Última oferta de venda'])/8\n",
    "df_abert_old = df_abert_old.drop(columns = ['Último Preço','Abertura','Máximo','Mínimo','Médio','Última oferta de compra','Última oferta de venda','Contratos Negociados', 'Ajuste'])\n",
    "\n",
    "\n",
    "df_change = df_abert_old[['target']]\n",
    "df_abert_old = df_abert_old.drop(columns = 'target')\n",
    "df_abert_old['target'] = df_change\n",
    "\n",
    "df_abert_old.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T18:06:27.164651Z",
     "start_time": "2019-09-13T18:06:27.027710Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>Data</th>\n",
       "      <th>Número Negócios</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Var pontos</th>\n",
       "      <th>Dif_contratos</th>\n",
       "      <th>Dif_minmax</th>\n",
       "      <th>Dif_abert_ultimo</th>\n",
       "      <th>Dif_abert_ajuste</th>\n",
       "      <th>Dif_abert_min</th>\n",
       "      <th>Dif_abert_max</th>\n",
       "      <th>Dif_abert_medio</th>\n",
       "      <th>Dif_ajuste_ultimo</th>\n",
       "      <th>Dif_ajuste_medio</th>\n",
       "      <th>Dif_ultimacomp_ultimavend</th>\n",
       "      <th>Média</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.498562</td>\n",
       "      <td>2.807394</td>\n",
       "      <td>0.723413</td>\n",
       "      <td>14/06/2019</td>\n",
       "      <td>2.865806</td>\n",
       "      <td>2.604802</td>\n",
       "      <td>1.099741</td>\n",
       "      <td>-0.181456</td>\n",
       "      <td>1.312772</td>\n",
       "      <td>1.557008</td>\n",
       "      <td>-0.120086</td>\n",
       "      <td>-0.332730</td>\n",
       "      <td>-2.054306</td>\n",
       "      <td>-1.942393</td>\n",
       "      <td>-0.196860</td>\n",
       "      <td>-0.178976</td>\n",
       "      <td>-0.012160</td>\n",
       "      <td>2.178146</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.236543</td>\n",
       "      <td>1.093142</td>\n",
       "      <td>0.813228</td>\n",
       "      <td>13/06/2019</td>\n",
       "      <td>2.062037</td>\n",
       "      <td>2.314525</td>\n",
       "      <td>-0.649702</td>\n",
       "      <td>-0.483898</td>\n",
       "      <td>-0.004895</td>\n",
       "      <td>-0.058399</td>\n",
       "      <td>-0.185457</td>\n",
       "      <td>0.076259</td>\n",
       "      <td>0.075808</td>\n",
       "      <td>0.280717</td>\n",
       "      <td>-0.182751</td>\n",
       "      <td>-0.177095</td>\n",
       "      <td>-0.011628</td>\n",
       "      <td>2.136805</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.688401</td>\n",
       "      <td>2.248905</td>\n",
       "      <td>0.239471</td>\n",
       "      <td>12/06/2019</td>\n",
       "      <td>2.507796</td>\n",
       "      <td>2.487949</td>\n",
       "      <td>-0.637429</td>\n",
       "      <td>-0.153140</td>\n",
       "      <td>0.440513</td>\n",
       "      <td>0.335603</td>\n",
       "      <td>-0.207233</td>\n",
       "      <td>0.785175</td>\n",
       "      <td>0.125346</td>\n",
       "      <td>0.694302</td>\n",
       "      <td>-0.223947</td>\n",
       "      <td>-0.186366</td>\n",
       "      <td>-0.012160</td>\n",
       "      <td>2.145966</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.172415</td>\n",
       "      <td>1.142010</td>\n",
       "      <td>0.374627</td>\n",
       "      <td>11/06/2019</td>\n",
       "      <td>1.687787</td>\n",
       "      <td>1.586883</td>\n",
       "      <td>0.608505</td>\n",
       "      <td>-0.243561</td>\n",
       "      <td>0.459072</td>\n",
       "      <td>-0.964603</td>\n",
       "      <td>-0.258565</td>\n",
       "      <td>1.303229</td>\n",
       "      <td>0.571184</td>\n",
       "      <td>1.353412</td>\n",
       "      <td>-0.211306</td>\n",
       "      <td>-0.217783</td>\n",
       "      <td>-0.011628</td>\n",
       "      <td>2.150522</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.012424</td>\n",
       "      <td>1.412341</td>\n",
       "      <td>1.183180</td>\n",
       "      <td>10/06/2019</td>\n",
       "      <td>1.377238</td>\n",
       "      <td>1.242523</td>\n",
       "      <td>-0.457664</td>\n",
       "      <td>-0.009270</td>\n",
       "      <td>0.069339</td>\n",
       "      <td>-0.334200</td>\n",
       "      <td>-0.229955</td>\n",
       "      <td>0.676111</td>\n",
       "      <td>0.521646</td>\n",
       "      <td>0.804634</td>\n",
       "      <td>-0.213709</td>\n",
       "      <td>-0.205765</td>\n",
       "      <td>-0.010034</td>\n",
       "      <td>2.179742</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2        Data  Número Negócios    Volume  \\\n",
       "0  1.498562  2.807394  0.723413  14/06/2019         2.865806  2.604802   \n",
       "1  2.236543  1.093142  0.813228  13/06/2019         2.062037  2.314525   \n",
       "2  1.688401  2.248905  0.239471  12/06/2019         2.507796  2.487949   \n",
       "3  2.172415  1.142010  0.374627  11/06/2019         1.687787  1.586883   \n",
       "4  2.012424  1.412341  1.183180  10/06/2019         1.377238  1.242523   \n",
       "\n",
       "   Var pontos  Dif_contratos  Dif_minmax  Dif_abert_ultimo  Dif_abert_ajuste  \\\n",
       "0    1.099741      -0.181456    1.312772          1.557008         -0.120086   \n",
       "1   -0.649702      -0.483898   -0.004895         -0.058399         -0.185457   \n",
       "2   -0.637429      -0.153140    0.440513          0.335603         -0.207233   \n",
       "3    0.608505      -0.243561    0.459072         -0.964603         -0.258565   \n",
       "4   -0.457664      -0.009270    0.069339         -0.334200         -0.229955   \n",
       "\n",
       "   Dif_abert_min  Dif_abert_max  Dif_abert_medio  Dif_ajuste_ultimo  \\\n",
       "0      -0.332730      -2.054306        -1.942393          -0.196860   \n",
       "1       0.076259       0.075808         0.280717          -0.182751   \n",
       "2       0.785175       0.125346         0.694302          -0.223947   \n",
       "3       1.303229       0.571184         1.353412          -0.211306   \n",
       "4       0.676111       0.521646         0.804634          -0.213709   \n",
       "\n",
       "   Dif_ajuste_medio  Dif_ultimacomp_ultimavend     Média  target  \n",
       "0         -0.178976                  -0.012160  2.178146       0  \n",
       "1         -0.177095                  -0.011628  2.136805       0  \n",
       "2         -0.186366                  -0.012160  2.145966       0  \n",
       "3         -0.217783                  -0.011628  2.150522       1  \n",
       "4         -0.205765                  -0.010034  2.179742       0  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = StandardScaler()\n",
    "df_abert_old.iloc[:,1:-1]  = sc.fit_transform(df_abert_old.iloc[:,1:-1])\n",
    "\n",
    "\n",
    "\n",
    "df_moeda = pd.read_csv('moedas_features.csv')\n",
    "\n",
    "sc = StandardScaler()\n",
    "df_moeda.iloc[:,1:] = sc.fit_transform(df_moeda.iloc[:,1:])\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "dataset = pca.fit_transform(df_moeda.iloc[:,1:])\n",
    "df_moeda_pca = pd.DataFrame(dataset)\n",
    "df_moeda_pca['Data'] = df_moeda.iloc[:,0:1]\n",
    "\n",
    "df_abert = pd.merge(df_moeda_pca, df_abert_old, on = 'Data')\n",
    "\n",
    "df_abert.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T18:06:32.017548Z",
     "start_time": "2019-09-13T18:06:31.997558Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.73532846,  1.39379165,  0.41961073, ..., -0.19596445,\n",
       "        -0.01402039,  2.00404183],\n",
       "       [ 1.0980536 ,  0.54176439,  0.47191895, ..., -0.19421976,\n",
       "        -0.01355552,  1.96200735],\n",
       "       [ 0.82863612,  1.1162082 ,  0.13776336, ..., -0.20281729,\n",
       "        -0.01402039,  1.97132267],\n",
       "       ...,\n",
       "       [ 2.64513829,  0.93990608,  0.91767338, ..., -0.22194049,\n",
       "        -0.01448526, -0.5714771 ],\n",
       "       [ 2.91088093,  0.5781823 , -1.47667751, ..., -0.21720465,\n",
       "        -0.01448526, -0.55704584],\n",
       "       [ 2.26629691,  1.88804075,  0.41997155, ..., -0.20357272,\n",
       "        -0.01448526, -0.55159947]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df_abert[['target']]\n",
    "X = df_abert.drop(columns = ['Data','target'])\n",
    "X_columns = df_abert.drop(columns = ['Data','target'])\n",
    "\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "#X = X.values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T18:06:32.776233Z",
     "start_time": "2019-09-13T18:06:32.768219Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T18:06:33.692985Z",
     "start_time": "2019-09-13T18:06:33.654029Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\choice\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\choice\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8506024096385543"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression().fit(x_train, y_train)\n",
    "\n",
    "predictions = clf.predict(x_test)\n",
    "\n",
    "probas = clf.predict_proba(x_test) \n",
    "\n",
    "\n",
    "score = clf.score(x_test, y_test)\n",
    "\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T18:06:35.143478Z",
     "start_time": "2019-09-13T18:06:35.019549Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\choice\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "c:\\users\\choice\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8409638554216867"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = RandomForestClassifier()\n",
    "r.fit(x_train, y_train)  \n",
    "\n",
    "predictions = r.predict(x_test)\n",
    "\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T18:06:38.126683Z",
     "start_time": "2019-09-13T18:06:37.855841Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfMAAAEWCAYAAAByhn56AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XmYXFW97vHvC0QSE0jEgAcQaOSAKAjBdFCQGcThcBgEDYNiREWUyQGVo/cCggPIERURMXoQBURkPIBDGCQEGTOnEwaVJFwUJIwhQECS/O4faxXZXVR1d3V3VXV1v5/nqad37b32GqoCq9bae/+WIgIzMzNrXWs0uwJmZmbWN+7MzczMWpw7czMzsxbnztzMzKzFuTM3MzNrce7MzczMWpw7czMzsxbnztzMXiVpsaTlkp4vvDbqY557SPp7f9Wxh2VeJOmbjSyzGkmnSbqk2fWwwc2duZmV+8+IGFV4PdrMykhaq5nl90Ur191aiztzM+sRSe+WdKekZyXNlbRH4dgnJN0vaZmkhZI+k/ePBP4AbFQc6ZePnMtH73mG4KuS5gEvSForn3eVpCckLZJ0Qg/r3SYpch0fkfSMpGMkTZA0L7fnvEL6SZLukPQjSUslPSBp78LxjSRdJ+lpSX+T9OnCsdMkXSnpEknPAccAXwMm5rbP7erzKn4Wkr4kaYmkxyR9onB8hKTvSXo41+/Pkkb04DualMtalj+/I3ry+Vlr8K9GM+uWpI2B3wEfA/4I7A1cJWnriHgCWALsBywEdgP+IGl6RMyS9AHgkoh4cyG/nhR7GPAfwJPAKuB64H/z/jcDN0t6MCKm9LAZ7wK2zPW7LrdjH2AYMFvSFRFxWyHtlcBY4EPA1ZI2j4ingcuABcBGwNbATZIWRsQt+dwDgA8DRwJr5zz+PSI+WqhL1c8rH/83YDSwMfBe4EpJ10bEM8B/A9sAOwP/zHVd1dV3BLwInAtMiIgHJW0IrNfDz81agEfmZlbu2jyye1bStXnfR4HfR8TvI2JVRNwEzAA+CBARv4uIhyK5DbgR2LWP9Tg3Ih6JiOXABGD9iDg9Iv4VEQuBnwGH1pDfGRHxUkTcCLwAXBYRSyLiH8DtwA6FtEuAH0TEKxFxOfAg8B+SNgF2Ab6a85oD/JzUgZbcFRHX5s9peaWK9ODzegU4PZf/e+B54K2S1gCOAk6MiH9ExMqIuDMiXqab74j0g2hbSSMi4rGIWFDDZ2cDnDtzMyt3YESMya8D877NgA8XOvlnSZ3ahgCSPiDp7jz1/CypAxnbx3o8UtjejDRVXyz/a8Cbasjv8cL28grvRxXe/yM6r0L1MGkkvhHwdEQsKzu2cZV6V9SDz+upiFhReP9irt9YYDjwUIVsq35HEfECMJE07f+YpN/lEbsNEu7MzawnHgEuLnTyYyJiZEScKWlt4CrS9O+bImIM8HugNJdeaWnGF4DXF97/W4U0xfMeARaVlb9ORHywwnn9YWN1vhawKfBofq0naZ2yY/+oUu/XvO/B59WVJ4GXgC0qHKv6HQFExJSIeC/pB9gDpJkNGyTcmZtZT1wC/Kek90laU9LwfKPWm4HXka4NPwGsyNfI9y2c+zjwRkmjC/vmAB+UtJ6kfwM+30359wLP5ZviRuQ6bCtpQr+1sLMNgBMkDZP0YeBtpCnsR4A7ge/kz2A74JPApV3k9TjQlqfIofvPq6qIWAVcCJyTb8RbU9JO+QdC1e9I0psk7a90Q+LLpGn7lTV+JjaAuTM3s27lTuwA0tT2E6RR4JeBNfKU8wnAb4FngMNJN5iVzn2AdNPYwjz9uxFwMTAXWEy6Xnx5N+WvBP4TGAcsIo1Qf066Sawe7iHdLPck8C3gkIh4Kh87DGgjjdKvAU7N16eruSL/fUrSrO4+rx44CegApgNPA2eRvoeq31F+fSnX+Wlgd+BzNZRpA5w6XxYyMxvaJE0CPhURuzS7LmY95ZG5mZlZi3NnbmZm1uI8zW5mZtbiPDI3MzNrcQ7nag0xduzYaGtra3Y1zMxaysyZM5+MiPW7S+fO3Bqira2NGTNmNLsaZmYtRdLDPUnnaXYzM7MW587czMysxbkzNzMza3HuzM3MzFqcO3MzM7MW587czMysxbkzNzMza3HuzM3MzFqcg8ZYQ8ycCVKza2Fm1liNWv7EI3MzM7MW587czMysxbkzL5C0UtIcSQskzZX0RUlr5GPtks7N22tLujmnnVhjGVMltfehjm2SDu/luRtJurKX506StFFvzjUzs/ryNfPOlkfEOABJGwC/BkYDp0bEDKC0UsgOwLBS2kaRtBbQBhye61aTiHgUOKSXxU8C5gOP9vJ8MzOrE4/Mq4iIJcDRwHFK9pB0Q+7kLwHG5ZH5FpXOl3SKpOmS5kuaLHW6/eujku7Mx3bM6UdKujCfM1vSAXn/JElXSLoeuBE4E9g1l/2FKmW3Sbpd0qz82rmwf34h3/MK59yQ27impIty3TokfUHSIUA7cGkud4Sk8ZJukzRT0hRJG1aox9GSZkiaAU/U+hWYmVkPeWTehYhYmKfZNyjsWyLpU8BJEbFfF6efFxGnA0i6GNgPuD4fGxkRO0vaDbgQ2Bb4OvCniDhK0hjgXkk35/Q7AdtFxNOS9uhB2UuA90bES5K2BC4jdcY9MQ7YOCK2zXUfExHPSjoulztD0jDgR8ABEfFEvtTwLeCoYkYRMRmYnPJpb9A9nWZmQ4878+719oGqPSV9BXg9sB6wgNWd+WUAETFN0rq5894X2F/SSTnNcGDTvH1TRDxdQ9nDgPMkjQNWAlvVcO5C4C2SfgT8jjQbUO6tpB8gN+UJhzWBx2oow8zM+pE78y5IegupM1wCvK2G84YD5wPtEfGIpNNInXNJ+Sg1SD8aDo6IB8vyehfwQo1V/wLwOLA96VLKSxXSrKDzZZbhABHxjKTtgfcBxwIfoWzEneu6ICJ2qrFeZmZWB75mXoWk9YELSNPltU4RlzruJyWN4rU3nU3MZewCLI2IpcAU4PjStXVJO1TJexmwTjfljwYei4hVwMdII+dyi0nX/deQtAlQunY/FlgjIq4C/i/wzgrlPgisL2mnfM4wSdt0UyczM6sTj8w7GyFpDmmaegVwMXBOrZnka8w/AzpIneb0siTPSLoTWJfVo94zgB8A83KHvph0nb3cPGCFpLnARRHx/QppzgeukvRh4FY6j+xLP0zuABblOs4HZuX9GwO/KD2SB/xX/nsRcIGk5aRr+IcA50oaTfp39APSpYSKxo+HGTOqHTUzs75Q7YNOa1WSxgPnRMTujS67vb09Zrg3NzOriaSZEdHtDcwemQ8ROVDNr4GTm1G+Y7ObNYbHZ0OTO/M+knQNsHnZ7q9GxJQGlP0+4Kyy3Ysi4qDytDnoTS13tZuZWYtwZ55JWkm6fly6Xv5L4AcRsSqPao+MiBMkrU16ZGss8J1KHWcXZUwlP6vdyzq2ATtHxK8B8g+GHv9okLSY9Lz5CuDwiDg/798IODciehsdzszMmsid+WqDOpRrmTHA50g3yvU1zKuZmTWZH02roMVDuVYM01qW7Exgi5zP2RXCvF4r6XpJiyQdp7TgzGxJd0taL6cbl9/Pk3SNpDfU/EGbmVm/cGdeRUQsJH0+nUK5Ap8Cbo+IcRHxUJXTz4uICTkk6gg6P2I2MiJ2Jo2ML8z7SqFcJwB7AmdLGpmP7QR8PCL2It28Viq70iNpPXUy8FDO58sVjm9LmgHYkRSm9cWI2AG4Czgyp/kV6d6A7UiXJ04tz8Sx2c3MGsOdedf6Esr1HkkdwF5AMaDKq6FcgWIo15PzM+5T6Vso1/5wa0Qsi4gngKWsDkPbAbTlZ8vHRMRtef8vgd3KM4mIyRHRnh6rWL8hFTczG4p8zbyKFg7lWjFMa41eLmyvKrxfhf/NmJkNOB6ZV9DioVwXUyFMay/yqSrX+RlJu+ZdHwNu6+IUMzOrI4+yVhssoVyrhWkt1vEpSXfkm97+APy4pkYmHyeFd309aaW1T3SV2OFczczqx+FcrSEcztXMrHY9DefqaXYzM7MW52n2PmiVUK4DgWOz20DlyUkbDDzNbg0htcfqIHpmA4f/F2gDmafZayRpZY6ItkDS3Bz1bI18rF3SuXl7bUk357QTayxjao7z3ts6tkk6vLfn97LM5/PfjSRd2ciyzcysZzzNvtpQis1eM8dvNzMbuDwyr2AQxGbvSWz1LST9UdJMSbdL2jrv31zSXbkuZxTyLcZvHy7pF5I6cr57VqmLw7mamTWAO/MqWjw2e09iq08Gjo+I8cBJ5BXUgB8CP8l1+WeV/I/Nn8c7gMOAX+bId504nKuZWWO4M+9aq8Zm7y62+ihgZ+CKXOZPgQ1zmveU6kgKnFPJLqVjEfEA8DCwVY11NDOzfuJr5lW0cGx26D62+hrAs11c9+/u/l4/ZGZmNoB4ZF5Bi8dm71ZEPAcskvThXJ4kbZ8P3wEcmrePqJLFtNIxSVuRZhEerJLWzMzqzCPz1QZLbPaeOgL4iaT/Q2rzb4C5wInAryWdCFxV5dzzSXHZO0if1aSIeLlKWsCx2c3M6slBY6whHJvdzKx2DhpjZmY2RHiavQ8cm73nhmpsdk98mVkjeJq9CSRNBb5T7PQlfR7YKiI+17SKpXq0ATtHRL9GmRuqsdn9n5eZ9YWn2Qe2y1h9x3jJoax+vrtL+e7zen13baSAM2Zm1iLcmTfHlcB+ktaGV0fDGwF/ljRK0i2SZuVwqaXQrm2S7pd0PjAL2KSYoaTFks6SdG9+/Xvev1nOb17+u2nef5Gkc3No2YWSSo/QdQoZWy10q6Rtcjlzct5b1v1TMzOzityZN0FEPAXcC7w/7zoUuDw/0/4ScFBEvJMU2vV7pefPgbcCv4qIHSLi4QpZPxcROwLnkR51I2//KiK2Ay4Fzi2k35AUzW0/UicOrw0ZWy106zHAD3PgmXbg7+WVcWx2M7PGcGfePMWp9uIUu4BvS5oH3AxsDLwpH3s4Iu7uJs/S353y9k6sXmXtYlLnXXJtRKyKiPsKZZSrFrr1LuBrkr4KbBYRy8tPdGx2M7PGcGfePNcCe0t6JzAiImbl/UeQer7xedT7OKujynUX2jWqbFdLUwz0Uu1e84r78w1y+wPLgSmS9uqmbmZmVifuzJskIp4nLapyIZ1vfBsNLImIV/L16c1qyHZi4e9deftOOodn/XM3eZSHjK0YujXHrl8YEecC1wHb1VBPMzPrR37OvLkuA66m853tlwLXp+vMzAEeqCG/tSXdQ/qRdljedwJwoaQvky5cf6KbPDqFjKVK6FZJE0lrs79CWir19BrqaWZm/cjPmQ8SkhaTVmp7stl1qcThXM3MaufnzM3MzIYIT7MPEhHR1uw6dGWwhHP1RJaZDUQemZuZmbU4d+ZmZmYtbsh25pJW5lCkCyTNlfTFUrxzSe2Szs3ba0u6Oaed2HWurynjdEn79KJubZL6PT66pKmS2vP218qO3dnf5ZmZWWMM5Wvmy3NQFiRtQIqSNho4NSJmsHqJrx2AYaW0tYiIU3pZtzbSYif9unJZma8B3y69iYid61iWmZnV0ZAdmRdFxBLgaOC4vCLZHpJuyJ38JcC4PDLfotL5kk6RNF3SfEmTS7HU82Imh+TtxZLG5u32vAwqknbPec/JC5msw2sXO1lT0tm5jHmSPlOtLaW6F96fJ2lSWZozgRE5/0vzvucL598m6beS/iLpTElH5EVVOkqfQbUFXMrKcWx2M7MGcGeeRcRC0uexQWHfEuBTrF545KEqp58XERMiYltgBGnhkp46CTg2j/x3JYVHLV/s5JPA0oiYAEwAPi1p8xqb+KqIOJk8MxERR1RIsj1wIvAO4GOkddZ3BH4OHJ/TdLWAS6kcx2Y3M2sAd+ad9fbhqT0l3ZOjpO0FbFPDuXcA50g6ARgTESsqpNkXOFLSHOAe4I1APZccnR4Rj0XEy8BDwI15fwfpEgB0vYCLmZk10FC+Zt5JjjW+ElgCvK2G84aTQp62R8Qjkk5j9cIoRStY/ePp1eMRcaak3wEfBO6ucsOcgOMjYkoPqlQsp1NZNSguwLKq8H4V1f/N+AlsM7Mm8cgckLQ+cAFpurzWTqnUWT4paRRwSJV0i4HxefvgQtlbRERHRJxFuulua1672MkU4LOShuVztpI0sko5DwNvz3fhjwb2rpLulVJ+vVTrAi5mZlYnQ3lkPiJPWw8jjWYvBs6pNZOIeFbSz0hT0IuB6eVJ8t9vAP+THwm7p3D883l1tJXAfcAfSCPg4mInPyRNb8/KN9c9ARxYpT6PSPotacGUvwKzq1R9MjBP0qwq1827U9MCLuPHg0Ozm5nVhxdaqSNJ1wPnRMStza5Ls3mhFTOz2vV0oZWhPDKvK0kXAq/H08+AY7ObmdWTO/MaSLoGKH8k7KuVbkyLiKPqXJd3kC4NFL0cEe+qZ7lmZjbwuDOvQUQc1Ow6lEREB1BzVLr+kmce9gOW5OfrzcysSXw3u/XWRcD7m10JMzNzZ269FBHTgKebXQ8zM3NnbnXk2OxmZo3hztzqxrHZzcwaw525mZlZi3NnbmZm1uLcmVuvSLoMuAt4q6S/S/pkV+nHj08BV1r9ZWY2EPk5c+uViDis2XUwM7PEI3MzM7MW55G5NUSrx2b3FLuZDWQemZuZmbW4IduZS1opaY6kBZLmSvqipDXysXZJ5+bttSXdnNNOrLGM0yXt04u6tUk6vNbz6kHSYklj8/adza6PmZm91lCeZl8eEeMAJG0A/BoYDZwaETOA0uLbOwDDSmlrERGn9LJubcDhuU4DRkTs3Ow6mJnZaw3ZkXlRRCwBjgaOU7KHpBtyJ38JMC6PzLeodL6kUyRNlzRf0mQpXR2WdJGkQ/J2cYTbLmlq3t495z1H0mxJ6wBnArvmfV+QtKaks3MZ8yR9plpbct1vk/RbSX+RdKakIyTdK6mj1AZJ60u6Kuc5XdJ78v43Srox1+WngAp5P5//Ktdnfs6zphkLMzPrX+7Ms4hYSPo8NijsWwJ8Crg9IsZFxENVTj8vIibkpUBHkJYG7amTgGPzyH9XYDlwcqHM7wOfBJZGxARgAvBpSeXrqhdtD5wIvAP4GLBVROwI/Bw4Pqf5IfD9nOfB+RjAqcCfI2IH4Dpg0wr5f4i0/Or2wD7A2ZI2LE/k2OxmZo3hzryz3t5vvaekeyR1AHsB29Rw7h3AOZJOAMZExIoKafYFjpQ0B7gHeCOwZRd5To+IxyLiZeAh4Ma8v4M0hQ+pEz4v53kdsG6eFdiNNBtBRPwOeKZC/rsAl0XEyoh4HLiN9COjE8dmNzNrjKF8zbwTSW8BVgJLgLfVcN5w4HygPSIekXQaMLxC0hWs/vH06vGIOFPS74APAndXuWFOwPERMaWH1Xq5sL2q8H4Vq7/zNYCdImJ5WXsAunsQq4UfMjMzG3w8MiddPwYuIE2X1/pEcaljflLSKOCQKukWA+Pz9sGFsreIiI6IOIt0093WwDJgncK5U4DPShqWz9lK0sga61nuRuC4Qj1KN/hNA47I+z4AvKHCudOAifla/vqk0fy9fayPmZn10lAemY/IU8zDSKPmi4Fzas0kIp6V9DPSFPZiYHp5kvz3G8D/SPoaaaq85POS9iTNCtwH/IE0gl4haS5wEen6dhswK99c9wRwYK11LXMC8GNJ80j/DqYBx+R6XiZpFmn6/P9VOPcaYCdgbm7fVyLin10VNn48zJjRVQozM+st1T4QtZ6SdD1wTkTc2uy6NFt7e3vMcG9uZlYTSTPTfUdd8zR7nUi6EHg98Odm18XMzAa3oTzN3iVJxwK/jIjnC/uuAcofCftqpRvTIuKoOtfvHaRLA0UvR8S7enDuROCeiFhcj7pVMtBjs3uCysxa2ZDrzCUFaer7S/n9ScCoiDitkOZjwHrFjhwgIg5qYD3bgEXACRHxo7zvPGBGRFwUER2kZ71rzfejwIYRcXk36U4HpkXEzbWWYWZmjTUUp9lfBj5UisZWxZrAN+tRuKRafkAtAU6U9Lr+Kj8iLomIs3uQ7hR35GZmrWEoduYrgMnAF8oPlMKv5pFvFMKX9jVE6mk5zOuNwK8kDZf0i3zu7Hw3eyVPALcAH69Q1y0k/VHSTEm3S9q6sP/uXP7pPQnBKukred9cSWcWP4u8vXeuZ4ekCyWtnfefKek+pRCz/927r8PMzPpqyE2zZz8G5kn6bg3nbE8KJvM0sBD4eUTsKOlEUojUz7M6ROqfJW1Kej68FIBmPLBLRCyX9CWAiHhH7oRvlLRVRLxUodwzgT/kG+qKJgPHRMRfJb2LFLhmr1yHH0bEZZKOKaQvhmAdC0yXNC3vOxB4V0S8KGm9YiE5KM5FwN4R8RdJvyI98/4r4CBg6/zDZ0x5xSUdTYp5T+WosGZm1h+G4siciHgO+BXpWeue6kuIVIDrCtHWdiHfvBYRDwAPA1tVqesiUkCWV5dEzcFpdgauyGX9FCjFRt8JuCJvF1ddqxaCdR/gFxHxYi7v6bIqvBVYFBF/ye9/SQoS8xzwEvBzSR8CXqxQd4dzNTNrgKE6Mgf4ATAL+EVh36shV3NwluK16r6GSH2huKvGun4buJIU2KVUzrM1LstarUzRdfjWiudFxApJOwJ7A4eSosntVUN9zMysnwzJkTm8OgL9LWlFspLFrA65egApOlwtqoVILVcMmboVaQ76wS7q+gApOtx++f1zwCJJH855SNL2OfndrA4Xe2hZmZVCsN4IHCXp9TmvTtPswANAm6R/z+8/BtyWZwdGR8TvSZcYar6z3szM+seQ7cyz75GuH5f8DNhd0r3Au+g8mu6JE4D2fEPYfaTwqJWcD6yptMra5cCkPH3flW8Bby68PwL4ZA75uoD04wNSx/rF3IYNgaV5/zXAPFII1j+RQ7BGxB9JlwRm5Cn7k4qF5uv4nyBN6XeQZiIuIMWOvyGHg72NCjcUmplZYzic6yCTR9jL801phwKHRcQB3Z1Xbw7namZWu56Gcx3K18wHq/Gkm/AEPAvUNRKdmZk1nzvzQSYibic9fjagDMRwrp6UMrPBYqhfMzczM2t57sytZpI2kXSrpPslLciBc8zMrEk8zW69sQL4UkTMykFxZkq6KSLua3bFzMyGIo/MrWY5Et6svL0MuB/YuLm1MjMbutyZW5/kpVp3AO6pcOxoSTMkzUhrxpiZWT24M7dey1HgrgI+n6PSdeLY7GZmjeHO3HpF0jBSR35pRFzd7PqYmQ1l7sytZjkgzf8A90fEOc2uj5nZUOfO3HrjPaQFV/aSNCe/PtjsSpmZDVV+NM1qFhF/psZlXMePB4dmNzOrD4/MzczMWpxH5tYQAyk2u2Oym9lg45G5mZlZi3Nnbr0i6f2SHpT0N0knN7s+ZmZDmTtzq5mkNYEfAx8A3g4cJuntza2VmdnQ5c7cemNH4G8RsTAi/gX8BjigyXUyMxuy3Jlbb2wMPFJ4/3cqLLTi2OxmZo3hztx6o9J96a+5R9yx2c3MGsOdufXG34FNCu/fDDzapLqYmQ157sytN6YDW0raXNLrgEOB65pcJzOzIctBY6xmEbFC0nHAFGBN4MKIWNDkapmZDVnuzK1XIuL3wO97mt6x2c3M6sfT7GZmZi3Onbkh6TOS3lDPMkqx2Zv1MjMbzNyZD1KSQtLFhfdrSXpC0g1l6U4Bno6IZ6rkM1VSe97+vaQxda24mZnVzNfMB68XgG0ljYiI5cB7gX+UJ4qI03uaYUR8sB/rZ2Zm/cQj88HtD8B/5O3DgMtKBySNlHShpOmSZks6IO8fIek3kuZJuhwYUThnsaSxeftaSTMlLZB0dOOaZGZm5dyZD26/AQ6VNBzYDrincOzrwJ8iYgKwJ3C2pJHAZ4EXI2I74FvA+Cp5HxUR44F24ARJb6xXI8zMrGueZh/EImKepDbSqLz8MbJ9gf0lnZTfDwc2BXYDzi2cP69K9idIOihvbwJsCTxVTJBH7HnUvmkfWmJmZl1xZz74XQf8N7AHUBw9Czg4Ih4sJla69fs1cdbL0uwB7APsFBEvSppK+jHQSURMBianc9q7zNPMzHrP0+yD34XA6RHRUbZ/CnC8cu8taYe8fxpwRN63LWl6vtxo4JnckW8NvLsuNTczsx5xZz7IRcTfI+KHFQ6dAQwD5kman98D/AQYlafXvwLcW+HcPwJr5TRnAHf3f83NzKynFOHZT6u/9vb2mOF4rmZmNZE0My0j3TWPzM3MzFqcO3MzM7MW57vZrSFKsdkbzVeRzGwo8Mi8BeV46e8r2/d5SedXSd+Wb3IzM7NByJ15a7oMOLRs36EUwrWamdnQ4c68NV0J7CdpbUgjb2Aj4M+SzpY0X1KHpInlJ0qaJOm8wvsbchAYJD0v6awcc/1mSTvmWYCFkvbPadbMZUzP8ds/U//mmplZV9yZt6CIeIr0/Pf7865DgcuBDwHjgO1JEdrOlrRhDVmPBKbmmOvLgG+SVls7CCitrvZJYGmO6T4B+LSkzStlJuloSTMkzYAnammimZnVwJ156ypOtZem2HcBLouIlRHxOHAbqcPtqX+RAsIAdAC3RcQrebst798XOFLSHNLCLW8kxWV/jYiYHBHt6RnJ9WuohpmZ1cKdeeu6Fthb0juBERExixRvvTsr6Py9F2OqvxKrowitAl4GiIhVrH7yQcDxETEuvzaPiBv70hAzM+sbd+YtKiKeB6aSYq+XbnybBkzM17XXJ62AVh6OdTEwTtIakjYBdqyx6CnAZyUNA5C0VV461czMmsTPmbe2y4CrWT3dfg2wEzCXtPLZVyLin/kGuZI7gEWkqfP5wKway/w5acp9Vl6k5QngwN5V38zM+oNjs1tDODa7mVntHJvdzMxsiPA0uzWEw7mamdWPR+ZmZmYtzp25mZlZi3NnXiNJKyXNkbRA0lxJX5S0Rj7WLuncvL12Dok6p1JY1W7KmCqp2xseuji/TdLhvT3fzMxai6+Z1255RIwDkLQB8GtgNHBqRMwASrds7wAMK6VtFElrkR4dOzzXzczMBjmPzPsgIpYARwPHKdkjL1yyAXAJKTjLHElbVDpf0il5wZL5kibn57ZLPirpznxsx5x+pKQL8zmzJR2Q90+SdIWk64En5oAnAAAVK0lEQVQbgTOBXXPZX6hS9iRJ10q6XtIiScflWYbZku6WtF5O9+lc3lxJV0l6fd7/v5KOzNufkXRphTIcm93MrAHcmfdRRCwkfY4bFPYtAT4F3J5Dnj5U5fTzImJCRGwLjAD2KxwbGRE7A58jRXkD+Drwp7zIyZ6khVRK0dd2Aj4eEXsBJxfK/n4X1d+WNILfEfgW8GJE7ADcBRyZ01yd67g9cD9poRVIP2JOkbQr8CXg+AqfjWOzm5k1gKfZ+0dvH7raU9JXgNcD6wELgOvzscsAImKapHUljSEtcrK/pJNymuHApnn7poh4usbyb42IZcAySUsLZXcA2+XtbSV9ExgDjCKFcyUiHpd0CnArcFAvyjYzs37izryPJL0FWAksAd5Ww3nDgfOB9oh4RNJpdF70pPwJ6SD9aDg4Ih4sy+tdwAu11z4tpJKtKrwvLqxyEXBgRMyVNAnYo3DOO4CnSGupm5lZk3iavQ/yYiYXkKbLaw1PUuq4n5Q0Cjik7PjEXMYupPXDl5JGxceXrq1L2qFK3suAdWqsTzXrAI/lhVWOKO3M1/E/QLrR76Rqa5qbmVn9uTOv3YjSo2nAzaQbzr5RayYR8SzwM9KU9rXA9LIkz0i6k/RjoXSd+gxgGDBP0vz8vpJ5wIp801rFG+Bq8H9J65bfBDwA6bG7XPejIuJR0jXzC8tu4Otk/PgUja3RLzOzocALrVhDeKEVM7Pa9XShFV8zt4ZwbHYzs/pxZ94Akq4Byq8pfzUipjSg7PcBZ5XtXhQRB9W7bDMzawxPs1tDSO2xOjhe4/ift5m1Mq9n3mCNiNneizp9rZfnfb4U6c3MzAY+j8z7iaTnI2JU3i7FbL8jIk4tS/du4KyI2L2RdSrbL9J3v6rKeYtJz78/2X918cjczKxWHpk3UT/EbJ+Q47LPlXSvpHUkDZf0C0kdOX76njntJElXS/qjpL9K+m7efyarH6O7VGkltfslnQ/MAjaR9JMcO32BpG/k804gBYG5VdKted9hudz5ks7K+9aUdFHe11HpETjHZjczawyPzPtJpVGwpGeArUmR4U6KiP0k7VHarpLP60jPc0+MiOmS1gVeBE4Eto2IT0jamvR8+1bAocAppOAtLwMPArvkqHLF2YI2YCGwc0TcnfetFxFPS1oTuAU4ISLmFUfmkjYC7gbGA8/kcs8FHgHOjIj35rzG5Gfnq3w+HpmbmdXKI/OBoTcPY70VeCwipgNExHMRsQLYBbg473sAeJjUmQPcEhFLI+Il4D5gsyp5P1zqyLOPSJoFzAa2Ad5e4ZwJwNSIeCLX41JgN9IPg7dI+pGk9wPP9aKtZmbWD9yZ10lZzPaaTuW1cdlL+6spxlhfSfVHDl+N357Dr54E7B0R2wG/o3Ns+C7LjYhngO2BqcCxwM+7qJ+ZmdWRO/M66GPM9geAjSRNyHmtI2ktYBo5NrqkrUirpT1YNZfklRxTvZJ1SZ37UklvIsVZLynGdr8H2F3S2Dwdfxhwm6SxwBoRcRUp5Os7a2ynmZn1EweN6T8jJM0hxU5fQZoSP6fWTCLiX/mRtR9JGgEsB/YhrbB2gaSOnP+kiHi5i3DoAJNJcdxnkdZCL5YzV9Js0rKrC4E7ys77g6THImJPSf9FWupUwO8j4n8lbQ/8ovT4HfBfXVVk/HhwNFczs/rwDXDWEI7NbmZWO8dmtwGl0bHZ/RvVzIYSd+ZN1MyY7WZmNnj4Brhe6o/wrRFxUESMK3tNKZQxVVK30ytd1LFN0uG9Pb8sr9Ml7dMfeZmZWf/yyLz3lkfEOOgUvnU0cGpEzGB1hJQdgGGltI2S74BvAw7PdeuTiDilr3mYmVl9eGTeD/ohfOspkqbn0KiT1fkW9Y/m0K7zJe2Y04+UdGE+Z7akA/L+SZKukHQ9KVLbmcCuuezXhFstnHOtpOslLZJ0XJ5lmC3pbknr5XQXSTokby+W9A1Js3Io163755M0M7PecGfeTyJiIenz3KCwbwnwKeD2PIX+UJXTz4uICRGxLTACKIZ6HRkROwOfAy7M+74O/CkiJgB7AmdLGpmP7QR8PCL2Ak4ulP39Lqq/LWkEvyPwLeDFiNgBuAs4sso5T0bEO4GfkILPvIZjs5uZNYY78/7V2/u195R0T36GfC9SaNWSywAiYhqwrqQxwL7Ayfm59qmkyG2b5vQ3RcTTNZZ/a0Qsi4gngKXA9Xl/B2mqvpKr89+Z1dJExOSIaE+PVaxfY5XMzKynfM28n5SFb31bDecNJwWEac+Lo5xG57Cq5Q9ZBelHw8ER0SkCnKR3UQjZWoNiONhVhferqP5vpJSmq/CxZmbWAB6Z94M+hm8tddxPShoFHFJ2fGIuYxdgaUQsBaYAx5eurUvaoUrexbCsZmY2SHlE1Xv9Fb71WUk/I01pLwamlyV5RtKdpFjqR+V9ZwA/IIVqVT6v0pKq84AVkuYCF3Vz3byuHM7VzKx+HM7VGsLhXM3Mauf1zM3MzIYIT7M3UDPDt0p6H3BW2e5FEXFQvcuGxsZm92STmQ01nma3hpDaY3VQvPryP2kzGyw8zT5A9EcM9xrL20jSlf1VfzMzG/g8zV5/DY3hHhGP8trH28zMbBDzyLyB+iGG+2JJ35Z0Vw6T+k5JUyQ9JOmYnKZN0vy8PUnS1ZL+KOmvkr5byOt5SWdJmplnBHbMq7QtlLR/Ia/bcwz2WZJ2zvsPyudI0oaS/iLp3yrU1+FczcwawJ15g/UxhjvAIxGxE3A7cBFpFP5u4PQq6ceRAs+8A5goaZO8fyQwNSLGk4LLfBN4L3BQIa8lwHtzDPaJwLm5vtcA/wSOBX5GmmX4Z4W2OpyrmVkDeJq9OfpyX/d1+W8HMCoilgHLJL2U47aXuyVHjUPSfcBmwCPAv4A/FvJ6OSJeyfHh2/L+YcB5ksaRwrZuVcj3eGA+cHdEXNaH9piZWR95ZN5gZTHce6MYN708pnqlH2fFNMU46q8UQs++mldEFPP5AvA4sD3QDryukNfG+bw3lW7oMzOz5vD/hBuojzHcm2E08Fju4D8GrAkgaS3gF6RlU+8Hvti0GpqZmafZG6BfYrg3yfnAVZI+DNzK6hXZvka6vn97btt0Sb+LiPurZeTY7GZm9eOgMdYQjs1uZlY7B40xMzMbIjzNPgA1M4Z7vdQSm92TRWZmtXFnPgA1avETMzMbHLqdZm9EbPEcqey8vH2gpLcXjp0uaZ/amtVaSpHgCts7F44dI+nI5tWue5Keb3YdzMyGsp6MzBsaWxw4ELgBuA8gIk7pY36tZg/geeBOgIi4oKm1MTOzAa+mG+D6Kbb42LzdLmlq2fGdgf2Bs0v5SLpI0iGF87uLTT5K0i05lniHpAMK+R8paV6eYbg479ssp5+X/26a918k6SeSbs3xyneXdKGk+yVdVMjzeUnfy+Xdkp8lryjHPm/P22MlLS473gYcA3wht39XSadJOqlw/vclTcv1mKAUe/2vkr5ZyOdapZjrCyQdnfd9Vp1js0+S9KO8/VFJ9+Yyfyqp9Dz585K+lT+vuyW9Ke/fPH8H0yWd0UV7HZvdzKwBar6bvR9ii3eV952kcKVf7iKf7mKTvwQclOOJ7wl8L//w2Ab4OrBXRGwPnJjTnwf8KiK2Ay4lxx/P3gDsRYqEdj3wfWAb4B1KIU4hxTiflcu7DTi1N23P7V9MCirz/dz+2ysk+1dE7JbT/S8pPvq2wCRJb8xpjsox19uBE/L+K4EPFfKZCFwu6W15+z15VmUlcEShbXfnz2sa8Om8/4fATyJiAilGe7X2ODa7mVkD9PbRtL7EFu+rYmzyeyJiWUQ8AZRikwv4tqR5wM2ksKNvInXKV0bEkwAR8XTOZyfSpQNIAV12KZR1fY7U1gE8HhEdORraAlbHL18FXJ63Lyk7vx6K7V8QEY9FxMvAQqC0iMoJkuYCd+d9W+bPaKGkd+fO/a3AHcDewHhS4Jc5+f1bcj7/Il3yAJjJ6ja/ByjFY7+4/5toZma1qPludnWOLf62Gk9fweofEMNrLTvrLjb5EaRh4Pi8cMjiXJaAnjz0VExTaxz08vPL1b39kvYA9gF2iogX86WMUlmXAx8BHgCuiYiQJOCXEfFfFcoqxm8vxnWHnn2WZmbWADWNzNX32OKLSaNAgIOrpFkGrNOLvEtGA0tyR74naZUwgFuAj5SmoiWtl/ffCRyat48A/lxjeWuQpvohxSrv6vzFrG7/IVXS9Ef7n8kd+dakSxAlV5NuMDyM1bMJtwCH5PsekLSepM3o2h10/szMzKyJetKZj8g3Ri0gTVvfCHyjl+V9A/ihpNtJI71KfgN8WdLsajfSdeNSoD3ddMURpFEoEbEA+BZwW56CLsVHPwH4RJ6W/xirr6X31AvANpJmkqbyq60rDvDfwGcl3QmMrZLmeuCg0g1wNdYF0rKma+X2nEGaagcgIp4hPSWwWUTcm/fdB/wf4MZ8zk3Aht2UcSJwrKTppB8P3Ro/PgWD6cnLzMxq49jsfSTp+YgY1ex6DHSOzW5mVjs5NruZmdnQUJdwrhqEscWrqTQql/Rj0h3fRT+MiF80plZmZjaU1KUzH+qxxSPi2GbXwczMhg5Ps5uZmbU4d+ZmZmYtzp25mZlZi3NnbmZm1uLcmZuZmbU4B42xhpC0DHiw2fVosLHAk82uRAMNtfaC2zwUNLu9m0VEt8tO1uXRNLMKHuxJFKPBRNKModTmodZecJuHglZpr6fZzczMWpw7czMzsxbnztwaZXKzK9AEQ63NQ6294DYPBS3RXt8AZ2Zm1uI8MjczM2tx7szNzMxanDtz6zNJ75f0oKS/STq5wvG1JV2ej98jqa1w7L/y/gclva+R9e6t3rZXUpuk5ZLm5NcFja57b/WgzbtJmiVphaRDyo59XNJf8+vjjat13/SxzSsL3/N1jat17/WgvV+UdJ+keZJukbRZ4dhg/Y67avPA+o4jwi+/ev0C1gQeAt4CvA6YC7y9LM3ngAvy9qHA5Xn77Tn92sDmOZ81m92mOra3DZjf7DbUqc1twHbAr4BDCvvXAxbmv2/I229odpvq2eZ87Plmt6EO7d0TeH3e/mzh3/Vg/o4rtnkgfscemVtf7Qj8LSIWRsS/gN8AB5SlOQD4Zd6+EthbkvL+30TEyxGxCPhbzm8g60t7W1W3bY6IxRExD1hVdu77gJsi4umIeAa4CXh/IyrdR31pcyvqSXtvjYgX89u7gTfn7cH8HVdr84Djztz6amPgkcL7v+d9FdNExApgKfDGHp470PSlvQCbS5ot6TZJu9a7sv2kL99TK37H0Pd6D5c0Q9Ldkg7s36rVRa3t/STwh16eO1D0pc0wwL5jh3O1vqo04ix/3rFamp6cO9D0pb2PAZtGxFOSxgPXStomIp7r70r2s758T634HUPf671pRDwq6S3AnyR1RMRD/VS3euhxeyV9FGgHdq/13AGmL22GAfYde2RuffV3YJPC+zcDj1ZLI2ktYDTwdA/PHWh63d58OeEpgIiYSbpet1Xda9x3ffmeWvE7hj7WOyIezX8XAlOBHfqzcnXQo/ZK2gf4OrB/RLxcy7kDUF/aPOC+Y3fm1lfTgS0lbS7pdaQbvsrv7LwOKN3hegjwp0h3kFwHHJrv/t4c2BK4t0H17q1et1fS+pLWBMi/5rck3Sw00PWkzdVMAfaV9AZJbwD2zfsGul63Obd17bw9FngPcF/dato/um2vpB2An5I6tSWFQ4P2O67W5gH5HTf7Djy/Wv8FfBD4C2mk+fW873TSfwAAw4ErSDe43Qu8pXDu1/N5DwIfaHZb6tle4GBgAemu2VnAfza7Lf3Y5gmkkc4LwFPAgsK5R+XP4m/AJ5rdlnq3GdgZ6MjfcwfwyWa3pZ/aezPwODAnv64bAt9xxTYPxO/Y4VzNzMxanKfZzczMWpw7czMzsxbnztzMzKzFuTM3MzNrce7MzczMWpw7czPrtcLKUfMlXS9pTA/Oeb6b42Mkfa7wfiNJV/ZDXdskze9rPjWWOU7SBxtZpg1N7szNrC+WR8S4iNiWFNXv2H7Icwxp5TkgRdqKiEO6SD8g5eh/40jPMpvVlTtzM+svd1FYqELSlyVNz2tBf6M8saRReY3oWZI6JJVWrDoT2CKP+M8ujqiV1offppDHVEnjJY2UdGEub3Yhr4okTZJ0bZ5NWCTpuLx29ey8cMZ6hfx/IOnOPPuwY96/Xj5/Xk6/Xd5/mqTJkm4kLY16OjAxt2WipB1zXrPz37cW6nO1pD8qrQn+3UJd358/o7mSbsn7amqvDQHNjlrjl19+te6LvKYzaW3oK4D35/f7ApNJi1msAdwA7FZ2zlrAunl7LCl6mChb9734HvgC8I28vSHwl7z9beCjeXsMKarXyLK6FvOZlMtbB1iftLLdMfnY94HP5+2pwM/y9m6F838EnJq39wLm5O3TgJnAiEI55xXqsC6wVt7eB7iqkG4hKY7/cOBhUtzw9Ukre22e063X0/b6NbReXjXNzPpihKQ5pI5yJmkta0id+b7A7Px+FCkW/bTCuQK+LWk30prgGwNv6qa83+YyTgU+QvoBUSpvf0kn5ffDgU2B+7vI69aIWAYsk7QUuD7v7wC2K6S7DCAipklaN98XsAspPC8R8SdJb5Q0Oqe/LiKWVylzNPBLSVuSVugaVjh2S0QsBZB0H7AZ8AZgWkQsymU93Yf22iDmztzM+mJ5RIzLHdkNpGvm55I66u9ExE+7OPcI0shzfES8ImkxqVOqKiL+IempPK09EfhMPiTg4Ih4sIa6v1zYXlV4v4rO/28sj3nd3fK9L3RR5hmkHxEHSWojjfwr1WdlroMqlA+9a68NYr5mbmZ9lkeUJwAnSRpGWjXrKEmjACRtLGmDstNGA0tyR74naSQKsIw0/V3Nb4CvAKMjoiPvmwIcL0m5vP5cjnJiznMXYGlu6zTSjxEk7QE8GZXXpS9vy2jgH3l7Ug/KvgvYXWlVQUrX8qlve60FuTM3s34REbNJq0gdGhE3Ar8G7pLUAVzJazvoS4F2STNIHeMDOZ+ngDvyDWdnVyjqStJylb8t7DuDNGU9L98sd0b/tYxnJN0JXAB8Mu87Ldd9HumGvY9XOfdW4O2lG+CA7wLfkXQH6T6DLkXEE8DRwNWS5gKX50P1bK+1IK+aZmZWhaSpwEkRMaPZdTHrikfmZmZmLc4jczMzsxbnkbmZmVmLc2duZmbW4tyZm5mZtTh35mZmZi3OnbmZmVmL+//E+ku5IfMlVwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = X_columns.columns\n",
    "importances = r.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T18:07:33.867282Z",
     "start_time": "2019-09-13T18:06:50.781652Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3731 samples, validate on 415 samples\n",
      "Epoch 1/200\n",
      "3731/3731 [==============================] - 1s 278us/step - loss: 0.6747 - acc: 0.7392 - val_loss: 0.6167 - val_acc: 0.8434\n",
      "Epoch 2/200\n",
      "3731/3731 [==============================] - 0s 61us/step - loss: 0.5782 - acc: 0.8231 - val_loss: 0.4608 - val_acc: 0.8554\n",
      "Epoch 3/200\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.4767 - acc: 0.8266 - val_loss: 0.3808 - val_acc: 0.8530\n",
      "Epoch 4/200\n",
      "3731/3731 [==============================] - 0s 56us/step - loss: 0.4325 - acc: 0.8269 - val_loss: 0.3515 - val_acc: 0.8578\n",
      "Epoch 5/200\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.4165 - acc: 0.8274 - val_loss: 0.3394 - val_acc: 0.8578\n",
      "Epoch 6/200\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.4096 - acc: 0.8298 - val_loss: 0.3329 - val_acc: 0.8627\n",
      "Epoch 7/200\n",
      "3731/3731 [==============================] - 0s 65us/step - loss: 0.4057 - acc: 0.8298 - val_loss: 0.3275 - val_acc: 0.8627\n",
      "Epoch 8/200\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.4034 - acc: 0.8295 - val_loss: 0.3250 - val_acc: 0.8627\n",
      "Epoch 9/200\n",
      "3731/3731 [==============================] - 0s 59us/step - loss: 0.4015 - acc: 0.8325 - val_loss: 0.3203 - val_acc: 0.8554\n",
      "Epoch 10/200\n",
      "3731/3731 [==============================] - 0s 66us/step - loss: 0.4000 - acc: 0.8336 - val_loss: 0.3189 - val_acc: 0.8627\n",
      "Epoch 11/200\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3987 - acc: 0.8330 - val_loss: 0.3170 - val_acc: 0.8602\n",
      "Epoch 12/200\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3974 - acc: 0.8362 - val_loss: 0.3157 - val_acc: 0.8627\n",
      "Epoch 13/200\n",
      "3731/3731 [==============================] - 0s 66us/step - loss: 0.3966 - acc: 0.8354 - val_loss: 0.3140 - val_acc: 0.8627\n",
      "Epoch 14/200\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3956 - acc: 0.8349 - val_loss: 0.3121 - val_acc: 0.8627\n",
      "Epoch 15/200\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3946 - acc: 0.8354 - val_loss: 0.3094 - val_acc: 0.8627\n",
      "Epoch 16/200\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3938 - acc: 0.8360 - val_loss: 0.3097 - val_acc: 0.8627\n",
      "Epoch 17/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3928 - acc: 0.8344 - val_loss: 0.3074 - val_acc: 0.8651\n",
      "Epoch 18/200\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3923 - acc: 0.8341 - val_loss: 0.3070 - val_acc: 0.8627\n",
      "Epoch 19/200\n",
      "3731/3731 [==============================] - 0s 56us/step - loss: 0.3913 - acc: 0.8365 - val_loss: 0.3053 - val_acc: 0.8723\n",
      "Epoch 20/200\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3907 - acc: 0.8346 - val_loss: 0.3049 - val_acc: 0.8699\n",
      "Epoch 21/200\n",
      "3731/3731 [==============================] - 0s 56us/step - loss: 0.3899 - acc: 0.8346 - val_loss: 0.3029 - val_acc: 0.8723\n",
      "Epoch 22/200\n",
      "3731/3731 [==============================] - 0s 62us/step - loss: 0.3892 - acc: 0.8365 - val_loss: 0.3020 - val_acc: 0.8747\n",
      "Epoch 23/200\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3887 - acc: 0.8338 - val_loss: 0.3005 - val_acc: 0.8723\n",
      "Epoch 24/200\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3882 - acc: 0.8354 - val_loss: 0.3004 - val_acc: 0.8747\n",
      "Epoch 25/200\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3873 - acc: 0.8325 - val_loss: 0.2982 - val_acc: 0.8747\n",
      "Epoch 26/200\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3870 - acc: 0.8330 - val_loss: 0.2977 - val_acc: 0.8723\n",
      "Epoch 27/200\n",
      "3731/3731 [==============================] - 0s 56us/step - loss: 0.3863 - acc: 0.8338 - val_loss: 0.2985 - val_acc: 0.8699\n",
      "Epoch 28/200\n",
      "3731/3731 [==============================] - 0s 62us/step - loss: 0.3857 - acc: 0.8336 - val_loss: 0.2967 - val_acc: 0.8771\n",
      "Epoch 29/200\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3853 - acc: 0.8328 - val_loss: 0.2976 - val_acc: 0.8699\n",
      "Epoch 30/200\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3848 - acc: 0.8344 - val_loss: 0.2989 - val_acc: 0.8699\n",
      "Epoch 31/200\n",
      "3731/3731 [==============================] - 0s 58us/step - loss: 0.3841 - acc: 0.8344 - val_loss: 0.2972 - val_acc: 0.8699\n",
      "Epoch 32/200\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.3840 - acc: 0.8344 - val_loss: 0.2974 - val_acc: 0.8651\n",
      "Epoch 33/200\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3835 - acc: 0.8319 - val_loss: 0.2976 - val_acc: 0.8675\n",
      "Epoch 34/200\n",
      "3731/3731 [==============================] - 0s 56us/step - loss: 0.3827 - acc: 0.8328 - val_loss: 0.2969 - val_acc: 0.8675\n",
      "Epoch 35/200\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3822 - acc: 0.8322 - val_loss: 0.2968 - val_acc: 0.8699\n",
      "Epoch 36/200\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3819 - acc: 0.8330 - val_loss: 0.2982 - val_acc: 0.8651\n",
      "Epoch 37/200\n",
      "3731/3731 [==============================] - ETA: 0s - loss: 0.3739 - acc: 0.8367- ETA: 0s - loss: 0.3757 - acc: 0.83 - 0s 55us/step - loss: 0.3815 - acc: 0.8328 - val_loss: 0.2976 - val_acc: 0.8651\n",
      "Epoch 38/200\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3808 - acc: 0.8338 - val_loss: 0.2964 - val_acc: 0.8699\n",
      "Epoch 39/200\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3809 - acc: 0.8341 - val_loss: 0.2965 - val_acc: 0.8675\n",
      "Epoch 40/200\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.3801 - acc: 0.8344 - val_loss: 0.2966 - val_acc: 0.8675\n",
      "Epoch 41/200\n",
      "3731/3731 [==============================] - 0s 59us/step - loss: 0.3799 - acc: 0.8325 - val_loss: 0.2976 - val_acc: 0.8651\n",
      "Epoch 42/200\n",
      "3731/3731 [==============================] - 0s 59us/step - loss: 0.3796 - acc: 0.8346 - val_loss: 0.2974 - val_acc: 0.8675\n",
      "Epoch 43/200\n",
      "3731/3731 [==============================] - 0s 67us/step - loss: 0.3790 - acc: 0.8330 - val_loss: 0.2965 - val_acc: 0.8675\n",
      "Epoch 44/200\n",
      "3731/3731 [==============================] - 0s 62us/step - loss: 0.3788 - acc: 0.8325 - val_loss: 0.2962 - val_acc: 0.8675\n",
      "Epoch 45/200\n",
      "3731/3731 [==============================] - 0s 63us/step - loss: 0.3785 - acc: 0.8325 - val_loss: 0.2974 - val_acc: 0.8675\n",
      "Epoch 46/200\n",
      "3731/3731 [==============================] - 0s 68us/step - loss: 0.3781 - acc: 0.8344 - val_loss: 0.2956 - val_acc: 0.8699\n",
      "Epoch 47/200\n",
      "3731/3731 [==============================] - 0s 71us/step - loss: 0.3778 - acc: 0.8314 - val_loss: 0.2961 - val_acc: 0.8699\n",
      "Epoch 48/200\n",
      "3731/3731 [==============================] - 0s 56us/step - loss: 0.3774 - acc: 0.8311 - val_loss: 0.2964 - val_acc: 0.8675\n",
      "Epoch 49/200\n",
      "3731/3731 [==============================] - 0s 66us/step - loss: 0.3772 - acc: 0.8317 - val_loss: 0.2950 - val_acc: 0.8627\n",
      "Epoch 50/200\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3767 - acc: 0.8325 - val_loss: 0.2967 - val_acc: 0.8651\n",
      "Epoch 51/200\n",
      "3731/3731 [==============================] - 0s 56us/step - loss: 0.3763 - acc: 0.8314 - val_loss: 0.2957 - val_acc: 0.8651\n",
      "Epoch 52/200\n",
      "3731/3731 [==============================] - ETA: 0s - loss: 0.3706 - acc: 0.838 - 0s 54us/step - loss: 0.3763 - acc: 0.8330 - val_loss: 0.2952 - val_acc: 0.8651\n",
      "Epoch 53/200\n",
      "3731/3731 [==============================] - 0s 58us/step - loss: 0.3759 - acc: 0.8322 - val_loss: 0.2952 - val_acc: 0.8627\n",
      "Epoch 54/200\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3758 - acc: 0.8314 - val_loss: 0.2954 - val_acc: 0.8602\n",
      "Epoch 55/200\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3753 - acc: 0.8298 - val_loss: 0.2954 - val_acc: 0.8602\n",
      "Epoch 56/200\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3751 - acc: 0.8319 - val_loss: 0.2950 - val_acc: 0.8602\n",
      "Epoch 57/200\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3751 - acc: 0.8314 - val_loss: 0.2961 - val_acc: 0.8627\n",
      "Epoch 58/200\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3744 - acc: 0.8309 - val_loss: 0.2950 - val_acc: 0.8602\n",
      "Epoch 59/200\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3739 - acc: 0.8319 - val_loss: 0.2939 - val_acc: 0.8627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/200\n",
      "3731/3731 [==============================] - 0s 59us/step - loss: 0.3739 - acc: 0.8314 - val_loss: 0.2946 - val_acc: 0.8651\n",
      "Epoch 61/200\n",
      "3731/3731 [==============================] - 0s 61us/step - loss: 0.3737 - acc: 0.8322 - val_loss: 0.2941 - val_acc: 0.8651\n",
      "Epoch 62/200\n",
      "3731/3731 [==============================] - 0s 67us/step - loss: 0.3731 - acc: 0.8328 - val_loss: 0.2937 - val_acc: 0.8675\n",
      "Epoch 63/200\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3732 - acc: 0.8338 - val_loss: 0.2933 - val_acc: 0.8867\n",
      "Epoch 64/200\n",
      "3731/3731 [==============================] - 0s 58us/step - loss: 0.3726 - acc: 0.8338 - val_loss: 0.2934 - val_acc: 0.8867\n",
      "Epoch 65/200\n",
      "3731/3731 [==============================] - 0s 59us/step - loss: 0.3723 - acc: 0.8368 - val_loss: 0.2934 - val_acc: 0.8843\n",
      "Epoch 66/200\n",
      "3731/3731 [==============================] - 0s 66us/step - loss: 0.3720 - acc: 0.8360 - val_loss: 0.2923 - val_acc: 0.8892\n",
      "Epoch 67/200\n",
      "3731/3731 [==============================] - 0s 56us/step - loss: 0.3717 - acc: 0.8368 - val_loss: 0.2914 - val_acc: 0.8867\n",
      "Epoch 68/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3711 - acc: 0.8370 - val_loss: 0.2938 - val_acc: 0.8819\n",
      "Epoch 69/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3715 - acc: 0.8344 - val_loss: 0.2918 - val_acc: 0.8843\n",
      "Epoch 70/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3713 - acc: 0.8368 - val_loss: 0.2905 - val_acc: 0.8892\n",
      "Epoch 71/200\n",
      "3731/3731 [==============================] - 0s 58us/step - loss: 0.3709 - acc: 0.8362 - val_loss: 0.2886 - val_acc: 0.8892\n",
      "Epoch 72/200\n",
      "3731/3731 [==============================] - 0s 59us/step - loss: 0.3708 - acc: 0.8370 - val_loss: 0.2895 - val_acc: 0.8916\n",
      "Epoch 73/200\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3700 - acc: 0.8378 - val_loss: 0.2907 - val_acc: 0.8819\n",
      "Epoch 74/200\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3707 - acc: 0.8368 - val_loss: 0.2890 - val_acc: 0.8916\n",
      "Epoch 75/200\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3697 - acc: 0.8370 - val_loss: 0.2904 - val_acc: 0.8819\n",
      "Epoch 76/200\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3700 - acc: 0.8381 - val_loss: 0.2902 - val_acc: 0.8867\n",
      "Epoch 77/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3694 - acc: 0.8370 - val_loss: 0.2881 - val_acc: 0.8892\n",
      "Epoch 78/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3693 - acc: 0.8376 - val_loss: 0.2897 - val_acc: 0.8867\n",
      "Epoch 79/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3692 - acc: 0.8397 - val_loss: 0.2873 - val_acc: 0.8892\n",
      "Epoch 80/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3691 - acc: 0.8395 - val_loss: 0.2880 - val_acc: 0.8916\n",
      "Epoch 81/200\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3687 - acc: 0.8384 - val_loss: 0.2863 - val_acc: 0.8916\n",
      "Epoch 82/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3687 - acc: 0.8381 - val_loss: 0.2857 - val_acc: 0.8916\n",
      "Epoch 83/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3683 - acc: 0.8389 - val_loss: 0.2863 - val_acc: 0.8916\n",
      "Epoch 84/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3682 - acc: 0.8386 - val_loss: 0.2852 - val_acc: 0.8940\n",
      "Epoch 85/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3680 - acc: 0.8384 - val_loss: 0.2839 - val_acc: 0.8940\n",
      "Epoch 86/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3679 - acc: 0.8389 - val_loss: 0.2851 - val_acc: 0.8940\n",
      "Epoch 87/200\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3680 - acc: 0.8384 - val_loss: 0.2851 - val_acc: 0.8940\n",
      "Epoch 88/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3679 - acc: 0.8389 - val_loss: 0.2849 - val_acc: 0.8940\n",
      "Epoch 89/200\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3675 - acc: 0.8395 - val_loss: 0.2839 - val_acc: 0.8940\n",
      "Epoch 90/200\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3675 - acc: 0.8389 - val_loss: 0.2834 - val_acc: 0.8940\n",
      "Epoch 91/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3671 - acc: 0.8392 - val_loss: 0.2826 - val_acc: 0.8916\n",
      "Epoch 92/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3670 - acc: 0.8397 - val_loss: 0.2829 - val_acc: 0.8916\n",
      "Epoch 93/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3671 - acc: 0.8400 - val_loss: 0.2830 - val_acc: 0.8867\n",
      "Epoch 94/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3669 - acc: 0.8389 - val_loss: 0.2828 - val_acc: 0.8892\n",
      "Epoch 95/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3668 - acc: 0.8389 - val_loss: 0.2828 - val_acc: 0.8892\n",
      "Epoch 96/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3667 - acc: 0.8419 - val_loss: 0.2836 - val_acc: 0.8892\n",
      "Epoch 97/200\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3668 - acc: 0.8400 - val_loss: 0.2824 - val_acc: 0.8892\n",
      "Epoch 98/200\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3661 - acc: 0.8400 - val_loss: 0.2826 - val_acc: 0.8892\n",
      "Epoch 99/200\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3660 - acc: 0.8384 - val_loss: 0.2836 - val_acc: 0.8867\n",
      "Epoch 100/200\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3663 - acc: 0.8405 - val_loss: 0.2834 - val_acc: 0.8867\n",
      "Epoch 101/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3657 - acc: 0.8403 - val_loss: 0.2819 - val_acc: 0.8940\n",
      "Epoch 102/200\n",
      "3731/3731 [==============================] - 0s 56us/step - loss: 0.3658 - acc: 0.8384 - val_loss: 0.2836 - val_acc: 0.8867\n",
      "Epoch 103/200\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3657 - acc: 0.8397 - val_loss: 0.2838 - val_acc: 0.8867\n",
      "Epoch 104/200\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3655 - acc: 0.8403 - val_loss: 0.2826 - val_acc: 0.8916\n",
      "Epoch 105/200\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3659 - acc: 0.8368 - val_loss: 0.2823 - val_acc: 0.8916\n",
      "Epoch 106/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3656 - acc: 0.8389 - val_loss: 0.2819 - val_acc: 0.8916\n",
      "Epoch 107/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3651 - acc: 0.8389 - val_loss: 0.2835 - val_acc: 0.8867\n",
      "Epoch 108/200\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3653 - acc: 0.8389 - val_loss: 0.2826 - val_acc: 0.8916\n",
      "Epoch 109/200\n",
      "3731/3731 [==============================] - 0s 59us/step - loss: 0.3649 - acc: 0.8400 - val_loss: 0.2828 - val_acc: 0.8892\n",
      "Epoch 110/200\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3653 - acc: 0.8389 - val_loss: 0.2832 - val_acc: 0.8892\n",
      "Epoch 111/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3651 - acc: 0.8392 - val_loss: 0.2827 - val_acc: 0.8867\n",
      "Epoch 112/200\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3648 - acc: 0.8400 - val_loss: 0.2821 - val_acc: 0.8867\n",
      "Epoch 113/200\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3646 - acc: 0.8403 - val_loss: 0.2820 - val_acc: 0.8916\n",
      "Epoch 114/200\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3646 - acc: 0.8395 - val_loss: 0.2823 - val_acc: 0.8916\n",
      "Epoch 115/200\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3644 - acc: 0.8403 - val_loss: 0.2820 - val_acc: 0.8916\n",
      "Epoch 116/200\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3643 - acc: 0.8389 - val_loss: 0.2814 - val_acc: 0.8916\n",
      "Epoch 117/200\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3644 - acc: 0.8384 - val_loss: 0.2824 - val_acc: 0.8916\n",
      "Epoch 118/200\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3642 - acc: 0.8400 - val_loss: 0.2821 - val_acc: 0.8892\n",
      "Epoch 119/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3644 - acc: 0.8373 - val_loss: 0.2831 - val_acc: 0.8892\n",
      "Epoch 120/200\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3641 - acc: 0.8386 - val_loss: 0.2838 - val_acc: 0.8867\n",
      "Epoch 121/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3639 - acc: 0.8397 - val_loss: 0.2833 - val_acc: 0.8892\n",
      "Epoch 122/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3639 - acc: 0.8392 - val_loss: 0.2824 - val_acc: 0.8867\n",
      "Epoch 123/200\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3637 - acc: 0.8392 - val_loss: 0.2838 - val_acc: 0.8892\n",
      "Epoch 124/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3639 - acc: 0.8386 - val_loss: 0.2829 - val_acc: 0.8867\n",
      "Epoch 125/200\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3638 - acc: 0.8389 - val_loss: 0.2841 - val_acc: 0.8867\n",
      "Epoch 126/200\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3633 - acc: 0.8376 - val_loss: 0.2828 - val_acc: 0.8867\n",
      "Epoch 127/200\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3635 - acc: 0.8389 - val_loss: 0.2846 - val_acc: 0.8892\n",
      "Epoch 128/200\n",
      "3731/3731 [==============================] - 0s 56us/step - loss: 0.3637 - acc: 0.8381 - val_loss: 0.2833 - val_acc: 0.8892\n",
      "Epoch 129/200\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.3632 - acc: 0.8389 - val_loss: 0.2830 - val_acc: 0.8867\n",
      "Epoch 130/200\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3633 - acc: 0.8362 - val_loss: 0.2835 - val_acc: 0.8843\n",
      "Epoch 131/200\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3630 - acc: 0.8400 - val_loss: 0.2835 - val_acc: 0.8843\n",
      "Epoch 132/200\n",
      "3731/3731 [==============================] - 0s 62us/step - loss: 0.3630 - acc: 0.8400 - val_loss: 0.2843 - val_acc: 0.8892\n",
      "Epoch 133/200\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3629 - acc: 0.8392 - val_loss: 0.2840 - val_acc: 0.8843\n",
      "Epoch 134/200\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3626 - acc: 0.8389 - val_loss: 0.2845 - val_acc: 0.8843\n",
      "Epoch 135/200\n",
      "3731/3731 [==============================] - 0s 68us/step - loss: 0.3629 - acc: 0.8389 - val_loss: 0.2853 - val_acc: 0.8867\n",
      "Epoch 136/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3630 - acc: 0.8389 - val_loss: 0.2842 - val_acc: 0.8819\n",
      "Epoch 137/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3625 - acc: 0.8411 - val_loss: 0.2839 - val_acc: 0.8843\n",
      "Epoch 138/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3628 - acc: 0.8389 - val_loss: 0.2833 - val_acc: 0.8843\n",
      "Epoch 139/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3630 - acc: 0.8386 - val_loss: 0.2838 - val_acc: 0.8819\n",
      "Epoch 140/200\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3623 - acc: 0.8395 - val_loss: 0.2845 - val_acc: 0.8867\n",
      "Epoch 141/200\n",
      "3731/3731 [==============================] - 0s 66us/step - loss: 0.3625 - acc: 0.8370 - val_loss: 0.2850 - val_acc: 0.8892\n",
      "Epoch 142/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3620 - acc: 0.8392 - val_loss: 0.2837 - val_acc: 0.8892\n",
      "Epoch 143/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3621 - acc: 0.8386 - val_loss: 0.2843 - val_acc: 0.8867\n",
      "Epoch 144/200\n",
      "3731/3731 [==============================] - 0s 58us/step - loss: 0.3621 - acc: 0.8386 - val_loss: 0.2846 - val_acc: 0.8892\n",
      "Epoch 145/200\n",
      "3731/3731 [==============================] - 0s 56us/step - loss: 0.3619 - acc: 0.8400 - val_loss: 0.2839 - val_acc: 0.8867\n",
      "Epoch 146/200\n",
      "3731/3731 [==============================] - 0s 65us/step - loss: 0.3621 - acc: 0.8392 - val_loss: 0.2837 - val_acc: 0.8867\n",
      "Epoch 147/200\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3618 - acc: 0.8378 - val_loss: 0.2835 - val_acc: 0.8867\n",
      "Epoch 148/200\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3617 - acc: 0.8370 - val_loss: 0.2861 - val_acc: 0.8892\n",
      "Epoch 149/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3620 - acc: 0.8400 - val_loss: 0.2842 - val_acc: 0.8867\n",
      "Epoch 150/200\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3615 - acc: 0.8392 - val_loss: 0.2849 - val_acc: 0.8843\n",
      "Epoch 151/200\n",
      "3731/3731 [==============================] - 0s 59us/step - loss: 0.3618 - acc: 0.8378 - val_loss: 0.2852 - val_acc: 0.8892\n",
      "Epoch 152/200\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.3615 - acc: 0.8397 - val_loss: 0.2845 - val_acc: 0.8843\n",
      "Epoch 153/200\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3612 - acc: 0.8395 - val_loss: 0.2855 - val_acc: 0.8867\n",
      "Epoch 154/200\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3614 - acc: 0.8384 - val_loss: 0.2850 - val_acc: 0.8867\n",
      "Epoch 155/200\n",
      "3731/3731 [==============================] - 0s 64us/step - loss: 0.3614 - acc: 0.8397 - val_loss: 0.2845 - val_acc: 0.8843\n",
      "Epoch 156/200\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.3612 - acc: 0.8413 - val_loss: 0.2846 - val_acc: 0.8843\n",
      "Epoch 157/200\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3611 - acc: 0.8397 - val_loss: 0.2848 - val_acc: 0.8892\n",
      "Epoch 158/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3615 - acc: 0.8395 - val_loss: 0.2844 - val_acc: 0.8843\n",
      "Epoch 159/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3610 - acc: 0.8408 - val_loss: 0.2843 - val_acc: 0.8916\n",
      "Epoch 160/200\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3609 - acc: 0.8416 - val_loss: 0.2840 - val_acc: 0.8892\n",
      "Epoch 161/200\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3610 - acc: 0.8397 - val_loss: 0.2839 - val_acc: 0.8867\n",
      "Epoch 162/200\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3608 - acc: 0.8400 - val_loss: 0.2841 - val_acc: 0.8867\n",
      "Epoch 163/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3609 - acc: 0.8389 - val_loss: 0.2846 - val_acc: 0.8843\n",
      "Epoch 164/200\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3608 - acc: 0.8408 - val_loss: 0.2850 - val_acc: 0.8867\n",
      "Epoch 165/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3604 - acc: 0.8405 - val_loss: 0.2837 - val_acc: 0.8892\n",
      "Epoch 166/200\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3608 - acc: 0.8395 - val_loss: 0.2839 - val_acc: 0.8843\n",
      "Epoch 167/200\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.3605 - acc: 0.8411 - val_loss: 0.2844 - val_acc: 0.8843\n",
      "Epoch 168/200\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.3605 - acc: 0.8405 - val_loss: 0.2846 - val_acc: 0.8892\n",
      "Epoch 169/200\n",
      "3731/3731 [==============================] - 0s 61us/step - loss: 0.3604 - acc: 0.8408 - val_loss: 0.2852 - val_acc: 0.8867\n",
      "Epoch 170/200\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3603 - acc: 0.8411 - val_loss: 0.2844 - val_acc: 0.8940\n",
      "Epoch 171/200\n",
      "3731/3731 [==============================] - 0s 69us/step - loss: 0.3604 - acc: 0.8395 - val_loss: 0.2853 - val_acc: 0.8867\n",
      "Epoch 172/200\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.3602 - acc: 0.8403 - val_loss: 0.2852 - val_acc: 0.8892\n",
      "Epoch 173/200\n",
      "3731/3731 [==============================] - 0s 58us/step - loss: 0.3603 - acc: 0.8411 - val_loss: 0.2847 - val_acc: 0.8916\n",
      "Epoch 174/200\n",
      "3731/3731 [==============================] - 0s 68us/step - loss: 0.3598 - acc: 0.8408 - val_loss: 0.2848 - val_acc: 0.8867\n",
      "Epoch 175/200\n",
      "3731/3731 [==============================] - 0s 70us/step - loss: 0.3599 - acc: 0.8408 - val_loss: 0.2840 - val_acc: 0.8916\n",
      "Epoch 176/200\n",
      "3731/3731 [==============================] - 0s 66us/step - loss: 0.3599 - acc: 0.8400 - val_loss: 0.2844 - val_acc: 0.8867\n",
      "Epoch 177/200\n",
      "3731/3731 [==============================] - 0s 65us/step - loss: 0.3600 - acc: 0.8408 - val_loss: 0.2841 - val_acc: 0.8940\n",
      "Epoch 178/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3731/3731 [==============================] - 0s 62us/step - loss: 0.3594 - acc: 0.8392 - val_loss: 0.2843 - val_acc: 0.8916\n",
      "Epoch 179/200\n",
      "3731/3731 [==============================] - 0s 66us/step - loss: 0.3596 - acc: 0.8408 - val_loss: 0.2847 - val_acc: 0.8867\n",
      "Epoch 180/200\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3598 - acc: 0.8397 - val_loss: 0.2843 - val_acc: 0.8916\n",
      "Epoch 181/200\n",
      "3731/3731 [==============================] - 0s 56us/step - loss: 0.3595 - acc: 0.8405 - val_loss: 0.2835 - val_acc: 0.8916\n",
      "Epoch 182/200\n",
      "3731/3731 [==============================] - 0s 68us/step - loss: 0.3595 - acc: 0.8416 - val_loss: 0.2848 - val_acc: 0.8892\n",
      "Epoch 183/200\n",
      "3731/3731 [==============================] - 0s 66us/step - loss: 0.3596 - acc: 0.8392 - val_loss: 0.2834 - val_acc: 0.8940\n",
      "Epoch 184/200\n",
      "3731/3731 [==============================] - 0s 56us/step - loss: 0.3595 - acc: 0.8384 - val_loss: 0.2836 - val_acc: 0.8892\n",
      "Epoch 185/200\n",
      "3731/3731 [==============================] - 0s 58us/step - loss: 0.3594 - acc: 0.8381 - val_loss: 0.2844 - val_acc: 0.8916\n",
      "Epoch 186/200\n",
      "3731/3731 [==============================] - 0s 65us/step - loss: 0.3589 - acc: 0.8408 - val_loss: 0.2829 - val_acc: 0.8940\n",
      "Epoch 187/200\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3592 - acc: 0.8392 - val_loss: 0.2822 - val_acc: 0.8940\n",
      "Epoch 188/200\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3588 - acc: 0.8408 - val_loss: 0.2822 - val_acc: 0.8916\n",
      "Epoch 189/200\n",
      "3731/3731 [==============================] - ETA: 0s - loss: 0.3463 - acc: 0.848 - 0s 54us/step - loss: 0.3590 - acc: 0.8395 - val_loss: 0.2826 - val_acc: 0.8892\n",
      "Epoch 190/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3590 - acc: 0.8392 - val_loss: 0.2826 - val_acc: 0.8892\n",
      "Epoch 191/200\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3588 - acc: 0.8395 - val_loss: 0.2830 - val_acc: 0.8916\n",
      "Epoch 192/200\n",
      "3731/3731 [==============================] - 0s 68us/step - loss: 0.3588 - acc: 0.8408 - val_loss: 0.2815 - val_acc: 0.8916\n",
      "Epoch 193/200\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3588 - acc: 0.8416 - val_loss: 0.2818 - val_acc: 0.8916\n",
      "Epoch 194/200\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3586 - acc: 0.8389 - val_loss: 0.2806 - val_acc: 0.8940\n",
      "Epoch 195/200\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3584 - acc: 0.8386 - val_loss: 0.2816 - val_acc: 0.8940\n",
      "Epoch 196/200\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3584 - acc: 0.8395 - val_loss: 0.2817 - val_acc: 0.8964\n",
      "Epoch 197/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3588 - acc: 0.8397 - val_loss: 0.2815 - val_acc: 0.8916\n",
      "Epoch 198/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3586 - acc: 0.8405 - val_loss: 0.2822 - val_acc: 0.8940\n",
      "Epoch 199/200\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3583 - acc: 0.8395 - val_loss: 0.2810 - val_acc: 0.8940\n",
      "Epoch 200/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3582 - acc: 0.8419 - val_loss: 0.2810 - val_acc: 0.8940\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(4, kernel_initializer='normal', input_dim=len(X[0]), activation='relu'))\n",
    "model.add(Dense(4, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adamax',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X, y.values, epochs=200, validation_split = 0.1)\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-11T21:06:37.111088Z",
     "start_time": "2019-09-11T21:05:35.287474Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3730 samples, validate on 415 samples\n",
      "Epoch 1/200\n",
      "3730/3730 [==============================] - 3s 692us/step - loss: 0.6693 - acc: 0.6987 - val_loss: 0.6250 - val_acc: 0.7518\n",
      "Epoch 2/200\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.5505 - acc: 0.7979 - val_loss: 0.4572 - val_acc: 0.8410\n",
      "Epoch 3/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4576 - acc: 0.8110 - val_loss: 0.3599 - val_acc: 0.8578\n",
      "Epoch 4/200\n",
      "3730/3730 [==============================] - 0s 74us/step - loss: 0.4251 - acc: 0.8198 - val_loss: 0.3225 - val_acc: 0.8627\n",
      "Epoch 5/200\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.4146 - acc: 0.8217 - val_loss: 0.3053 - val_acc: 0.8627\n",
      "Epoch 6/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4096 - acc: 0.8201 - val_loss: 0.2972 - val_acc: 0.8699\n",
      "Epoch 7/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4069 - acc: 0.8190 - val_loss: 0.2919 - val_acc: 0.8747\n",
      "Epoch 8/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.4045 - acc: 0.8225 - val_loss: 0.2866 - val_acc: 0.8819\n",
      "Epoch 9/200\n",
      "3730/3730 [==============================] - 0s 74us/step - loss: 0.4036 - acc: 0.8217 - val_loss: 0.2859 - val_acc: 0.8819\n",
      "Epoch 10/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4016 - acc: 0.8228 - val_loss: 0.2839 - val_acc: 0.8795\n",
      "Epoch 11/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.4000 - acc: 0.8241 - val_loss: 0.2836 - val_acc: 0.8795\n",
      "Epoch 12/200\n",
      "3730/3730 [==============================] - 0s 74us/step - loss: 0.4002 - acc: 0.8244 - val_loss: 0.2810 - val_acc: 0.8867\n",
      "Epoch 13/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3979 - acc: 0.8225 - val_loss: 0.2818 - val_acc: 0.8819\n",
      "Epoch 14/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3967 - acc: 0.8241 - val_loss: 0.2799 - val_acc: 0.8843\n",
      "Epoch 15/200\n",
      "3730/3730 [==============================] - 0s 74us/step - loss: 0.3957 - acc: 0.8263 - val_loss: 0.2800 - val_acc: 0.8843\n",
      "Epoch 16/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3949 - acc: 0.8249 - val_loss: 0.2801 - val_acc: 0.8843\n",
      "Epoch 17/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3937 - acc: 0.8236 - val_loss: 0.2785 - val_acc: 0.8843\n",
      "Epoch 18/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3926 - acc: 0.8220 - val_loss: 0.2799 - val_acc: 0.8843\n",
      "Epoch 19/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3920 - acc: 0.8220 - val_loss: 0.2784 - val_acc: 0.8867\n",
      "Epoch 20/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3911 - acc: 0.8236 - val_loss: 0.2785 - val_acc: 0.8867\n",
      "Epoch 21/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3904 - acc: 0.8209 - val_loss: 0.2799 - val_acc: 0.8843\n",
      "Epoch 22/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3896 - acc: 0.8209 - val_loss: 0.2783 - val_acc: 0.8843\n",
      "Epoch 23/200\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.3890 - acc: 0.8223 - val_loss: 0.2787 - val_acc: 0.8867\n",
      "Epoch 24/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3885 - acc: 0.8217 - val_loss: 0.2785 - val_acc: 0.8843\n",
      "Epoch 25/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3877 - acc: 0.8214 - val_loss: 0.2791 - val_acc: 0.8867\n",
      "Epoch 26/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3872 - acc: 0.8220 - val_loss: 0.2778 - val_acc: 0.8867\n",
      "Epoch 27/200\n",
      "3730/3730 [==============================] - 0s 74us/step - loss: 0.3871 - acc: 0.8223 - val_loss: 0.2756 - val_acc: 0.8892\n",
      "Epoch 28/200\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.3857 - acc: 0.8228 - val_loss: 0.2770 - val_acc: 0.8892\n",
      "Epoch 29/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3852 - acc: 0.8225 - val_loss: 0.2770 - val_acc: 0.8892\n",
      "Epoch 30/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3855 - acc: 0.8265 - val_loss: 0.2776 - val_acc: 0.8916\n",
      "Epoch 31/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3845 - acc: 0.8233 - val_loss: 0.2775 - val_acc: 0.8916\n",
      "Epoch 32/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3834 - acc: 0.8244 - val_loss: 0.2767 - val_acc: 0.8916\n",
      "Epoch 33/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3840 - acc: 0.8247 - val_loss: 0.2774 - val_acc: 0.8916\n",
      "Epoch 34/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3822 - acc: 0.8255 - val_loss: 0.2760 - val_acc: 0.8988\n",
      "Epoch 35/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3819 - acc: 0.8252 - val_loss: 0.2770 - val_acc: 0.8916\n",
      "Epoch 36/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3805 - acc: 0.8249 - val_loss: 0.2767 - val_acc: 0.8964\n",
      "Epoch 37/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3815 - acc: 0.8255 - val_loss: 0.2778 - val_acc: 0.8964\n",
      "Epoch 38/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3801 - acc: 0.8273 - val_loss: 0.2769 - val_acc: 0.8916\n",
      "Epoch 39/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3793 - acc: 0.8265 - val_loss: 0.2761 - val_acc: 0.8964\n",
      "Epoch 40/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3788 - acc: 0.8263 - val_loss: 0.2767 - val_acc: 0.8940\n",
      "Epoch 41/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3783 - acc: 0.8265 - val_loss: 0.2758 - val_acc: 0.8988\n",
      "Epoch 42/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3781 - acc: 0.8271 - val_loss: 0.2764 - val_acc: 0.8916\n",
      "Epoch 43/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3776 - acc: 0.8276 - val_loss: 0.2766 - val_acc: 0.8964\n",
      "Epoch 44/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3769 - acc: 0.8284 - val_loss: 0.2770 - val_acc: 0.8988\n",
      "Epoch 45/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3767 - acc: 0.8271 - val_loss: 0.2755 - val_acc: 0.8964\n",
      "Epoch 46/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3758 - acc: 0.8257 - val_loss: 0.2750 - val_acc: 0.8964\n",
      "Epoch 47/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3752 - acc: 0.8282 - val_loss: 0.2754 - val_acc: 0.9012\n",
      "Epoch 48/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3755 - acc: 0.8298 - val_loss: 0.2752 - val_acc: 0.8964\n",
      "Epoch 49/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3743 - acc: 0.8308 - val_loss: 0.2744 - val_acc: 0.9012\n",
      "Epoch 50/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3746 - acc: 0.8273 - val_loss: 0.2746 - val_acc: 0.8988\n",
      "Epoch 51/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3746 - acc: 0.8268 - val_loss: 0.2749 - val_acc: 0.8988\n",
      "Epoch 52/200\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.3737 - acc: 0.8271 - val_loss: 0.2747 - val_acc: 0.8988\n",
      "Epoch 53/200\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.3732 - acc: 0.8295 - val_loss: 0.2743 - val_acc: 0.8988\n",
      "Epoch 54/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3725 - acc: 0.8292 - val_loss: 0.2752 - val_acc: 0.8988\n",
      "Epoch 55/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3727 - acc: 0.8295 - val_loss: 0.2751 - val_acc: 0.8940\n",
      "Epoch 56/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3727 - acc: 0.8279 - val_loss: 0.2743 - val_acc: 0.8964\n",
      "Epoch 57/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3718 - acc: 0.8300 - val_loss: 0.2748 - val_acc: 0.8988\n",
      "Epoch 58/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3716 - acc: 0.8282 - val_loss: 0.2749 - val_acc: 0.8988\n",
      "Epoch 59/200\n",
      "3730/3730 [==============================] - 0s 74us/step - loss: 0.3715 - acc: 0.8300 - val_loss: 0.2756 - val_acc: 0.8964\n",
      "Epoch 60/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3721 - acc: 0.8300 - val_loss: 0.2749 - val_acc: 0.8916\n",
      "Epoch 61/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3715 - acc: 0.8298 - val_loss: 0.2743 - val_acc: 0.8916\n",
      "Epoch 62/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3711 - acc: 0.8316 - val_loss: 0.2744 - val_acc: 0.8916\n",
      "Epoch 63/200\n",
      "3730/3730 [==============================] - 0s 74us/step - loss: 0.3710 - acc: 0.8298 - val_loss: 0.2749 - val_acc: 0.8940\n",
      "Epoch 64/200\n",
      "3730/3730 [==============================] - 0s 74us/step - loss: 0.3708 - acc: 0.8295 - val_loss: 0.2747 - val_acc: 0.8988\n",
      "Epoch 65/200\n",
      "3730/3730 [==============================] - 0s 74us/step - loss: 0.3700 - acc: 0.8324 - val_loss: 0.2751 - val_acc: 0.8988\n",
      "Epoch 66/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3700 - acc: 0.8273 - val_loss: 0.2749 - val_acc: 0.9036\n",
      "Epoch 67/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3698 - acc: 0.8282 - val_loss: 0.2744 - val_acc: 0.8964\n",
      "Epoch 68/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3696 - acc: 0.8298 - val_loss: 0.2745 - val_acc: 0.8940\n",
      "Epoch 69/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3692 - acc: 0.8303 - val_loss: 0.2751 - val_acc: 0.8916\n",
      "Epoch 70/200\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.3692 - acc: 0.8311 - val_loss: 0.2741 - val_acc: 0.8964\n",
      "Epoch 71/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3683 - acc: 0.8290 - val_loss: 0.2751 - val_acc: 0.9012\n",
      "Epoch 72/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3683 - acc: 0.8308 - val_loss: 0.2757 - val_acc: 0.8988\n",
      "Epoch 73/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3687 - acc: 0.8300 - val_loss: 0.2764 - val_acc: 0.8916\n",
      "Epoch 74/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3685 - acc: 0.8322 - val_loss: 0.2774 - val_acc: 0.8964\n",
      "Epoch 75/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3687 - acc: 0.8300 - val_loss: 0.2774 - val_acc: 0.8892\n",
      "Epoch 76/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3679 - acc: 0.8319 - val_loss: 0.2766 - val_acc: 0.8988\n",
      "Epoch 77/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3673 - acc: 0.8314 - val_loss: 0.2764 - val_acc: 0.8964\n",
      "Epoch 78/200\n",
      "3730/3730 [==============================] - 0s 74us/step - loss: 0.3674 - acc: 0.8311 - val_loss: 0.2764 - val_acc: 0.8964\n",
      "Epoch 79/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3673 - acc: 0.8340 - val_loss: 0.2765 - val_acc: 0.8964\n",
      "Epoch 80/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3672 - acc: 0.8311 - val_loss: 0.2777 - val_acc: 0.8988\n",
      "Epoch 81/200\n",
      "3730/3730 [==============================] - 0s 74us/step - loss: 0.3672 - acc: 0.8314 - val_loss: 0.2769 - val_acc: 0.8940\n",
      "Epoch 82/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3670 - acc: 0.8306 - val_loss: 0.2780 - val_acc: 0.8916\n",
      "Epoch 83/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3665 - acc: 0.8306 - val_loss: 0.2772 - val_acc: 0.8892\n",
      "Epoch 84/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3666 - acc: 0.8311 - val_loss: 0.2784 - val_acc: 0.8940\n",
      "Epoch 85/200\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.3660 - acc: 0.8303 - val_loss: 0.2779 - val_acc: 0.8916\n",
      "Epoch 86/200\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.3664 - acc: 0.8343 - val_loss: 0.2791 - val_acc: 0.8916\n",
      "Epoch 87/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3659 - acc: 0.8332 - val_loss: 0.2777 - val_acc: 0.8892\n",
      "Epoch 88/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3657 - acc: 0.8357 - val_loss: 0.2774 - val_acc: 0.8964\n",
      "Epoch 89/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3658 - acc: 0.8343 - val_loss: 0.2786 - val_acc: 0.8892\n",
      "Epoch 90/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3660 - acc: 0.8332 - val_loss: 0.2795 - val_acc: 0.8940\n",
      "Epoch 91/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3653 - acc: 0.8343 - val_loss: 0.2789 - val_acc: 0.8988\n",
      "Epoch 92/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3657 - acc: 0.8330 - val_loss: 0.2791 - val_acc: 0.8940\n",
      "Epoch 93/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3653 - acc: 0.8327 - val_loss: 0.2798 - val_acc: 0.8964\n",
      "Epoch 94/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3650 - acc: 0.8319 - val_loss: 0.2792 - val_acc: 0.8964\n",
      "Epoch 95/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3649 - acc: 0.8335 - val_loss: 0.2789 - val_acc: 0.8964\n",
      "Epoch 96/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3645 - acc: 0.8357 - val_loss: 0.2797 - val_acc: 0.8988\n",
      "Epoch 97/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3650 - acc: 0.8351 - val_loss: 0.2812 - val_acc: 0.8988\n",
      "Epoch 98/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3649 - acc: 0.8351 - val_loss: 0.2803 - val_acc: 0.8940\n",
      "Epoch 99/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3648 - acc: 0.8319 - val_loss: 0.2806 - val_acc: 0.8964\n",
      "Epoch 100/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3643 - acc: 0.8375 - val_loss: 0.2805 - val_acc: 0.8964\n",
      "Epoch 101/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3644 - acc: 0.8362 - val_loss: 0.2809 - val_acc: 0.8940\n",
      "Epoch 102/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3641 - acc: 0.8362 - val_loss: 0.2834 - val_acc: 0.8916\n",
      "Epoch 103/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3639 - acc: 0.8349 - val_loss: 0.2824 - val_acc: 0.8892\n",
      "Epoch 104/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3640 - acc: 0.8346 - val_loss: 0.2822 - val_acc: 0.8867\n",
      "Epoch 105/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3636 - acc: 0.8340 - val_loss: 0.2820 - val_acc: 0.8916\n",
      "Epoch 106/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3641 - acc: 0.8349 - val_loss: 0.2835 - val_acc: 0.8892\n",
      "Epoch 107/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3632 - acc: 0.8359 - val_loss: 0.2836 - val_acc: 0.8867\n",
      "Epoch 108/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3633 - acc: 0.8359 - val_loss: 0.2829 - val_acc: 0.8916\n",
      "Epoch 109/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3630 - acc: 0.8373 - val_loss: 0.2845 - val_acc: 0.8892\n",
      "Epoch 110/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3632 - acc: 0.8373 - val_loss: 0.2823 - val_acc: 0.8892\n",
      "Epoch 111/200\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.3631 - acc: 0.8362 - val_loss: 0.2830 - val_acc: 0.8892\n",
      "Epoch 112/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3633 - acc: 0.8359 - val_loss: 0.2832 - val_acc: 0.8916\n",
      "Epoch 113/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3626 - acc: 0.8378 - val_loss: 0.2845 - val_acc: 0.8867\n",
      "Epoch 114/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3625 - acc: 0.8351 - val_loss: 0.2834 - val_acc: 0.8892\n",
      "Epoch 115/200\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.3629 - acc: 0.8349 - val_loss: 0.2832 - val_acc: 0.8940\n",
      "Epoch 116/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3623 - acc: 0.8365 - val_loss: 0.2839 - val_acc: 0.8892\n",
      "Epoch 117/200\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.3628 - acc: 0.8330 - val_loss: 0.2857 - val_acc: 0.8892\n",
      "Epoch 118/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3628 - acc: 0.8370 - val_loss: 0.2852 - val_acc: 0.8892\n",
      "Epoch 119/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3628 - acc: 0.8365 - val_loss: 0.2863 - val_acc: 0.8867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3621 - acc: 0.8359 - val_loss: 0.2863 - val_acc: 0.8843\n",
      "Epoch 121/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3624 - acc: 0.8378 - val_loss: 0.2870 - val_acc: 0.8819\n",
      "Epoch 122/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3620 - acc: 0.8373 - val_loss: 0.2856 - val_acc: 0.8867\n",
      "Epoch 123/200\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.3619 - acc: 0.8383 - val_loss: 0.2861 - val_acc: 0.8892\n",
      "Epoch 124/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3619 - acc: 0.8375 - val_loss: 0.2869 - val_acc: 0.8892\n",
      "Epoch 125/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3615 - acc: 0.8357 - val_loss: 0.2865 - val_acc: 0.8843\n",
      "Epoch 126/200\n",
      "3730/3730 [==============================] - 0s 74us/step - loss: 0.3620 - acc: 0.8359 - val_loss: 0.2867 - val_acc: 0.8843\n",
      "Epoch 127/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3611 - acc: 0.8373 - val_loss: 0.2880 - val_acc: 0.8843\n",
      "Epoch 128/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3616 - acc: 0.8386 - val_loss: 0.2880 - val_acc: 0.8843\n",
      "Epoch 129/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3616 - acc: 0.8383 - val_loss: 0.2869 - val_acc: 0.8867\n",
      "Epoch 130/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3613 - acc: 0.8383 - val_loss: 0.2898 - val_acc: 0.8892\n",
      "Epoch 131/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3611 - acc: 0.8386 - val_loss: 0.2895 - val_acc: 0.8867\n",
      "Epoch 132/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3609 - acc: 0.8381 - val_loss: 0.2886 - val_acc: 0.8819\n",
      "Epoch 133/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3613 - acc: 0.8381 - val_loss: 0.2904 - val_acc: 0.8867\n",
      "Epoch 134/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3613 - acc: 0.8343 - val_loss: 0.2898 - val_acc: 0.8843\n",
      "Epoch 135/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3608 - acc: 0.8351 - val_loss: 0.2879 - val_acc: 0.8843\n",
      "Epoch 136/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3604 - acc: 0.8383 - val_loss: 0.2887 - val_acc: 0.8892\n",
      "Epoch 137/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3608 - acc: 0.8354 - val_loss: 0.2893 - val_acc: 0.8867\n",
      "Epoch 138/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3610 - acc: 0.8370 - val_loss: 0.2889 - val_acc: 0.8892\n",
      "Epoch 139/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3608 - acc: 0.8370 - val_loss: 0.2909 - val_acc: 0.8843\n",
      "Epoch 140/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3607 - acc: 0.8378 - val_loss: 0.2903 - val_acc: 0.8867\n",
      "Epoch 141/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3613 - acc: 0.8370 - val_loss: 0.2887 - val_acc: 0.8843\n",
      "Epoch 142/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3607 - acc: 0.8394 - val_loss: 0.2881 - val_acc: 0.8843\n",
      "Epoch 143/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3605 - acc: 0.8402 - val_loss: 0.2894 - val_acc: 0.8867\n",
      "Epoch 144/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3602 - acc: 0.8365 - val_loss: 0.2899 - val_acc: 0.8867\n",
      "Epoch 145/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3604 - acc: 0.8378 - val_loss: 0.2910 - val_acc: 0.8867\n",
      "Epoch 146/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3603 - acc: 0.8375 - val_loss: 0.2901 - val_acc: 0.8892\n",
      "Epoch 147/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3604 - acc: 0.8373 - val_loss: 0.2906 - val_acc: 0.8916\n",
      "Epoch 148/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3602 - acc: 0.8365 - val_loss: 0.2917 - val_acc: 0.8867\n",
      "Epoch 149/200\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.3601 - acc: 0.8381 - val_loss: 0.2898 - val_acc: 0.8867\n",
      "Epoch 150/200\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.3606 - acc: 0.8354 - val_loss: 0.2906 - val_acc: 0.8867\n",
      "Epoch 151/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3605 - acc: 0.8383 - val_loss: 0.2902 - val_acc: 0.8916\n",
      "Epoch 152/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3596 - acc: 0.8383 - val_loss: 0.2896 - val_acc: 0.8867\n",
      "Epoch 153/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3601 - acc: 0.8399 - val_loss: 0.2911 - val_acc: 0.8867\n",
      "Epoch 154/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3597 - acc: 0.8378 - val_loss: 0.2904 - val_acc: 0.8867\n",
      "Epoch 155/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3600 - acc: 0.8357 - val_loss: 0.2917 - val_acc: 0.8916\n",
      "Epoch 156/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3602 - acc: 0.8391 - val_loss: 0.2901 - val_acc: 0.8867\n",
      "Epoch 157/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3599 - acc: 0.8381 - val_loss: 0.2907 - val_acc: 0.8892\n",
      "Epoch 158/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3588 - acc: 0.8389 - val_loss: 0.2904 - val_acc: 0.8916\n",
      "Epoch 159/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3592 - acc: 0.8386 - val_loss: 0.2895 - val_acc: 0.8843\n",
      "Epoch 160/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3595 - acc: 0.8383 - val_loss: 0.2900 - val_acc: 0.8867\n",
      "Epoch 161/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3594 - acc: 0.8391 - val_loss: 0.2898 - val_acc: 0.8843\n",
      "Epoch 162/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3594 - acc: 0.8378 - val_loss: 0.2899 - val_acc: 0.8843\n",
      "Epoch 163/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3596 - acc: 0.8375 - val_loss: 0.2910 - val_acc: 0.8867\n",
      "Epoch 164/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3600 - acc: 0.8367 - val_loss: 0.2913 - val_acc: 0.8843\n",
      "Epoch 165/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3593 - acc: 0.8367 - val_loss: 0.2929 - val_acc: 0.8892\n",
      "Epoch 166/200\n",
      "3730/3730 [==============================] - 0s 82us/step - loss: 0.3590 - acc: 0.8354 - val_loss: 0.2942 - val_acc: 0.8867\n",
      "Epoch 167/200\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.3595 - acc: 0.8381 - val_loss: 0.2904 - val_acc: 0.8843\n",
      "Epoch 168/200\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.3587 - acc: 0.8405 - val_loss: 0.2912 - val_acc: 0.8843\n",
      "Epoch 169/200\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.3589 - acc: 0.8391 - val_loss: 0.2916 - val_acc: 0.8843\n",
      "Epoch 170/200\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.3586 - acc: 0.8399 - val_loss: 0.2908 - val_acc: 0.8867\n",
      "Epoch 171/200\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.3597 - acc: 0.8381 - val_loss: 0.2907 - val_acc: 0.8843\n",
      "Epoch 172/200\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.3589 - acc: 0.8370 - val_loss: 0.2905 - val_acc: 0.8843\n",
      "Epoch 173/200\n",
      "3730/3730 [==============================] - 0s 74us/step - loss: 0.3584 - acc: 0.8386 - val_loss: 0.2899 - val_acc: 0.8867\n",
      "Epoch 174/200\n",
      "3730/3730 [==============================] - 0s 86us/step - loss: 0.3581 - acc: 0.8386 - val_loss: 0.2914 - val_acc: 0.8867\n",
      "Epoch 175/200\n",
      "3730/3730 [==============================] - 0s 87us/step - loss: 0.3586 - acc: 0.8381 - val_loss: 0.2907 - val_acc: 0.8843\n",
      "Epoch 176/200\n",
      "3730/3730 [==============================] - 0s 97us/step - loss: 0.3586 - acc: 0.8397 - val_loss: 0.2929 - val_acc: 0.8916\n",
      "Epoch 177/200\n",
      "3730/3730 [==============================] - 0s 89us/step - loss: 0.3590 - acc: 0.8391 - val_loss: 0.2921 - val_acc: 0.8843\n",
      "Epoch 178/200\n",
      "3730/3730 [==============================] - 0s 95us/step - loss: 0.3580 - acc: 0.8386 - val_loss: 0.2915 - val_acc: 0.8867\n",
      "Epoch 179/200\n",
      "3730/3730 [==============================] - 0s 100us/step - loss: 0.3584 - acc: 0.8397 - val_loss: 0.2918 - val_acc: 0.8867\n",
      "Epoch 180/200\n",
      "3730/3730 [==============================] - 0s 116us/step - loss: 0.3586 - acc: 0.8357 - val_loss: 0.2931 - val_acc: 0.8892\n",
      "Epoch 181/200\n",
      "3730/3730 [==============================] - 0s 114us/step - loss: 0.3583 - acc: 0.8375 - val_loss: 0.2917 - val_acc: 0.8843\n",
      "Epoch 182/200\n",
      "3730/3730 [==============================] - 0s 88us/step - loss: 0.3584 - acc: 0.8413 - val_loss: 0.2919 - val_acc: 0.8843\n",
      "Epoch 183/200\n",
      "3730/3730 [==============================] - 0s 83us/step - loss: 0.3582 - acc: 0.8399 - val_loss: 0.2916 - val_acc: 0.8867\n",
      "Epoch 184/200\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.3582 - acc: 0.8381 - val_loss: 0.2919 - val_acc: 0.8867\n",
      "Epoch 185/200\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.3573 - acc: 0.8375 - val_loss: 0.2905 - val_acc: 0.8795\n",
      "Epoch 186/200\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.3578 - acc: 0.8394 - val_loss: 0.2918 - val_acc: 0.8843\n",
      "Epoch 187/200\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.3574 - acc: 0.8381 - val_loss: 0.2904 - val_acc: 0.8867\n",
      "Epoch 188/200\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.3578 - acc: 0.8383 - val_loss: 0.2907 - val_acc: 0.8819\n",
      "Epoch 189/200\n",
      "3730/3730 [==============================] - 0s 83us/step - loss: 0.3586 - acc: 0.8397 - val_loss: 0.2898 - val_acc: 0.8843\n",
      "Epoch 190/200\n",
      "3730/3730 [==============================] - 0s 110us/step - loss: 0.3573 - acc: 0.8416 - val_loss: 0.2905 - val_acc: 0.8867\n",
      "Epoch 191/200\n",
      "3730/3730 [==============================] - 0s 101us/step - loss: 0.3572 - acc: 0.8402 - val_loss: 0.2916 - val_acc: 0.8843\n",
      "Epoch 192/200\n",
      "3730/3730 [==============================] - 0s 116us/step - loss: 0.3587 - acc: 0.8383 - val_loss: 0.2910 - val_acc: 0.8867\n",
      "Epoch 193/200\n",
      "3730/3730 [==============================] - 0s 127us/step - loss: 0.3574 - acc: 0.8389 - val_loss: 0.2894 - val_acc: 0.8867\n",
      "Epoch 194/200\n",
      "3730/3730 [==============================] - 1s 144us/step - loss: 0.3571 - acc: 0.8386 - val_loss: 0.2904 - val_acc: 0.8867\n",
      "Epoch 195/200\n",
      "3730/3730 [==============================] - 1s 149us/step - loss: 0.3574 - acc: 0.8408 - val_loss: 0.2917 - val_acc: 0.8843\n",
      "Epoch 196/200\n",
      "3730/3730 [==============================] - 0s 127us/step - loss: 0.3573 - acc: 0.8413 - val_loss: 0.2919 - val_acc: 0.8867\n",
      "Epoch 197/200\n",
      "3730/3730 [==============================] - 0s 114us/step - loss: 0.3571 - acc: 0.8383 - val_loss: 0.2916 - val_acc: 0.8867\n",
      "Epoch 198/200\n",
      "3730/3730 [==============================] - 1s 134us/step - loss: 0.3572 - acc: 0.8410 - val_loss: 0.2914 - val_acc: 0.8867\n",
      "Epoch 199/200\n",
      "3730/3730 [==============================] - 0s 116us/step - loss: 0.3571 - acc: 0.8399 - val_loss: 0.2916 - val_acc: 0.8843\n",
      "Epoch 200/200\n",
      "3730/3730 [==============================] - 0s 130us/step - loss: 0.3580 - acc: 0.8413 - val_loss: 0.2921 - val_acc: 0.8867\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(8, kernel_initializer='normal', input_dim=len(X[0]), activation='relu'))\n",
    "model.add(Dense(8, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adamax',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X, y.values, epochs=200, validation_split = 0.1)\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-11T21:07:49.874492Z",
     "start_time": "2019-09-11T21:06:37.115579Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3730 samples, validate on 415 samples\n",
      "Epoch 1/200\n",
      "3730/3730 [==============================] - 4s 1ms/step - loss: 0.6504 - acc: 0.7657 - val_loss: 0.5538 - val_acc: 0.8602\n",
      "Epoch 2/200\n",
      "3730/3730 [==============================] - 0s 124us/step - loss: 0.5169 - acc: 0.8054 - val_loss: 0.3880 - val_acc: 0.8530\n",
      "Epoch 3/200\n",
      "3730/3730 [==============================] - 0s 129us/step - loss: 0.4383 - acc: 0.8172 - val_loss: 0.3211 - val_acc: 0.8747\n",
      "Epoch 4/200\n",
      "3730/3730 [==============================] - 0s 124us/step - loss: 0.4176 - acc: 0.8214 - val_loss: 0.3043 - val_acc: 0.8723\n",
      "Epoch 5/200\n",
      "3730/3730 [==============================] - 0s 126us/step - loss: 0.4106 - acc: 0.8228 - val_loss: 0.2951 - val_acc: 0.8892\n",
      "Epoch 6/200\n",
      "3730/3730 [==============================] - 0s 115us/step - loss: 0.4069 - acc: 0.8198 - val_loss: 0.2880 - val_acc: 0.8843\n",
      "Epoch 7/200\n",
      "3730/3730 [==============================] - 0s 117us/step - loss: 0.4042 - acc: 0.8188 - val_loss: 0.2841 - val_acc: 0.8819\n",
      "Epoch 8/200\n",
      "3730/3730 [==============================] - 0s 111us/step - loss: 0.4021 - acc: 0.8217 - val_loss: 0.2828 - val_acc: 0.8819\n",
      "Epoch 9/200\n",
      "3730/3730 [==============================] - 0s 109us/step - loss: 0.4011 - acc: 0.8209 - val_loss: 0.2798 - val_acc: 0.8867\n",
      "Epoch 10/200\n",
      "3730/3730 [==============================] - 0s 110us/step - loss: 0.3991 - acc: 0.8209 - val_loss: 0.2780 - val_acc: 0.8795\n",
      "Epoch 11/200\n",
      "3730/3730 [==============================] - 0s 111us/step - loss: 0.3983 - acc: 0.8193 - val_loss: 0.2773 - val_acc: 0.8795\n",
      "Epoch 12/200\n",
      "3730/3730 [==============================] - ETA: 0s - loss: 0.3995 - acc: 0.820 - 0s 110us/step - loss: 0.3964 - acc: 0.8231 - val_loss: 0.2745 - val_acc: 0.8916\n",
      "Epoch 13/200\n",
      "3730/3730 [==============================] - 0s 110us/step - loss: 0.3955 - acc: 0.8214 - val_loss: 0.2783 - val_acc: 0.8843\n",
      "Epoch 14/200\n",
      "3730/3730 [==============================] - 0s 109us/step - loss: 0.3950 - acc: 0.8212 - val_loss: 0.2765 - val_acc: 0.8819\n",
      "Epoch 15/200\n",
      "3730/3730 [==============================] - 1s 149us/step - loss: 0.3935 - acc: 0.8231 - val_loss: 0.2757 - val_acc: 0.8819\n",
      "Epoch 16/200\n",
      "3730/3730 [==============================] - 0s 121us/step - loss: 0.3930 - acc: 0.8214 - val_loss: 0.2748 - val_acc: 0.8819\n",
      "Epoch 17/200\n",
      "3730/3730 [==============================] - 0s 109us/step - loss: 0.3913 - acc: 0.8223 - val_loss: 0.2762 - val_acc: 0.8843\n",
      "Epoch 18/200\n",
      "3730/3730 [==============================] - 0s 111us/step - loss: 0.3908 - acc: 0.8217 - val_loss: 0.2738 - val_acc: 0.8843\n",
      "Epoch 19/200\n",
      "3730/3730 [==============================] - 0s 126us/step - loss: 0.3894 - acc: 0.8217 - val_loss: 0.2747 - val_acc: 0.8843\n",
      "Epoch 20/200\n",
      "3730/3730 [==============================] - 1s 148us/step - loss: 0.3889 - acc: 0.8233 - val_loss: 0.2743 - val_acc: 0.8843\n",
      "Epoch 21/200\n",
      "3730/3730 [==============================] - 1s 145us/step - loss: 0.3884 - acc: 0.8239 - val_loss: 0.2731 - val_acc: 0.8867\n",
      "Epoch 22/200\n",
      "3730/3730 [==============================] - 0s 122us/step - loss: 0.3875 - acc: 0.8214 - val_loss: 0.2750 - val_acc: 0.8819\n",
      "Epoch 23/200\n",
      "3730/3730 [==============================] - 0s 87us/step - loss: 0.3871 - acc: 0.8225 - val_loss: 0.2725 - val_acc: 0.8843\n",
      "Epoch 24/200\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.3861 - acc: 0.8257 - val_loss: 0.2729 - val_acc: 0.8819\n",
      "Epoch 25/200\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.3855 - acc: 0.8249 - val_loss: 0.2719 - val_acc: 0.8843\n",
      "Epoch 26/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3848 - acc: 0.8241 - val_loss: 0.2745 - val_acc: 0.8795\n",
      "Epoch 27/200\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.3845 - acc: 0.8263 - val_loss: 0.2735 - val_acc: 0.8795\n",
      "Epoch 28/200\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.3838 - acc: 0.8276 - val_loss: 0.2733 - val_acc: 0.8795\n",
      "Epoch 29/200\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.3837 - acc: 0.8225 - val_loss: 0.2740 - val_acc: 0.8795\n",
      "Epoch 30/200\n",
      "3730/3730 [==============================] - 0s 89us/step - loss: 0.3823 - acc: 0.8255 - val_loss: 0.2741 - val_acc: 0.8867\n",
      "Epoch 31/200\n",
      "3730/3730 [==============================] - 0s 73us/step - loss: 0.3826 - acc: 0.8231 - val_loss: 0.2748 - val_acc: 0.8843\n",
      "Epoch 32/200\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.3819 - acc: 0.8231 - val_loss: 0.2750 - val_acc: 0.8843\n",
      "Epoch 33/200\n",
      "3730/3730 [==============================] - 0s 91us/step - loss: 0.3814 - acc: 0.8252 - val_loss: 0.2751 - val_acc: 0.8843\n",
      "Epoch 34/200\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.3810 - acc: 0.8236 - val_loss: 0.2742 - val_acc: 0.8892\n",
      "Epoch 35/200\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.3801 - acc: 0.8239 - val_loss: 0.2743 - val_acc: 0.8843\n",
      "Epoch 36/200\n",
      "3730/3730 [==============================] - 0s 74us/step - loss: 0.3796 - acc: 0.8247 - val_loss: 0.2743 - val_acc: 0.8867\n",
      "Epoch 37/200\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.3793 - acc: 0.8265 - val_loss: 0.2745 - val_acc: 0.8819\n",
      "Epoch 38/200\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.3789 - acc: 0.8233 - val_loss: 0.2737 - val_acc: 0.8892\n",
      "Epoch 39/200\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.3784 - acc: 0.8260 - val_loss: 0.2750 - val_acc: 0.8892\n",
      "Epoch 40/200\n",
      "3730/3730 [==============================] - 0s 85us/step - loss: 0.3783 - acc: 0.8244 - val_loss: 0.2759 - val_acc: 0.8843\n",
      "Epoch 41/200\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.3774 - acc: 0.8244 - val_loss: 0.2747 - val_acc: 0.8867\n",
      "Epoch 42/200\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.3772 - acc: 0.8263 - val_loss: 0.2747 - val_acc: 0.8843\n",
      "Epoch 43/200\n",
      "3730/3730 [==============================] - 0s 74us/step - loss: 0.3769 - acc: 0.8255 - val_loss: 0.2739 - val_acc: 0.8892\n",
      "Epoch 44/200\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.3758 - acc: 0.8284 - val_loss: 0.2743 - val_acc: 0.8867\n",
      "Epoch 45/200\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.3759 - acc: 0.8260 - val_loss: 0.2758 - val_acc: 0.8892\n",
      "Epoch 46/200\n",
      "3730/3730 [==============================] - 0s 82us/step - loss: 0.3758 - acc: 0.8265 - val_loss: 0.2754 - val_acc: 0.8867\n",
      "Epoch 47/200\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.3745 - acc: 0.8265 - val_loss: 0.2749 - val_acc: 0.8843\n",
      "Epoch 48/200\n",
      "3730/3730 [==============================] - 0s 100us/step - loss: 0.3748 - acc: 0.8276 - val_loss: 0.2753 - val_acc: 0.8867\n",
      "Epoch 49/200\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.3741 - acc: 0.8271 - val_loss: 0.2757 - val_acc: 0.8892\n",
      "Epoch 50/200\n",
      "3730/3730 [==============================] - 0s 77us/step - loss: 0.3734 - acc: 0.8273 - val_loss: 0.2756 - val_acc: 0.8892\n",
      "Epoch 51/200\n",
      "3730/3730 [==============================] - 0s 103us/step - loss: 0.3735 - acc: 0.8268 - val_loss: 0.2758 - val_acc: 0.8892\n",
      "Epoch 52/200\n",
      "3730/3730 [==============================] - 0s 78us/step - loss: 0.3726 - acc: 0.8279 - val_loss: 0.2750 - val_acc: 0.8916\n",
      "Epoch 53/200\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.3717 - acc: 0.8298 - val_loss: 0.2745 - val_acc: 0.8892\n",
      "Epoch 54/200\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.3722 - acc: 0.8260 - val_loss: 0.2745 - val_acc: 0.8867\n",
      "Epoch 55/200\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.3716 - acc: 0.8324 - val_loss: 0.2741 - val_acc: 0.8843\n",
      "Epoch 56/200\n",
      "3730/3730 [==============================] - 0s 86us/step - loss: 0.3712 - acc: 0.8306 - val_loss: 0.2733 - val_acc: 0.8892\n",
      "Epoch 57/200\n",
      "3730/3730 [==============================] - 0s 76us/step - loss: 0.3709 - acc: 0.8290 - val_loss: 0.2744 - val_acc: 0.8916\n",
      "Epoch 58/200\n",
      "3730/3730 [==============================] - 0s 72us/step - loss: 0.3707 - acc: 0.8303 - val_loss: 0.2733 - val_acc: 0.8892\n",
      "Epoch 59/200\n",
      "3730/3730 [==============================] - 0s 91us/step - loss: 0.3704 - acc: 0.8292 - val_loss: 0.2739 - val_acc: 0.8892\n",
      "Epoch 60/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3730/3730 [==============================] - 0s 91us/step - loss: 0.3699 - acc: 0.8303 - val_loss: 0.2743 - val_acc: 0.8940\n",
      "Epoch 61/200\n",
      "3730/3730 [==============================] - 0s 97us/step - loss: 0.3699 - acc: 0.8308 - val_loss: 0.2728 - val_acc: 0.8916\n",
      "Epoch 62/200\n",
      "3730/3730 [==============================] - 0s 75us/step - loss: 0.3698 - acc: 0.8290 - val_loss: 0.2728 - val_acc: 0.8940\n",
      "Epoch 63/200\n",
      "3730/3730 [==============================] - 0s 94us/step - loss: 0.3691 - acc: 0.8308 - val_loss: 0.2723 - val_acc: 0.8916\n",
      "Epoch 64/200\n",
      "3730/3730 [==============================] - 0s 120us/step - loss: 0.3691 - acc: 0.8303 - val_loss: 0.2726 - val_acc: 0.8916\n",
      "Epoch 65/200\n",
      "3730/3730 [==============================] - 0s 119us/step - loss: 0.3688 - acc: 0.8292 - val_loss: 0.2726 - val_acc: 0.8940\n",
      "Epoch 66/200\n",
      "3730/3730 [==============================] - 0s 96us/step - loss: 0.3684 - acc: 0.8314 - val_loss: 0.2722 - val_acc: 0.8940\n",
      "Epoch 67/200\n",
      "3730/3730 [==============================] - 0s 105us/step - loss: 0.3683 - acc: 0.8290 - val_loss: 0.2728 - val_acc: 0.8964\n",
      "Epoch 68/200\n",
      "3730/3730 [==============================] - 0s 96us/step - loss: 0.3685 - acc: 0.8319 - val_loss: 0.2733 - val_acc: 0.8964\n",
      "Epoch 69/200\n",
      "3730/3730 [==============================] - 0s 82us/step - loss: 0.3678 - acc: 0.8287 - val_loss: 0.2738 - val_acc: 0.8988\n",
      "Epoch 70/200\n",
      "3730/3730 [==============================] - 0s 116us/step - loss: 0.3679 - acc: 0.8330 - val_loss: 0.2727 - val_acc: 0.8940\n",
      "Epoch 71/200\n",
      "3730/3730 [==============================] - 0s 130us/step - loss: 0.3677 - acc: 0.8306 - val_loss: 0.2734 - val_acc: 0.8964\n",
      "Epoch 72/200\n",
      "3730/3730 [==============================] - 0s 109us/step - loss: 0.3673 - acc: 0.8295 - val_loss: 0.2736 - val_acc: 0.8964\n",
      "Epoch 73/200\n",
      "3730/3730 [==============================] - 0s 117us/step - loss: 0.3668 - acc: 0.8319 - val_loss: 0.2741 - val_acc: 0.8916\n",
      "Epoch 74/200\n",
      "3730/3730 [==============================] - 0s 97us/step - loss: 0.3669 - acc: 0.8308 - val_loss: 0.2726 - val_acc: 0.8940\n",
      "Epoch 75/200\n",
      "3730/3730 [==============================] - 0s 86us/step - loss: 0.3663 - acc: 0.8316 - val_loss: 0.2724 - val_acc: 0.8940\n",
      "Epoch 76/200\n",
      "3730/3730 [==============================] - 0s 85us/step - loss: 0.3663 - acc: 0.8308 - val_loss: 0.2705 - val_acc: 0.8964\n",
      "Epoch 77/200\n",
      "3730/3730 [==============================] - 0s 83us/step - loss: 0.3664 - acc: 0.8322 - val_loss: 0.2715 - val_acc: 0.8964\n",
      "Epoch 78/200\n",
      "3730/3730 [==============================] - 0s 87us/step - loss: 0.3654 - acc: 0.8300 - val_loss: 0.2726 - val_acc: 0.8964\n",
      "Epoch 79/200\n",
      "3730/3730 [==============================] - 0s 83us/step - loss: 0.3653 - acc: 0.8316 - val_loss: 0.2722 - val_acc: 0.8964\n",
      "Epoch 80/200\n",
      "3730/3730 [==============================] - 0s 87us/step - loss: 0.3653 - acc: 0.8319 - val_loss: 0.2714 - val_acc: 0.8964\n",
      "Epoch 81/200\n",
      "3730/3730 [==============================] - 0s 83us/step - loss: 0.3652 - acc: 0.8340 - val_loss: 0.2706 - val_acc: 0.8964\n",
      "Epoch 82/200\n",
      "3730/3730 [==============================] - 0s 83us/step - loss: 0.3646 - acc: 0.8322 - val_loss: 0.2714 - val_acc: 0.8964\n",
      "Epoch 83/200\n",
      "3730/3730 [==============================] - 0s 84us/step - loss: 0.3646 - acc: 0.8322 - val_loss: 0.2714 - val_acc: 0.8964\n",
      "Epoch 84/200\n",
      "3730/3730 [==============================] - 0s 85us/step - loss: 0.3640 - acc: 0.8303 - val_loss: 0.2705 - val_acc: 0.8964\n",
      "Epoch 85/200\n",
      "3730/3730 [==============================] - 0s 83us/step - loss: 0.3640 - acc: 0.8322 - val_loss: 0.2706 - val_acc: 0.8988\n",
      "Epoch 86/200\n",
      "3730/3730 [==============================] - 0s 84us/step - loss: 0.3638 - acc: 0.8327 - val_loss: 0.2730 - val_acc: 0.8964\n",
      "Epoch 87/200\n",
      "3730/3730 [==============================] - 0s 86us/step - loss: 0.3641 - acc: 0.8327 - val_loss: 0.2728 - val_acc: 0.8940\n",
      "Epoch 88/200\n",
      "3730/3730 [==============================] - 0s 99us/step - loss: 0.3634 - acc: 0.8316 - val_loss: 0.2708 - val_acc: 0.8940\n",
      "Epoch 89/200\n",
      "3730/3730 [==============================] - 0s 104us/step - loss: 0.3631 - acc: 0.8332 - val_loss: 0.2705 - val_acc: 0.8940\n",
      "Epoch 90/200\n",
      "3730/3730 [==============================] - 0s 103us/step - loss: 0.3633 - acc: 0.8340 - val_loss: 0.2706 - val_acc: 0.8940\n",
      "Epoch 91/200\n",
      "3730/3730 [==============================] - 0s 109us/step - loss: 0.3632 - acc: 0.8370 - val_loss: 0.2716 - val_acc: 0.8940\n",
      "Epoch 92/200\n",
      "3730/3730 [==============================] - 0s 101us/step - loss: 0.3620 - acc: 0.8324 - val_loss: 0.2728 - val_acc: 0.8988\n",
      "Epoch 93/200\n",
      "3730/3730 [==============================] - 0s 109us/step - loss: 0.3629 - acc: 0.8308 - val_loss: 0.2715 - val_acc: 0.8988\n",
      "Epoch 94/200\n",
      "3730/3730 [==============================] - 0s 97us/step - loss: 0.3620 - acc: 0.8354 - val_loss: 0.2719 - val_acc: 0.8940\n",
      "Epoch 95/200\n",
      "3730/3730 [==============================] - 0s 112us/step - loss: 0.3625 - acc: 0.8324 - val_loss: 0.2725 - val_acc: 0.8964\n",
      "Epoch 96/200\n",
      "3730/3730 [==============================] - 0s 102us/step - loss: 0.3618 - acc: 0.8349 - val_loss: 0.2724 - val_acc: 0.8964\n",
      "Epoch 97/200\n",
      "3730/3730 [==============================] - 0s 95us/step - loss: 0.3615 - acc: 0.8351 - val_loss: 0.2727 - val_acc: 0.8940\n",
      "Epoch 98/200\n",
      "3730/3730 [==============================] - 0s 97us/step - loss: 0.3617 - acc: 0.8383 - val_loss: 0.2732 - val_acc: 0.8940\n",
      "Epoch 99/200\n",
      "3730/3730 [==============================] - 0s 102us/step - loss: 0.3615 - acc: 0.8349 - val_loss: 0.2748 - val_acc: 0.8916\n",
      "Epoch 100/200\n",
      "3730/3730 [==============================] - 0s 102us/step - loss: 0.3610 - acc: 0.8351 - val_loss: 0.2732 - val_acc: 0.8940\n",
      "Epoch 101/200\n",
      "3730/3730 [==============================] - 0s 109us/step - loss: 0.3610 - acc: 0.8335 - val_loss: 0.2736 - val_acc: 0.8964\n",
      "Epoch 102/200\n",
      "3730/3730 [==============================] - 0s 83us/step - loss: 0.3605 - acc: 0.8354 - val_loss: 0.2737 - val_acc: 0.8988\n",
      "Epoch 103/200\n",
      "3730/3730 [==============================] - 0s 110us/step - loss: 0.3599 - acc: 0.8362 - val_loss: 0.2734 - val_acc: 0.8964\n",
      "Epoch 104/200\n",
      "3730/3730 [==============================] - 0s 99us/step - loss: 0.3605 - acc: 0.8365 - val_loss: 0.2745 - val_acc: 0.8940\n",
      "Epoch 105/200\n",
      "3730/3730 [==============================] - 0s 88us/step - loss: 0.3604 - acc: 0.8354 - val_loss: 0.2737 - val_acc: 0.8940\n",
      "Epoch 106/200\n",
      "3730/3730 [==============================] - 0s 99us/step - loss: 0.3594 - acc: 0.8389 - val_loss: 0.2743 - val_acc: 0.8964\n",
      "Epoch 107/200\n",
      "3730/3730 [==============================] - 0s 99us/step - loss: 0.3599 - acc: 0.8351 - val_loss: 0.2738 - val_acc: 0.8940\n",
      "Epoch 108/200\n",
      "3730/3730 [==============================] - 0s 82us/step - loss: 0.3596 - acc: 0.8367 - val_loss: 0.2763 - val_acc: 0.8916\n",
      "Epoch 109/200\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.3594 - acc: 0.8357 - val_loss: 0.2760 - val_acc: 0.8964\n",
      "Epoch 110/200\n",
      "3730/3730 [==============================] - 0s 83us/step - loss: 0.3591 - acc: 0.8367 - val_loss: 0.2757 - val_acc: 0.8940\n",
      "Epoch 111/200\n",
      "3730/3730 [==============================] - 0s 82us/step - loss: 0.3593 - acc: 0.8362 - val_loss: 0.2766 - val_acc: 0.8916\n",
      "Epoch 112/200\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.3584 - acc: 0.8386 - val_loss: 0.2771 - val_acc: 0.8916\n",
      "Epoch 113/200\n",
      "3730/3730 [==============================] - 0s 94us/step - loss: 0.3587 - acc: 0.8378 - val_loss: 0.2775 - val_acc: 0.8940\n",
      "Epoch 114/200\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.3589 - acc: 0.8383 - val_loss: 0.2776 - val_acc: 0.8916\n",
      "Epoch 115/200\n",
      "3730/3730 [==============================] - 0s 117us/step - loss: 0.3577 - acc: 0.8402 - val_loss: 0.2785 - val_acc: 0.8940\n",
      "Epoch 116/200\n",
      "3730/3730 [==============================] - 0s 108us/step - loss: 0.3582 - acc: 0.8375 - val_loss: 0.2789 - val_acc: 0.8940\n",
      "Epoch 117/200\n",
      "3730/3730 [==============================] - 0s 89us/step - loss: 0.3589 - acc: 0.8389 - val_loss: 0.2791 - val_acc: 0.8940\n",
      "Epoch 118/200\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.3578 - acc: 0.8365 - val_loss: 0.2779 - val_acc: 0.8940\n",
      "Epoch 119/200\n",
      "3730/3730 [==============================] - 0s 82us/step - loss: 0.3578 - acc: 0.8394 - val_loss: 0.2781 - val_acc: 0.8940\n",
      "Epoch 120/200\n",
      "3730/3730 [==============================] - 0s 83us/step - loss: 0.3581 - acc: 0.8370 - val_loss: 0.2787 - val_acc: 0.8940\n",
      "Epoch 121/200\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.3569 - acc: 0.8359 - val_loss: 0.2818 - val_acc: 0.8940\n",
      "Epoch 122/200\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.3579 - acc: 0.8359 - val_loss: 0.2796 - val_acc: 0.8916\n",
      "Epoch 123/200\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.3576 - acc: 0.8365 - val_loss: 0.2806 - val_acc: 0.8916\n",
      "Epoch 124/200\n",
      "3730/3730 [==============================] - 0s 82us/step - loss: 0.3569 - acc: 0.8375 - val_loss: 0.2797 - val_acc: 0.8916\n",
      "Epoch 125/200\n",
      "3730/3730 [==============================] - 0s 79us/step - loss: 0.3570 - acc: 0.8378 - val_loss: 0.2793 - val_acc: 0.8916\n",
      "Epoch 126/200\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.3570 - acc: 0.8386 - val_loss: 0.2804 - val_acc: 0.8964\n",
      "Epoch 127/200\n",
      "3730/3730 [==============================] - 0s 101us/step - loss: 0.3570 - acc: 0.8343 - val_loss: 0.2803 - val_acc: 0.8940\n",
      "Epoch 128/200\n",
      "3730/3730 [==============================] - 0s 105us/step - loss: 0.3567 - acc: 0.8367 - val_loss: 0.2827 - val_acc: 0.8940\n",
      "Epoch 129/200\n",
      "3730/3730 [==============================] - 0s 101us/step - loss: 0.3564 - acc: 0.8381 - val_loss: 0.2818 - val_acc: 0.8916\n",
      "Epoch 130/200\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.3552 - acc: 0.8383 - val_loss: 0.2781 - val_acc: 0.8988\n",
      "Epoch 131/200\n",
      "3730/3730 [==============================] - 0s 84us/step - loss: 0.3566 - acc: 0.8349 - val_loss: 0.2824 - val_acc: 0.8940\n",
      "Epoch 132/200\n",
      "3730/3730 [==============================] - 0s 84us/step - loss: 0.3564 - acc: 0.8378 - val_loss: 0.2822 - val_acc: 0.8940\n",
      "Epoch 133/200\n",
      "3730/3730 [==============================] - 0s 87us/step - loss: 0.3563 - acc: 0.8391 - val_loss: 0.2806 - val_acc: 0.8940\n",
      "Epoch 134/200\n",
      "3730/3730 [==============================] - 0s 84us/step - loss: 0.3558 - acc: 0.8375 - val_loss: 0.2814 - val_acc: 0.8988\n",
      "Epoch 135/200\n",
      "3730/3730 [==============================] - 0s 88us/step - loss: 0.3561 - acc: 0.8375 - val_loss: 0.2831 - val_acc: 0.8940\n",
      "Epoch 136/200\n",
      "3730/3730 [==============================] - 0s 86us/step - loss: 0.3557 - acc: 0.8383 - val_loss: 0.2828 - val_acc: 0.8916\n",
      "Epoch 137/200\n",
      "3730/3730 [==============================] - 0s 98us/step - loss: 0.3558 - acc: 0.8370 - val_loss: 0.2831 - val_acc: 0.8940\n",
      "Epoch 138/200\n",
      "3730/3730 [==============================] - 0s 92us/step - loss: 0.3550 - acc: 0.8381 - val_loss: 0.2827 - val_acc: 0.8940\n",
      "Epoch 139/200\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.3552 - acc: 0.8362 - val_loss: 0.2813 - val_acc: 0.8964\n",
      "Epoch 140/200\n",
      "3730/3730 [==============================] - 0s 98us/step - loss: 0.3554 - acc: 0.8351 - val_loss: 0.2831 - val_acc: 0.8940\n",
      "Epoch 141/200\n",
      "3730/3730 [==============================] - 0s 100us/step - loss: 0.3551 - acc: 0.8367 - val_loss: 0.2820 - val_acc: 0.8916\n",
      "Epoch 142/200\n",
      "3730/3730 [==============================] - 0s 85us/step - loss: 0.3550 - acc: 0.8394 - val_loss: 0.2812 - val_acc: 0.8940\n",
      "Epoch 143/200\n",
      "3730/3730 [==============================] - 0s 85us/step - loss: 0.3549 - acc: 0.8367 - val_loss: 0.2815 - val_acc: 0.8964\n",
      "Epoch 144/200\n",
      "3730/3730 [==============================] - 0s 85us/step - loss: 0.3545 - acc: 0.8389 - val_loss: 0.2827 - val_acc: 0.8988\n",
      "Epoch 145/200\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.3551 - acc: 0.8391 - val_loss: 0.2815 - val_acc: 0.8964\n",
      "Epoch 146/200\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.3558 - acc: 0.8373 - val_loss: 0.2839 - val_acc: 0.8940\n",
      "Epoch 147/200\n",
      "3730/3730 [==============================] - 0s 83us/step - loss: 0.3547 - acc: 0.8349 - val_loss: 0.2828 - val_acc: 0.8988\n",
      "Epoch 148/200\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.3556 - acc: 0.8381 - val_loss: 0.2821 - val_acc: 0.8964\n",
      "Epoch 149/200\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.3548 - acc: 0.8391 - val_loss: 0.2831 - val_acc: 0.8964\n",
      "Epoch 150/200\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.3542 - acc: 0.8367 - val_loss: 0.2849 - val_acc: 0.8964\n",
      "Epoch 151/200\n",
      "3730/3730 [==============================] - 0s 82us/step - loss: 0.3544 - acc: 0.8386 - val_loss: 0.2838 - val_acc: 0.8916\n",
      "Epoch 152/200\n",
      "3730/3730 [==============================] - 0s 83us/step - loss: 0.3540 - acc: 0.8389 - val_loss: 0.2824 - val_acc: 0.8916\n",
      "Epoch 153/200\n",
      "3730/3730 [==============================] - 0s 102us/step - loss: 0.3540 - acc: 0.8389 - val_loss: 0.2827 - val_acc: 0.8916\n",
      "Epoch 154/200\n",
      "3730/3730 [==============================] - 0s 89us/step - loss: 0.3536 - acc: 0.8397 - val_loss: 0.2827 - val_acc: 0.8916\n",
      "Epoch 155/200\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.3534 - acc: 0.8402 - val_loss: 0.2837 - val_acc: 0.8916\n",
      "Epoch 156/200\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.3539 - acc: 0.8378 - val_loss: 0.2831 - val_acc: 0.8916\n",
      "Epoch 157/200\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.3537 - acc: 0.8373 - val_loss: 0.2823 - val_acc: 0.8940\n",
      "Epoch 158/200\n",
      "3730/3730 [==============================] - 0s 82us/step - loss: 0.3544 - acc: 0.8397 - val_loss: 0.2839 - val_acc: 0.8964\n",
      "Epoch 159/200\n",
      "3730/3730 [==============================] - 0s 82us/step - loss: 0.3538 - acc: 0.8370 - val_loss: 0.2847 - val_acc: 0.8940\n",
      "Epoch 160/200\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.3549 - acc: 0.8381 - val_loss: 0.2856 - val_acc: 0.8916\n",
      "Epoch 161/200\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.3533 - acc: 0.8389 - val_loss: 0.2853 - val_acc: 0.8964\n",
      "Epoch 162/200\n",
      "3730/3730 [==============================] - 0s 83us/step - loss: 0.3542 - acc: 0.8397 - val_loss: 0.2863 - val_acc: 0.8867\n",
      "Epoch 163/200\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.3537 - acc: 0.8424 - val_loss: 0.2868 - val_acc: 0.8892\n",
      "Epoch 164/200\n",
      "3730/3730 [==============================] - 0s 83us/step - loss: 0.3528 - acc: 0.8421 - val_loss: 0.2854 - val_acc: 0.8892\n",
      "Epoch 165/200\n",
      "3730/3730 [==============================] - 0s 86us/step - loss: 0.3533 - acc: 0.8381 - val_loss: 0.2846 - val_acc: 0.8940\n",
      "Epoch 166/200\n",
      "3730/3730 [==============================] - 0s 82us/step - loss: 0.3535 - acc: 0.8429 - val_loss: 0.2863 - val_acc: 0.8892\n",
      "Epoch 167/200\n",
      "3730/3730 [==============================] - 0s 82us/step - loss: 0.3532 - acc: 0.8408 - val_loss: 0.2858 - val_acc: 0.8892\n",
      "Epoch 168/200\n",
      "3730/3730 [==============================] - 0s 82us/step - loss: 0.3526 - acc: 0.8418 - val_loss: 0.2850 - val_acc: 0.8940\n",
      "Epoch 169/200\n",
      "3730/3730 [==============================] - 0s 82us/step - loss: 0.3529 - acc: 0.8383 - val_loss: 0.2869 - val_acc: 0.8867\n",
      "Epoch 170/200\n",
      "3730/3730 [==============================] - 0s 83us/step - loss: 0.3526 - acc: 0.8410 - val_loss: 0.2865 - val_acc: 0.8892\n",
      "Epoch 171/200\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.3536 - acc: 0.8408 - val_loss: 0.2846 - val_acc: 0.8892\n",
      "Epoch 172/200\n",
      "3730/3730 [==============================] - 0s 82us/step - loss: 0.3531 - acc: 0.8378 - val_loss: 0.2842 - val_acc: 0.8867\n",
      "Epoch 173/200\n",
      "3730/3730 [==============================] - 0s 82us/step - loss: 0.3533 - acc: 0.8386 - val_loss: 0.2860 - val_acc: 0.8867\n",
      "Epoch 174/200\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.3527 - acc: 0.8394 - val_loss: 0.2873 - val_acc: 0.8843\n",
      "Epoch 175/200\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.3526 - acc: 0.8394 - val_loss: 0.2856 - val_acc: 0.8916\n",
      "Epoch 176/200\n",
      "3730/3730 [==============================] - 0s 85us/step - loss: 0.3539 - acc: 0.8394 - val_loss: 0.2863 - val_acc: 0.8892\n",
      "Epoch 177/200\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.3530 - acc: 0.8383 - val_loss: 0.2857 - val_acc: 0.8916\n",
      "Epoch 178/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3730/3730 [==============================] - 0s 83us/step - loss: 0.3519 - acc: 0.8373 - val_loss: 0.2854 - val_acc: 0.8892\n",
      "Epoch 179/200\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.3528 - acc: 0.8399 - val_loss: 0.2850 - val_acc: 0.8892\n",
      "Epoch 180/200\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.3526 - acc: 0.8405 - val_loss: 0.2853 - val_acc: 0.8892\n",
      "Epoch 181/200\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.3521 - acc: 0.8399 - val_loss: 0.2854 - val_acc: 0.8892\n",
      "Epoch 182/200\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.3526 - acc: 0.8399 - val_loss: 0.2858 - val_acc: 0.8892\n",
      "Epoch 183/200\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.3521 - acc: 0.8416 - val_loss: 0.2877 - val_acc: 0.8867\n",
      "Epoch 184/200\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.3519 - acc: 0.8399 - val_loss: 0.2831 - val_acc: 0.8892\n",
      "Epoch 185/200\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.3523 - acc: 0.8399 - val_loss: 0.2860 - val_acc: 0.8867\n",
      "Epoch 186/200\n",
      "3730/3730 [==============================] - 0s 82us/step - loss: 0.3520 - acc: 0.8402 - val_loss: 0.2856 - val_acc: 0.8892\n",
      "Epoch 187/200\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.3519 - acc: 0.8402 - val_loss: 0.2850 - val_acc: 0.8892\n",
      "Epoch 188/200\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.3517 - acc: 0.8405 - val_loss: 0.2862 - val_acc: 0.8843\n",
      "Epoch 189/200\n",
      "3730/3730 [==============================] - 0s 82us/step - loss: 0.3518 - acc: 0.8402 - val_loss: 0.2844 - val_acc: 0.8843\n",
      "Epoch 190/200\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.3518 - acc: 0.8405 - val_loss: 0.2857 - val_acc: 0.8843\n",
      "Epoch 191/200\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.3512 - acc: 0.8418 - val_loss: 0.2875 - val_acc: 0.8819\n",
      "Epoch 192/200\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.3523 - acc: 0.8405 - val_loss: 0.2861 - val_acc: 0.8843\n",
      "Epoch 193/200\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.3520 - acc: 0.8418 - val_loss: 0.2868 - val_acc: 0.8867\n",
      "Epoch 194/200\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.3516 - acc: 0.8399 - val_loss: 0.2876 - val_acc: 0.8843\n",
      "Epoch 195/200\n",
      "3730/3730 [==============================] - 0s 84us/step - loss: 0.3515 - acc: 0.8408 - val_loss: 0.2848 - val_acc: 0.8892\n",
      "Epoch 196/200\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.3518 - acc: 0.8378 - val_loss: 0.2869 - val_acc: 0.8843\n",
      "Epoch 197/200\n",
      "3730/3730 [==============================] - 0s 82us/step - loss: 0.3515 - acc: 0.8416 - val_loss: 0.2856 - val_acc: 0.8843\n",
      "Epoch 198/200\n",
      "3730/3730 [==============================] - 0s 84us/step - loss: 0.3512 - acc: 0.8391 - val_loss: 0.2858 - val_acc: 0.8867\n",
      "Epoch 199/200\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.3516 - acc: 0.8405 - val_loss: 0.2874 - val_acc: 0.8867\n",
      "Epoch 200/200\n",
      "3730/3730 [==============================] - 0s 81us/step - loss: 0.3511 - acc: 0.8410 - val_loss: 0.2856 - val_acc: 0.8867\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, kernel_initializer='normal', input_dim=len(X[0]), activation='relu'))\n",
    "model.add(Dense(10, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adamax',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X, y.values, epochs=200, validation_split = 0.1)\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T17:36:40.893318Z",
     "start_time": "2019-09-13T17:34:34.892247Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3731 samples, validate on 415 samples\n",
      "Epoch 1/600\n",
      "3731/3731 [==============================] - 1s 228us/step - loss: 0.6803 - acc: 0.7172 - val_loss: 0.6406 - val_acc: 0.7590\n",
      "Epoch 2/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.6144 - acc: 0.7727 - val_loss: 0.5372 - val_acc: 0.8193\n",
      "Epoch 3/600\n",
      "3731/3731 [==============================] - 0s 60us/step - loss: 0.5519 - acc: 0.8014 - val_loss: 0.4935 - val_acc: 0.8386\n",
      "Epoch 4/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.5209 - acc: 0.8215 - val_loss: 0.4687 - val_acc: 0.8578\n",
      "Epoch 5/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.5008 - acc: 0.8261 - val_loss: 0.4498 - val_acc: 0.8602\n",
      "Epoch 6/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.4856 - acc: 0.8282 - val_loss: 0.4352 - val_acc: 0.8675\n",
      "Epoch 7/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.4730 - acc: 0.8298 - val_loss: 0.4233 - val_acc: 0.8651\n",
      "Epoch 8/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.4628 - acc: 0.8317 - val_loss: 0.4129 - val_acc: 0.8627\n",
      "Epoch 9/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.4541 - acc: 0.8319 - val_loss: 0.4057 - val_acc: 0.8627\n",
      "Epoch 10/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.4473 - acc: 0.8330 - val_loss: 0.3980 - val_acc: 0.8602\n",
      "Epoch 11/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.4410 - acc: 0.8317 - val_loss: 0.3913 - val_acc: 0.8602\n",
      "Epoch 12/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.4356 - acc: 0.8325 - val_loss: 0.3860 - val_acc: 0.8602\n",
      "Epoch 13/600\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.4310 - acc: 0.8303 - val_loss: 0.3817 - val_acc: 0.8627\n",
      "Epoch 14/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.4264 - acc: 0.8317 - val_loss: 0.3774 - val_acc: 0.8627\n",
      "Epoch 15/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.4230 - acc: 0.8328 - val_loss: 0.3749 - val_acc: 0.8602\n",
      "Epoch 16/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.4199 - acc: 0.8306 - val_loss: 0.3711 - val_acc: 0.8627\n",
      "Epoch 17/600\n",
      "3731/3731 [==============================] - 0s 59us/step - loss: 0.4173 - acc: 0.8333 - val_loss: 0.3684 - val_acc: 0.8602\n",
      "Epoch 18/600\n",
      "3731/3731 [==============================] - 0s 76us/step - loss: 0.4145 - acc: 0.8311 - val_loss: 0.3666 - val_acc: 0.8602\n",
      "Epoch 19/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.4124 - acc: 0.8311 - val_loss: 0.3632 - val_acc: 0.8602\n",
      "Epoch 20/600\n",
      "3731/3731 [==============================] - ETA: 0s - loss: 0.4131 - acc: 0.826 - 0s 53us/step - loss: 0.4103 - acc: 0.8309 - val_loss: 0.3620 - val_acc: 0.8602\n",
      "Epoch 21/600\n",
      "3731/3731 [==============================] - 0s 63us/step - loss: 0.4087 - acc: 0.8317 - val_loss: 0.3588 - val_acc: 0.8627\n",
      "Epoch 22/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.4068 - acc: 0.8306 - val_loss: 0.3572 - val_acc: 0.8627\n",
      "Epoch 23/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.4059 - acc: 0.8298 - val_loss: 0.3532 - val_acc: 0.8627\n",
      "Epoch 24/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.4039 - acc: 0.8330 - val_loss: 0.3522 - val_acc: 0.8675\n",
      "Epoch 25/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.4027 - acc: 0.8319 - val_loss: 0.3490 - val_acc: 0.8651\n",
      "Epoch 26/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.4016 - acc: 0.8322 - val_loss: 0.3472 - val_acc: 0.8651\n",
      "Epoch 27/600\n",
      "3731/3731 [==============================] - 0s 69us/step - loss: 0.4005 - acc: 0.8325 - val_loss: 0.3458 - val_acc: 0.8651\n",
      "Epoch 28/600\n",
      "3731/3731 [==============================] - 0s 67us/step - loss: 0.3993 - acc: 0.8298 - val_loss: 0.3426 - val_acc: 0.8675\n",
      "Epoch 29/600\n",
      "3731/3731 [==============================] - 0s 61us/step - loss: 0.3988 - acc: 0.8311 - val_loss: 0.3391 - val_acc: 0.8675\n",
      "Epoch 30/600\n",
      "3731/3731 [==============================] - 0s 58us/step - loss: 0.3982 - acc: 0.8319 - val_loss: 0.3386 - val_acc: 0.8675\n",
      "Epoch 31/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3967 - acc: 0.8317 - val_loss: 0.3371 - val_acc: 0.8675\n",
      "Epoch 32/600\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3954 - acc: 0.8306 - val_loss: 0.3338 - val_acc: 0.8699\n",
      "Epoch 33/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3942 - acc: 0.8309 - val_loss: 0.3328 - val_acc: 0.8651\n",
      "Epoch 34/600\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3936 - acc: 0.8349 - val_loss: 0.3307 - val_acc: 0.8699\n",
      "Epoch 35/600\n",
      "3731/3731 [==============================] - 0s 59us/step - loss: 0.3925 - acc: 0.8325 - val_loss: 0.3292 - val_acc: 0.8651\n",
      "Epoch 36/600\n",
      "3731/3731 [==============================] - 0s 59us/step - loss: 0.3921 - acc: 0.8322 - val_loss: 0.3283 - val_acc: 0.8651\n",
      "Epoch 37/600\n",
      "3731/3731 [==============================] - 0s 62us/step - loss: 0.3913 - acc: 0.8317 - val_loss: 0.3274 - val_acc: 0.8675\n",
      "Epoch 38/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3906 - acc: 0.8330 - val_loss: 0.3249 - val_acc: 0.8699\n",
      "Epoch 39/600\n",
      "3731/3731 [==============================] - 0s 62us/step - loss: 0.3904 - acc: 0.8328 - val_loss: 0.3229 - val_acc: 0.8699\n",
      "Epoch 40/600\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3896 - acc: 0.8314 - val_loss: 0.3250 - val_acc: 0.8675\n",
      "Epoch 41/600\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.3891 - acc: 0.8311 - val_loss: 0.3253 - val_acc: 0.8699\n",
      "Epoch 42/600\n",
      "3731/3731 [==============================] - 0s 66us/step - loss: 0.3885 - acc: 0.8328 - val_loss: 0.3231 - val_acc: 0.8675\n",
      "Epoch 43/600\n",
      "3731/3731 [==============================] - 0s 56us/step - loss: 0.3878 - acc: 0.8338 - val_loss: 0.3210 - val_acc: 0.8723\n",
      "Epoch 44/600\n",
      "3731/3731 [==============================] - 0s 62us/step - loss: 0.3876 - acc: 0.8333 - val_loss: 0.3194 - val_acc: 0.8747\n",
      "Epoch 45/600\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.3867 - acc: 0.8344 - val_loss: 0.3200 - val_acc: 0.8699\n",
      "Epoch 46/600\n",
      "3731/3731 [==============================] - 0s 63us/step - loss: 0.3862 - acc: 0.8336 - val_loss: 0.3187 - val_acc: 0.8675\n",
      "Epoch 47/600\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.3856 - acc: 0.8333 - val_loss: 0.3179 - val_acc: 0.8699\n",
      "Epoch 48/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3850 - acc: 0.8354 - val_loss: 0.3155 - val_acc: 0.8723\n",
      "Epoch 49/600\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.3843 - acc: 0.8338 - val_loss: 0.3149 - val_acc: 0.8723\n",
      "Epoch 50/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3837 - acc: 0.8352 - val_loss: 0.3128 - val_acc: 0.8699\n",
      "Epoch 51/600\n",
      "3731/3731 [==============================] - 0s 56us/step - loss: 0.3832 - acc: 0.8357 - val_loss: 0.3130 - val_acc: 0.8699\n",
      "Epoch 52/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3828 - acc: 0.8330 - val_loss: 0.3089 - val_acc: 0.8723\n",
      "Epoch 53/600\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.3825 - acc: 0.8344 - val_loss: 0.3113 - val_acc: 0.8699\n",
      "Epoch 54/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3822 - acc: 0.8349 - val_loss: 0.3101 - val_acc: 0.8699\n",
      "Epoch 55/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3815 - acc: 0.8330 - val_loss: 0.3075 - val_acc: 0.8699\n",
      "Epoch 56/600\n",
      "3731/3731 [==============================] - 0s 62us/step - loss: 0.3814 - acc: 0.8333 - val_loss: 0.3086 - val_acc: 0.8699\n",
      "Epoch 57/600\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3807 - acc: 0.8354 - val_loss: 0.3075 - val_acc: 0.8699\n",
      "Epoch 58/600\n",
      "3731/3731 [==============================] - 0s 67us/step - loss: 0.3807 - acc: 0.8362 - val_loss: 0.3062 - val_acc: 0.8675\n",
      "Epoch 59/600\n",
      "3731/3731 [==============================] - 0s 58us/step - loss: 0.3802 - acc: 0.8360 - val_loss: 0.3055 - val_acc: 0.8675\n",
      "Epoch 60/600\n",
      "3731/3731 [==============================] - 0s 66us/step - loss: 0.3799 - acc: 0.8349 - val_loss: 0.3057 - val_acc: 0.8675\n",
      "Epoch 61/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3796 - acc: 0.8357 - val_loss: 0.3062 - val_acc: 0.8699\n",
      "Epoch 62/600\n",
      "3731/3731 [==============================] - 0s 64us/step - loss: 0.3802 - acc: 0.8352 - val_loss: 0.3057 - val_acc: 0.8675\n",
      "Epoch 63/600\n",
      "3731/3731 [==============================] - 0s 56us/step - loss: 0.3790 - acc: 0.8354 - val_loss: 0.3032 - val_acc: 0.8675\n",
      "Epoch 64/600\n",
      "3731/3731 [==============================] - 0s 75us/step - loss: 0.3788 - acc: 0.8354 - val_loss: 0.3032 - val_acc: 0.8699\n",
      "Epoch 65/600\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3784 - acc: 0.8352 - val_loss: 0.3036 - val_acc: 0.8675\n",
      "Epoch 66/600\n",
      "3731/3731 [==============================] - 0s 69us/step - loss: 0.3782 - acc: 0.8368 - val_loss: 0.3039 - val_acc: 0.8747\n",
      "Epoch 67/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3781 - acc: 0.8357 - val_loss: 0.3044 - val_acc: 0.8699\n",
      "Epoch 68/600\n",
      "3731/3731 [==============================] - 0s 63us/step - loss: 0.3780 - acc: 0.8370 - val_loss: 0.3045 - val_acc: 0.8723\n",
      "Epoch 69/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3778 - acc: 0.8360 - val_loss: 0.3025 - val_acc: 0.8747\n",
      "Epoch 70/600\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.3777 - acc: 0.8344 - val_loss: 0.3039 - val_acc: 0.8723\n",
      "Epoch 71/600\n",
      "3731/3731 [==============================] - 0s 60us/step - loss: 0.3770 - acc: 0.8360 - val_loss: 0.3013 - val_acc: 0.8723\n",
      "Epoch 72/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3766 - acc: 0.8376 - val_loss: 0.2955 - val_acc: 0.8723\n",
      "Epoch 73/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3744 - acc: 0.8360 - val_loss: 0.2930 - val_acc: 0.8747\n",
      "Epoch 74/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3738 - acc: 0.8344 - val_loss: 0.2889 - val_acc: 0.8723\n",
      "Epoch 75/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3733 - acc: 0.8354 - val_loss: 0.2894 - val_acc: 0.8771\n",
      "Epoch 76/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3729 - acc: 0.8362 - val_loss: 0.2894 - val_acc: 0.8771\n",
      "Epoch 77/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3724 - acc: 0.8368 - val_loss: 0.2877 - val_acc: 0.8795\n",
      "Epoch 78/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3723 - acc: 0.8344 - val_loss: 0.2878 - val_acc: 0.8795\n",
      "Epoch 79/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3717 - acc: 0.8368 - val_loss: 0.2874 - val_acc: 0.8795\n",
      "Epoch 80/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3715 - acc: 0.8357 - val_loss: 0.2870 - val_acc: 0.8747\n",
      "Epoch 81/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3718 - acc: 0.8349 - val_loss: 0.2849 - val_acc: 0.8843\n",
      "Epoch 82/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3708 - acc: 0.8352 - val_loss: 0.2862 - val_acc: 0.8795\n",
      "Epoch 83/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3707 - acc: 0.8349 - val_loss: 0.2867 - val_acc: 0.8771\n",
      "Epoch 84/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3708 - acc: 0.8357 - val_loss: 0.2845 - val_acc: 0.8795\n",
      "Epoch 85/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3703 - acc: 0.8349 - val_loss: 0.2845 - val_acc: 0.8819\n",
      "Epoch 86/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3703 - acc: 0.8338 - val_loss: 0.2842 - val_acc: 0.8819\n",
      "Epoch 87/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3696 - acc: 0.8357 - val_loss: 0.2842 - val_acc: 0.8795\n",
      "Epoch 88/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3693 - acc: 0.8370 - val_loss: 0.2819 - val_acc: 0.8819\n",
      "Epoch 89/600\n",
      "3731/3731 [==============================] - 0s 64us/step - loss: 0.3692 - acc: 0.8346 - val_loss: 0.2837 - val_acc: 0.8819\n",
      "Epoch 90/600\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3691 - acc: 0.8344 - val_loss: 0.2825 - val_acc: 0.8795\n",
      "Epoch 91/600\n",
      "3731/3731 [==============================] - 0s 68us/step - loss: 0.3694 - acc: 0.8381 - val_loss: 0.2817 - val_acc: 0.8843\n",
      "Epoch 92/600\n",
      "3731/3731 [==============================] - 0s 60us/step - loss: 0.3686 - acc: 0.8373 - val_loss: 0.2807 - val_acc: 0.8819\n",
      "Epoch 93/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3681 - acc: 0.8362 - val_loss: 0.2810 - val_acc: 0.8819\n",
      "Epoch 94/600\n",
      "3731/3731 [==============================] - 0s 64us/step - loss: 0.3680 - acc: 0.8392 - val_loss: 0.2788 - val_acc: 0.8843\n",
      "Epoch 95/600\n",
      "3731/3731 [==============================] - 0s 65us/step - loss: 0.3679 - acc: 0.8378 - val_loss: 0.2797 - val_acc: 0.8819\n",
      "Epoch 96/600\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.3682 - acc: 0.8378 - val_loss: 0.2806 - val_acc: 0.8795\n",
      "Epoch 97/600\n",
      "3731/3731 [==============================] - 0s 61us/step - loss: 0.3677 - acc: 0.8368 - val_loss: 0.2809 - val_acc: 0.8819\n",
      "Epoch 98/600\n",
      "3731/3731 [==============================] - 0s 60us/step - loss: 0.3673 - acc: 0.8389 - val_loss: 0.2793 - val_acc: 0.8843\n",
      "Epoch 99/600\n",
      "3731/3731 [==============================] - 0s 60us/step - loss: 0.3668 - acc: 0.8381 - val_loss: 0.2776 - val_acc: 0.8843\n",
      "Epoch 100/600\n",
      "3731/3731 [==============================] - 0s 62us/step - loss: 0.3669 - acc: 0.8357 - val_loss: 0.2795 - val_acc: 0.8843\n",
      "Epoch 101/600\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.3667 - acc: 0.8378 - val_loss: 0.2780 - val_acc: 0.8819\n",
      "Epoch 102/600\n",
      "3731/3731 [==============================] - 0s 61us/step - loss: 0.3673 - acc: 0.8373 - val_loss: 0.2778 - val_acc: 0.8867\n",
      "Epoch 103/600\n",
      "3731/3731 [==============================] - 0s 62us/step - loss: 0.3666 - acc: 0.8368 - val_loss: 0.2785 - val_acc: 0.8819\n",
      "Epoch 104/600\n",
      "3731/3731 [==============================] - 0s 63us/step - loss: 0.3665 - acc: 0.8362 - val_loss: 0.2755 - val_acc: 0.8916\n",
      "Epoch 105/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3664 - acc: 0.8368 - val_loss: 0.2777 - val_acc: 0.8916\n",
      "Epoch 106/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3659 - acc: 0.8386 - val_loss: 0.2777 - val_acc: 0.8916\n",
      "Epoch 107/600\n",
      "3731/3731 [==============================] - 0s 66us/step - loss: 0.3659 - acc: 0.8370 - val_loss: 0.2775 - val_acc: 0.8916\n",
      "Epoch 108/600\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3656 - acc: 0.8386 - val_loss: 0.2766 - val_acc: 0.8892\n",
      "Epoch 109/600\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.3653 - acc: 0.8395 - val_loss: 0.2774 - val_acc: 0.8916\n",
      "Epoch 110/600\n",
      "3731/3731 [==============================] - 0s 64us/step - loss: 0.3652 - acc: 0.8365 - val_loss: 0.2775 - val_acc: 0.8892\n",
      "Epoch 111/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3657 - acc: 0.8400 - val_loss: 0.2765 - val_acc: 0.8916\n",
      "Epoch 112/600\n",
      "3731/3731 [==============================] - 0s 67us/step - loss: 0.3656 - acc: 0.8395 - val_loss: 0.2766 - val_acc: 0.8916\n",
      "Epoch 113/600\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3646 - acc: 0.8397 - val_loss: 0.2757 - val_acc: 0.8892\n",
      "Epoch 114/600\n",
      "3731/3731 [==============================] - 0s 61us/step - loss: 0.3647 - acc: 0.8392 - val_loss: 0.2753 - val_acc: 0.8916\n",
      "Epoch 115/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3648 - acc: 0.8378 - val_loss: 0.2761 - val_acc: 0.8940\n",
      "Epoch 116/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3643 - acc: 0.8403 - val_loss: 0.2770 - val_acc: 0.8892\n",
      "Epoch 117/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3646 - acc: 0.8381 - val_loss: 0.2749 - val_acc: 0.8916\n",
      "Epoch 118/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3645 - acc: 0.8378 - val_loss: 0.2757 - val_acc: 0.8892\n",
      "Epoch 119/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3639 - acc: 0.8386 - val_loss: 0.2771 - val_acc: 0.8867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3649 - acc: 0.8389 - val_loss: 0.2742 - val_acc: 0.8964\n",
      "Epoch 121/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3644 - acc: 0.8400 - val_loss: 0.2762 - val_acc: 0.8940\n",
      "Epoch 122/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3636 - acc: 0.8400 - val_loss: 0.2748 - val_acc: 0.8988\n",
      "Epoch 123/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3634 - acc: 0.8381 - val_loss: 0.2746 - val_acc: 0.8867\n",
      "Epoch 124/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3635 - acc: 0.8365 - val_loss: 0.2752 - val_acc: 0.8892\n",
      "Epoch 125/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3636 - acc: 0.8416 - val_loss: 0.2750 - val_acc: 0.8892\n",
      "Epoch 126/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3632 - acc: 0.8386 - val_loss: 0.2747 - val_acc: 0.8964\n",
      "Epoch 127/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3628 - acc: 0.8421 - val_loss: 0.2741 - val_acc: 0.8940\n",
      "Epoch 128/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3632 - acc: 0.8403 - val_loss: 0.2761 - val_acc: 0.8892\n",
      "Epoch 129/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3634 - acc: 0.8400 - val_loss: 0.2735 - val_acc: 0.8964\n",
      "Epoch 130/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3627 - acc: 0.8378 - val_loss: 0.2747 - val_acc: 0.8916\n",
      "Epoch 131/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3629 - acc: 0.8405 - val_loss: 0.2740 - val_acc: 0.8940\n",
      "Epoch 132/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3626 - acc: 0.8397 - val_loss: 0.2737 - val_acc: 0.8940\n",
      "Epoch 133/600\n",
      "3731/3731 [==============================] - 0s 60us/step - loss: 0.3633 - acc: 0.8384 - val_loss: 0.2739 - val_acc: 0.8988\n",
      "Epoch 134/600\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.3628 - acc: 0.8376 - val_loss: 0.2726 - val_acc: 0.8988\n",
      "Epoch 135/600\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.3628 - acc: 0.8389 - val_loss: 0.2728 - val_acc: 0.8988\n",
      "Epoch 136/600\n",
      "3731/3731 [==============================] - 0s 61us/step - loss: 0.3629 - acc: 0.8408 - val_loss: 0.2731 - val_acc: 0.9036\n",
      "Epoch 137/600\n",
      "3731/3731 [==============================] - 0s 62us/step - loss: 0.3625 - acc: 0.8381 - val_loss: 0.2741 - val_acc: 0.8988\n",
      "Epoch 138/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3620 - acc: 0.8400 - val_loss: 0.2748 - val_acc: 0.8988\n",
      "Epoch 139/600\n",
      "3731/3731 [==============================] - 0s 64us/step - loss: 0.3623 - acc: 0.8395 - val_loss: 0.2730 - val_acc: 0.8988\n",
      "Epoch 140/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3620 - acc: 0.8395 - val_loss: 0.2733 - val_acc: 0.9012\n",
      "Epoch 141/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3620 - acc: 0.8395 - val_loss: 0.2731 - val_acc: 0.9012\n",
      "Epoch 142/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3620 - acc: 0.8392 - val_loss: 0.2718 - val_acc: 0.9060\n",
      "Epoch 143/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3625 - acc: 0.8416 - val_loss: 0.2724 - val_acc: 0.9060\n",
      "Epoch 144/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3621 - acc: 0.8384 - val_loss: 0.2728 - val_acc: 0.9060\n",
      "Epoch 145/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3618 - acc: 0.8395 - val_loss: 0.2720 - val_acc: 0.9036\n",
      "Epoch 146/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3615 - acc: 0.8397 - val_loss: 0.2739 - val_acc: 0.9060\n",
      "Epoch 147/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3615 - acc: 0.8389 - val_loss: 0.2724 - val_acc: 0.9084\n",
      "Epoch 148/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3621 - acc: 0.8400 - val_loss: 0.2746 - val_acc: 0.9012\n",
      "Epoch 149/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3616 - acc: 0.8411 - val_loss: 0.2744 - val_acc: 0.9012\n",
      "Epoch 150/600\n",
      "3731/3731 [==============================] - 0s 62us/step - loss: 0.3614 - acc: 0.8392 - val_loss: 0.2727 - val_acc: 0.9084\n",
      "Epoch 151/600\n",
      "3731/3731 [==============================] - 0s 66us/step - loss: 0.3617 - acc: 0.8403 - val_loss: 0.2741 - val_acc: 0.9060\n",
      "Epoch 152/600\n",
      "3731/3731 [==============================] - 0s 71us/step - loss: 0.3614 - acc: 0.8411 - val_loss: 0.2728 - val_acc: 0.9084\n",
      "Epoch 153/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3609 - acc: 0.8400 - val_loss: 0.2739 - val_acc: 0.9036\n",
      "Epoch 154/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3612 - acc: 0.8386 - val_loss: 0.2724 - val_acc: 0.9084\n",
      "Epoch 155/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3609 - acc: 0.8395 - val_loss: 0.2738 - val_acc: 0.9060\n",
      "Epoch 156/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3610 - acc: 0.8397 - val_loss: 0.2727 - val_acc: 0.9060\n",
      "Epoch 157/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3611 - acc: 0.8378 - val_loss: 0.2736 - val_acc: 0.9036\n",
      "Epoch 158/600\n",
      "3731/3731 [==============================] - 0s 61us/step - loss: 0.3606 - acc: 0.8395 - val_loss: 0.2730 - val_acc: 0.9036\n",
      "Epoch 159/600\n",
      "3731/3731 [==============================] - 0s 56us/step - loss: 0.3611 - acc: 0.8411 - val_loss: 0.2721 - val_acc: 0.9133\n",
      "Epoch 160/600\n",
      "3731/3731 [==============================] - 0s 60us/step - loss: 0.3607 - acc: 0.8405 - val_loss: 0.2718 - val_acc: 0.9084\n",
      "Epoch 161/600\n",
      "3731/3731 [==============================] - 0s 64us/step - loss: 0.3607 - acc: 0.8411 - val_loss: 0.2734 - val_acc: 0.9084\n",
      "Epoch 162/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3609 - acc: 0.8400 - val_loss: 0.2732 - val_acc: 0.9060\n",
      "Epoch 163/600\n",
      "3731/3731 [==============================] - 0s 59us/step - loss: 0.3604 - acc: 0.8403 - val_loss: 0.2736 - val_acc: 0.9084\n",
      "Epoch 164/600\n",
      "3731/3731 [==============================] - 0s 58us/step - loss: 0.3612 - acc: 0.8403 - val_loss: 0.2723 - val_acc: 0.9060\n",
      "Epoch 165/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3605 - acc: 0.8405 - val_loss: 0.2736 - val_acc: 0.9060\n",
      "Epoch 166/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3607 - acc: 0.8405 - val_loss: 0.2744 - val_acc: 0.9060\n",
      "Epoch 167/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3604 - acc: 0.8389 - val_loss: 0.2737 - val_acc: 0.9012\n",
      "Epoch 168/600\n",
      "3731/3731 [==============================] - ETA: 0s - loss: 0.3657 - acc: 0.838 - 0s 53us/step - loss: 0.3598 - acc: 0.8416 - val_loss: 0.2741 - val_acc: 0.9084\n",
      "Epoch 169/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3605 - acc: 0.8392 - val_loss: 0.2731 - val_acc: 0.9036\n",
      "Epoch 170/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3607 - acc: 0.8408 - val_loss: 0.2742 - val_acc: 0.9060\n",
      "Epoch 171/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3601 - acc: 0.8413 - val_loss: 0.2752 - val_acc: 0.9036\n",
      "Epoch 172/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3604 - acc: 0.8397 - val_loss: 0.2733 - val_acc: 0.9060\n",
      "Epoch 173/600\n",
      "3731/3731 [==============================] - 0s 61us/step - loss: 0.3598 - acc: 0.8386 - val_loss: 0.2732 - val_acc: 0.9060\n",
      "Epoch 174/600\n",
      "3731/3731 [==============================] - 0s 68us/step - loss: 0.3594 - acc: 0.8386 - val_loss: 0.2729 - val_acc: 0.9060\n",
      "Epoch 175/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3594 - acc: 0.8413 - val_loss: 0.2756 - val_acc: 0.9060\n",
      "Epoch 176/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3598 - acc: 0.8397 - val_loss: 0.2746 - val_acc: 0.9012\n",
      "Epoch 177/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3595 - acc: 0.8413 - val_loss: 0.2740 - val_acc: 0.9036\n",
      "Epoch 178/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3593 - acc: 0.8397 - val_loss: 0.2736 - val_acc: 0.9060\n",
      "Epoch 179/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3731/3731 [==============================] - ETA: 0s - loss: 0.3607 - acc: 0.841 - 0s 53us/step - loss: 0.3597 - acc: 0.8405 - val_loss: 0.2745 - val_acc: 0.9060\n",
      "Epoch 180/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3594 - acc: 0.8395 - val_loss: 0.2752 - val_acc: 0.9060\n",
      "Epoch 181/600\n",
      "3731/3731 [==============================] - 0s 62us/step - loss: 0.3594 - acc: 0.8384 - val_loss: 0.2751 - val_acc: 0.9036\n",
      "Epoch 182/600\n",
      "3731/3731 [==============================] - 0s 58us/step - loss: 0.3595 - acc: 0.8405 - val_loss: 0.2739 - val_acc: 0.9060\n",
      "Epoch 183/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3594 - acc: 0.8378 - val_loss: 0.2774 - val_acc: 0.8964\n",
      "Epoch 184/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3591 - acc: 0.8395 - val_loss: 0.2757 - val_acc: 0.9012\n",
      "Epoch 185/600\n",
      "3731/3731 [==============================] - 0s 60us/step - loss: 0.3595 - acc: 0.8389 - val_loss: 0.2769 - val_acc: 0.8988\n",
      "Epoch 186/600\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3596 - acc: 0.8400 - val_loss: 0.2759 - val_acc: 0.9012\n",
      "Epoch 187/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3590 - acc: 0.8413 - val_loss: 0.2754 - val_acc: 0.9036\n",
      "Epoch 188/600\n",
      "3731/3731 [==============================] - 0s 65us/step - loss: 0.3588 - acc: 0.8411 - val_loss: 0.2762 - val_acc: 0.9012\n",
      "Epoch 189/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3592 - acc: 0.8419 - val_loss: 0.2753 - val_acc: 0.9084\n",
      "Epoch 190/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3590 - acc: 0.8395 - val_loss: 0.2767 - val_acc: 0.8988\n",
      "Epoch 191/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3586 - acc: 0.8384 - val_loss: 0.2770 - val_acc: 0.9036\n",
      "Epoch 192/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3592 - acc: 0.8376 - val_loss: 0.2780 - val_acc: 0.8988\n",
      "Epoch 193/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3593 - acc: 0.8424 - val_loss: 0.2779 - val_acc: 0.9012\n",
      "Epoch 194/600\n",
      "3731/3731 [==============================] - 0s 65us/step - loss: 0.3592 - acc: 0.8384 - val_loss: 0.2758 - val_acc: 0.9036\n",
      "Epoch 195/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3583 - acc: 0.8389 - val_loss: 0.2785 - val_acc: 0.8988\n",
      "Epoch 196/600\n",
      "3731/3731 [==============================] - 0s 68us/step - loss: 0.3592 - acc: 0.8381 - val_loss: 0.2767 - val_acc: 0.8988\n",
      "Epoch 197/600\n",
      "3731/3731 [==============================] - 0s 56us/step - loss: 0.3586 - acc: 0.8419 - val_loss: 0.2777 - val_acc: 0.9036\n",
      "Epoch 198/600\n",
      "3731/3731 [==============================] - 0s 67us/step - loss: 0.3588 - acc: 0.8397 - val_loss: 0.2768 - val_acc: 0.9060\n",
      "Epoch 199/600\n",
      "3731/3731 [==============================] - 0s 58us/step - loss: 0.3585 - acc: 0.8386 - val_loss: 0.2763 - val_acc: 0.9036\n",
      "Epoch 200/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3580 - acc: 0.8421 - val_loss: 0.2781 - val_acc: 0.9036\n",
      "Epoch 201/600\n",
      "3731/3731 [==============================] - ETA: 0s - loss: 0.3529 - acc: 0.838 - 0s 53us/step - loss: 0.3585 - acc: 0.8376 - val_loss: 0.2763 - val_acc: 0.9036\n",
      "Epoch 202/600\n",
      "3731/3731 [==============================] - 0s 56us/step - loss: 0.3581 - acc: 0.8397 - val_loss: 0.2792 - val_acc: 0.8988\n",
      "Epoch 203/600\n",
      "3731/3731 [==============================] - 0s 63us/step - loss: 0.3583 - acc: 0.8405 - val_loss: 0.2781 - val_acc: 0.9036\n",
      "Epoch 204/600\n",
      "3731/3731 [==============================] - 0s 59us/step - loss: 0.3582 - acc: 0.8408 - val_loss: 0.2782 - val_acc: 0.9012\n",
      "Epoch 205/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3584 - acc: 0.8392 - val_loss: 0.2796 - val_acc: 0.9036\n",
      "Epoch 206/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3584 - acc: 0.8384 - val_loss: 0.2762 - val_acc: 0.9060\n",
      "Epoch 207/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3577 - acc: 0.8411 - val_loss: 0.2773 - val_acc: 0.9060\n",
      "Epoch 208/600\n",
      "3731/3731 [==============================] - 0s 69us/step - loss: 0.3581 - acc: 0.8386 - val_loss: 0.2780 - val_acc: 0.9036\n",
      "Epoch 209/600\n",
      "3731/3731 [==============================] - 0s 71us/step - loss: 0.3587 - acc: 0.8408 - val_loss: 0.2775 - val_acc: 0.9036\n",
      "Epoch 210/600\n",
      "3731/3731 [==============================] - 0s 70us/step - loss: 0.3580 - acc: 0.8432 - val_loss: 0.2766 - val_acc: 0.9060\n",
      "Epoch 211/600\n",
      "3731/3731 [==============================] - 0s 67us/step - loss: 0.3579 - acc: 0.8381 - val_loss: 0.2774 - val_acc: 0.9060\n",
      "Epoch 212/600\n",
      "3731/3731 [==============================] - 0s 63us/step - loss: 0.3581 - acc: 0.8400 - val_loss: 0.2767 - val_acc: 0.9060\n",
      "Epoch 213/600\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3576 - acc: 0.8403 - val_loss: 0.2767 - val_acc: 0.9012\n",
      "Epoch 214/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3578 - acc: 0.8405 - val_loss: 0.2786 - val_acc: 0.9036\n",
      "Epoch 215/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3574 - acc: 0.8376 - val_loss: 0.2782 - val_acc: 0.9060\n",
      "Epoch 216/600\n",
      "3731/3731 [==============================] - 0s 56us/step - loss: 0.3582 - acc: 0.8419 - val_loss: 0.2769 - val_acc: 0.9060\n",
      "Epoch 217/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3579 - acc: 0.8405 - val_loss: 0.2786 - val_acc: 0.9060\n",
      "Epoch 218/600\n",
      "3731/3731 [==============================] - 0s 60us/step - loss: 0.3579 - acc: 0.8397 - val_loss: 0.2772 - val_acc: 0.9060\n",
      "Epoch 219/600\n",
      "3731/3731 [==============================] - ETA: 0s - loss: 0.3584 - acc: 0.842 - 0s 53us/step - loss: 0.3577 - acc: 0.8421 - val_loss: 0.2766 - val_acc: 0.9060\n",
      "Epoch 220/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3576 - acc: 0.8395 - val_loss: 0.2768 - val_acc: 0.9060\n",
      "Epoch 221/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3578 - acc: 0.8395 - val_loss: 0.2767 - val_acc: 0.9036\n",
      "Epoch 222/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3582 - acc: 0.8360 - val_loss: 0.2787 - val_acc: 0.9036\n",
      "Epoch 223/600\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3581 - acc: 0.8400 - val_loss: 0.2771 - val_acc: 0.9060\n",
      "Epoch 224/600\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.3578 - acc: 0.8381 - val_loss: 0.2782 - val_acc: 0.8964\n",
      "Epoch 225/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3577 - acc: 0.8400 - val_loss: 0.2790 - val_acc: 0.9060\n",
      "Epoch 226/600\n",
      "3731/3731 [==============================] - 0s 62us/step - loss: 0.3573 - acc: 0.8389 - val_loss: 0.2774 - val_acc: 0.9036\n",
      "Epoch 227/600\n",
      "3731/3731 [==============================] - 0s 58us/step - loss: 0.3573 - acc: 0.8403 - val_loss: 0.2773 - val_acc: 0.9036\n",
      "Epoch 228/600\n",
      "3731/3731 [==============================] - 0s 62us/step - loss: 0.3576 - acc: 0.8424 - val_loss: 0.2781 - val_acc: 0.9060\n",
      "Epoch 229/600\n",
      "3731/3731 [==============================] - 0s 66us/step - loss: 0.3576 - acc: 0.8392 - val_loss: 0.2766 - val_acc: 0.9036\n",
      "Epoch 230/600\n",
      "3731/3731 [==============================] - 0s 56us/step - loss: 0.3576 - acc: 0.8378 - val_loss: 0.2768 - val_acc: 0.9036\n",
      "Epoch 231/600\n",
      "3731/3731 [==============================] - 0s 56us/step - loss: 0.3570 - acc: 0.8421 - val_loss: 0.2782 - val_acc: 0.9036\n",
      "Epoch 232/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3577 - acc: 0.8405 - val_loss: 0.2775 - val_acc: 0.9036\n",
      "Epoch 233/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3569 - acc: 0.8405 - val_loss: 0.2755 - val_acc: 0.9036\n",
      "Epoch 234/600\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3570 - acc: 0.8411 - val_loss: 0.2794 - val_acc: 0.9060\n",
      "Epoch 235/600\n",
      "3731/3731 [==============================] - 0s 58us/step - loss: 0.3573 - acc: 0.8392 - val_loss: 0.2779 - val_acc: 0.8988\n",
      "Epoch 236/600\n",
      "3731/3731 [==============================] - 0s 62us/step - loss: 0.3568 - acc: 0.8392 - val_loss: 0.2769 - val_acc: 0.8964\n",
      "Epoch 237/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3580 - acc: 0.8395 - val_loss: 0.2791 - val_acc: 0.9012\n",
      "Epoch 238/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3569 - acc: 0.8400 - val_loss: 0.2773 - val_acc: 0.9012\n",
      "Epoch 239/600\n",
      "3731/3731 [==============================] - 0s 65us/step - loss: 0.3573 - acc: 0.8405 - val_loss: 0.2774 - val_acc: 0.8988\n",
      "Epoch 240/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3569 - acc: 0.8424 - val_loss: 0.2777 - val_acc: 0.9012\n",
      "Epoch 241/600\n",
      "3731/3731 [==============================] - 0s 61us/step - loss: 0.3564 - acc: 0.8403 - val_loss: 0.2770 - val_acc: 0.8964\n",
      "Epoch 242/600\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3573 - acc: 0.8397 - val_loss: 0.2771 - val_acc: 0.8988\n",
      "Epoch 243/600\n",
      "3731/3731 [==============================] - 0s 61us/step - loss: 0.3571 - acc: 0.8416 - val_loss: 0.2768 - val_acc: 0.8988\n",
      "Epoch 244/600\n",
      "3731/3731 [==============================] - 0s 61us/step - loss: 0.3570 - acc: 0.8405 - val_loss: 0.2773 - val_acc: 0.8988\n",
      "Epoch 245/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3568 - acc: 0.8403 - val_loss: 0.2772 - val_acc: 0.9012\n",
      "Epoch 246/600\n",
      "3731/3731 [==============================] - 0s 59us/step - loss: 0.3564 - acc: 0.8408 - val_loss: 0.2780 - val_acc: 0.8988\n",
      "Epoch 247/600\n",
      "3731/3731 [==============================] - 0s 61us/step - loss: 0.3565 - acc: 0.8386 - val_loss: 0.2780 - val_acc: 0.9012\n",
      "Epoch 248/600\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3567 - acc: 0.8389 - val_loss: 0.2782 - val_acc: 0.9012\n",
      "Epoch 249/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3564 - acc: 0.8424 - val_loss: 0.2762 - val_acc: 0.8964\n",
      "Epoch 250/600\n",
      "3731/3731 [==============================] - 0s 61us/step - loss: 0.3569 - acc: 0.8395 - val_loss: 0.2764 - val_acc: 0.8964\n",
      "Epoch 251/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3566 - acc: 0.8408 - val_loss: 0.2774 - val_acc: 0.9012\n",
      "Epoch 252/600\n",
      "3731/3731 [==============================] - 0s 64us/step - loss: 0.3568 - acc: 0.8413 - val_loss: 0.2759 - val_acc: 0.9012\n",
      "Epoch 253/600\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3571 - acc: 0.8400 - val_loss: 0.2774 - val_acc: 0.8988\n",
      "Epoch 254/600\n",
      "3731/3731 [==============================] - 0s 65us/step - loss: 0.3564 - acc: 0.8403 - val_loss: 0.2777 - val_acc: 0.8964\n",
      "Epoch 255/600\n",
      "3731/3731 [==============================] - 0s 58us/step - loss: 0.3566 - acc: 0.8413 - val_loss: 0.2758 - val_acc: 0.8964\n",
      "Epoch 256/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3564 - acc: 0.8400 - val_loss: 0.2763 - val_acc: 0.8964\n",
      "Epoch 257/600\n",
      "3731/3731 [==============================] - 0s 61us/step - loss: 0.3563 - acc: 0.8408 - val_loss: 0.2771 - val_acc: 0.8940\n",
      "Epoch 258/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3562 - acc: 0.8413 - val_loss: 0.2758 - val_acc: 0.8988\n",
      "Epoch 259/600\n",
      "3731/3731 [==============================] - 0s 64us/step - loss: 0.3567 - acc: 0.8416 - val_loss: 0.2764 - val_acc: 0.8940\n",
      "Epoch 260/600\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3561 - acc: 0.8386 - val_loss: 0.2764 - val_acc: 0.8940\n",
      "Epoch 261/600\n",
      "3731/3731 [==============================] - 0s 56us/step - loss: 0.3563 - acc: 0.8384 - val_loss: 0.2768 - val_acc: 0.8940\n",
      "Epoch 262/600\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.3564 - acc: 0.8397 - val_loss: 0.2764 - val_acc: 0.8916\n",
      "Epoch 263/600\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3561 - acc: 0.8381 - val_loss: 0.2764 - val_acc: 0.8964\n",
      "Epoch 264/600\n",
      "3731/3731 [==============================] - 0s 60us/step - loss: 0.3560 - acc: 0.8392 - val_loss: 0.2758 - val_acc: 0.8916\n",
      "Epoch 265/600\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3557 - acc: 0.8416 - val_loss: 0.2769 - val_acc: 0.8940\n",
      "Epoch 266/600\n",
      "3731/3731 [==============================] - 0s 60us/step - loss: 0.3561 - acc: 0.8400 - val_loss: 0.2772 - val_acc: 0.8940\n",
      "Epoch 267/600\n",
      "3731/3731 [==============================] - 0s 62us/step - loss: 0.3558 - acc: 0.8413 - val_loss: 0.2764 - val_acc: 0.8940\n",
      "Epoch 268/600\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3559 - acc: 0.8395 - val_loss: 0.2761 - val_acc: 0.8988\n",
      "Epoch 269/600\n",
      "3731/3731 [==============================] - 0s 60us/step - loss: 0.3558 - acc: 0.8403 - val_loss: 0.2774 - val_acc: 0.8964\n",
      "Epoch 270/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3570 - acc: 0.8397 - val_loss: 0.2766 - val_acc: 0.8964\n",
      "Epoch 271/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3557 - acc: 0.8403 - val_loss: 0.2756 - val_acc: 0.8964\n",
      "Epoch 272/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3556 - acc: 0.8403 - val_loss: 0.2743 - val_acc: 0.8940\n",
      "Epoch 273/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3558 - acc: 0.8405 - val_loss: 0.2750 - val_acc: 0.8892\n",
      "Epoch 274/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3555 - acc: 0.8389 - val_loss: 0.2744 - val_acc: 0.8940\n",
      "Epoch 275/600\n",
      "3731/3731 [==============================] - 0s 60us/step - loss: 0.3556 - acc: 0.8395 - val_loss: 0.2752 - val_acc: 0.8892\n",
      "Epoch 276/600\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3561 - acc: 0.8411 - val_loss: 0.2759 - val_acc: 0.8964\n",
      "Epoch 277/600\n",
      "3731/3731 [==============================] - 0s 60us/step - loss: 0.3557 - acc: 0.8411 - val_loss: 0.2772 - val_acc: 0.8940\n",
      "Epoch 278/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3556 - acc: 0.8389 - val_loss: 0.2757 - val_acc: 0.8916\n",
      "Epoch 279/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3548 - acc: 0.8403 - val_loss: 0.2750 - val_acc: 0.8892\n",
      "Epoch 280/600\n",
      "3731/3731 [==============================] - 0s 58us/step - loss: 0.3559 - acc: 0.8424 - val_loss: 0.2761 - val_acc: 0.8964\n",
      "Epoch 281/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3554 - acc: 0.8397 - val_loss: 0.2772 - val_acc: 0.8916\n",
      "Epoch 282/600\n",
      "3731/3731 [==============================] - 0s 62us/step - loss: 0.3553 - acc: 0.8395 - val_loss: 0.2764 - val_acc: 0.8988\n",
      "Epoch 283/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3554 - acc: 0.8429 - val_loss: 0.2757 - val_acc: 0.8916\n",
      "Epoch 284/600\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3551 - acc: 0.8408 - val_loss: 0.2762 - val_acc: 0.8940\n",
      "Epoch 285/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3552 - acc: 0.8408 - val_loss: 0.2752 - val_acc: 0.8916\n",
      "Epoch 286/600\n",
      "3731/3731 [==============================] - 0s 58us/step - loss: 0.3556 - acc: 0.8389 - val_loss: 0.2753 - val_acc: 0.8916\n",
      "Epoch 287/600\n",
      "3731/3731 [==============================] - 0s 59us/step - loss: 0.3546 - acc: 0.8421 - val_loss: 0.2759 - val_acc: 0.8916\n",
      "Epoch 288/600\n",
      "3731/3731 [==============================] - 0s 56us/step - loss: 0.3552 - acc: 0.8403 - val_loss: 0.2756 - val_acc: 0.8940\n",
      "Epoch 289/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3549 - acc: 0.8424 - val_loss: 0.2766 - val_acc: 0.8916\n",
      "Epoch 290/600\n",
      "3731/3731 [==============================] - ETA: 0s - loss: 0.3582 - acc: 0.843 - 0s 53us/step - loss: 0.3547 - acc: 0.8437 - val_loss: 0.2771 - val_acc: 0.8988\n",
      "Epoch 291/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3550 - acc: 0.8416 - val_loss: 0.2768 - val_acc: 0.8940\n",
      "Epoch 292/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3550 - acc: 0.8429 - val_loss: 0.2768 - val_acc: 0.8916\n",
      "Epoch 293/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3548 - acc: 0.8395 - val_loss: 0.2756 - val_acc: 0.8916\n",
      "Epoch 294/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3547 - acc: 0.8408 - val_loss: 0.2766 - val_acc: 0.8916\n",
      "Epoch 295/600\n",
      "3731/3731 [==============================] - 0s 64us/step - loss: 0.3541 - acc: 0.8424 - val_loss: 0.2766 - val_acc: 0.8940\n",
      "Epoch 296/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3555 - acc: 0.8424 - val_loss: 0.2746 - val_acc: 0.8940\n",
      "Epoch 297/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3547 - acc: 0.8419 - val_loss: 0.2759 - val_acc: 0.8940\n",
      "Epoch 298/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3546 - acc: 0.8453 - val_loss: 0.2760 - val_acc: 0.8940\n",
      "Epoch 299/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3546 - acc: 0.8462 - val_loss: 0.2742 - val_acc: 0.8964\n",
      "Epoch 300/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3549 - acc: 0.8427 - val_loss: 0.2760 - val_acc: 0.8916\n",
      "Epoch 301/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3545 - acc: 0.8443 - val_loss: 0.2764 - val_acc: 0.8940\n",
      "Epoch 302/600\n",
      "3731/3731 [==============================] - 0s 63us/step - loss: 0.3551 - acc: 0.8403 - val_loss: 0.2758 - val_acc: 0.8916\n",
      "Epoch 303/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3547 - acc: 0.8429 - val_loss: 0.2753 - val_acc: 0.8940\n",
      "Epoch 304/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3540 - acc: 0.8416 - val_loss: 0.2764 - val_acc: 0.8940\n",
      "Epoch 305/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3539 - acc: 0.8392 - val_loss: 0.2748 - val_acc: 0.8964\n",
      "Epoch 306/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3539 - acc: 0.8424 - val_loss: 0.2755 - val_acc: 0.8940\n",
      "Epoch 307/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3544 - acc: 0.8421 - val_loss: 0.2755 - val_acc: 0.8940\n",
      "Epoch 308/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3543 - acc: 0.8411 - val_loss: 0.2757 - val_acc: 0.8940\n",
      "Epoch 309/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3549 - acc: 0.8429 - val_loss: 0.2744 - val_acc: 0.8964\n",
      "Epoch 310/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3541 - acc: 0.8416 - val_loss: 0.2747 - val_acc: 0.8940\n",
      "Epoch 311/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3543 - acc: 0.8408 - val_loss: 0.2754 - val_acc: 0.8892\n",
      "Epoch 312/600\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.3541 - acc: 0.8437 - val_loss: 0.2768 - val_acc: 0.8916\n",
      "Epoch 313/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3540 - acc: 0.8411 - val_loss: 0.2768 - val_acc: 0.8892\n",
      "Epoch 314/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3544 - acc: 0.8429 - val_loss: 0.2751 - val_acc: 0.8916\n",
      "Epoch 315/600\n",
      "3731/3731 [==============================] - 0s 60us/step - loss: 0.3546 - acc: 0.8411 - val_loss: 0.2746 - val_acc: 0.8916\n",
      "Epoch 316/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3539 - acc: 0.8424 - val_loss: 0.2771 - val_acc: 0.8916\n",
      "Epoch 317/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3539 - acc: 0.8405 - val_loss: 0.2756 - val_acc: 0.8940\n",
      "Epoch 318/600\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3540 - acc: 0.8427 - val_loss: 0.2771 - val_acc: 0.8940\n",
      "Epoch 319/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3538 - acc: 0.8411 - val_loss: 0.2762 - val_acc: 0.8940\n",
      "Epoch 320/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3535 - acc: 0.8411 - val_loss: 0.2760 - val_acc: 0.8940\n",
      "Epoch 321/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3542 - acc: 0.8421 - val_loss: 0.2770 - val_acc: 0.8940\n",
      "Epoch 322/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3535 - acc: 0.8419 - val_loss: 0.2769 - val_acc: 0.8964\n",
      "Epoch 323/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3541 - acc: 0.8411 - val_loss: 0.2752 - val_acc: 0.8964\n",
      "Epoch 324/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3543 - acc: 0.8440 - val_loss: 0.2765 - val_acc: 0.8940\n",
      "Epoch 325/600\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.3532 - acc: 0.8421 - val_loss: 0.2763 - val_acc: 0.8940\n",
      "Epoch 326/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3535 - acc: 0.8421 - val_loss: 0.2773 - val_acc: 0.8940\n",
      "Epoch 327/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3536 - acc: 0.8424 - val_loss: 0.2766 - val_acc: 0.8940\n",
      "Epoch 328/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3539 - acc: 0.8411 - val_loss: 0.2766 - val_acc: 0.8940\n",
      "Epoch 329/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3539 - acc: 0.8411 - val_loss: 0.2768 - val_acc: 0.8940\n",
      "Epoch 330/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3536 - acc: 0.8405 - val_loss: 0.2763 - val_acc: 0.8916\n",
      "Epoch 331/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3531 - acc: 0.8427 - val_loss: 0.2768 - val_acc: 0.8916\n",
      "Epoch 332/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3538 - acc: 0.8427 - val_loss: 0.2770 - val_acc: 0.8916\n",
      "Epoch 333/600\n",
      "3731/3731 [==============================] - ETA: 0s - loss: 0.3537 - acc: 0.843 - 0s 53us/step - loss: 0.3534 - acc: 0.8429 - val_loss: 0.2783 - val_acc: 0.8940\n",
      "Epoch 334/600\n",
      "3731/3731 [==============================] - ETA: 0s - loss: 0.3523 - acc: 0.839 - 0s 53us/step - loss: 0.3534 - acc: 0.8424 - val_loss: 0.2779 - val_acc: 0.8964\n",
      "Epoch 335/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3535 - acc: 0.8432 - val_loss: 0.2768 - val_acc: 0.8964\n",
      "Epoch 336/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3533 - acc: 0.8432 - val_loss: 0.2760 - val_acc: 0.8916\n",
      "Epoch 337/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3529 - acc: 0.8419 - val_loss: 0.2756 - val_acc: 0.8940\n",
      "Epoch 338/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3534 - acc: 0.8429 - val_loss: 0.2756 - val_acc: 0.8940\n",
      "Epoch 339/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3531 - acc: 0.8451 - val_loss: 0.2760 - val_acc: 0.8940\n",
      "Epoch 340/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3530 - acc: 0.8435 - val_loss: 0.2772 - val_acc: 0.8916\n",
      "Epoch 341/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3532 - acc: 0.8389 - val_loss: 0.2784 - val_acc: 0.8964\n",
      "Epoch 342/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3532 - acc: 0.8427 - val_loss: 0.2769 - val_acc: 0.8940\n",
      "Epoch 343/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3532 - acc: 0.8435 - val_loss: 0.2772 - val_acc: 0.8940\n",
      "Epoch 344/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3533 - acc: 0.8411 - val_loss: 0.2778 - val_acc: 0.8964\n",
      "Epoch 345/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3532 - acc: 0.8427 - val_loss: 0.2775 - val_acc: 0.8964\n",
      "Epoch 346/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3528 - acc: 0.8427 - val_loss: 0.2767 - val_acc: 0.8964\n",
      "Epoch 347/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3527 - acc: 0.8413 - val_loss: 0.2768 - val_acc: 0.8940\n",
      "Epoch 348/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3524 - acc: 0.8432 - val_loss: 0.2768 - val_acc: 0.8964\n",
      "Epoch 349/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3531 - acc: 0.8445 - val_loss: 0.2766 - val_acc: 0.8940\n",
      "Epoch 350/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3528 - acc: 0.8427 - val_loss: 0.2763 - val_acc: 0.8940\n",
      "Epoch 351/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3529 - acc: 0.8432 - val_loss: 0.2768 - val_acc: 0.8940\n",
      "Epoch 352/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3528 - acc: 0.8424 - val_loss: 0.2766 - val_acc: 0.8964\n",
      "Epoch 353/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3525 - acc: 0.8405 - val_loss: 0.2768 - val_acc: 0.8964\n",
      "Epoch 354/600\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3521 - acc: 0.8440 - val_loss: 0.2775 - val_acc: 0.8964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 355/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3533 - acc: 0.8421 - val_loss: 0.2769 - val_acc: 0.8964\n",
      "Epoch 356/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3524 - acc: 0.8435 - val_loss: 0.2770 - val_acc: 0.8964\n",
      "Epoch 357/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3530 - acc: 0.8437 - val_loss: 0.2770 - val_acc: 0.8964\n",
      "Epoch 358/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3522 - acc: 0.8419 - val_loss: 0.2765 - val_acc: 0.8940\n",
      "Epoch 359/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3533 - acc: 0.8427 - val_loss: 0.2768 - val_acc: 0.8940\n",
      "Epoch 360/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3524 - acc: 0.8413 - val_loss: 0.2762 - val_acc: 0.8964\n",
      "Epoch 361/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3525 - acc: 0.8411 - val_loss: 0.2773 - val_acc: 0.8964\n",
      "Epoch 362/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3528 - acc: 0.8403 - val_loss: 0.2766 - val_acc: 0.8964\n",
      "Epoch 363/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3527 - acc: 0.8445 - val_loss: 0.2778 - val_acc: 0.8964\n",
      "Epoch 364/600\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3522 - acc: 0.8448 - val_loss: 0.2770 - val_acc: 0.8964\n",
      "Epoch 365/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3524 - acc: 0.8451 - val_loss: 0.2775 - val_acc: 0.8964\n",
      "Epoch 366/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3517 - acc: 0.8411 - val_loss: 0.2779 - val_acc: 0.8964\n",
      "Epoch 367/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3523 - acc: 0.8432 - val_loss: 0.2791 - val_acc: 0.8940\n",
      "Epoch 368/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3516 - acc: 0.8395 - val_loss: 0.2781 - val_acc: 0.8964\n",
      "Epoch 369/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3519 - acc: 0.8435 - val_loss: 0.2783 - val_acc: 0.8940\n",
      "Epoch 370/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3518 - acc: 0.8432 - val_loss: 0.2780 - val_acc: 0.8964\n",
      "Epoch 371/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3521 - acc: 0.8429 - val_loss: 0.2783 - val_acc: 0.8964\n",
      "Epoch 372/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3522 - acc: 0.8443 - val_loss: 0.2777 - val_acc: 0.8940\n",
      "Epoch 373/600\n",
      "3731/3731 [==============================] - 0s 59us/step - loss: 0.3520 - acc: 0.8432 - val_loss: 0.2785 - val_acc: 0.8940\n",
      "Epoch 374/600\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3516 - acc: 0.8421 - val_loss: 0.2795 - val_acc: 0.8940\n",
      "Epoch 375/600\n",
      "3731/3731 [==============================] - 0s 69us/step - loss: 0.3520 - acc: 0.8413 - val_loss: 0.2783 - val_acc: 0.8940\n",
      "Epoch 376/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3521 - acc: 0.8440 - val_loss: 0.2792 - val_acc: 0.8940\n",
      "Epoch 377/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3517 - acc: 0.8427 - val_loss: 0.2790 - val_acc: 0.8964\n",
      "Epoch 378/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3517 - acc: 0.8432 - val_loss: 0.2782 - val_acc: 0.8940\n",
      "Epoch 379/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3517 - acc: 0.8419 - val_loss: 0.2777 - val_acc: 0.8940\n",
      "Epoch 380/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3517 - acc: 0.8445 - val_loss: 0.2781 - val_acc: 0.8964\n",
      "Epoch 381/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3516 - acc: 0.8437 - val_loss: 0.2782 - val_acc: 0.8964\n",
      "Epoch 382/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3516 - acc: 0.8451 - val_loss: 0.2763 - val_acc: 0.8940\n",
      "Epoch 383/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3519 - acc: 0.8453 - val_loss: 0.2783 - val_acc: 0.8964\n",
      "Epoch 384/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3519 - acc: 0.8437 - val_loss: 0.2763 - val_acc: 0.8964\n",
      "Epoch 385/600\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3519 - acc: 0.8424 - val_loss: 0.2775 - val_acc: 0.8964\n",
      "Epoch 386/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3513 - acc: 0.8421 - val_loss: 0.2759 - val_acc: 0.8964\n",
      "Epoch 387/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3519 - acc: 0.8456 - val_loss: 0.2754 - val_acc: 0.8988\n",
      "Epoch 388/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3516 - acc: 0.8432 - val_loss: 0.2759 - val_acc: 0.8988\n",
      "Epoch 389/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3506 - acc: 0.8464 - val_loss: 0.2762 - val_acc: 0.8988\n",
      "Epoch 390/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3519 - acc: 0.8419 - val_loss: 0.2762 - val_acc: 0.8988\n",
      "Epoch 391/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3518 - acc: 0.8448 - val_loss: 0.2756 - val_acc: 0.8940\n",
      "Epoch 392/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3506 - acc: 0.8416 - val_loss: 0.2773 - val_acc: 0.8940\n",
      "Epoch 393/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3514 - acc: 0.8445 - val_loss: 0.2768 - val_acc: 0.8940\n",
      "Epoch 394/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3509 - acc: 0.8451 - val_loss: 0.2754 - val_acc: 0.8988\n",
      "Epoch 395/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3516 - acc: 0.8443 - val_loss: 0.2759 - val_acc: 0.8940\n",
      "Epoch 396/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3509 - acc: 0.8432 - val_loss: 0.2753 - val_acc: 0.8940\n",
      "Epoch 397/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3509 - acc: 0.8443 - val_loss: 0.2759 - val_acc: 0.8940\n",
      "Epoch 398/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3507 - acc: 0.8464 - val_loss: 0.2762 - val_acc: 0.8940\n",
      "Epoch 399/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3507 - acc: 0.8424 - val_loss: 0.2755 - val_acc: 0.8988\n",
      "Epoch 400/600\n",
      "3731/3731 [==============================] - 0s 62us/step - loss: 0.3510 - acc: 0.8429 - val_loss: 0.2740 - val_acc: 0.8988\n",
      "Epoch 401/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3507 - acc: 0.8443 - val_loss: 0.2769 - val_acc: 0.8940\n",
      "Epoch 402/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3507 - acc: 0.8464 - val_loss: 0.2756 - val_acc: 0.9012\n",
      "Epoch 403/600\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3506 - acc: 0.8459 - val_loss: 0.2771 - val_acc: 0.8940\n",
      "Epoch 404/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3514 - acc: 0.8451 - val_loss: 0.2751 - val_acc: 0.8988\n",
      "Epoch 405/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3503 - acc: 0.8443 - val_loss: 0.2748 - val_acc: 0.8940\n",
      "Epoch 406/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3521 - acc: 0.8456 - val_loss: 0.2753 - val_acc: 0.8964\n",
      "Epoch 407/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3504 - acc: 0.8472 - val_loss: 0.2727 - val_acc: 0.8964\n",
      "Epoch 408/600\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.3506 - acc: 0.8445 - val_loss: 0.2727 - val_acc: 0.8988\n",
      "Epoch 409/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3504 - acc: 0.8443 - val_loss: 0.2734 - val_acc: 0.8964\n",
      "Epoch 410/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3508 - acc: 0.8453 - val_loss: 0.2733 - val_acc: 0.8988\n",
      "Epoch 411/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3509 - acc: 0.8424 - val_loss: 0.2736 - val_acc: 0.8964\n",
      "Epoch 412/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3506 - acc: 0.8437 - val_loss: 0.2730 - val_acc: 0.8988\n",
      "Epoch 413/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3510 - acc: 0.8432 - val_loss: 0.2742 - val_acc: 0.8964\n",
      "Epoch 414/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3510 - acc: 0.8421 - val_loss: 0.2732 - val_acc: 0.8988\n",
      "Epoch 415/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3498 - acc: 0.8435 - val_loss: 0.2728 - val_acc: 0.9036\n",
      "Epoch 416/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3510 - acc: 0.8453 - val_loss: 0.2726 - val_acc: 0.8964\n",
      "Epoch 417/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3502 - acc: 0.8445 - val_loss: 0.2715 - val_acc: 0.8988\n",
      "Epoch 418/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3506 - acc: 0.8448 - val_loss: 0.2723 - val_acc: 0.8940\n",
      "Epoch 419/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3500 - acc: 0.8459 - val_loss: 0.2722 - val_acc: 0.9012\n",
      "Epoch 420/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3510 - acc: 0.8470 - val_loss: 0.2717 - val_acc: 0.8988\n",
      "Epoch 421/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3503 - acc: 0.8424 - val_loss: 0.2713 - val_acc: 0.8988\n",
      "Epoch 422/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3502 - acc: 0.8464 - val_loss: 0.2709 - val_acc: 0.8964\n",
      "Epoch 423/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3506 - acc: 0.8421 - val_loss: 0.2688 - val_acc: 0.8988\n",
      "Epoch 424/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3497 - acc: 0.8456 - val_loss: 0.2697 - val_acc: 0.8964\n",
      "Epoch 425/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3501 - acc: 0.8451 - val_loss: 0.2692 - val_acc: 0.8964\n",
      "Epoch 426/600\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3499 - acc: 0.8464 - val_loss: 0.2682 - val_acc: 0.8988\n",
      "Epoch 427/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3508 - acc: 0.8413 - val_loss: 0.2684 - val_acc: 0.9012\n",
      "Epoch 428/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3493 - acc: 0.8467 - val_loss: 0.2677 - val_acc: 0.9012\n",
      "Epoch 429/600\n",
      "3731/3731 [==============================] - 0s 68us/step - loss: 0.3496 - acc: 0.8448 - val_loss: 0.2676 - val_acc: 0.8988\n",
      "Epoch 430/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3500 - acc: 0.8462 - val_loss: 0.2673 - val_acc: 0.9012\n",
      "Epoch 431/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3487 - acc: 0.8462 - val_loss: 0.2682 - val_acc: 0.8988\n",
      "Epoch 432/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3489 - acc: 0.8445 - val_loss: 0.2660 - val_acc: 0.9060\n",
      "Epoch 433/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3486 - acc: 0.8464 - val_loss: 0.2653 - val_acc: 0.9012\n",
      "Epoch 434/600\n",
      "3731/3731 [==============================] - 0s 64us/step - loss: 0.3488 - acc: 0.8448 - val_loss: 0.2660 - val_acc: 0.9060\n",
      "Epoch 435/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3494 - acc: 0.8456 - val_loss: 0.2670 - val_acc: 0.9036\n",
      "Epoch 436/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3489 - acc: 0.8445 - val_loss: 0.2649 - val_acc: 0.9060\n",
      "Epoch 437/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3489 - acc: 0.8459 - val_loss: 0.2644 - val_acc: 0.9036\n",
      "Epoch 438/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3495 - acc: 0.8448 - val_loss: 0.2652 - val_acc: 0.9012\n",
      "Epoch 439/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3488 - acc: 0.8459 - val_loss: 0.2646 - val_acc: 0.9012\n",
      "Epoch 440/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3495 - acc: 0.8456 - val_loss: 0.2645 - val_acc: 0.9012\n",
      "Epoch 441/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3484 - acc: 0.8464 - val_loss: 0.2647 - val_acc: 0.9036\n",
      "Epoch 442/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3485 - acc: 0.8483 - val_loss: 0.2652 - val_acc: 0.9036\n",
      "Epoch 443/600\n",
      "3731/3731 [==============================] - ETA: 0s - loss: 0.3393 - acc: 0.847 - 0s 54us/step - loss: 0.3494 - acc: 0.8440 - val_loss: 0.2648 - val_acc: 0.9060\n",
      "Epoch 444/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3487 - acc: 0.8456 - val_loss: 0.2641 - val_acc: 0.9036\n",
      "Epoch 445/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3487 - acc: 0.8445 - val_loss: 0.2640 - val_acc: 0.9036\n",
      "Epoch 446/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3482 - acc: 0.8480 - val_loss: 0.2637 - val_acc: 0.9036\n",
      "Epoch 447/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3482 - acc: 0.8470 - val_loss: 0.2640 - val_acc: 0.9060\n",
      "Epoch 448/600\n",
      "3731/3731 [==============================] - 0s 68us/step - loss: 0.3482 - acc: 0.8462 - val_loss: 0.2649 - val_acc: 0.9012\n",
      "Epoch 449/600\n",
      "3731/3731 [==============================] - 0s 44us/step - loss: 0.3484 - acc: 0.8453 - val_loss: 0.2657 - val_acc: 0.9012\n",
      "Epoch 450/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3481 - acc: 0.8462 - val_loss: 0.2644 - val_acc: 0.9060\n",
      "Epoch 451/600\n",
      "3731/3731 [==============================] - 0s 70us/step - loss: 0.3481 - acc: 0.8464 - val_loss: 0.2646 - val_acc: 0.9012\n",
      "Epoch 452/600\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3474 - acc: 0.8462 - val_loss: 0.2654 - val_acc: 0.8988\n",
      "Epoch 453/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3482 - acc: 0.8472 - val_loss: 0.2632 - val_acc: 0.9012\n",
      "Epoch 454/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3480 - acc: 0.8453 - val_loss: 0.2653 - val_acc: 0.9012\n",
      "Epoch 455/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3481 - acc: 0.8443 - val_loss: 0.2632 - val_acc: 0.9036\n",
      "Epoch 456/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3479 - acc: 0.8483 - val_loss: 0.2643 - val_acc: 0.9060\n",
      "Epoch 457/600\n",
      "3731/3731 [==============================] - 0s 56us/step - loss: 0.3488 - acc: 0.8451 - val_loss: 0.2643 - val_acc: 0.9036\n",
      "Epoch 458/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3485 - acc: 0.8470 - val_loss: 0.2639 - val_acc: 0.9036\n",
      "Epoch 459/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3480 - acc: 0.8462 - val_loss: 0.2644 - val_acc: 0.9036\n",
      "Epoch 460/600\n",
      "3731/3731 [==============================] - 0s 59us/step - loss: 0.3475 - acc: 0.8467 - val_loss: 0.2656 - val_acc: 0.9012\n",
      "Epoch 461/600\n",
      "3731/3731 [==============================] - 0s 65us/step - loss: 0.3475 - acc: 0.8472 - val_loss: 0.2647 - val_acc: 0.9012\n",
      "Epoch 462/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3474 - acc: 0.8429 - val_loss: 0.2647 - val_acc: 0.9012\n",
      "Epoch 463/600\n",
      "3731/3731 [==============================] - 0s 93us/step - loss: 0.3473 - acc: 0.8464 - val_loss: 0.2643 - val_acc: 0.9060\n",
      "Epoch 464/600\n",
      "3731/3731 [==============================] - 0s 60us/step - loss: 0.3476 - acc: 0.8475 - val_loss: 0.2630 - val_acc: 0.9060\n",
      "Epoch 465/600\n",
      "3731/3731 [==============================] - 0s 61us/step - loss: 0.3471 - acc: 0.8488 - val_loss: 0.2640 - val_acc: 0.9036\n",
      "Epoch 466/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3469 - acc: 0.8464 - val_loss: 0.2659 - val_acc: 0.9036\n",
      "Epoch 467/600\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.3476 - acc: 0.8470 - val_loss: 0.2645 - val_acc: 0.9012\n",
      "Epoch 468/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3471 - acc: 0.8459 - val_loss: 0.2650 - val_acc: 0.8940\n",
      "Epoch 469/600\n",
      "3731/3731 [==============================] - 0s 66us/step - loss: 0.3464 - acc: 0.8464 - val_loss: 0.2636 - val_acc: 0.9060\n",
      "Epoch 470/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3468 - acc: 0.8451 - val_loss: 0.2630 - val_acc: 0.9060\n",
      "Epoch 471/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3477 - acc: 0.8486 - val_loss: 0.2637 - val_acc: 0.9036\n",
      "Epoch 472/600\n",
      "3731/3731 [==============================] - 0s 58us/step - loss: 0.3471 - acc: 0.8456 - val_loss: 0.2632 - val_acc: 0.9036\n",
      "Epoch 473/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3731/3731 [==============================] - 0s 56us/step - loss: 0.3471 - acc: 0.8472 - val_loss: 0.2635 - val_acc: 0.9036\n",
      "Epoch 474/600\n",
      "3731/3731 [==============================] - 0s 56us/step - loss: 0.3475 - acc: 0.8470 - val_loss: 0.2638 - val_acc: 0.9036\n",
      "Epoch 475/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3464 - acc: 0.8472 - val_loss: 0.2621 - val_acc: 0.9084\n",
      "Epoch 476/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3466 - acc: 0.8475 - val_loss: 0.2631 - val_acc: 0.9060\n",
      "Epoch 477/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3465 - acc: 0.8472 - val_loss: 0.2646 - val_acc: 0.9012\n",
      "Epoch 478/600\n",
      "3731/3731 [==============================] - 0s 71us/step - loss: 0.3465 - acc: 0.8462 - val_loss: 0.2639 - val_acc: 0.9036\n",
      "Epoch 479/600\n",
      "3731/3731 [==============================] - 0s 67us/step - loss: 0.3467 - acc: 0.8486 - val_loss: 0.2635 - val_acc: 0.9036\n",
      "Epoch 480/600\n",
      "3731/3731 [==============================] - 0s 63us/step - loss: 0.3459 - acc: 0.8467 - val_loss: 0.2631 - val_acc: 0.9060\n",
      "Epoch 481/600\n",
      "3731/3731 [==============================] - 0s 70us/step - loss: 0.3463 - acc: 0.8472 - val_loss: 0.2633 - val_acc: 0.9060\n",
      "Epoch 482/600\n",
      "3731/3731 [==============================] - 0s 67us/step - loss: 0.3462 - acc: 0.8443 - val_loss: 0.2633 - val_acc: 0.9036\n",
      "Epoch 483/600\n",
      "3731/3731 [==============================] - 0s 79us/step - loss: 0.3458 - acc: 0.8451 - val_loss: 0.2652 - val_acc: 0.9036\n",
      "Epoch 484/600\n",
      "3731/3731 [==============================] - 0s 74us/step - loss: 0.3466 - acc: 0.8483 - val_loss: 0.2642 - val_acc: 0.9012\n",
      "Epoch 485/600\n",
      "3731/3731 [==============================] - 0s 78us/step - loss: 0.3464 - acc: 0.8472 - val_loss: 0.2625 - val_acc: 0.9036\n",
      "Epoch 486/600\n",
      "3731/3731 [==============================] - 0s 74us/step - loss: 0.3459 - acc: 0.8475 - val_loss: 0.2641 - val_acc: 0.9012\n",
      "Epoch 487/600\n",
      "3731/3731 [==============================] - 0s 60us/step - loss: 0.3456 - acc: 0.8494 - val_loss: 0.2646 - val_acc: 0.9012\n",
      "Epoch 488/600\n",
      "3731/3731 [==============================] - 0s 77us/step - loss: 0.3468 - acc: 0.8486 - val_loss: 0.2642 - val_acc: 0.9012\n",
      "Epoch 489/600\n",
      "3731/3731 [==============================] - 0s 70us/step - loss: 0.3452 - acc: 0.8483 - val_loss: 0.2650 - val_acc: 0.9012\n",
      "Epoch 490/600\n",
      "3731/3731 [==============================] - 0s 79us/step - loss: 0.3458 - acc: 0.8451 - val_loss: 0.2645 - val_acc: 0.9012\n",
      "Epoch 491/600\n",
      "3731/3731 [==============================] - 0s 80us/step - loss: 0.3458 - acc: 0.8475 - val_loss: 0.2638 - val_acc: 0.9012\n",
      "Epoch 492/600\n",
      "3731/3731 [==============================] - 0s 66us/step - loss: 0.3455 - acc: 0.8472 - val_loss: 0.2638 - val_acc: 0.9012\n",
      "Epoch 493/600\n",
      "3731/3731 [==============================] - 0s 73us/step - loss: 0.3454 - acc: 0.8459 - val_loss: 0.2637 - val_acc: 0.9036\n",
      "Epoch 494/600\n",
      "3731/3731 [==============================] - 0s 78us/step - loss: 0.3457 - acc: 0.8494 - val_loss: 0.2640 - val_acc: 0.8988\n",
      "Epoch 495/600\n",
      "3731/3731 [==============================] - 0s 62us/step - loss: 0.3459 - acc: 0.8478 - val_loss: 0.2653 - val_acc: 0.8988\n",
      "Epoch 496/600\n",
      "3731/3731 [==============================] - 0s 70us/step - loss: 0.3461 - acc: 0.8499 - val_loss: 0.2647 - val_acc: 0.8988\n",
      "Epoch 497/600\n",
      "3731/3731 [==============================] - 0s 67us/step - loss: 0.3456 - acc: 0.8480 - val_loss: 0.2672 - val_acc: 0.8988\n",
      "Epoch 498/600\n",
      "3731/3731 [==============================] - 0s 85us/step - loss: 0.3454 - acc: 0.8470 - val_loss: 0.2652 - val_acc: 0.8988\n",
      "Epoch 499/600\n",
      "3731/3731 [==============================] - 0s 93us/step - loss: 0.3453 - acc: 0.8467 - val_loss: 0.2657 - val_acc: 0.8988\n",
      "Epoch 500/600\n",
      "3731/3731 [==============================] - 0s 67us/step - loss: 0.3454 - acc: 0.8480 - val_loss: 0.2659 - val_acc: 0.9012\n",
      "Epoch 501/600\n",
      "3731/3731 [==============================] - 0s 67us/step - loss: 0.3450 - acc: 0.8480 - val_loss: 0.2652 - val_acc: 0.9036\n",
      "Epoch 502/600\n",
      "3731/3731 [==============================] - 0s 67us/step - loss: 0.3448 - acc: 0.8491 - val_loss: 0.2656 - val_acc: 0.8988\n",
      "Epoch 503/600\n",
      "3731/3731 [==============================] - 0s 69us/step - loss: 0.3457 - acc: 0.8467 - val_loss: 0.2662 - val_acc: 0.8988\n",
      "Epoch 504/600\n",
      "3731/3731 [==============================] - 0s 66us/step - loss: 0.3448 - acc: 0.8504 - val_loss: 0.2651 - val_acc: 0.9012\n",
      "Epoch 505/600\n",
      "3731/3731 [==============================] - 0s 72us/step - loss: 0.3447 - acc: 0.8478 - val_loss: 0.2670 - val_acc: 0.8988\n",
      "Epoch 506/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3446 - acc: 0.8494 - val_loss: 0.2657 - val_acc: 0.9012\n",
      "Epoch 507/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3453 - acc: 0.8483 - val_loss: 0.2671 - val_acc: 0.8988\n",
      "Epoch 508/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3450 - acc: 0.8499 - val_loss: 0.2661 - val_acc: 0.9012\n",
      "Epoch 509/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3452 - acc: 0.8494 - val_loss: 0.2660 - val_acc: 0.8988\n",
      "Epoch 510/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3448 - acc: 0.8478 - val_loss: 0.2657 - val_acc: 0.8988\n",
      "Epoch 511/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3455 - acc: 0.8470 - val_loss: 0.2656 - val_acc: 0.9012\n",
      "Epoch 512/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3454 - acc: 0.8494 - val_loss: 0.2659 - val_acc: 0.9012\n",
      "Epoch 513/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3446 - acc: 0.8486 - val_loss: 0.2664 - val_acc: 0.8988\n",
      "Epoch 514/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3453 - acc: 0.8496 - val_loss: 0.2654 - val_acc: 0.9012\n",
      "Epoch 515/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3446 - acc: 0.8504 - val_loss: 0.2648 - val_acc: 0.9036\n",
      "Epoch 516/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3449 - acc: 0.8499 - val_loss: 0.2669 - val_acc: 0.9012\n",
      "Epoch 517/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3443 - acc: 0.8472 - val_loss: 0.2670 - val_acc: 0.8988\n",
      "Epoch 518/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3450 - acc: 0.8488 - val_loss: 0.2674 - val_acc: 0.8988\n",
      "Epoch 519/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3444 - acc: 0.8478 - val_loss: 0.2655 - val_acc: 0.9012\n",
      "Epoch 520/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3443 - acc: 0.8478 - val_loss: 0.2666 - val_acc: 0.9012\n",
      "Epoch 521/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3457 - acc: 0.8483 - val_loss: 0.2666 - val_acc: 0.8988\n",
      "Epoch 522/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3443 - acc: 0.8499 - val_loss: 0.2662 - val_acc: 0.8988\n",
      "Epoch 523/600\n",
      "3731/3731 [==============================] - 0s 56us/step - loss: 0.3448 - acc: 0.8491 - val_loss: 0.2673 - val_acc: 0.8988\n",
      "Epoch 524/600\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.3445 - acc: 0.8491 - val_loss: 0.2673 - val_acc: 0.8988\n",
      "Epoch 525/600\n",
      "3731/3731 [==============================] - 0s 65us/step - loss: 0.3440 - acc: 0.8499 - val_loss: 0.2665 - val_acc: 0.9036\n",
      "Epoch 526/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3441 - acc: 0.8470 - val_loss: 0.2688 - val_acc: 0.9036\n",
      "Epoch 527/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3436 - acc: 0.8491 - val_loss: 0.2673 - val_acc: 0.9036\n",
      "Epoch 528/600\n",
      "3731/3731 [==============================] - 0s 62us/step - loss: 0.3447 - acc: 0.8488 - val_loss: 0.2683 - val_acc: 0.9036\n",
      "Epoch 529/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3443 - acc: 0.8504 - val_loss: 0.2681 - val_acc: 0.9012\n",
      "Epoch 530/600\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.3445 - acc: 0.8488 - val_loss: 0.2682 - val_acc: 0.9012\n",
      "Epoch 531/600\n",
      "3731/3731 [==============================] - 0s 62us/step - loss: 0.3444 - acc: 0.8470 - val_loss: 0.2678 - val_acc: 0.9036\n",
      "Epoch 532/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3428 - acc: 0.8467 - val_loss: 0.2691 - val_acc: 0.9036\n",
      "Epoch 533/600\n",
      "3731/3731 [==============================] - 0s 67us/step - loss: 0.3434 - acc: 0.8515 - val_loss: 0.2688 - val_acc: 0.9036\n",
      "Epoch 534/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3436 - acc: 0.8491 - val_loss: 0.2694 - val_acc: 0.9036\n",
      "Epoch 535/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3439 - acc: 0.8507 - val_loss: 0.2696 - val_acc: 0.9036\n",
      "Epoch 536/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3438 - acc: 0.8494 - val_loss: 0.2686 - val_acc: 0.9060\n",
      "Epoch 537/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3436 - acc: 0.8488 - val_loss: 0.2686 - val_acc: 0.9012\n",
      "Epoch 538/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3439 - acc: 0.8499 - val_loss: 0.2732 - val_acc: 0.8964\n",
      "Epoch 539/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3446 - acc: 0.8483 - val_loss: 0.2712 - val_acc: 0.9036\n",
      "Epoch 540/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3432 - acc: 0.8462 - val_loss: 0.2710 - val_acc: 0.9036\n",
      "Epoch 541/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3434 - acc: 0.8475 - val_loss: 0.2704 - val_acc: 0.9036\n",
      "Epoch 542/600\n",
      "3731/3731 [==============================] - 0s 62us/step - loss: 0.3436 - acc: 0.8507 - val_loss: 0.2720 - val_acc: 0.8988\n",
      "Epoch 543/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3445 - acc: 0.8475 - val_loss: 0.2721 - val_acc: 0.9036\n",
      "Epoch 544/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3437 - acc: 0.8488 - val_loss: 0.2731 - val_acc: 0.8988\n",
      "Epoch 545/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3433 - acc: 0.8491 - val_loss: 0.2732 - val_acc: 0.9012\n",
      "Epoch 546/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3440 - acc: 0.8478 - val_loss: 0.2715 - val_acc: 0.8988\n",
      "Epoch 547/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3432 - acc: 0.8478 - val_loss: 0.2715 - val_acc: 0.8964\n",
      "Epoch 548/600\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3435 - acc: 0.8507 - val_loss: 0.2732 - val_acc: 0.8988\n",
      "Epoch 549/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3435 - acc: 0.8499 - val_loss: 0.2749 - val_acc: 0.8964\n",
      "Epoch 550/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3428 - acc: 0.8496 - val_loss: 0.2733 - val_acc: 0.8988\n",
      "Epoch 551/600\n",
      "3731/3731 [==============================] - 0s 64us/step - loss: 0.3442 - acc: 0.8464 - val_loss: 0.2730 - val_acc: 0.8964\n",
      "Epoch 552/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3432 - acc: 0.8494 - val_loss: 0.2735 - val_acc: 0.8964\n",
      "Epoch 553/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3434 - acc: 0.8496 - val_loss: 0.2744 - val_acc: 0.8988\n",
      "Epoch 554/600\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3429 - acc: 0.8510 - val_loss: 0.2746 - val_acc: 0.8988\n",
      "Epoch 555/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3435 - acc: 0.8502 - val_loss: 0.2738 - val_acc: 0.8940\n",
      "Epoch 556/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3439 - acc: 0.8483 - val_loss: 0.2749 - val_acc: 0.8988\n",
      "Epoch 557/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3426 - acc: 0.8507 - val_loss: 0.2732 - val_acc: 0.8940\n",
      "Epoch 558/600\n",
      "3731/3731 [==============================] - 0s 60us/step - loss: 0.3431 - acc: 0.8491 - val_loss: 0.2762 - val_acc: 0.8964\n",
      "Epoch 559/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3432 - acc: 0.8507 - val_loss: 0.2730 - val_acc: 0.8988\n",
      "Epoch 560/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3434 - acc: 0.8510 - val_loss: 0.2740 - val_acc: 0.8964\n",
      "Epoch 561/600\n",
      "3731/3731 [==============================] - ETA: 0s - loss: 0.3460 - acc: 0.845 - 0s 48us/step - loss: 0.3438 - acc: 0.8475 - val_loss: 0.2739 - val_acc: 0.8988\n",
      "Epoch 562/600\n",
      "3731/3731 [==============================] - 0s 59us/step - loss: 0.3431 - acc: 0.8464 - val_loss: 0.2763 - val_acc: 0.8964\n",
      "Epoch 563/600\n",
      "3731/3731 [==============================] - ETA: 0s - loss: 0.3445 - acc: 0.849 - 0s 54us/step - loss: 0.3433 - acc: 0.8483 - val_loss: 0.2769 - val_acc: 0.8988\n",
      "Epoch 564/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3430 - acc: 0.8488 - val_loss: 0.2762 - val_acc: 0.8964\n",
      "Epoch 565/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3425 - acc: 0.8488 - val_loss: 0.2760 - val_acc: 0.8988\n",
      "Epoch 566/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3428 - acc: 0.8510 - val_loss: 0.2758 - val_acc: 0.8964\n",
      "Epoch 567/600\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.3432 - acc: 0.8486 - val_loss: 0.2761 - val_acc: 0.8964\n",
      "Epoch 568/600\n",
      "3731/3731 [==============================] - 0s 60us/step - loss: 0.3421 - acc: 0.8521 - val_loss: 0.2757 - val_acc: 0.9012\n",
      "Epoch 569/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3431 - acc: 0.8488 - val_loss: 0.2748 - val_acc: 0.8988\n",
      "Epoch 570/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3434 - acc: 0.8486 - val_loss: 0.2765 - val_acc: 0.8988\n",
      "Epoch 571/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3437 - acc: 0.8504 - val_loss: 0.2793 - val_acc: 0.8988\n",
      "Epoch 572/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3444 - acc: 0.8475 - val_loss: 0.2766 - val_acc: 0.8988\n",
      "Epoch 573/600\n",
      "3731/3731 [==============================] - 0s 64us/step - loss: 0.3422 - acc: 0.8499 - val_loss: 0.2754 - val_acc: 0.8988\n",
      "Epoch 574/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3424 - acc: 0.8483 - val_loss: 0.2752 - val_acc: 0.9012\n",
      "Epoch 575/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3428 - acc: 0.8496 - val_loss: 0.2770 - val_acc: 0.8988\n",
      "Epoch 576/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3422 - acc: 0.8512 - val_loss: 0.2764 - val_acc: 0.8988\n",
      "Epoch 577/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3429 - acc: 0.8494 - val_loss: 0.2765 - val_acc: 0.8988\n",
      "Epoch 578/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3421 - acc: 0.8486 - val_loss: 0.2743 - val_acc: 0.8988\n",
      "Epoch 579/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3434 - acc: 0.8502 - val_loss: 0.2758 - val_acc: 0.9012\n",
      "Epoch 580/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3419 - acc: 0.8523 - val_loss: 0.2782 - val_acc: 0.8988\n",
      "Epoch 581/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3422 - acc: 0.8480 - val_loss: 0.2810 - val_acc: 0.8964\n",
      "Epoch 582/600\n",
      "3731/3731 [==============================] - 0s 58us/step - loss: 0.3425 - acc: 0.8499 - val_loss: 0.2782 - val_acc: 0.8988\n",
      "Epoch 583/600\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3419 - acc: 0.8499 - val_loss: 0.2763 - val_acc: 0.9012\n",
      "Epoch 584/600\n",
      "3731/3731 [==============================] - 0s 66us/step - loss: 0.3424 - acc: 0.8475 - val_loss: 0.2768 - val_acc: 0.8988\n",
      "Epoch 585/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3423 - acc: 0.8537 - val_loss: 0.2786 - val_acc: 0.8988\n",
      "Epoch 586/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3423 - acc: 0.8507 - val_loss: 0.2809 - val_acc: 0.8940\n",
      "Epoch 587/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3416 - acc: 0.8507 - val_loss: 0.2785 - val_acc: 0.8988\n",
      "Epoch 588/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3422 - acc: 0.8510 - val_loss: 0.2783 - val_acc: 0.8988\n",
      "Epoch 589/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3419 - acc: 0.8496 - val_loss: 0.2771 - val_acc: 0.8988\n",
      "Epoch 590/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3418 - acc: 0.8507 - val_loss: 0.2772 - val_acc: 0.9012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 591/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3419 - acc: 0.8523 - val_loss: 0.2784 - val_acc: 0.8988\n",
      "Epoch 592/600\n",
      "3731/3731 [==============================] - 0s 70us/step - loss: 0.3429 - acc: 0.8491 - val_loss: 0.2775 - val_acc: 0.9012\n",
      "Epoch 593/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3417 - acc: 0.8510 - val_loss: 0.2773 - val_acc: 0.8988\n",
      "Epoch 594/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3424 - acc: 0.8488 - val_loss: 0.2791 - val_acc: 0.8988\n",
      "Epoch 595/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3427 - acc: 0.8491 - val_loss: 0.2791 - val_acc: 0.8988\n",
      "Epoch 596/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3420 - acc: 0.8494 - val_loss: 0.2799 - val_acc: 0.8964\n",
      "Epoch 597/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3420 - acc: 0.8523 - val_loss: 0.2786 - val_acc: 0.9012\n",
      "Epoch 598/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3423 - acc: 0.8507 - val_loss: 0.2798 - val_acc: 0.8988\n",
      "Epoch 599/600\n",
      "3731/3731 [==============================] - 0s 61us/step - loss: 0.3418 - acc: 0.8507 - val_loss: 0.2797 - val_acc: 0.8988\n",
      "Epoch 600/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3414 - acc: 0.8502 - val_loss: 0.2795 - val_acc: 0.8988\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(4, kernel_initializer='normal', input_dim=len(X[0]), activation='relu'))\n",
    "model.add(Dense(4, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X, y.values, epochs=600, validation_split = 0.1)\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T17:38:36.907303Z",
     "start_time": "2019-09-13T17:36:40.898313Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3731 samples, validate on 415 samples\n",
      "Epoch 1/600\n",
      "3731/3731 [==============================] - 1s 268us/step - loss: 0.6415 - acc: 0.7229 - val_loss: 0.5017 - val_acc: 0.8530\n",
      "Epoch 2/600\n",
      "3731/3731 [==============================] - 0s 69us/step - loss: 0.4801 - acc: 0.8207 - val_loss: 0.3749 - val_acc: 0.8530\n",
      "Epoch 3/600\n",
      "3731/3731 [==============================] - 0s 64us/step - loss: 0.4232 - acc: 0.8252 - val_loss: 0.3393 - val_acc: 0.8627\n",
      "Epoch 4/600\n",
      "3731/3731 [==============================] - 0s 61us/step - loss: 0.4081 - acc: 0.8285 - val_loss: 0.3242 - val_acc: 0.8627\n",
      "Epoch 5/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3999 - acc: 0.8357 - val_loss: 0.3187 - val_acc: 0.8651\n",
      "Epoch 6/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3968 - acc: 0.8295 - val_loss: 0.3135 - val_acc: 0.8651\n",
      "Epoch 7/600\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3939 - acc: 0.8322 - val_loss: 0.3021 - val_acc: 0.8675\n",
      "Epoch 8/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3915 - acc: 0.8357 - val_loss: 0.2985 - val_acc: 0.8771\n",
      "Epoch 9/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3893 - acc: 0.8360 - val_loss: 0.2924 - val_acc: 0.8867\n",
      "Epoch 10/600\n",
      "3731/3731 [==============================] - 0s 58us/step - loss: 0.3869 - acc: 0.8333 - val_loss: 0.2970 - val_acc: 0.8747\n",
      "Epoch 11/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3858 - acc: 0.8322 - val_loss: 0.2902 - val_acc: 0.8819\n",
      "Epoch 12/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3844 - acc: 0.8344 - val_loss: 0.2880 - val_acc: 0.8771\n",
      "Epoch 13/600\n",
      "3731/3731 [==============================] - 0s 58us/step - loss: 0.3832 - acc: 0.8341 - val_loss: 0.2860 - val_acc: 0.8795\n",
      "Epoch 14/600\n",
      "3731/3731 [==============================] - 0s 62us/step - loss: 0.3809 - acc: 0.8360 - val_loss: 0.2901 - val_acc: 0.8723\n",
      "Epoch 15/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3800 - acc: 0.8341 - val_loss: 0.2841 - val_acc: 0.8819\n",
      "Epoch 16/600\n",
      "3731/3731 [==============================] - 0s 66us/step - loss: 0.3790 - acc: 0.8370 - val_loss: 0.2820 - val_acc: 0.8867\n",
      "Epoch 17/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3785 - acc: 0.8346 - val_loss: 0.2821 - val_acc: 0.8819\n",
      "Epoch 18/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3770 - acc: 0.8360 - val_loss: 0.2835 - val_acc: 0.8843\n",
      "Epoch 19/600\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3759 - acc: 0.8354 - val_loss: 0.2808 - val_acc: 0.8819\n",
      "Epoch 20/600\n",
      "3731/3731 [==============================] - ETA: 0s - loss: 0.3806 - acc: 0.834 - 0s 53us/step - loss: 0.3751 - acc: 0.8360 - val_loss: 0.2825 - val_acc: 0.8843\n",
      "Epoch 21/600\n",
      "3731/3731 [==============================] - 0s 69us/step - loss: 0.3753 - acc: 0.8349 - val_loss: 0.2816 - val_acc: 0.8867\n",
      "Epoch 22/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3730 - acc: 0.8354 - val_loss: 0.2790 - val_acc: 0.8892\n",
      "Epoch 23/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3723 - acc: 0.8384 - val_loss: 0.2778 - val_acc: 0.8916\n",
      "Epoch 24/600\n",
      "3731/3731 [==============================] - 0s 68us/step - loss: 0.3715 - acc: 0.8373 - val_loss: 0.2764 - val_acc: 0.8867\n",
      "Epoch 25/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3707 - acc: 0.8381 - val_loss: 0.2747 - val_acc: 0.8940\n",
      "Epoch 26/600\n",
      "3731/3731 [==============================] - 0s 64us/step - loss: 0.3700 - acc: 0.8392 - val_loss: 0.2747 - val_acc: 0.8940\n",
      "Epoch 27/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3693 - acc: 0.8365 - val_loss: 0.2715 - val_acc: 0.8964\n",
      "Epoch 28/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3689 - acc: 0.8381 - val_loss: 0.2713 - val_acc: 0.9012\n",
      "Epoch 29/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3673 - acc: 0.8381 - val_loss: 0.2721 - val_acc: 0.8916\n",
      "Epoch 30/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3675 - acc: 0.8389 - val_loss: 0.2699 - val_acc: 0.8916\n",
      "Epoch 31/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3666 - acc: 0.8381 - val_loss: 0.2680 - val_acc: 0.8988\n",
      "Epoch 32/600\n",
      "3731/3731 [==============================] - 0s 61us/step - loss: 0.3655 - acc: 0.8419 - val_loss: 0.2698 - val_acc: 0.8940\n",
      "Epoch 33/600\n",
      "3731/3731 [==============================] - 0s 80us/step - loss: 0.3654 - acc: 0.8381 - val_loss: 0.2661 - val_acc: 0.8988\n",
      "Epoch 34/600\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.3655 - acc: 0.8381 - val_loss: 0.2658 - val_acc: 0.8988\n",
      "Epoch 35/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3645 - acc: 0.8397 - val_loss: 0.2642 - val_acc: 0.9012\n",
      "Epoch 36/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3637 - acc: 0.8416 - val_loss: 0.2663 - val_acc: 0.8964\n",
      "Epoch 37/600\n",
      "3731/3731 [==============================] - 0s 67us/step - loss: 0.3632 - acc: 0.8424 - val_loss: 0.2667 - val_acc: 0.8916\n",
      "Epoch 38/600\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3629 - acc: 0.8386 - val_loss: 0.2670 - val_acc: 0.8940\n",
      "Epoch 39/600\n",
      "3731/3731 [==============================] - 0s 69us/step - loss: 0.3620 - acc: 0.8400 - val_loss: 0.2691 - val_acc: 0.8940\n",
      "Epoch 40/600\n",
      "3731/3731 [==============================] - 0s 58us/step - loss: 0.3619 - acc: 0.8416 - val_loss: 0.2659 - val_acc: 0.8988\n",
      "Epoch 41/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3615 - acc: 0.8411 - val_loss: 0.2684 - val_acc: 0.8940\n",
      "Epoch 42/600\n",
      "3731/3731 [==============================] - 0s 74us/step - loss: 0.3611 - acc: 0.8386 - val_loss: 0.2646 - val_acc: 0.8964\n",
      "Epoch 43/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3611 - acc: 0.8397 - val_loss: 0.2665 - val_acc: 0.8988\n",
      "Epoch 44/600\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3605 - acc: 0.8411 - val_loss: 0.2652 - val_acc: 0.8964\n",
      "Epoch 45/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3599 - acc: 0.8400 - val_loss: 0.2675 - val_acc: 0.8916\n",
      "Epoch 46/600\n",
      "3731/3731 [==============================] - ETA: 0s - loss: 0.3604 - acc: 0.843 - 0s 53us/step - loss: 0.3604 - acc: 0.8424 - val_loss: 0.2670 - val_acc: 0.8964\n",
      "Epoch 47/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3593 - acc: 0.8405 - val_loss: 0.2653 - val_acc: 0.8964\n",
      "Epoch 48/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3590 - acc: 0.8445 - val_loss: 0.2654 - val_acc: 0.8940\n",
      "Epoch 49/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3593 - acc: 0.8421 - val_loss: 0.2657 - val_acc: 0.8892\n",
      "Epoch 50/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3592 - acc: 0.8443 - val_loss: 0.2654 - val_acc: 0.8964\n",
      "Epoch 51/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3590 - acc: 0.8421 - val_loss: 0.2647 - val_acc: 0.8916\n",
      "Epoch 52/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3583 - acc: 0.8437 - val_loss: 0.2655 - val_acc: 0.8964\n",
      "Epoch 53/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3588 - acc: 0.8427 - val_loss: 0.2647 - val_acc: 0.8916\n",
      "Epoch 54/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3578 - acc: 0.8443 - val_loss: 0.2641 - val_acc: 0.8940\n",
      "Epoch 55/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3585 - acc: 0.8445 - val_loss: 0.2636 - val_acc: 0.8916\n",
      "Epoch 56/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3573 - acc: 0.8445 - val_loss: 0.2643 - val_acc: 0.8940\n",
      "Epoch 57/600\n",
      "3731/3731 [==============================] - ETA: 0s - loss: 0.3626 - acc: 0.843 - 0s 54us/step - loss: 0.3568 - acc: 0.8448 - val_loss: 0.2629 - val_acc: 0.8916\n",
      "Epoch 58/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3568 - acc: 0.8437 - val_loss: 0.2642 - val_acc: 0.8940\n",
      "Epoch 59/600\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.3573 - acc: 0.8448 - val_loss: 0.2647 - val_acc: 0.8964\n",
      "Epoch 60/600\n",
      "3731/3731 [==============================] - 0s 69us/step - loss: 0.3571 - acc: 0.8429 - val_loss: 0.2655 - val_acc: 0.8940\n",
      "Epoch 61/600\n",
      "3731/3731 [==============================] - 0s 72us/step - loss: 0.3566 - acc: 0.8403 - val_loss: 0.2667 - val_acc: 0.8964\n",
      "Epoch 62/600\n",
      "3731/3731 [==============================] - 0s 65us/step - loss: 0.3566 - acc: 0.8443 - val_loss: 0.2681 - val_acc: 0.8940\n",
      "Epoch 63/600\n",
      "3731/3731 [==============================] - 0s 67us/step - loss: 0.3561 - acc: 0.8424 - val_loss: 0.2686 - val_acc: 0.8988\n",
      "Epoch 64/600\n",
      "3731/3731 [==============================] - 0s 66us/step - loss: 0.3573 - acc: 0.8437 - val_loss: 0.2678 - val_acc: 0.8964\n",
      "Epoch 65/600\n",
      "3731/3731 [==============================] - 0s 62us/step - loss: 0.3570 - acc: 0.8443 - val_loss: 0.2681 - val_acc: 0.8964\n",
      "Epoch 66/600\n",
      "3731/3731 [==============================] - 0s 62us/step - loss: 0.3554 - acc: 0.8448 - val_loss: 0.2664 - val_acc: 0.8940\n",
      "Epoch 67/600\n",
      "3731/3731 [==============================] - 0s 59us/step - loss: 0.3561 - acc: 0.8424 - val_loss: 0.2655 - val_acc: 0.8988\n",
      "Epoch 68/600\n",
      "3731/3731 [==============================] - 0s 63us/step - loss: 0.3553 - acc: 0.8459 - val_loss: 0.2643 - val_acc: 0.8964\n",
      "Epoch 69/600\n",
      "3731/3731 [==============================] - 0s 61us/step - loss: 0.3551 - acc: 0.8467 - val_loss: 0.2667 - val_acc: 0.9012\n",
      "Epoch 70/600\n",
      "3731/3731 [==============================] - 0s 58us/step - loss: 0.3548 - acc: 0.8421 - val_loss: 0.2669 - val_acc: 0.8988\n",
      "Epoch 71/600\n",
      "3731/3731 [==============================] - 0s 59us/step - loss: 0.3548 - acc: 0.8443 - val_loss: 0.2674 - val_acc: 0.8940\n",
      "Epoch 72/600\n",
      "3731/3731 [==============================] - 0s 60us/step - loss: 0.3546 - acc: 0.8445 - val_loss: 0.2687 - val_acc: 0.8964\n",
      "Epoch 73/600\n",
      "3731/3731 [==============================] - 0s 56us/step - loss: 0.3539 - acc: 0.8467 - val_loss: 0.2676 - val_acc: 0.8940\n",
      "Epoch 74/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3540 - acc: 0.8451 - val_loss: 0.2680 - val_acc: 0.8916\n",
      "Epoch 75/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3538 - acc: 0.8440 - val_loss: 0.2691 - val_acc: 0.8940\n",
      "Epoch 76/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3544 - acc: 0.8451 - val_loss: 0.2688 - val_acc: 0.8964\n",
      "Epoch 77/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3539 - acc: 0.8456 - val_loss: 0.2675 - val_acc: 0.9012\n",
      "Epoch 78/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3528 - acc: 0.8478 - val_loss: 0.2648 - val_acc: 0.8964\n",
      "Epoch 79/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3530 - acc: 0.8459 - val_loss: 0.2685 - val_acc: 0.8964\n",
      "Epoch 80/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3531 - acc: 0.8451 - val_loss: 0.2671 - val_acc: 0.8988\n",
      "Epoch 81/600\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3534 - acc: 0.8488 - val_loss: 0.2710 - val_acc: 0.8940\n",
      "Epoch 82/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3524 - acc: 0.8480 - val_loss: 0.2703 - val_acc: 0.8940\n",
      "Epoch 83/600\n",
      "3731/3731 [==============================] - 0s 67us/step - loss: 0.3530 - acc: 0.8437 - val_loss: 0.2701 - val_acc: 0.8892\n",
      "Epoch 84/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3518 - acc: 0.8483 - val_loss: 0.2685 - val_acc: 0.8940\n",
      "Epoch 85/600\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.3516 - acc: 0.8467 - val_loss: 0.2670 - val_acc: 0.8964\n",
      "Epoch 86/600\n",
      "3731/3731 [==============================] - 0s 64us/step - loss: 0.3515 - acc: 0.8448 - val_loss: 0.2679 - val_acc: 0.8892\n",
      "Epoch 87/600\n",
      "3731/3731 [==============================] - 0s 68us/step - loss: 0.3512 - acc: 0.8443 - val_loss: 0.2679 - val_acc: 0.8916\n",
      "Epoch 88/600\n",
      "3731/3731 [==============================] - 0s 59us/step - loss: 0.3511 - acc: 0.8445 - val_loss: 0.2685 - val_acc: 0.8916\n",
      "Epoch 89/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3519 - acc: 0.8467 - val_loss: 0.2711 - val_acc: 0.8916\n",
      "Epoch 90/600\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3510 - acc: 0.8440 - val_loss: 0.2679 - val_acc: 0.8892\n",
      "Epoch 91/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3512 - acc: 0.8440 - val_loss: 0.2696 - val_acc: 0.8916\n",
      "Epoch 92/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3503 - acc: 0.8496 - val_loss: 0.2695 - val_acc: 0.8867\n",
      "Epoch 93/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3498 - acc: 0.8470 - val_loss: 0.2654 - val_acc: 0.8916\n",
      "Epoch 94/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3507 - acc: 0.8491 - val_loss: 0.2668 - val_acc: 0.8940\n",
      "Epoch 95/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3492 - acc: 0.8486 - val_loss: 0.2692 - val_acc: 0.8892\n",
      "Epoch 96/600\n",
      "3731/3731 [==============================] - 0s 58us/step - loss: 0.3500 - acc: 0.8451 - val_loss: 0.2673 - val_acc: 0.8916\n",
      "Epoch 97/600\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3501 - acc: 0.8475 - val_loss: 0.2671 - val_acc: 0.8916\n",
      "Epoch 98/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3499 - acc: 0.8491 - val_loss: 0.2721 - val_acc: 0.8916\n",
      "Epoch 99/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3495 - acc: 0.8486 - val_loss: 0.2659 - val_acc: 0.8940\n",
      "Epoch 100/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3487 - acc: 0.8464 - val_loss: 0.2664 - val_acc: 0.8940\n",
      "Epoch 101/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3487 - acc: 0.8451 - val_loss: 0.2707 - val_acc: 0.8916\n",
      "Epoch 102/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3492 - acc: 0.8467 - val_loss: 0.2680 - val_acc: 0.8892\n",
      "Epoch 103/600\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.3485 - acc: 0.8483 - val_loss: 0.2700 - val_acc: 0.8892\n",
      "Epoch 104/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3477 - acc: 0.8483 - val_loss: 0.2687 - val_acc: 0.8916\n",
      "Epoch 105/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3489 - acc: 0.8483 - val_loss: 0.2683 - val_acc: 0.8964\n",
      "Epoch 106/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3479 - acc: 0.8459 - val_loss: 0.2705 - val_acc: 0.8892\n",
      "Epoch 107/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3478 - acc: 0.8475 - val_loss: 0.2709 - val_acc: 0.8867\n",
      "Epoch 108/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3479 - acc: 0.8464 - val_loss: 0.2715 - val_acc: 0.8867\n",
      "Epoch 109/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3475 - acc: 0.8518 - val_loss: 0.2707 - val_acc: 0.8892\n",
      "Epoch 110/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3478 - acc: 0.8480 - val_loss: 0.2725 - val_acc: 0.8843\n",
      "Epoch 111/600\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3477 - acc: 0.8494 - val_loss: 0.2731 - val_acc: 0.8843\n",
      "Epoch 112/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3474 - acc: 0.8488 - val_loss: 0.2722 - val_acc: 0.8819\n",
      "Epoch 113/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3472 - acc: 0.8496 - val_loss: 0.2752 - val_acc: 0.8892\n",
      "Epoch 114/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3472 - acc: 0.8486 - val_loss: 0.2751 - val_acc: 0.8867\n",
      "Epoch 115/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3481 - acc: 0.8453 - val_loss: 0.2742 - val_acc: 0.8843\n",
      "Epoch 116/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3469 - acc: 0.8483 - val_loss: 0.2732 - val_acc: 0.8843\n",
      "Epoch 117/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3465 - acc: 0.8496 - val_loss: 0.2752 - val_acc: 0.8843\n",
      "Epoch 118/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3469 - acc: 0.8480 - val_loss: 0.2708 - val_acc: 0.8843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3461 - acc: 0.8499 - val_loss: 0.2731 - val_acc: 0.8843\n",
      "Epoch 120/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3458 - acc: 0.8488 - val_loss: 0.2698 - val_acc: 0.8867\n",
      "Epoch 121/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3454 - acc: 0.8480 - val_loss: 0.2727 - val_acc: 0.8867\n",
      "Epoch 122/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3458 - acc: 0.8486 - val_loss: 0.2704 - val_acc: 0.8867\n",
      "Epoch 123/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3459 - acc: 0.8453 - val_loss: 0.2724 - val_acc: 0.8867\n",
      "Epoch 124/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3455 - acc: 0.8478 - val_loss: 0.2730 - val_acc: 0.8867\n",
      "Epoch 125/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3465 - acc: 0.8494 - val_loss: 0.2719 - val_acc: 0.8867\n",
      "Epoch 126/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3459 - acc: 0.8488 - val_loss: 0.2748 - val_acc: 0.8892\n",
      "Epoch 127/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3459 - acc: 0.8472 - val_loss: 0.2707 - val_acc: 0.8843\n",
      "Epoch 128/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3442 - acc: 0.8523 - val_loss: 0.2680 - val_acc: 0.8916\n",
      "Epoch 129/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3452 - acc: 0.8470 - val_loss: 0.2738 - val_acc: 0.8843\n",
      "Epoch 130/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3452 - acc: 0.8470 - val_loss: 0.2703 - val_acc: 0.8819\n",
      "Epoch 131/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3450 - acc: 0.8510 - val_loss: 0.2744 - val_acc: 0.8867\n",
      "Epoch 132/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3444 - acc: 0.8480 - val_loss: 0.2703 - val_acc: 0.8843\n",
      "Epoch 133/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3446 - acc: 0.8502 - val_loss: 0.2711 - val_acc: 0.8867\n",
      "Epoch 134/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3440 - acc: 0.8507 - val_loss: 0.2722 - val_acc: 0.8867\n",
      "Epoch 135/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3440 - acc: 0.8488 - val_loss: 0.2686 - val_acc: 0.8843\n",
      "Epoch 136/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3450 - acc: 0.8499 - val_loss: 0.2651 - val_acc: 0.8940\n",
      "Epoch 137/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3439 - acc: 0.8494 - val_loss: 0.2731 - val_acc: 0.8867\n",
      "Epoch 138/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3438 - acc: 0.8496 - val_loss: 0.2700 - val_acc: 0.8892\n",
      "Epoch 139/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3451 - acc: 0.8475 - val_loss: 0.2730 - val_acc: 0.8867\n",
      "Epoch 140/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3446 - acc: 0.8483 - val_loss: 0.2707 - val_acc: 0.8892\n",
      "Epoch 141/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3435 - acc: 0.8488 - val_loss: 0.2710 - val_acc: 0.8867\n",
      "Epoch 142/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3447 - acc: 0.8504 - val_loss: 0.2679 - val_acc: 0.8916\n",
      "Epoch 143/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3428 - acc: 0.8496 - val_loss: 0.2686 - val_acc: 0.8843\n",
      "Epoch 144/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3441 - acc: 0.8515 - val_loss: 0.2715 - val_acc: 0.8843\n",
      "Epoch 145/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3439 - acc: 0.8486 - val_loss: 0.2682 - val_acc: 0.8843\n",
      "Epoch 146/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3432 - acc: 0.8475 - val_loss: 0.2676 - val_acc: 0.8892\n",
      "Epoch 147/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3426 - acc: 0.8515 - val_loss: 0.2683 - val_acc: 0.8892\n",
      "Epoch 148/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3430 - acc: 0.8518 - val_loss: 0.2674 - val_acc: 0.8916\n",
      "Epoch 149/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3439 - acc: 0.8523 - val_loss: 0.2680 - val_acc: 0.8867\n",
      "Epoch 150/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3425 - acc: 0.8510 - val_loss: 0.2657 - val_acc: 0.8964\n",
      "Epoch 151/600\n",
      "3731/3731 [==============================] - 0s 60us/step - loss: 0.3439 - acc: 0.8496 - val_loss: 0.2711 - val_acc: 0.8916\n",
      "Epoch 152/600\n",
      "3731/3731 [==============================] - 0s 61us/step - loss: 0.3428 - acc: 0.8515 - val_loss: 0.2730 - val_acc: 0.8867\n",
      "Epoch 153/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3428 - acc: 0.8488 - val_loss: 0.2746 - val_acc: 0.8843\n",
      "Epoch 154/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3428 - acc: 0.8512 - val_loss: 0.2720 - val_acc: 0.8819\n",
      "Epoch 155/600\n",
      "3731/3731 [==============================] - 0s 56us/step - loss: 0.3424 - acc: 0.8512 - val_loss: 0.2775 - val_acc: 0.8843\n",
      "Epoch 156/600\n",
      "3731/3731 [==============================] - 0s 66us/step - loss: 0.3421 - acc: 0.8537 - val_loss: 0.2807 - val_acc: 0.8771\n",
      "Epoch 157/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3428 - acc: 0.8521 - val_loss: 0.2765 - val_acc: 0.8867\n",
      "Epoch 158/600\n",
      "3731/3731 [==============================] - 0s 61us/step - loss: 0.3418 - acc: 0.8512 - val_loss: 0.2729 - val_acc: 0.8771\n",
      "Epoch 159/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3415 - acc: 0.8504 - val_loss: 0.2739 - val_acc: 0.8771\n",
      "Epoch 160/600\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3422 - acc: 0.8537 - val_loss: 0.2712 - val_acc: 0.8819\n",
      "Epoch 161/600\n",
      "3731/3731 [==============================] - 0s 56us/step - loss: 0.3418 - acc: 0.8510 - val_loss: 0.2731 - val_acc: 0.8843\n",
      "Epoch 162/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3418 - acc: 0.8512 - val_loss: 0.2774 - val_acc: 0.8843\n",
      "Epoch 163/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3411 - acc: 0.8507 - val_loss: 0.2719 - val_acc: 0.8795\n",
      "Epoch 164/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3424 - acc: 0.8483 - val_loss: 0.2741 - val_acc: 0.8867\n",
      "Epoch 165/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3428 - acc: 0.8496 - val_loss: 0.2725 - val_acc: 0.8843\n",
      "Epoch 166/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3419 - acc: 0.8499 - val_loss: 0.2701 - val_acc: 0.8819\n",
      "Epoch 167/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3412 - acc: 0.8529 - val_loss: 0.2712 - val_acc: 0.8819\n",
      "Epoch 168/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3411 - acc: 0.8496 - val_loss: 0.2769 - val_acc: 0.8795\n",
      "Epoch 169/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3421 - acc: 0.8523 - val_loss: 0.2734 - val_acc: 0.8771\n",
      "Epoch 170/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3411 - acc: 0.8515 - val_loss: 0.2751 - val_acc: 0.8843\n",
      "Epoch 171/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3417 - acc: 0.8515 - val_loss: 0.2747 - val_acc: 0.8843\n",
      "Epoch 172/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3411 - acc: 0.8526 - val_loss: 0.2707 - val_acc: 0.8892\n",
      "Epoch 173/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3419 - acc: 0.8510 - val_loss: 0.2742 - val_acc: 0.8843\n",
      "Epoch 174/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3409 - acc: 0.8529 - val_loss: 0.2724 - val_acc: 0.8819\n",
      "Epoch 175/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3401 - acc: 0.8542 - val_loss: 0.2705 - val_acc: 0.8843\n",
      "Epoch 176/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3410 - acc: 0.8529 - val_loss: 0.2716 - val_acc: 0.8843\n",
      "Epoch 177/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3409 - acc: 0.8518 - val_loss: 0.2724 - val_acc: 0.8819\n",
      "Epoch 178/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3401 - acc: 0.8518 - val_loss: 0.2739 - val_acc: 0.8843\n",
      "Epoch 179/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3405 - acc: 0.8537 - val_loss: 0.2755 - val_acc: 0.8892\n",
      "Epoch 180/600\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3395 - acc: 0.8529 - val_loss: 0.2722 - val_acc: 0.8892\n",
      "Epoch 181/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3404 - acc: 0.8518 - val_loss: 0.2699 - val_acc: 0.8843\n",
      "Epoch 182/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3394 - acc: 0.8529 - val_loss: 0.2706 - val_acc: 0.8819\n",
      "Epoch 183/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3399 - acc: 0.8534 - val_loss: 0.2735 - val_acc: 0.8843\n",
      "Epoch 184/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3394 - acc: 0.8537 - val_loss: 0.2705 - val_acc: 0.8819\n",
      "Epoch 185/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3408 - acc: 0.8537 - val_loss: 0.2685 - val_acc: 0.8867\n",
      "Epoch 186/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3392 - acc: 0.8521 - val_loss: 0.2715 - val_acc: 0.8819\n",
      "Epoch 187/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3411 - acc: 0.8510 - val_loss: 0.2714 - val_acc: 0.8843\n",
      "Epoch 188/600\n",
      "3731/3731 [==============================] - 0s 65us/step - loss: 0.3402 - acc: 0.8515 - val_loss: 0.2702 - val_acc: 0.8867\n",
      "Epoch 189/600\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3391 - acc: 0.8523 - val_loss: 0.2692 - val_acc: 0.8867\n",
      "Epoch 190/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3390 - acc: 0.8563 - val_loss: 0.2704 - val_acc: 0.8819\n",
      "Epoch 191/600\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3379 - acc: 0.8521 - val_loss: 0.2684 - val_acc: 0.8843\n",
      "Epoch 192/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3390 - acc: 0.8529 - val_loss: 0.2690 - val_acc: 0.8867\n",
      "Epoch 193/600\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3384 - acc: 0.8499 - val_loss: 0.2683 - val_acc: 0.8843\n",
      "Epoch 194/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3379 - acc: 0.8534 - val_loss: 0.2705 - val_acc: 0.8843\n",
      "Epoch 195/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3387 - acc: 0.8526 - val_loss: 0.2666 - val_acc: 0.8892\n",
      "Epoch 196/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3382 - acc: 0.8539 - val_loss: 0.2703 - val_acc: 0.8843\n",
      "Epoch 197/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3391 - acc: 0.8534 - val_loss: 0.2692 - val_acc: 0.8892\n",
      "Epoch 198/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3381 - acc: 0.8512 - val_loss: 0.2765 - val_acc: 0.8819\n",
      "Epoch 199/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3385 - acc: 0.8537 - val_loss: 0.2727 - val_acc: 0.8843\n",
      "Epoch 200/600\n",
      "3731/3731 [==============================] - 0s 66us/step - loss: 0.3389 - acc: 0.8539 - val_loss: 0.2752 - val_acc: 0.8795\n",
      "Epoch 201/600\n",
      "3731/3731 [==============================] - 0s 68us/step - loss: 0.3383 - acc: 0.8566 - val_loss: 0.2760 - val_acc: 0.8843\n",
      "Epoch 202/600\n",
      "3731/3731 [==============================] - 0s 72us/step - loss: 0.3365 - acc: 0.8521 - val_loss: 0.2714 - val_acc: 0.8843\n",
      "Epoch 203/600\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3381 - acc: 0.8539 - val_loss: 0.2722 - val_acc: 0.8819\n",
      "Epoch 204/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3359 - acc: 0.8561 - val_loss: 0.2741 - val_acc: 0.8843\n",
      "Epoch 205/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3385 - acc: 0.8526 - val_loss: 0.2785 - val_acc: 0.8819\n",
      "Epoch 206/600\n",
      "3731/3731 [==============================] - 0s 56us/step - loss: 0.3378 - acc: 0.8526 - val_loss: 0.2782 - val_acc: 0.8795\n",
      "Epoch 207/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3372 - acc: 0.8529 - val_loss: 0.2722 - val_acc: 0.8843\n",
      "Epoch 208/600\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3365 - acc: 0.8529 - val_loss: 0.2740 - val_acc: 0.8819\n",
      "Epoch 209/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3371 - acc: 0.8561 - val_loss: 0.2744 - val_acc: 0.8843\n",
      "Epoch 210/600\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3368 - acc: 0.8569 - val_loss: 0.2754 - val_acc: 0.8819\n",
      "Epoch 211/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3371 - acc: 0.8523 - val_loss: 0.2712 - val_acc: 0.8892\n",
      "Epoch 212/600\n",
      "3731/3731 [==============================] - 0s 56us/step - loss: 0.3367 - acc: 0.8563 - val_loss: 0.2743 - val_acc: 0.8819\n",
      "Epoch 213/600\n",
      "3731/3731 [==============================] - 0s 58us/step - loss: 0.3360 - acc: 0.8547 - val_loss: 0.2781 - val_acc: 0.8795\n",
      "Epoch 214/600\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.3373 - acc: 0.8537 - val_loss: 0.2759 - val_acc: 0.8819\n",
      "Epoch 215/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3360 - acc: 0.8574 - val_loss: 0.2744 - val_acc: 0.8819\n",
      "Epoch 216/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3354 - acc: 0.8585 - val_loss: 0.2721 - val_acc: 0.8843\n",
      "Epoch 217/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3366 - acc: 0.8558 - val_loss: 0.2717 - val_acc: 0.8795\n",
      "Epoch 218/600\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.3376 - acc: 0.8542 - val_loss: 0.2709 - val_acc: 0.8819\n",
      "Epoch 219/600\n",
      "3731/3731 [==============================] - 0s 56us/step - loss: 0.3355 - acc: 0.8542 - val_loss: 0.2745 - val_acc: 0.8843\n",
      "Epoch 220/600\n",
      "3731/3731 [==============================] - 0s 65us/step - loss: 0.3352 - acc: 0.8579 - val_loss: 0.2765 - val_acc: 0.8819\n",
      "Epoch 221/600\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.3365 - acc: 0.8547 - val_loss: 0.2762 - val_acc: 0.8795\n",
      "Epoch 222/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3350 - acc: 0.8561 - val_loss: 0.2719 - val_acc: 0.8867\n",
      "Epoch 223/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3354 - acc: 0.8561 - val_loss: 0.2724 - val_acc: 0.8843\n",
      "Epoch 224/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3353 - acc: 0.8550 - val_loss: 0.2788 - val_acc: 0.8819\n",
      "Epoch 225/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3370 - acc: 0.8539 - val_loss: 0.2837 - val_acc: 0.8795\n",
      "Epoch 226/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3343 - acc: 0.8539 - val_loss: 0.2771 - val_acc: 0.8867\n",
      "Epoch 227/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3348 - acc: 0.8561 - val_loss: 0.2839 - val_acc: 0.8795\n",
      "Epoch 228/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3347 - acc: 0.8596 - val_loss: 0.2805 - val_acc: 0.8795\n",
      "Epoch 229/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3359 - acc: 0.8555 - val_loss: 0.2747 - val_acc: 0.8916\n",
      "Epoch 230/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3349 - acc: 0.8547 - val_loss: 0.2820 - val_acc: 0.8795\n",
      "Epoch 231/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3348 - acc: 0.8555 - val_loss: 0.2813 - val_acc: 0.8819\n",
      "Epoch 232/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3353 - acc: 0.8555 - val_loss: 0.2822 - val_acc: 0.8819\n",
      "Epoch 233/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3342 - acc: 0.8558 - val_loss: 0.2820 - val_acc: 0.8819\n",
      "Epoch 234/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3351 - acc: 0.8534 - val_loss: 0.2822 - val_acc: 0.8771\n",
      "Epoch 235/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3349 - acc: 0.8558 - val_loss: 0.2891 - val_acc: 0.8795\n",
      "Epoch 236/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3338 - acc: 0.8555 - val_loss: 0.2852 - val_acc: 0.8819\n",
      "Epoch 237/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3341 - acc: 0.8563 - val_loss: 0.2867 - val_acc: 0.8795\n",
      "Epoch 238/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3348 - acc: 0.8582 - val_loss: 0.2875 - val_acc: 0.8795\n",
      "Epoch 239/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3336 - acc: 0.8547 - val_loss: 0.2860 - val_acc: 0.8795\n",
      "Epoch 240/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3349 - acc: 0.8545 - val_loss: 0.2832 - val_acc: 0.8795\n",
      "Epoch 241/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3342 - acc: 0.8537 - val_loss: 0.2826 - val_acc: 0.8795\n",
      "Epoch 242/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3337 - acc: 0.8563 - val_loss: 0.2852 - val_acc: 0.8795\n",
      "Epoch 243/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3356 - acc: 0.8534 - val_loss: 0.2855 - val_acc: 0.8795\n",
      "Epoch 244/600\n",
      "3731/3731 [==============================] - 0s 56us/step - loss: 0.3336 - acc: 0.8555 - val_loss: 0.2795 - val_acc: 0.8795\n",
      "Epoch 245/600\n",
      "3731/3731 [==============================] - 0s 59us/step - loss: 0.3336 - acc: 0.8553 - val_loss: 0.2855 - val_acc: 0.8771\n",
      "Epoch 246/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3337 - acc: 0.8553 - val_loss: 0.2888 - val_acc: 0.8795\n",
      "Epoch 247/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3334 - acc: 0.8553 - val_loss: 0.2849 - val_acc: 0.8795\n",
      "Epoch 248/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3348 - acc: 0.8531 - val_loss: 0.2835 - val_acc: 0.8795\n",
      "Epoch 249/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3337 - acc: 0.8561 - val_loss: 0.2825 - val_acc: 0.8771\n",
      "Epoch 250/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3339 - acc: 0.8561 - val_loss: 0.2863 - val_acc: 0.8795\n",
      "Epoch 251/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3335 - acc: 0.8547 - val_loss: 0.2848 - val_acc: 0.8819\n",
      "Epoch 252/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3332 - acc: 0.8555 - val_loss: 0.2828 - val_acc: 0.8771\n",
      "Epoch 253/600\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3335 - acc: 0.8545 - val_loss: 0.2873 - val_acc: 0.8795\n",
      "Epoch 254/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3339 - acc: 0.8550 - val_loss: 0.2831 - val_acc: 0.8795\n",
      "Epoch 255/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3335 - acc: 0.8553 - val_loss: 0.2880 - val_acc: 0.8795\n",
      "Epoch 256/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3340 - acc: 0.8555 - val_loss: 0.2845 - val_acc: 0.8795\n",
      "Epoch 257/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3330 - acc: 0.8579 - val_loss: 0.2832 - val_acc: 0.8795\n",
      "Epoch 258/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3324 - acc: 0.8571 - val_loss: 0.2853 - val_acc: 0.8795\n",
      "Epoch 259/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3321 - acc: 0.8553 - val_loss: 0.2770 - val_acc: 0.8892\n",
      "Epoch 260/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3334 - acc: 0.8531 - val_loss: 0.2824 - val_acc: 0.8795\n",
      "Epoch 261/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3328 - acc: 0.8555 - val_loss: 0.2823 - val_acc: 0.8771\n",
      "Epoch 262/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3339 - acc: 0.8566 - val_loss: 0.2868 - val_acc: 0.8795\n",
      "Epoch 263/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3328 - acc: 0.8561 - val_loss: 0.2909 - val_acc: 0.8771\n",
      "Epoch 264/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3325 - acc: 0.8561 - val_loss: 0.2831 - val_acc: 0.8795\n",
      "Epoch 265/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3319 - acc: 0.8571 - val_loss: 0.2814 - val_acc: 0.8867\n",
      "Epoch 266/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3315 - acc: 0.8563 - val_loss: 0.2906 - val_acc: 0.8819\n",
      "Epoch 267/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3318 - acc: 0.8558 - val_loss: 0.2898 - val_acc: 0.8795\n",
      "Epoch 268/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3328 - acc: 0.8555 - val_loss: 0.2874 - val_acc: 0.8795\n",
      "Epoch 269/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3317 - acc: 0.8529 - val_loss: 0.2898 - val_acc: 0.8795\n",
      "Epoch 270/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3333 - acc: 0.8545 - val_loss: 0.2879 - val_acc: 0.8771\n",
      "Epoch 271/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3319 - acc: 0.8558 - val_loss: 0.2834 - val_acc: 0.8819\n",
      "Epoch 272/600\n",
      "3731/3731 [==============================] - ETA: 0s - loss: 0.3316 - acc: 0.853 - 0s 46us/step - loss: 0.3322 - acc: 0.8534 - val_loss: 0.2896 - val_acc: 0.8771\n",
      "Epoch 273/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3321 - acc: 0.8547 - val_loss: 0.2862 - val_acc: 0.8747\n",
      "Epoch 274/600\n",
      "3731/3731 [==============================] - 0s 60us/step - loss: 0.3315 - acc: 0.8550 - val_loss: 0.2848 - val_acc: 0.8795: 0s - loss: 0.3355 - acc: 0.85\n",
      "Epoch 275/600\n",
      "3731/3731 [==============================] - 0s 61us/step - loss: 0.3319 - acc: 0.8534 - val_loss: 0.2854 - val_acc: 0.8747\n",
      "Epoch 276/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3322 - acc: 0.8529 - val_loss: 0.2902 - val_acc: 0.8771\n",
      "Epoch 277/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3320 - acc: 0.8569 - val_loss: 0.2865 - val_acc: 0.8771\n",
      "Epoch 278/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3315 - acc: 0.8542 - val_loss: 0.2902 - val_acc: 0.8771\n",
      "Epoch 279/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3314 - acc: 0.8531 - val_loss: 0.2890 - val_acc: 0.8795\n",
      "Epoch 280/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3327 - acc: 0.8566 - val_loss: 0.2886 - val_acc: 0.8771\n",
      "Epoch 281/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3308 - acc: 0.8588 - val_loss: 0.2827 - val_acc: 0.8819\n",
      "Epoch 282/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3324 - acc: 0.8531 - val_loss: 0.2856 - val_acc: 0.8771\n",
      "Epoch 283/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3308 - acc: 0.8561 - val_loss: 0.2914 - val_acc: 0.8795\n",
      "Epoch 284/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3312 - acc: 0.8537 - val_loss: 0.2877 - val_acc: 0.8795\n",
      "Epoch 285/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3311 - acc: 0.8563 - val_loss: 0.2865 - val_acc: 0.8747\n",
      "Epoch 286/600\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3310 - acc: 0.8569 - val_loss: 0.2915 - val_acc: 0.8723\n",
      "Epoch 287/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3314 - acc: 0.8571 - val_loss: 0.3026 - val_acc: 0.8819\n",
      "Epoch 288/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3307 - acc: 0.8569 - val_loss: 0.2973 - val_acc: 0.8747\n",
      "Epoch 289/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3318 - acc: 0.8577 - val_loss: 0.2929 - val_acc: 0.8771\n",
      "Epoch 290/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3312 - acc: 0.8558 - val_loss: 0.2971 - val_acc: 0.8747\n",
      "Epoch 291/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3299 - acc: 0.8569 - val_loss: 0.2978 - val_acc: 0.8819\n",
      "Epoch 292/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3320 - acc: 0.8539 - val_loss: 0.2916 - val_acc: 0.8747\n",
      "Epoch 293/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3301 - acc: 0.8569 - val_loss: 0.2907 - val_acc: 0.8747\n",
      "Epoch 294/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3309 - acc: 0.8539 - val_loss: 0.2975 - val_acc: 0.8843\n",
      "Epoch 295/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3312 - acc: 0.8547 - val_loss: 0.2875 - val_acc: 0.8795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 296/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3299 - acc: 0.8542 - val_loss: 0.2892 - val_acc: 0.8747\n",
      "Epoch 297/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3312 - acc: 0.8547 - val_loss: 0.2911 - val_acc: 0.8747\n",
      "Epoch 298/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3301 - acc: 0.8561 - val_loss: 0.2943 - val_acc: 0.8747\n",
      "Epoch 299/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3305 - acc: 0.8561 - val_loss: 0.3026 - val_acc: 0.8843\n",
      "Epoch 300/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3308 - acc: 0.8558 - val_loss: 0.2924 - val_acc: 0.8771\n",
      "Epoch 301/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3297 - acc: 0.8534 - val_loss: 0.2954 - val_acc: 0.8843\n",
      "Epoch 302/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3306 - acc: 0.8574 - val_loss: 0.2978 - val_acc: 0.8771\n",
      "Epoch 303/600\n",
      "3731/3731 [==============================] - 0s 62us/step - loss: 0.3292 - acc: 0.8529 - val_loss: 0.2888 - val_acc: 0.8771\n",
      "Epoch 304/600\n",
      "3731/3731 [==============================] - 0s 77us/step - loss: 0.3302 - acc: 0.8563 - val_loss: 0.2923 - val_acc: 0.8771\n",
      "Epoch 305/600\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3294 - acc: 0.8550 - val_loss: 0.2949 - val_acc: 0.8795\n",
      "Epoch 306/600\n",
      "3731/3731 [==============================] - 0s 60us/step - loss: 0.3297 - acc: 0.8582 - val_loss: 0.2974 - val_acc: 0.8819\n",
      "Epoch 307/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3312 - acc: 0.8518 - val_loss: 0.2929 - val_acc: 0.8747\n",
      "Epoch 308/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3309 - acc: 0.8561 - val_loss: 0.2916 - val_acc: 0.8771\n",
      "Epoch 309/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3301 - acc: 0.8555 - val_loss: 0.2924 - val_acc: 0.8771\n",
      "Epoch 310/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3295 - acc: 0.8547 - val_loss: 0.2876 - val_acc: 0.8771\n",
      "Epoch 311/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3294 - acc: 0.8553 - val_loss: 0.2952 - val_acc: 0.8747\n",
      "Epoch 312/600\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3302 - acc: 0.8571 - val_loss: 0.2936 - val_acc: 0.8771\n",
      "Epoch 313/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3307 - acc: 0.8545 - val_loss: 0.2888 - val_acc: 0.8771\n",
      "Epoch 314/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3296 - acc: 0.8550 - val_loss: 0.2964 - val_acc: 0.8771\n",
      "Epoch 315/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3295 - acc: 0.8553 - val_loss: 0.2933 - val_acc: 0.8771\n",
      "Epoch 316/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3289 - acc: 0.8555 - val_loss: 0.2918 - val_acc: 0.8771\n",
      "Epoch 317/600\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3295 - acc: 0.8555 - val_loss: 0.2948 - val_acc: 0.8771\n",
      "Epoch 318/600\n",
      "3731/3731 [==============================] - 0s 58us/step - loss: 0.3289 - acc: 0.8550 - val_loss: 0.2925 - val_acc: 0.8771\n",
      "Epoch 319/600\n",
      "3731/3731 [==============================] - 0s 43us/step - loss: 0.3304 - acc: 0.8555 - val_loss: 0.2938 - val_acc: 0.8747\n",
      "Epoch 320/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3293 - acc: 0.8521 - val_loss: 0.2895 - val_acc: 0.8771\n",
      "Epoch 321/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3292 - acc: 0.8550 - val_loss: 0.2973 - val_acc: 0.8771\n",
      "Epoch 322/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3298 - acc: 0.8577 - val_loss: 0.2977 - val_acc: 0.8747\n",
      "Epoch 323/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3270 - acc: 0.8593 - val_loss: 0.2940 - val_acc: 0.8819\n",
      "Epoch 324/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3294 - acc: 0.8574 - val_loss: 0.2940 - val_acc: 0.8771\n",
      "Epoch 325/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3295 - acc: 0.8539 - val_loss: 0.2953 - val_acc: 0.8747\n",
      "Epoch 326/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3293 - acc: 0.8585 - val_loss: 0.2943 - val_acc: 0.8795\n",
      "Epoch 327/600\n",
      "3731/3731 [==============================] - 0s 56us/step - loss: 0.3286 - acc: 0.8569 - val_loss: 0.2948 - val_acc: 0.8771\n",
      "Epoch 328/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3301 - acc: 0.8547 - val_loss: 0.2933 - val_acc: 0.8819\n",
      "Epoch 329/600\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.3284 - acc: 0.8561 - val_loss: 0.2918 - val_acc: 0.8771\n",
      "Epoch 330/600\n",
      "3731/3731 [==============================] - 0s 58us/step - loss: 0.3276 - acc: 0.8558 - val_loss: 0.2920 - val_acc: 0.8747\n",
      "Epoch 331/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3278 - acc: 0.8555 - val_loss: 0.2924 - val_acc: 0.8771\n",
      "Epoch 332/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3291 - acc: 0.8596 - val_loss: 0.2889 - val_acc: 0.8867\n",
      "Epoch 333/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3291 - acc: 0.8585 - val_loss: 0.2898 - val_acc: 0.8795\n",
      "Epoch 334/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3280 - acc: 0.8571 - val_loss: 0.2973 - val_acc: 0.8747\n",
      "Epoch 335/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3280 - acc: 0.8582 - val_loss: 0.2954 - val_acc: 0.8819\n",
      "Epoch 336/600\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3282 - acc: 0.8555 - val_loss: 0.2917 - val_acc: 0.8771\n",
      "Epoch 337/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3285 - acc: 0.8558 - val_loss: 0.2958 - val_acc: 0.8771\n",
      "Epoch 338/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3301 - acc: 0.8561 - val_loss: 0.2932 - val_acc: 0.8771\n",
      "Epoch 339/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3282 - acc: 0.8553 - val_loss: 0.2951 - val_acc: 0.8795\n",
      "Epoch 340/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3275 - acc: 0.8574 - val_loss: 0.2892 - val_acc: 0.8843\n",
      "Epoch 341/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3281 - acc: 0.8596 - val_loss: 0.2913 - val_acc: 0.8771\n",
      "Epoch 342/600\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3279 - acc: 0.8555 - val_loss: 0.2952 - val_acc: 0.8771\n",
      "Epoch 343/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3276 - acc: 0.8588 - val_loss: 0.2973 - val_acc: 0.8747\n",
      "Epoch 344/600\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3268 - acc: 0.8569 - val_loss: 0.2878 - val_acc: 0.8795\n",
      "Epoch 345/600\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3289 - acc: 0.8547 - val_loss: 0.2964 - val_acc: 0.8771\n",
      "Epoch 346/600\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3278 - acc: 0.8571 - val_loss: 0.2958 - val_acc: 0.8771\n",
      "Epoch 347/600\n",
      "3731/3731 [==============================] - 0s 59us/step - loss: 0.3284 - acc: 0.8561 - val_loss: 0.2936 - val_acc: 0.8771\n",
      "Epoch 348/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3277 - acc: 0.8550 - val_loss: 0.2882 - val_acc: 0.8747\n",
      "Epoch 349/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3290 - acc: 0.8566 - val_loss: 0.2937 - val_acc: 0.8747\n",
      "Epoch 350/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3288 - acc: 0.8537 - val_loss: 0.2971 - val_acc: 0.8747\n",
      "Epoch 351/600\n",
      "3731/3731 [==============================] - 0s 58us/step - loss: 0.3279 - acc: 0.8563 - val_loss: 0.2895 - val_acc: 0.8819\n",
      "Epoch 352/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3272 - acc: 0.8590 - val_loss: 0.2933 - val_acc: 0.8795\n",
      "Epoch 353/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3279 - acc: 0.8571 - val_loss: 0.2929 - val_acc: 0.8771\n",
      "Epoch 354/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3271 - acc: 0.8566 - val_loss: 0.2874 - val_acc: 0.8819\n",
      "Epoch 355/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3278 - acc: 0.8566 - val_loss: 0.2873 - val_acc: 0.8795\n",
      "Epoch 356/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3276 - acc: 0.8563 - val_loss: 0.2898 - val_acc: 0.8795\n",
      "Epoch 357/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3282 - acc: 0.8563 - val_loss: 0.2915 - val_acc: 0.8771\n",
      "Epoch 358/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3285 - acc: 0.8596 - val_loss: 0.2871 - val_acc: 0.8795\n",
      "Epoch 359/600\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.3276 - acc: 0.8553 - val_loss: 0.2921 - val_acc: 0.8747\n",
      "Epoch 360/600\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.3278 - acc: 0.8569 - val_loss: 0.2900 - val_acc: 0.8747\n",
      "Epoch 361/600\n",
      "3731/3731 [==============================] - 0s 58us/step - loss: 0.3268 - acc: 0.8579 - val_loss: 0.2913 - val_acc: 0.8771\n",
      "Epoch 362/600\n",
      "3731/3731 [==============================] - 0s 59us/step - loss: 0.3257 - acc: 0.8582 - val_loss: 0.2867 - val_acc: 0.8795\n",
      "Epoch 363/600\n",
      "3731/3731 [==============================] - 0s 58us/step - loss: 0.3271 - acc: 0.8571 - val_loss: 0.2903 - val_acc: 0.8795\n",
      "Epoch 364/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3284 - acc: 0.8547 - val_loss: 0.2868 - val_acc: 0.8819\n",
      "Epoch 365/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3271 - acc: 0.8563 - val_loss: 0.2879 - val_acc: 0.8795\n",
      "Epoch 366/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3277 - acc: 0.8542 - val_loss: 0.2885 - val_acc: 0.8819\n",
      "Epoch 367/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3267 - acc: 0.8563 - val_loss: 0.2921 - val_acc: 0.8819\n",
      "Epoch 368/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3283 - acc: 0.8545 - val_loss: 0.2876 - val_acc: 0.8795\n",
      "Epoch 369/600\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3260 - acc: 0.8569 - val_loss: 0.2856 - val_acc: 0.8795\n",
      "Epoch 370/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3272 - acc: 0.8550 - val_loss: 0.2922 - val_acc: 0.8795\n",
      "Epoch 371/600\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3271 - acc: 0.8574 - val_loss: 0.2923 - val_acc: 0.8795\n",
      "Epoch 372/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3264 - acc: 0.8585 - val_loss: 0.2929 - val_acc: 0.8747\n",
      "Epoch 373/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3264 - acc: 0.8579 - val_loss: 0.2912 - val_acc: 0.8843\n",
      "Epoch 374/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3270 - acc: 0.8545 - val_loss: 0.2992 - val_acc: 0.8771\n",
      "Epoch 375/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3271 - acc: 0.8555 - val_loss: 0.2907 - val_acc: 0.8795\n",
      "Epoch 376/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3264 - acc: 0.8571 - val_loss: 0.2946 - val_acc: 0.8771\n",
      "Epoch 377/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3265 - acc: 0.8588 - val_loss: 0.2947 - val_acc: 0.8795\n",
      "Epoch 378/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3277 - acc: 0.8547 - val_loss: 0.2917 - val_acc: 0.8795\n",
      "Epoch 379/600\n",
      "3731/3731 [==============================] - 0s 63us/step - loss: 0.3275 - acc: 0.8579 - val_loss: 0.2982 - val_acc: 0.8795\n",
      "Epoch 380/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3265 - acc: 0.8582 - val_loss: 0.2958 - val_acc: 0.8795\n",
      "Epoch 381/600\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3268 - acc: 0.8566 - val_loss: 0.2947 - val_acc: 0.8771\n",
      "Epoch 382/600\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3271 - acc: 0.8569 - val_loss: 0.2992 - val_acc: 0.8795\n",
      "Epoch 383/600\n",
      "3731/3731 [==============================] - 0s 58us/step - loss: 0.3259 - acc: 0.8563 - val_loss: 0.2958 - val_acc: 0.8819\n",
      "Epoch 384/600\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.3270 - acc: 0.8577 - val_loss: 0.2913 - val_acc: 0.8795\n",
      "Epoch 385/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3245 - acc: 0.8596 - val_loss: 0.2951 - val_acc: 0.8795\n",
      "Epoch 386/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3270 - acc: 0.8539 - val_loss: 0.3006 - val_acc: 0.8747\n",
      "Epoch 387/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3261 - acc: 0.8555 - val_loss: 0.2942 - val_acc: 0.8771\n",
      "Epoch 388/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3254 - acc: 0.8571 - val_loss: 0.2968 - val_acc: 0.8771\n",
      "Epoch 389/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3263 - acc: 0.8571 - val_loss: 0.2925 - val_acc: 0.8795\n",
      "Epoch 390/600\n",
      "3731/3731 [==============================] - 0s 69us/step - loss: 0.3249 - acc: 0.8555 - val_loss: 0.2942 - val_acc: 0.8795\n",
      "Epoch 391/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3272 - acc: 0.8577 - val_loss: 0.2902 - val_acc: 0.8771\n",
      "Epoch 392/600\n",
      "3731/3731 [==============================] - 0s 64us/step - loss: 0.3263 - acc: 0.8563 - val_loss: 0.3000 - val_acc: 0.8795\n",
      "Epoch 393/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3254 - acc: 0.8569 - val_loss: 0.2906 - val_acc: 0.8795\n",
      "Epoch 394/600\n",
      "3731/3731 [==============================] - 0s 86us/step - loss: 0.3264 - acc: 0.8555 - val_loss: 0.2930 - val_acc: 0.8747\n",
      "Epoch 395/600\n",
      "3731/3731 [==============================] - 0s 77us/step - loss: 0.3249 - acc: 0.8601 - val_loss: 0.2878 - val_acc: 0.8819\n",
      "Epoch 396/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3269 - acc: 0.8555 - val_loss: 0.2960 - val_acc: 0.8747\n",
      "Epoch 397/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3260 - acc: 0.8534 - val_loss: 0.2985 - val_acc: 0.8771\n",
      "Epoch 398/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3250 - acc: 0.8601 - val_loss: 0.2974 - val_acc: 0.8795\n",
      "Epoch 399/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3262 - acc: 0.8553 - val_loss: 0.2940 - val_acc: 0.8747\n",
      "Epoch 400/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3251 - acc: 0.8571 - val_loss: 0.2964 - val_acc: 0.8819\n",
      "Epoch 401/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3236 - acc: 0.8590 - val_loss: 0.2892 - val_acc: 0.8795\n",
      "Epoch 402/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3262 - acc: 0.8569 - val_loss: 0.2970 - val_acc: 0.8747\n",
      "Epoch 403/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3252 - acc: 0.8569 - val_loss: 0.2939 - val_acc: 0.8819\n",
      "Epoch 404/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3257 - acc: 0.8555 - val_loss: 0.2994 - val_acc: 0.8795\n",
      "Epoch 405/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3259 - acc: 0.8566 - val_loss: 0.2991 - val_acc: 0.8771\n",
      "Epoch 406/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3254 - acc: 0.8550 - val_loss: 0.2959 - val_acc: 0.8795\n",
      "Epoch 407/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3253 - acc: 0.8574 - val_loss: 0.2939 - val_acc: 0.8795\n",
      "Epoch 408/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3245 - acc: 0.8569 - val_loss: 0.2926 - val_acc: 0.8771\n",
      "Epoch 409/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3259 - acc: 0.8574 - val_loss: 0.2862 - val_acc: 0.8819\n",
      "Epoch 410/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3243 - acc: 0.8558 - val_loss: 0.2912 - val_acc: 0.8867\n",
      "Epoch 411/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3251 - acc: 0.8555 - val_loss: 0.2960 - val_acc: 0.8771\n",
      "Epoch 412/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3248 - acc: 0.8579 - val_loss: 0.2937 - val_acc: 0.8795\n",
      "Epoch 413/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3264 - acc: 0.8542 - val_loss: 0.2929 - val_acc: 0.8795\n",
      "Epoch 414/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3255 - acc: 0.8550 - val_loss: 0.2928 - val_acc: 0.8819\n",
      "Epoch 415/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3254 - acc: 0.8593 - val_loss: 0.2956 - val_acc: 0.8819\n",
      "Epoch 416/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3249 - acc: 0.8566 - val_loss: 0.2888 - val_acc: 0.8819\n",
      "Epoch 417/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3249 - acc: 0.8571 - val_loss: 0.2932 - val_acc: 0.8795\n",
      "Epoch 418/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3243 - acc: 0.8547 - val_loss: 0.2958 - val_acc: 0.8795\n",
      "Epoch 419/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3239 - acc: 0.8531 - val_loss: 0.2937 - val_acc: 0.8795\n",
      "Epoch 420/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3243 - acc: 0.8555 - val_loss: 0.2969 - val_acc: 0.8819\n",
      "Epoch 421/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3244 - acc: 0.8569 - val_loss: 0.2993 - val_acc: 0.8843\n",
      "Epoch 422/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3247 - acc: 0.8566 - val_loss: 0.2947 - val_acc: 0.8795\n",
      "Epoch 423/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3257 - acc: 0.8553 - val_loss: 0.2916 - val_acc: 0.8795\n",
      "Epoch 424/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3243 - acc: 0.8601 - val_loss: 0.2906 - val_acc: 0.8843\n",
      "Epoch 425/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3242 - acc: 0.8563 - val_loss: 0.2942 - val_acc: 0.8771\n",
      "Epoch 426/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3247 - acc: 0.8561 - val_loss: 0.2943 - val_acc: 0.8747\n",
      "Epoch 427/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3248 - acc: 0.8574 - val_loss: 0.2943 - val_acc: 0.8843\n",
      "Epoch 428/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3243 - acc: 0.8563 - val_loss: 0.2881 - val_acc: 0.8843\n",
      "Epoch 429/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3240 - acc: 0.8579 - val_loss: 0.2932 - val_acc: 0.8795\n",
      "Epoch 430/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3238 - acc: 0.8577 - val_loss: 0.2931 - val_acc: 0.8843\n",
      "Epoch 431/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3231 - acc: 0.8579 - val_loss: 0.2901 - val_acc: 0.8819\n",
      "Epoch 432/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3240 - acc: 0.8582 - val_loss: 0.2929 - val_acc: 0.8819\n",
      "Epoch 433/600\n",
      "3731/3731 [==============================] - ETA: 0s - loss: 0.3239 - acc: 0.854 - 0s 47us/step - loss: 0.3242 - acc: 0.8542 - val_loss: 0.2937 - val_acc: 0.8795\n",
      "Epoch 434/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3241 - acc: 0.8571 - val_loss: 0.2955 - val_acc: 0.8843\n",
      "Epoch 435/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3247 - acc: 0.8563 - val_loss: 0.2912 - val_acc: 0.8771\n",
      "Epoch 436/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3236 - acc: 0.8553 - val_loss: 0.2892 - val_acc: 0.8795\n",
      "Epoch 437/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3248 - acc: 0.8588 - val_loss: 0.2867 - val_acc: 0.8867\n",
      "Epoch 438/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3243 - acc: 0.8571 - val_loss: 0.2892 - val_acc: 0.8867\n",
      "Epoch 439/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3247 - acc: 0.8571 - val_loss: 0.2881 - val_acc: 0.8819\n",
      "Epoch 440/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3247 - acc: 0.8574 - val_loss: 0.2909 - val_acc: 0.8795\n",
      "Epoch 441/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3239 - acc: 0.8617 - val_loss: 0.2943 - val_acc: 0.8819\n",
      "Epoch 442/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3252 - acc: 0.8539 - val_loss: 0.2907 - val_acc: 0.8795\n",
      "Epoch 443/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3240 - acc: 0.8566 - val_loss: 0.2991 - val_acc: 0.8771\n",
      "Epoch 444/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3233 - acc: 0.8579 - val_loss: 0.2900 - val_acc: 0.8819\n",
      "Epoch 445/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3228 - acc: 0.8582 - val_loss: 0.2938 - val_acc: 0.8771\n",
      "Epoch 446/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3230 - acc: 0.8558 - val_loss: 0.2891 - val_acc: 0.8843\n",
      "Epoch 447/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3233 - acc: 0.8550 - val_loss: 0.2854 - val_acc: 0.8843\n",
      "Epoch 448/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3245 - acc: 0.8574 - val_loss: 0.2858 - val_acc: 0.8795\n",
      "Epoch 449/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3237 - acc: 0.8550 - val_loss: 0.2844 - val_acc: 0.8843\n",
      "Epoch 450/600\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3234 - acc: 0.8555 - val_loss: 0.2916 - val_acc: 0.8795\n",
      "Epoch 451/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3247 - acc: 0.8526 - val_loss: 0.2972 - val_acc: 0.8747\n",
      "Epoch 452/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3254 - acc: 0.8550 - val_loss: 0.2906 - val_acc: 0.8819\n",
      "Epoch 453/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3239 - acc: 0.8566 - val_loss: 0.2928 - val_acc: 0.8819\n",
      "Epoch 454/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3234 - acc: 0.8582 - val_loss: 0.2883 - val_acc: 0.8795\n",
      "Epoch 455/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3231 - acc: 0.8537 - val_loss: 0.2976 - val_acc: 0.8723\n",
      "Epoch 456/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3241 - acc: 0.8558 - val_loss: 0.2896 - val_acc: 0.8795\n",
      "Epoch 457/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3234 - acc: 0.8539 - val_loss: 0.2967 - val_acc: 0.8795\n",
      "Epoch 458/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3237 - acc: 0.8561 - val_loss: 0.2911 - val_acc: 0.8771\n",
      "Epoch 459/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3239 - acc: 0.8566 - val_loss: 0.2981 - val_acc: 0.8771\n",
      "Epoch 460/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3237 - acc: 0.8588 - val_loss: 0.2943 - val_acc: 0.8771\n",
      "Epoch 461/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3244 - acc: 0.8515 - val_loss: 0.2836 - val_acc: 0.8867\n",
      "Epoch 462/600\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3235 - acc: 0.8569 - val_loss: 0.2964 - val_acc: 0.8819\n",
      "Epoch 463/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3229 - acc: 0.8585 - val_loss: 0.2911 - val_acc: 0.8795\n",
      "Epoch 464/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3241 - acc: 0.8553 - val_loss: 0.2916 - val_acc: 0.8795\n",
      "Epoch 465/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3234 - acc: 0.8539 - val_loss: 0.2934 - val_acc: 0.8819\n",
      "Epoch 466/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3215 - acc: 0.8585 - val_loss: 0.2949 - val_acc: 0.8819\n",
      "Epoch 467/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3240 - acc: 0.8593 - val_loss: 0.2905 - val_acc: 0.8795\n",
      "Epoch 468/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3227 - acc: 0.8585 - val_loss: 0.2917 - val_acc: 0.8819\n",
      "Epoch 469/600\n",
      "3731/3731 [==============================] - 0s 44us/step - loss: 0.3259 - acc: 0.8534 - val_loss: 0.2980 - val_acc: 0.8771\n",
      "Epoch 470/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3230 - acc: 0.8553 - val_loss: 0.2903 - val_acc: 0.8819\n",
      "Epoch 471/600\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3225 - acc: 0.8582 - val_loss: 0.2870 - val_acc: 0.8819\n",
      "Epoch 472/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3224 - acc: 0.8574 - val_loss: 0.2881 - val_acc: 0.8795\n",
      "Epoch 473/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3230 - acc: 0.8555 - val_loss: 0.2972 - val_acc: 0.8795\n",
      "Epoch 474/600\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3229 - acc: 0.8582 - val_loss: 0.2972 - val_acc: 0.8795\n",
      "Epoch 475/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3237 - acc: 0.8566 - val_loss: 0.2881 - val_acc: 0.8795\n",
      "Epoch 476/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3227 - acc: 0.8569 - val_loss: 0.2890 - val_acc: 0.8795\n",
      "Epoch 477/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3233 - acc: 0.8585 - val_loss: 0.2864 - val_acc: 0.8795\n",
      "Epoch 478/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3244 - acc: 0.8577 - val_loss: 0.2881 - val_acc: 0.8795\n",
      "Epoch 479/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3215 - acc: 0.8566 - val_loss: 0.2889 - val_acc: 0.8819\n",
      "Epoch 480/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3223 - acc: 0.8545 - val_loss: 0.2935 - val_acc: 0.8771\n",
      "Epoch 481/600\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3240 - acc: 0.8566 - val_loss: 0.2967 - val_acc: 0.8747\n",
      "Epoch 482/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3231 - acc: 0.8571 - val_loss: 0.2920 - val_acc: 0.8771\n",
      "Epoch 483/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3228 - acc: 0.8542 - val_loss: 0.2940 - val_acc: 0.8795\n",
      "Epoch 484/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3223 - acc: 0.8558 - val_loss: 0.3005 - val_acc: 0.8795\n",
      "Epoch 485/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3235 - acc: 0.8550 - val_loss: 0.2889 - val_acc: 0.8795\n",
      "Epoch 486/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3235 - acc: 0.8521 - val_loss: 0.3015 - val_acc: 0.8819\n",
      "Epoch 487/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3233 - acc: 0.8569 - val_loss: 0.2976 - val_acc: 0.8795\n",
      "Epoch 488/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3213 - acc: 0.8577 - val_loss: 0.2977 - val_acc: 0.8771\n",
      "Epoch 489/600\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.3219 - acc: 0.8588 - val_loss: 0.2902 - val_acc: 0.8795\n",
      "Epoch 490/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3225 - acc: 0.8569 - val_loss: 0.2956 - val_acc: 0.8795\n",
      "Epoch 491/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3232 - acc: 0.8553 - val_loss: 0.2946 - val_acc: 0.8819\n",
      "Epoch 492/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3224 - acc: 0.8588 - val_loss: 0.2945 - val_acc: 0.8771\n",
      "Epoch 493/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3220 - acc: 0.8553 - val_loss: 0.2945 - val_acc: 0.8795\n",
      "Epoch 494/600\n",
      "3731/3731 [==============================] - ETA: 0s - loss: 0.3235 - acc: 0.856 - 0s 47us/step - loss: 0.3240 - acc: 0.8566 - val_loss: 0.2878 - val_acc: 0.8843\n",
      "Epoch 495/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3223 - acc: 0.8579 - val_loss: 0.2951 - val_acc: 0.8819\n",
      "Epoch 496/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3218 - acc: 0.8593 - val_loss: 0.2910 - val_acc: 0.8819\n",
      "Epoch 497/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3226 - acc: 0.8579 - val_loss: 0.2883 - val_acc: 0.8795\n",
      "Epoch 498/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3231 - acc: 0.8569 - val_loss: 0.2883 - val_acc: 0.8843\n",
      "Epoch 499/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3217 - acc: 0.8585 - val_loss: 0.2928 - val_acc: 0.8819\n",
      "Epoch 500/600\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3226 - acc: 0.8558 - val_loss: 0.2870 - val_acc: 0.8843\n",
      "Epoch 501/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3226 - acc: 0.8539 - val_loss: 0.2959 - val_acc: 0.8795\n",
      "Epoch 502/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3222 - acc: 0.8553 - val_loss: 0.2926 - val_acc: 0.8795\n",
      "Epoch 503/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3214 - acc: 0.8590 - val_loss: 0.2916 - val_acc: 0.8795\n",
      "Epoch 504/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3210 - acc: 0.8579 - val_loss: 0.2944 - val_acc: 0.8795\n",
      "Epoch 505/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3225 - acc: 0.8558 - val_loss: 0.2932 - val_acc: 0.8819\n",
      "Epoch 506/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3225 - acc: 0.8558 - val_loss: 0.3061 - val_acc: 0.8795\n",
      "Epoch 507/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3217 - acc: 0.8547 - val_loss: 0.2975 - val_acc: 0.8771\n",
      "Epoch 508/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3233 - acc: 0.8553 - val_loss: 0.2946 - val_acc: 0.8795\n",
      "Epoch 509/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3211 - acc: 0.8577 - val_loss: 0.2892 - val_acc: 0.8819\n",
      "Epoch 510/600\n",
      "3731/3731 [==============================] - 0s 61us/step - loss: 0.3219 - acc: 0.8547 - val_loss: 0.2908 - val_acc: 0.8819\n",
      "Epoch 511/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3218 - acc: 0.8585 - val_loss: 0.2905 - val_acc: 0.8819\n",
      "Epoch 512/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3232 - acc: 0.8561 - val_loss: 0.2905 - val_acc: 0.8819\n",
      "Epoch 513/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3215 - acc: 0.8579 - val_loss: 0.2923 - val_acc: 0.8795\n",
      "Epoch 514/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3207 - acc: 0.8574 - val_loss: 0.2914 - val_acc: 0.8771\n",
      "Epoch 515/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3203 - acc: 0.8590 - val_loss: 0.2880 - val_acc: 0.8819\n",
      "Epoch 516/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3209 - acc: 0.8588 - val_loss: 0.2905 - val_acc: 0.8819\n",
      "Epoch 517/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3210 - acc: 0.8566 - val_loss: 0.2873 - val_acc: 0.8795\n",
      "Epoch 518/600\n",
      "3731/3731 [==============================] - 0s 59us/step - loss: 0.3211 - acc: 0.8558 - val_loss: 0.2931 - val_acc: 0.8795\n",
      "Epoch 519/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3227 - acc: 0.8547 - val_loss: 0.2894 - val_acc: 0.8795\n",
      "Epoch 520/600\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3215 - acc: 0.8577 - val_loss: 0.2913 - val_acc: 0.8795\n",
      "Epoch 521/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3228 - acc: 0.8550 - val_loss: 0.2933 - val_acc: 0.8771\n",
      "Epoch 522/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3206 - acc: 0.8577 - val_loss: 0.2899 - val_acc: 0.8819\n",
      "Epoch 523/600\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3217 - acc: 0.8566 - val_loss: 0.2951 - val_acc: 0.8771\n",
      "Epoch 524/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3212 - acc: 0.8601 - val_loss: 0.2956 - val_acc: 0.8819\n",
      "Epoch 525/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3213 - acc: 0.8571 - val_loss: 0.2883 - val_acc: 0.8819\n",
      "Epoch 526/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3203 - acc: 0.8577 - val_loss: 0.2903 - val_acc: 0.8795\n",
      "Epoch 527/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3215 - acc: 0.8585 - val_loss: 0.2951 - val_acc: 0.8771\n",
      "Epoch 528/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3208 - acc: 0.8561 - val_loss: 0.2963 - val_acc: 0.8819\n",
      "Epoch 529/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3216 - acc: 0.8550 - val_loss: 0.2980 - val_acc: 0.8771\n",
      "Epoch 530/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3206 - acc: 0.8582 - val_loss: 0.2940 - val_acc: 0.8819\n",
      "Epoch 531/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3205 - acc: 0.8537 - val_loss: 0.2959 - val_acc: 0.8819\n",
      "Epoch 532/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3228 - acc: 0.8577 - val_loss: 0.2920 - val_acc: 0.8795\n",
      "Epoch 533/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3206 - acc: 0.8550 - val_loss: 0.2951 - val_acc: 0.8771\n",
      "Epoch 534/600\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3207 - acc: 0.8571 - val_loss: 0.2958 - val_acc: 0.8843\n",
      "Epoch 535/600\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.3202 - acc: 0.8558 - val_loss: 0.2895 - val_acc: 0.8819\n",
      "Epoch 536/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3221 - acc: 0.8569 - val_loss: 0.2938 - val_acc: 0.8819\n",
      "Epoch 537/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3221 - acc: 0.8553 - val_loss: 0.2931 - val_acc: 0.8819\n",
      "Epoch 538/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3207 - acc: 0.8542 - val_loss: 0.2922 - val_acc: 0.8819\n",
      "Epoch 539/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3198 - acc: 0.8561 - val_loss: 0.2916 - val_acc: 0.8843\n",
      "Epoch 540/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3196 - acc: 0.8609 - val_loss: 0.2898 - val_acc: 0.8843\n",
      "Epoch 541/600\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3210 - acc: 0.8585 - val_loss: 0.2950 - val_acc: 0.8795\n",
      "Epoch 542/600\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3205 - acc: 0.8585 - val_loss: 0.2917 - val_acc: 0.8819\n",
      "Epoch 543/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3194 - acc: 0.8566 - val_loss: 0.2895 - val_acc: 0.8819\n",
      "Epoch 544/600\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3206 - acc: 0.8577 - val_loss: 0.2991 - val_acc: 0.8795\n",
      "Epoch 545/600\n",
      "3731/3731 [==============================] - 0s 44us/step - loss: 0.3210 - acc: 0.8550 - val_loss: 0.2854 - val_acc: 0.8867\n",
      "Epoch 546/600\n",
      "3731/3731 [==============================] - 0s 44us/step - loss: 0.3198 - acc: 0.8558 - val_loss: 0.2874 - val_acc: 0.8819\n",
      "Epoch 547/600\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3215 - acc: 0.8588 - val_loss: 0.2963 - val_acc: 0.8819\n",
      "Epoch 548/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3220 - acc: 0.8588 - val_loss: 0.2942 - val_acc: 0.8819\n",
      "Epoch 549/600\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3214 - acc: 0.8588 - val_loss: 0.2912 - val_acc: 0.8795\n",
      "Epoch 550/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3206 - acc: 0.8598 - val_loss: 0.2980 - val_acc: 0.8747\n",
      "Epoch 551/600\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.3189 - acc: 0.8630 - val_loss: 0.2910 - val_acc: 0.8819\n",
      "Epoch 552/600\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.3203 - acc: 0.8582 - val_loss: 0.2907 - val_acc: 0.8843\n",
      "Epoch 553/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3204 - acc: 0.8571 - val_loss: 0.2947 - val_acc: 0.8819\n",
      "Epoch 554/600\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.3220 - acc: 0.8574 - val_loss: 0.2955 - val_acc: 0.8771\n",
      "Epoch 555/600\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3188 - acc: 0.8593 - val_loss: 0.3020 - val_acc: 0.8771\n",
      "Epoch 556/600\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3203 - acc: 0.8633 - val_loss: 0.2914 - val_acc: 0.8819\n",
      "Epoch 557/600\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3192 - acc: 0.8571 - val_loss: 0.2945 - val_acc: 0.8819\n",
      "Epoch 558/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3217 - acc: 0.8553 - val_loss: 0.2927 - val_acc: 0.8843\n",
      "Epoch 559/600\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3196 - acc: 0.8569 - val_loss: 0.2915 - val_acc: 0.8843\n",
      "Epoch 560/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3203 - acc: 0.8561 - val_loss: 0.2906 - val_acc: 0.8819\n",
      "Epoch 561/600\n",
      "3731/3731 [==============================] - 0s 44us/step - loss: 0.3201 - acc: 0.8577 - val_loss: 0.2922 - val_acc: 0.8795\n",
      "Epoch 562/600\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3207 - acc: 0.8547 - val_loss: 0.2896 - val_acc: 0.8843\n",
      "Epoch 563/600\n",
      "3731/3731 [==============================] - 0s 43us/step - loss: 0.3183 - acc: 0.8604 - val_loss: 0.2932 - val_acc: 0.8771\n",
      "Epoch 564/600\n",
      "3731/3731 [==============================] - 0s 44us/step - loss: 0.3196 - acc: 0.8590 - val_loss: 0.3073 - val_acc: 0.8747\n",
      "Epoch 565/600\n",
      "3731/3731 [==============================] - 0s 44us/step - loss: 0.3207 - acc: 0.8585 - val_loss: 0.2912 - val_acc: 0.8843\n",
      "Epoch 566/600\n",
      "3731/3731 [==============================] - 0s 44us/step - loss: 0.3213 - acc: 0.8566 - val_loss: 0.2940 - val_acc: 0.8819\n",
      "Epoch 567/600\n",
      "3731/3731 [==============================] - 0s 44us/step - loss: 0.3213 - acc: 0.8561 - val_loss: 0.2922 - val_acc: 0.8819\n",
      "Epoch 568/600\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3208 - acc: 0.8593 - val_loss: 0.2871 - val_acc: 0.8867\n",
      "Epoch 569/600\n",
      "3731/3731 [==============================] - 0s 43us/step - loss: 0.3198 - acc: 0.8582 - val_loss: 0.2905 - val_acc: 0.8795\n",
      "Epoch 570/600\n",
      "3731/3731 [==============================] - 0s 43us/step - loss: 0.3200 - acc: 0.8601 - val_loss: 0.2932 - val_acc: 0.8843\n",
      "Epoch 571/600\n",
      "3731/3731 [==============================] - 0s 43us/step - loss: 0.3215 - acc: 0.8542 - val_loss: 0.2953 - val_acc: 0.8795\n",
      "Epoch 572/600\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3191 - acc: 0.8579 - val_loss: 0.2948 - val_acc: 0.8771\n",
      "Epoch 573/600\n",
      "3731/3731 [==============================] - 0s 59us/step - loss: 0.3190 - acc: 0.8590 - val_loss: 0.2978 - val_acc: 0.8795\n",
      "Epoch 574/600\n",
      "3731/3731 [==============================] - 0s 44us/step - loss: 0.3198 - acc: 0.8571 - val_loss: 0.2904 - val_acc: 0.8843\n",
      "Epoch 575/600\n",
      "3731/3731 [==============================] - 0s 44us/step - loss: 0.3199 - acc: 0.8553 - val_loss: 0.2935 - val_acc: 0.8795\n",
      "Epoch 576/600\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3216 - acc: 0.8563 - val_loss: 0.2929 - val_acc: 0.8771\n",
      "Epoch 577/600\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3198 - acc: 0.8582 - val_loss: 0.2938 - val_acc: 0.8843\n",
      "Epoch 578/600\n",
      "3731/3731 [==============================] - 0s 44us/step - loss: 0.3214 - acc: 0.8577 - val_loss: 0.2913 - val_acc: 0.8843\n",
      "Epoch 579/600\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3202 - acc: 0.8585 - val_loss: 0.2857 - val_acc: 0.8916\n",
      "Epoch 580/600\n",
      "3731/3731 [==============================] - 0s 43us/step - loss: 0.3195 - acc: 0.8558 - val_loss: 0.2882 - val_acc: 0.8867\n",
      "Epoch 581/600\n",
      "3731/3731 [==============================] - 0s 43us/step - loss: 0.3204 - acc: 0.8571 - val_loss: 0.2923 - val_acc: 0.8843\n",
      "Epoch 582/600\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3198 - acc: 0.8585 - val_loss: 0.2900 - val_acc: 0.8892\n",
      "Epoch 583/600\n",
      "3731/3731 [==============================] - 0s 44us/step - loss: 0.3194 - acc: 0.8582 - val_loss: 0.2959 - val_acc: 0.8819\n",
      "Epoch 584/600\n",
      "3731/3731 [==============================] - 0s 43us/step - loss: 0.3194 - acc: 0.8585 - val_loss: 0.2912 - val_acc: 0.8867\n",
      "Epoch 585/600\n",
      "3731/3731 [==============================] - 0s 44us/step - loss: 0.3202 - acc: 0.8579 - val_loss: 0.2944 - val_acc: 0.8819\n",
      "Epoch 586/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3203 - acc: 0.8628 - val_loss: 0.2934 - val_acc: 0.8795\n",
      "Epoch 587/600\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3193 - acc: 0.8579 - val_loss: 0.2920 - val_acc: 0.8843\n",
      "Epoch 588/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3194 - acc: 0.8601 - val_loss: 0.2990 - val_acc: 0.8795\n",
      "Epoch 589/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3209 - acc: 0.8598 - val_loss: 0.2893 - val_acc: 0.8819\n",
      "Epoch 590/600\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3199 - acc: 0.8606 - val_loss: 0.3039 - val_acc: 0.8747\n",
      "Epoch 591/600\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3204 - acc: 0.8577 - val_loss: 0.2964 - val_acc: 0.8747\n",
      "Epoch 592/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3197 - acc: 0.8590 - val_loss: 0.2972 - val_acc: 0.8795\n",
      "Epoch 593/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3193 - acc: 0.8593 - val_loss: 0.2933 - val_acc: 0.8819\n",
      "Epoch 594/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3182 - acc: 0.8606 - val_loss: 0.2945 - val_acc: 0.8819\n",
      "Epoch 595/600\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3203 - acc: 0.8590 - val_loss: 0.2888 - val_acc: 0.8819\n",
      "Epoch 596/600\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3192 - acc: 0.8601 - val_loss: 0.2918 - val_acc: 0.8819\n",
      "Epoch 597/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3203 - acc: 0.8601 - val_loss: 0.2876 - val_acc: 0.8916\n",
      "Epoch 598/600\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3204 - acc: 0.8604 - val_loss: 0.2879 - val_acc: 0.8843\n",
      "Epoch 599/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3186 - acc: 0.8622 - val_loss: 0.2994 - val_acc: 0.8771\n",
      "Epoch 600/600\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3201 - acc: 0.8582 - val_loss: 0.2950 - val_acc: 0.8771\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(8, kernel_initializer='normal', input_dim=len(X[0]), activation='relu'))\n",
    "model.add(Dense(8, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X, y.values, epochs=600, validation_split = 0.1)\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T17:39:13.305641Z",
     "start_time": "2019-09-13T17:38:36.911299Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3731 samples, validate on 415 samples\n",
      "Epoch 1/200\n",
      "3731/3731 [==============================] - 1s 222us/step - loss: 0.6592 - acc: 0.7242 - val_loss: 0.5421 - val_acc: 0.8193\n",
      "Epoch 2/200\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.5125 - acc: 0.8094 - val_loss: 0.3828 - val_acc: 0.8530\n",
      "Epoch 3/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.4310 - acc: 0.8250 - val_loss: 0.3368 - val_acc: 0.8675\n",
      "Epoch 4/200\n",
      "3731/3731 [==============================] - 0s 44us/step - loss: 0.4086 - acc: 0.8319 - val_loss: 0.3287 - val_acc: 0.8699\n",
      "Epoch 5/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.4018 - acc: 0.8290 - val_loss: 0.3251 - val_acc: 0.8651\n",
      "Epoch 6/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3983 - acc: 0.8319 - val_loss: 0.3218 - val_acc: 0.8675\n",
      "Epoch 7/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3954 - acc: 0.8338 - val_loss: 0.3194 - val_acc: 0.8627\n",
      "Epoch 8/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3923 - acc: 0.8360 - val_loss: 0.3193 - val_acc: 0.8675\n",
      "Epoch 9/200\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3916 - acc: 0.8317 - val_loss: 0.3155 - val_acc: 0.8723\n",
      "Epoch 10/200\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3896 - acc: 0.8376 - val_loss: 0.3123 - val_acc: 0.8771\n",
      "Epoch 11/200\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3872 - acc: 0.8354 - val_loss: 0.3126 - val_acc: 0.8699\n",
      "Epoch 12/200\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3858 - acc: 0.8346 - val_loss: 0.3088 - val_acc: 0.8771\n",
      "Epoch 13/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3848 - acc: 0.8368 - val_loss: 0.3074 - val_acc: 0.8723\n",
      "Epoch 14/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3831 - acc: 0.8333 - val_loss: 0.3046 - val_acc: 0.8747\n",
      "Epoch 15/200\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3819 - acc: 0.8336 - val_loss: 0.3048 - val_acc: 0.8675\n",
      "Epoch 16/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3811 - acc: 0.8346 - val_loss: 0.3031 - val_acc: 0.8651\n",
      "Epoch 17/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3796 - acc: 0.8344 - val_loss: 0.3009 - val_acc: 0.8675\n",
      "Epoch 18/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3786 - acc: 0.8349 - val_loss: 0.3009 - val_acc: 0.8699\n",
      "Epoch 19/200\n",
      "3731/3731 [==============================] - 0s 43us/step - loss: 0.3780 - acc: 0.8330 - val_loss: 0.2995 - val_acc: 0.8675\n",
      "Epoch 20/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3766 - acc: 0.8357 - val_loss: 0.2984 - val_acc: 0.8723\n",
      "Epoch 21/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3763 - acc: 0.8338 - val_loss: 0.2960 - val_acc: 0.8723\n",
      "Epoch 22/200\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3751 - acc: 0.8328 - val_loss: 0.2966 - val_acc: 0.8723\n",
      "Epoch 23/200\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3742 - acc: 0.8352 - val_loss: 0.2963 - val_acc: 0.8747\n",
      "Epoch 24/200\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3736 - acc: 0.8328 - val_loss: 0.2950 - val_acc: 0.8819\n",
      "Epoch 25/200\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3732 - acc: 0.8357 - val_loss: 0.2952 - val_acc: 0.8771\n",
      "Epoch 26/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3719 - acc: 0.8338 - val_loss: 0.2963 - val_acc: 0.8771\n",
      "Epoch 27/200\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3714 - acc: 0.8357 - val_loss: 0.2937 - val_acc: 0.8795\n",
      "Epoch 28/200\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3706 - acc: 0.8341 - val_loss: 0.2932 - val_acc: 0.8771\n",
      "Epoch 29/200\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3703 - acc: 0.8344 - val_loss: 0.2943 - val_acc: 0.8771\n",
      "Epoch 30/200\n",
      "3731/3731 [==============================] - 0s 42us/step - loss: 0.3696 - acc: 0.8349 - val_loss: 0.2928 - val_acc: 0.8795\n",
      "Epoch 31/200\n",
      "3731/3731 [==============================] - 0s 43us/step - loss: 0.3691 - acc: 0.8362 - val_loss: 0.2910 - val_acc: 0.8771\n",
      "Epoch 32/200\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3682 - acc: 0.8344 - val_loss: 0.2903 - val_acc: 0.8795\n",
      "Epoch 33/200\n",
      "3731/3731 [==============================] - 0s 43us/step - loss: 0.3677 - acc: 0.8344 - val_loss: 0.2898 - val_acc: 0.8771\n",
      "Epoch 34/200\n",
      "3731/3731 [==============================] - 0s 43us/step - loss: 0.3675 - acc: 0.8349 - val_loss: 0.2909 - val_acc: 0.8819\n",
      "Epoch 35/200\n",
      "3731/3731 [==============================] - 0s 43us/step - loss: 0.3670 - acc: 0.8368 - val_loss: 0.2897 - val_acc: 0.8819\n",
      "Epoch 36/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3669 - acc: 0.8322 - val_loss: 0.2917 - val_acc: 0.8795\n",
      "Epoch 37/200\n",
      "3731/3731 [==============================] - 0s 43us/step - loss: 0.3661 - acc: 0.8344 - val_loss: 0.2881 - val_acc: 0.8795\n",
      "Epoch 38/200\n",
      "3731/3731 [==============================] - 0s 44us/step - loss: 0.3657 - acc: 0.8349 - val_loss: 0.2879 - val_acc: 0.8819\n",
      "Epoch 39/200\n",
      "3731/3731 [==============================] - 0s 43us/step - loss: 0.3655 - acc: 0.8360 - val_loss: 0.2873 - val_acc: 0.8795\n",
      "Epoch 40/200\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3648 - acc: 0.8365 - val_loss: 0.2876 - val_acc: 0.8795\n",
      "Epoch 41/200\n",
      "3731/3731 [==============================] - 0s 43us/step - loss: 0.3648 - acc: 0.8349 - val_loss: 0.2873 - val_acc: 0.8843\n",
      "Epoch 42/200\n",
      "3731/3731 [==============================] - 0s 43us/step - loss: 0.3644 - acc: 0.8344 - val_loss: 0.2876 - val_acc: 0.8843\n",
      "Epoch 43/200\n",
      "3731/3731 [==============================] - 0s 43us/step - loss: 0.3649 - acc: 0.8360 - val_loss: 0.2844 - val_acc: 0.8867\n",
      "Epoch 44/200\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3637 - acc: 0.8381 - val_loss: 0.2871 - val_acc: 0.8795\n",
      "Epoch 45/200\n",
      "3731/3731 [==============================] - 0s 42us/step - loss: 0.3636 - acc: 0.8357 - val_loss: 0.2862 - val_acc: 0.8819\n",
      "Epoch 46/200\n",
      "3731/3731 [==============================] - 0s 43us/step - loss: 0.3631 - acc: 0.8392 - val_loss: 0.2861 - val_acc: 0.8819\n",
      "Epoch 47/200\n",
      "3731/3731 [==============================] - 0s 43us/step - loss: 0.3621 - acc: 0.8395 - val_loss: 0.2851 - val_acc: 0.8867\n",
      "Epoch 48/200\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3630 - acc: 0.8395 - val_loss: 0.2854 - val_acc: 0.8843\n",
      "Epoch 49/200\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3622 - acc: 0.8392 - val_loss: 0.2848 - val_acc: 0.8843\n",
      "Epoch 50/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3621 - acc: 0.8376 - val_loss: 0.2848 - val_acc: 0.8819\n",
      "Epoch 51/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3623 - acc: 0.8370 - val_loss: 0.2842 - val_acc: 0.8843\n",
      "Epoch 52/200\n",
      "3731/3731 [==============================] - 0s 43us/step - loss: 0.3612 - acc: 0.8368 - val_loss: 0.2836 - val_acc: 0.8819\n",
      "Epoch 53/200\n",
      "3731/3731 [==============================] - 0s 44us/step - loss: 0.3609 - acc: 0.8368 - val_loss: 0.2833 - val_acc: 0.8819\n",
      "Epoch 54/200\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3607 - acc: 0.8370 - val_loss: 0.2857 - val_acc: 0.8819\n",
      "Epoch 55/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3603 - acc: 0.8360 - val_loss: 0.2838 - val_acc: 0.8795\n",
      "Epoch 56/200\n",
      "3731/3731 [==============================] - 0s 44us/step - loss: 0.3603 - acc: 0.8378 - val_loss: 0.2824 - val_acc: 0.8843\n",
      "Epoch 57/200\n",
      "3731/3731 [==============================] - 0s 44us/step - loss: 0.3600 - acc: 0.8395 - val_loss: 0.2833 - val_acc: 0.8819\n",
      "Epoch 58/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3605 - acc: 0.8395 - val_loss: 0.2827 - val_acc: 0.8843\n",
      "Epoch 59/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3601 - acc: 0.8373 - val_loss: 0.2828 - val_acc: 0.8819\n",
      "Epoch 60/200\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3591 - acc: 0.8381 - val_loss: 0.2797 - val_acc: 0.8916\n",
      "Epoch 61/200\n",
      "3731/3731 [==============================] - 0s 44us/step - loss: 0.3593 - acc: 0.8403 - val_loss: 0.2803 - val_acc: 0.8795\n",
      "Epoch 62/200\n",
      "3731/3731 [==============================] - 0s 44us/step - loss: 0.3587 - acc: 0.8392 - val_loss: 0.2813 - val_acc: 0.8843\n",
      "Epoch 63/200\n",
      "3731/3731 [==============================] - 0s 44us/step - loss: 0.3590 - acc: 0.8368 - val_loss: 0.2828 - val_acc: 0.8795\n",
      "Epoch 64/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3593 - acc: 0.8397 - val_loss: 0.2782 - val_acc: 0.8819\n",
      "Epoch 65/200\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3584 - acc: 0.8389 - val_loss: 0.2805 - val_acc: 0.8795\n",
      "Epoch 66/200\n",
      "3731/3731 [==============================] - 0s 44us/step - loss: 0.3582 - acc: 0.8405 - val_loss: 0.2819 - val_acc: 0.8819\n",
      "Epoch 67/200\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3582 - acc: 0.8405 - val_loss: 0.2835 - val_acc: 0.8819\n",
      "Epoch 68/200\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3580 - acc: 0.8386 - val_loss: 0.2800 - val_acc: 0.8819\n",
      "Epoch 69/200\n",
      "3731/3731 [==============================] - 0s 58us/step - loss: 0.3581 - acc: 0.8403 - val_loss: 0.2784 - val_acc: 0.8843\n",
      "Epoch 70/200\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.3576 - acc: 0.8411 - val_loss: 0.2791 - val_acc: 0.8867\n",
      "Epoch 71/200\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.3574 - acc: 0.8389 - val_loss: 0.2790 - val_acc: 0.8819\n",
      "Epoch 72/200\n",
      "3731/3731 [==============================] - 0s 56us/step - loss: 0.3575 - acc: 0.8405 - val_loss: 0.2773 - val_acc: 0.8819\n",
      "Epoch 73/200\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.3570 - acc: 0.8392 - val_loss: 0.2776 - val_acc: 0.8819\n",
      "Epoch 74/200\n",
      "3731/3731 [==============================] - 0s 58us/step - loss: 0.3566 - acc: 0.8424 - val_loss: 0.2798 - val_acc: 0.8819\n",
      "Epoch 75/200\n",
      "3731/3731 [==============================] - 0s 58us/step - loss: 0.3569 - acc: 0.8413 - val_loss: 0.2795 - val_acc: 0.8819\n",
      "Epoch 76/200\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.3566 - acc: 0.8427 - val_loss: 0.2767 - val_acc: 0.8819\n",
      "Epoch 77/200\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3567 - acc: 0.8429 - val_loss: 0.2789 - val_acc: 0.8843\n",
      "Epoch 78/200\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3568 - acc: 0.8400 - val_loss: 0.2770 - val_acc: 0.8867\n",
      "Epoch 79/200\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3562 - acc: 0.8440 - val_loss: 0.2767 - val_acc: 0.8843\n",
      "Epoch 80/200\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3553 - acc: 0.8435 - val_loss: 0.2780 - val_acc: 0.8843\n",
      "Epoch 81/200\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3554 - acc: 0.8411 - val_loss: 0.2755 - val_acc: 0.8843\n",
      "Epoch 82/200\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3557 - acc: 0.8424 - val_loss: 0.2745 - val_acc: 0.8843\n",
      "Epoch 83/200\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3552 - acc: 0.8421 - val_loss: 0.2755 - val_acc: 0.8867\n",
      "Epoch 84/200\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.3554 - acc: 0.8408 - val_loss: 0.2744 - val_acc: 0.8892\n",
      "Epoch 85/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3568 - acc: 0.8416 - val_loss: 0.2751 - val_acc: 0.8843\n",
      "Epoch 86/200\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.3544 - acc: 0.8448 - val_loss: 0.2748 - val_acc: 0.8867\n",
      "Epoch 87/200\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.3546 - acc: 0.8445 - val_loss: 0.2744 - val_acc: 0.8843\n",
      "Epoch 88/200\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3547 - acc: 0.8419 - val_loss: 0.2736 - val_acc: 0.8843\n",
      "Epoch 89/200\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.3546 - acc: 0.8427 - val_loss: 0.2744 - val_acc: 0.8843\n",
      "Epoch 90/200\n",
      "3731/3731 [==============================] - 0s 60us/step - loss: 0.3542 - acc: 0.8445 - val_loss: 0.2740 - val_acc: 0.8867\n",
      "Epoch 91/200\n",
      "3731/3731 [==============================] - 0s 58us/step - loss: 0.3544 - acc: 0.8421 - val_loss: 0.2741 - val_acc: 0.8843\n",
      "Epoch 92/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3537 - acc: 0.8443 - val_loss: 0.2743 - val_acc: 0.8843\n",
      "Epoch 93/200\n",
      "3731/3731 [==============================] - 0s 44us/step - loss: 0.3545 - acc: 0.8413 - val_loss: 0.2727 - val_acc: 0.8819\n",
      "Epoch 94/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3536 - acc: 0.8405 - val_loss: 0.2728 - val_acc: 0.8819\n",
      "Epoch 95/200\n",
      "3731/3731 [==============================] - 0s 44us/step - loss: 0.3539 - acc: 0.8427 - val_loss: 0.2723 - val_acc: 0.8819\n",
      "Epoch 96/200\n",
      "3731/3731 [==============================] - 0s 44us/step - loss: 0.3530 - acc: 0.8429 - val_loss: 0.2698 - val_acc: 0.8867\n",
      "Epoch 97/200\n",
      "3731/3731 [==============================] - 0s 44us/step - loss: 0.3536 - acc: 0.8408 - val_loss: 0.2729 - val_acc: 0.8916\n",
      "Epoch 98/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3535 - acc: 0.8432 - val_loss: 0.2701 - val_acc: 0.8843\n",
      "Epoch 99/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3530 - acc: 0.8440 - val_loss: 0.2733 - val_acc: 0.8867\n",
      "Epoch 100/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3527 - acc: 0.8448 - val_loss: 0.2719 - val_acc: 0.8819\n",
      "Epoch 101/200\n",
      "3731/3731 [==============================] - 0s 44us/step - loss: 0.3528 - acc: 0.8432 - val_loss: 0.2703 - val_acc: 0.8843\n",
      "Epoch 102/200\n",
      "3731/3731 [==============================] - 0s 44us/step - loss: 0.3526 - acc: 0.8427 - val_loss: 0.2743 - val_acc: 0.8892\n",
      "Epoch 103/200\n",
      "3731/3731 [==============================] - 0s 44us/step - loss: 0.3524 - acc: 0.8411 - val_loss: 0.2742 - val_acc: 0.8892\n",
      "Epoch 104/200\n",
      "3731/3731 [==============================] - 0s 44us/step - loss: 0.3523 - acc: 0.8419 - val_loss: 0.2701 - val_acc: 0.8892\n",
      "Epoch 105/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3523 - acc: 0.8429 - val_loss: 0.2705 - val_acc: 0.8843\n",
      "Epoch 106/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3517 - acc: 0.8435 - val_loss: 0.2695 - val_acc: 0.8867\n",
      "Epoch 107/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3519 - acc: 0.8424 - val_loss: 0.2715 - val_acc: 0.8916\n",
      "Epoch 108/200\n",
      "3731/3731 [==============================] - 0s 44us/step - loss: 0.3521 - acc: 0.8386 - val_loss: 0.2710 - val_acc: 0.8892\n",
      "Epoch 109/200\n",
      "3731/3731 [==============================] - 0s 44us/step - loss: 0.3515 - acc: 0.8421 - val_loss: 0.2725 - val_acc: 0.8843\n",
      "Epoch 110/200\n",
      "3731/3731 [==============================] - 0s 44us/step - loss: 0.3518 - acc: 0.8421 - val_loss: 0.2704 - val_acc: 0.8916\n",
      "Epoch 111/200\n",
      "3731/3731 [==============================] - 0s 44us/step - loss: 0.3517 - acc: 0.8448 - val_loss: 0.2743 - val_acc: 0.8892\n",
      "Epoch 112/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3509 - acc: 0.8427 - val_loss: 0.2764 - val_acc: 0.8940\n",
      "Epoch 113/200\n",
      "3731/3731 [==============================] - 0s 43us/step - loss: 0.3507 - acc: 0.8432 - val_loss: 0.2746 - val_acc: 0.8892\n",
      "Epoch 114/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3502 - acc: 0.8419 - val_loss: 0.2756 - val_acc: 0.8892\n",
      "Epoch 115/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3500 - acc: 0.8445 - val_loss: 0.2738 - val_acc: 0.8867\n",
      "Epoch 116/200\n",
      "3731/3731 [==============================] - 0s 44us/step - loss: 0.3508 - acc: 0.8424 - val_loss: 0.2731 - val_acc: 0.8867\n",
      "Epoch 117/200\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3503 - acc: 0.8453 - val_loss: 0.2743 - val_acc: 0.8892\n",
      "Epoch 118/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3494 - acc: 0.8462 - val_loss: 0.2732 - val_acc: 0.8867\n",
      "Epoch 119/200\n",
      "3731/3731 [==============================] - 0s 43us/step - loss: 0.3498 - acc: 0.8419 - val_loss: 0.2727 - val_acc: 0.8916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3504 - acc: 0.8451 - val_loss: 0.2724 - val_acc: 0.8916\n",
      "Epoch 121/200\n",
      "3731/3731 [==============================] - 0s 43us/step - loss: 0.3500 - acc: 0.8456 - val_loss: 0.2754 - val_acc: 0.8916\n",
      "Epoch 122/200\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3503 - acc: 0.8427 - val_loss: 0.2740 - val_acc: 0.8892\n",
      "Epoch 123/200\n",
      "3731/3731 [==============================] - 0s 43us/step - loss: 0.3496 - acc: 0.8445 - val_loss: 0.2745 - val_acc: 0.8892\n",
      "Epoch 124/200\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3495 - acc: 0.8445 - val_loss: 0.2748 - val_acc: 0.8892\n",
      "Epoch 125/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3483 - acc: 0.8456 - val_loss: 0.2757 - val_acc: 0.8916\n",
      "Epoch 126/200\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3492 - acc: 0.8443 - val_loss: 0.2798 - val_acc: 0.8916\n",
      "Epoch 127/200\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3486 - acc: 0.8462 - val_loss: 0.2784 - val_acc: 0.8916\n",
      "Epoch 128/200\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3490 - acc: 0.8432 - val_loss: 0.2785 - val_acc: 0.8916\n",
      "Epoch 129/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3479 - acc: 0.8443 - val_loss: 0.2810 - val_acc: 0.8892\n",
      "Epoch 130/200\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3481 - acc: 0.8437 - val_loss: 0.2758 - val_acc: 0.8916\n",
      "Epoch 131/200\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3487 - acc: 0.8424 - val_loss: 0.2771 - val_acc: 0.8940\n",
      "Epoch 132/200\n",
      "3731/3731 [==============================] - 0s 43us/step - loss: 0.3478 - acc: 0.8427 - val_loss: 0.2804 - val_acc: 0.8867\n",
      "Epoch 133/200\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3480 - acc: 0.8437 - val_loss: 0.2772 - val_acc: 0.8892\n",
      "Epoch 134/200\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3481 - acc: 0.8448 - val_loss: 0.2780 - val_acc: 0.8867\n",
      "Epoch 135/200\n",
      "3731/3731 [==============================] - 0s 43us/step - loss: 0.3477 - acc: 0.8448 - val_loss: 0.2809 - val_acc: 0.8867\n",
      "Epoch 136/200\n",
      "3731/3731 [==============================] - 0s 43us/step - loss: 0.3475 - acc: 0.8432 - val_loss: 0.2782 - val_acc: 0.8916\n",
      "Epoch 137/200\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3475 - acc: 0.8421 - val_loss: 0.2783 - val_acc: 0.8867\n",
      "Epoch 138/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3473 - acc: 0.8440 - val_loss: 0.2780 - val_acc: 0.8843\n",
      "Epoch 139/200\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3474 - acc: 0.8421 - val_loss: 0.2773 - val_acc: 0.8988\n",
      "Epoch 140/200\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3467 - acc: 0.8480 - val_loss: 0.2791 - val_acc: 0.8916\n",
      "Epoch 141/200\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3465 - acc: 0.8462 - val_loss: 0.2753 - val_acc: 0.8940\n",
      "Epoch 142/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3468 - acc: 0.8451 - val_loss: 0.2774 - val_acc: 0.8892\n",
      "Epoch 143/200\n",
      "3731/3731 [==============================] - 0s 44us/step - loss: 0.3471 - acc: 0.8480 - val_loss: 0.2793 - val_acc: 0.8892\n",
      "Epoch 144/200\n",
      "3731/3731 [==============================] - 0s 44us/step - loss: 0.3469 - acc: 0.8480 - val_loss: 0.2785 - val_acc: 0.8916\n",
      "Epoch 145/200\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3469 - acc: 0.8459 - val_loss: 0.2805 - val_acc: 0.8940\n",
      "Epoch 146/200\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3461 - acc: 0.8445 - val_loss: 0.2808 - val_acc: 0.8867\n",
      "Epoch 147/200\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3456 - acc: 0.8478 - val_loss: 0.2802 - val_acc: 0.8892\n",
      "Epoch 148/200\n",
      "3731/3731 [==============================] - 0s 43us/step - loss: 0.3465 - acc: 0.8416 - val_loss: 0.2807 - val_acc: 0.8940\n",
      "Epoch 149/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3468 - acc: 0.8443 - val_loss: 0.2780 - val_acc: 0.8940\n",
      "Epoch 150/200\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3458 - acc: 0.8443 - val_loss: 0.2739 - val_acc: 0.9036\n",
      "Epoch 151/200\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3457 - acc: 0.8459 - val_loss: 0.2803 - val_acc: 0.8916\n",
      "Epoch 152/200\n",
      "3731/3731 [==============================] - 0s 44us/step - loss: 0.3473 - acc: 0.8459 - val_loss: 0.2779 - val_acc: 0.8940\n",
      "Epoch 153/200\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3451 - acc: 0.8475 - val_loss: 0.2785 - val_acc: 0.8916\n",
      "Epoch 154/200\n",
      "3731/3731 [==============================] - 0s 44us/step - loss: 0.3452 - acc: 0.8475 - val_loss: 0.2779 - val_acc: 0.8988\n",
      "Epoch 155/200\n",
      "3731/3731 [==============================] - 0s 44us/step - loss: 0.3446 - acc: 0.8459 - val_loss: 0.2869 - val_acc: 0.8916\n",
      "Epoch 156/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3453 - acc: 0.8456 - val_loss: 0.2791 - val_acc: 0.8964\n",
      "Epoch 157/200\n",
      "3731/3731 [==============================] - 0s 44us/step - loss: 0.3458 - acc: 0.8472 - val_loss: 0.2780 - val_acc: 0.9036\n",
      "Epoch 158/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3451 - acc: 0.8467 - val_loss: 0.2798 - val_acc: 0.8916\n",
      "Epoch 159/200\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3443 - acc: 0.8448 - val_loss: 0.2767 - val_acc: 0.9012\n",
      "Epoch 160/200\n",
      "3731/3731 [==============================] - 0s 44us/step - loss: 0.3449 - acc: 0.8464 - val_loss: 0.2802 - val_acc: 0.8940\n",
      "Epoch 161/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3441 - acc: 0.8491 - val_loss: 0.2756 - val_acc: 0.9036\n",
      "Epoch 162/200\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3444 - acc: 0.8464 - val_loss: 0.2763 - val_acc: 0.8988\n",
      "Epoch 163/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3439 - acc: 0.8467 - val_loss: 0.2757 - val_acc: 0.8988\n",
      "Epoch 164/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3440 - acc: 0.8464 - val_loss: 0.2788 - val_acc: 0.8988\n",
      "Epoch 165/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3432 - acc: 0.8456 - val_loss: 0.2760 - val_acc: 0.8988\n",
      "Epoch 166/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3434 - acc: 0.8478 - val_loss: 0.2779 - val_acc: 0.8988\n",
      "Epoch 167/200\n",
      "3731/3731 [==============================] - 0s 44us/step - loss: 0.3438 - acc: 0.8453 - val_loss: 0.2783 - val_acc: 0.8988\n",
      "Epoch 168/200\n",
      "3731/3731 [==============================] - 0s 43us/step - loss: 0.3436 - acc: 0.8467 - val_loss: 0.2790 - val_acc: 0.8988\n",
      "Epoch 169/200\n",
      "3731/3731 [==============================] - 0s 44us/step - loss: 0.3426 - acc: 0.8480 - val_loss: 0.2820 - val_acc: 0.8940\n",
      "Epoch 170/200\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3438 - acc: 0.8445 - val_loss: 0.2762 - val_acc: 0.8988\n",
      "Epoch 171/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3422 - acc: 0.8480 - val_loss: 0.2757 - val_acc: 0.9012\n",
      "Epoch 172/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3429 - acc: 0.8464 - val_loss: 0.2775 - val_acc: 0.9012\n",
      "Epoch 173/200\n",
      "3731/3731 [==============================] - 0s 44us/step - loss: 0.3423 - acc: 0.8499 - val_loss: 0.2753 - val_acc: 0.9060\n",
      "Epoch 174/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3417 - acc: 0.8499 - val_loss: 0.2773 - val_acc: 0.9036\n",
      "Epoch 175/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3418 - acc: 0.8534 - val_loss: 0.2780 - val_acc: 0.9036\n",
      "Epoch 176/200\n",
      "3731/3731 [==============================] - 0s 44us/step - loss: 0.3429 - acc: 0.8486 - val_loss: 0.2750 - val_acc: 0.8964\n",
      "Epoch 177/200\n",
      "3731/3731 [==============================] - 0s 43us/step - loss: 0.3424 - acc: 0.8499 - val_loss: 0.2762 - val_acc: 0.8988\n",
      "Epoch 178/200\n",
      "3731/3731 [==============================] - 0s 44us/step - loss: 0.3430 - acc: 0.8480 - val_loss: 0.2774 - val_acc: 0.8988\n",
      "Epoch 179/200\n",
      "3731/3731 [==============================] - 0s 43us/step - loss: 0.3418 - acc: 0.8494 - val_loss: 0.2792 - val_acc: 0.8964\n",
      "Epoch 180/200\n",
      "3731/3731 [==============================] - 0s 44us/step - loss: 0.3412 - acc: 0.8494 - val_loss: 0.2787 - val_acc: 0.8964\n",
      "Epoch 181/200\n",
      "3731/3731 [==============================] - 0s 44us/step - loss: 0.3410 - acc: 0.8510 - val_loss: 0.2775 - val_acc: 0.8988\n",
      "Epoch 182/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3413 - acc: 0.8467 - val_loss: 0.2825 - val_acc: 0.8988\n",
      "Epoch 183/200\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3410 - acc: 0.8518 - val_loss: 0.2803 - val_acc: 0.8964\n",
      "Epoch 184/200\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3409 - acc: 0.8502 - val_loss: 0.2804 - val_acc: 0.8940\n",
      "Epoch 185/200\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3402 - acc: 0.8483 - val_loss: 0.2837 - val_acc: 0.8964\n",
      "Epoch 186/200\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3411 - acc: 0.8494 - val_loss: 0.2775 - val_acc: 0.8964\n",
      "Epoch 187/200\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3407 - acc: 0.8499 - val_loss: 0.2827 - val_acc: 0.9012\n",
      "Epoch 188/200\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3407 - acc: 0.8494 - val_loss: 0.2779 - val_acc: 0.8988\n",
      "Epoch 189/200\n",
      "3731/3731 [==============================] - 0s 46us/step - loss: 0.3402 - acc: 0.8504 - val_loss: 0.2773 - val_acc: 0.8988\n",
      "Epoch 190/200\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.3402 - acc: 0.8504 - val_loss: 0.2780 - val_acc: 0.8988\n",
      "Epoch 191/200\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.3403 - acc: 0.8470 - val_loss: 0.2792 - val_acc: 0.8916\n",
      "Epoch 192/200\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3397 - acc: 0.8475 - val_loss: 0.2828 - val_acc: 0.8916\n",
      "Epoch 193/200\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3400 - acc: 0.8507 - val_loss: 0.2808 - val_acc: 0.8940\n",
      "Epoch 194/200\n",
      "3731/3731 [==============================] - 0s 45us/step - loss: 0.3401 - acc: 0.8518 - val_loss: 0.2801 - val_acc: 0.8964\n",
      "Epoch 195/200\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3394 - acc: 0.8537 - val_loss: 0.2777 - val_acc: 0.8940\n",
      "Epoch 196/200\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3395 - acc: 0.8507 - val_loss: 0.2803 - val_acc: 0.8940\n",
      "Epoch 197/200\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.3397 - acc: 0.8515 - val_loss: 0.2832 - val_acc: 0.8892\n",
      "Epoch 198/200\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.3403 - acc: 0.8507 - val_loss: 0.2835 - val_acc: 0.8940\n",
      "Epoch 199/200\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3391 - acc: 0.8515 - val_loss: 0.2825 - val_acc: 0.8916\n",
      "Epoch 200/200\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.3389 - acc: 0.8494 - val_loss: 0.2841 - val_acc: 0.8892\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzsnXd0VVXWwH87jQRIgYQSCCEBAkgnhC4I0rF3QFGxYMMZ+zCfOpaxjs6MBRuOiCCKiKKoKIgCitTQOwQIEAglBFIg7SXn++O8JC8hjZAHQfZvrbfeu/eee+65Nytn312PGGNQFEVRlMrica4HoCiKopzfqCBRFEVRzggVJIqiKMoZoYJEURRFOSNUkCiKoihnhAoSRVEU5YxQQaIobkJEIkTEiIhXBdreLiKLz7QfRTkXqCBRFEBE4kUkW0RCiu1f65zEI87NyBSl+qOCRFEK2Q2MzN8QkfaA37kbjqKcH6ggUZRCpgK3umzfBkxxbSAigSIyRUSOiMgeEXlKRDycxzxF5HURSRKRXcBlJZz7kYgkish+EXlBRDxPd5Ai0khEZotIsojEicjdLse6iUisiKSKyCER+Y9zv6+IfCoiR0XkuIisFJEGp3ttRSkJFSSKUsgyIEBELnJO8DcBnxZr8zYQCDQDLsEKnjHOY3cDlwOdgRjg+mLnfgI4gBbONoOBuyoxzs+BBKCR8xovicgA57E3gTeNMQFAc2CGc/9tznE3AYKBe4GMSlxbUU5BBYmiFCVfKxkEbAX25x9wES5/N8akGWPigX8Do51NbgTeMMbsM8YkAy+7nNsAGAY8ZIw5YYw5DPwXGHE6gxORJsDFwN+MMZnGmLXA/1zGkAO0EJEQY0y6MWaZy/5goIUxJtcYs8oYk3o611aU0lBBoihFmQqMAm6nmFkLCAF8gD0u+/YAjZ2/GwH7ih3LpyngDSQ6TUvHgQ+A+qc5vkZAsjEmrZQx3Am0BLY6zVeXu9zXXGC6iBwQkX+JiPdpXltRSkQFiaK4YIzZg3W6Dwe+LnY4Cftm39RlXziFWksi1nTkeiyffUAWEGKMCXJ+AowxbU9ziAeAuiLiX9IYjDE7jDEjsQLqVWCmiNQyxuQYY54zxrQBemFNcLeiKFWAChJFOZU7gUuNMSdcdxpjcrE+hxdFxF9EmgKPUOhHmQH8RUTCRKQOMN7l3ERgHvBvEQkQEQ8RaS4il5zOwIwx+4AlwMtOB3oH53inAYjILSJSzxiTBxx3npYrIv1FpL3TPJeKFYi5p3NtRSkNFSSKUgxjzE5jTGwphx8ETgC7gMXAZ8Ak57EPseajdcBqTtVobsWaxjYDx4CZQGglhjgSiMBqJ7OAZ4wxPzuPDQU2iUg61vE+whiTCTR0Xi8V2AIs4tRAAkWpFKILWymKoihngmokiqIoyhmhgkRRFEU5I1SQKIqiKGeEChJFURTljLggylKHhISYiIiIcz0MRVGU84pVq1YlGWPqldfughAkERERxMaWFs2pKIqilISI7Cm/lZq2FEVRlDNEBYmiKIpyRqggURRFUc6IC8JHUhI5OTkkJCSQmZl5rodyVvD19SUsLAxvby34qihK1XLBCpKEhAT8/f2JiIhARM71cNyKMYajR4+SkJBAZGTkuR6Ooih/Mi5Y01ZmZibBwcF/eiECICIEBwdfMNqXoihnlwtWkAAXhBDJ50K6V0VRzi4XtCBRFEWpFAc3wvZ553oU1QYVJOeIo0eP0qlTJzp16kTDhg1p3LhxwXZ2dnaF+hgzZgzbtm1z80gVRTmFH/8G00dB0o5zPZJqwQXrbD/XBAcHs3btWgCeffZZateuzWOPPVakjTEGYwweHiXL+48//tjt41QUpRiZKbB3KZhc+Gk83DwTLnDTsWok1Yy4uDjatWvHvffeS3R0NImJiYwdO5aYmBjatm3L888/X9D24osvZu3atTgcDoKCghg/fjwdO3akZ8+eHD58+BzehaK4gblPwrL3ym+XfQImXw77Vxfdbwx8NgK2/nBm49j5qxUiF10JcfPhPxfBF6PPrM/zHNVIgOe+28TmA6lV2mebRgE8c0XbSp27efNmPv74Y95//30AXnnlFerWrYvD4aB///5cf/31tGnTpsg5KSkpXHLJJbzyyis88sgjTJo0ifHjx5fUvaKcn6z9DOq1gh73ld1u/yqI/x12L4LG0YX70w/B9h8hNwtaX1b5cWyfB75BcO1E+KMtxP0CW2ZDxnHwC6p8v+cxbtVIRGSoiGwTkTgROWVWE5GmIvKLiKwXkYUiEuZy7DYR2eH83Oayv4uIbHD2+Zb8CcORmjdvTteuXQu2P//8c6Kjo4mOjmbLli1s3rz5lHP8/PwYNmwYAF26dCE+Pv5sDVdR3M/JZMhIhpSE8tsmrrff+W2Td0FuDhzdabfjF0NW+umPISsNdi6AuJ+hxUDw9oN+46Hf3+zxgxtOv8/iHN5iNafzDLdpJCLiCbwDDAISgJUiMtsY4zoLvg5MMcZ8IiKXAi8Do0WkLvAMEAMYYJXz3GPAe8BYYBkwBxgK/HgmY62s5uAuatWqVfB7x44dvPnmm6xYsYKgoCBuueWWEvNBfHx8Cn57enricDjOylgV5ayQvMt+px6AXAd4ljF1Ja6z3ykJ1p/xTg8Y9Bx417T7c7OttnI6WkmuAz4eVigsWg8vPNawY+F1I/tUvM/ixC+GyZfB5W9AzJjK93MOcKdG0g2IM8bsMsZkA9OBq4q1aQP84vy9wOX4EOBnY0yyU3j8DAwVkVAgwBiz1BhjgCnA1W68h3NOamoq/v7+BAQEkJiYyNy5c8/1kBTl7JOvTZhcSD9YdltXQZIUZ01Z+1ZA8k7w8AYff9hxmqG7qydbITL0Fbj7V2hzTeGx2vUgoHHhdSvL1jn2+5fnIePYmfV1lnGnj6QxsM9lOwHoXqzNOuA64E3gGsBfRIJLObex85NQwv5TEJGxWM2F8PDwSt/EuSY6Opo2bdrQrl07mjVrRu/evc/1kBTl9IlfDMf3QqdRlTs/eWfh75QECAwr3N7xs9U82l9vHe1J2wGBlH2F5yWus5pI3Uio1xo2fVO+eatGbRj8IuTlwK8vQEQf6H5vyRFaDTvYaySuh6UT7PV7jYOG7Z3j3w2/vW6FWpfbIeLiU/vYMRdCWsLROPj0OqjjLGfUtCd0vauCD+rc4E5BUpLvorjx7zFggojcDvwG7AccZZxbkT7tTmMmAhMBYmJiqrXR8dlnny343aJFi4KwYLAZ6VOnTi3xvMWLFxf8Pn78eMHvESNGMGLEiKofqKJUlqXvWgd4hxFQSjh7mRyNA/G0GklxP8mClyDtoBUkBzcCBpr0gH3L4IDzfyl5pxUkDdvbifzIVjiwpvTrmVw4Fg/hvSDPYTWEgc+WHuYb2tEKghmj4cRRu+/AarhvCXh4wbcP2CgyrxrWz/LgqqKO+aM77T0Oew0cGbDqE8hYY/1C2+dClzsq99zOEu4UJAlAE5ftMOCAawNjzAHgWgARqQ1cZ4xJEZEEoF+xcxc6+wwrtr9In4qiVEPSD0JWKhzbDcHNT//8ozshLAb2LbeaRj65OXBok33TTz8MB52O9tbDrSDZvaiwbco+aHMVtBgA41aWfb28PPh3KysccnPAPxQadym9fWhHMHlW+Nz8lRU+n98Ey9+H2g1hzx/W99E4Gj64BBa9CkNfdt6DA7Y53bxRg6zW1Puvdnv1VJg9ruTnZky1yV9xp4hbCUSJSKSI+AAjgNmuDUQkRETyx/B3YJLz91xgsIjUEZE6wGBgrjEmEUgTkR7OaK1bgW/deA+KolQF6c68psr4EYyxzvbQjjbs1lUjObLNChGwZqX9q6FmMDRxWtEPbYQG7QvbB7eo2DU9POykHjffahBRg8qetEOdDveWQyFqILQcYiO75j0FX99lTV/Rt9p2XW6HFRPh8FbYtQheCYd5T1qzVt3IkvtNXFt0/x9vwTvdbchxNcBtgsQY4wDGYYXCFmCGMWaTiDwvIlc6m/UDtonIdqAB8KLz3GTgn1hhtBJ43rkP4D7gf0AcsJMzjNhSFMXNGGNzOKByguTEEavN1G1ufSMp+wuPufaXuMYmC0ZcDIEuxpDwHlajgNPThqIGW99LdhpEDSm7bWBjuOETuHKC3RaBaybC4BesSWzk5+DhaY9d+jT41IIfn4AfHrXO+gH/gKtLSLas1xo8fYreZ/Ju67NJ2gaL/lXx+3Ejbk1INMbMwYbouu77h8vvmcDMUs6dRKGG4ro/FmhXtSNVlPOYfSsgqCn4Nzh710xYBbXrQ1CT8ttmHLP+CbATYsp+q1WEdz+13YG10Lx/4b69y20SIVhtIjCsMBpLxPbnXQtqhcDaz60JLWoI+Dcs9KkEt7AaQVpixTUSsOPw8AIEmvUrv33bYgGktYKh14OntqsVDP2ftIIEYNQMq8GUhJcP1G9TVJDMe8oKpajLYcUHVogFt7B9ZKXDniXla1BVTPX13iiKUj5Z6bYcyM9Pn71rHtsDk4dX/JppznBd3yBrovniFph6NeRkFG337TiYeg2cSLLbuTnw2Q2w+L/2rbxBWytIjsXDpCE2r2PPEgjtAI06F0ZoRQ2yE22AM6AzuDk0vxQCwws1k4rgG2iFUqthNoKrKom5ExrHQJurSxci+YR2sGY7Y6yZbev30OdRuOJNqFUf5v4ffHYjHN9nfTKf3QDb5pTdZxWjgkRRzmd2L7I+gh0/Q17u2bnmvKfAkVkYEVUe+XkfLQY4tY7VkHPShgTns2uhnSAxhW/f+5Zb09LV78ETuyAg1AqS7DQ4edSayw5tsNpGaAd7TqNoqylBYYhw3WbQ/R7467rTf0u/6VNrsqpqPL3gjrlww+Ty24Z2tNFbx3bbIpF1IqDnOKuF/WUN3OHMidkx10Z4gRUuOWdvITsVJOeIqigjDzBp0iQOHiwnQau6kxALsx+0kTJ/VuY/B5tmVe7czbPh+0cKS2cYY8NJd8wvTKzLSLbPsSzSD1vtZWJ/+5l8uXX4upKTATPvKGyT//nqbnBkWefwltnWB3Fsd8nO3vQjMP1mm4UOkOb0j+T7GRp3sVnm+ZNebg78OB4CnBN/viDZPtcmEF50BdTwt/vyfR9dboNOt9jfoR1dnN0ub/eBYdY0FdTUCpDKhM96eLgv7NbTq2KCLbST/Z58hQ1bHvISePvafd6+0KSbvcd1X0DCSpvvcizemc9ydlBBco7ILyO/du1a7r33Xh5++OGCbddyJ+XxpxAkG7+C1VPgxJ+0YvGJJGueiT3F5VcxlrwFsR/Z5wSQuh/WfGrDQrfPhci+1h9QXrb2pm9sLodfkI1sOrgevn+oaG2nJW/b6/gG2jY1g8E3ADbMsJFCP423k9awV237kupLbZpltYv1M+x2vkbScgjE3AFXvQuRl9g3aGNg5UdwZAsM/5ftO1+Q7JgHTXsVChGwvoroW+HSf9iyJ51H20ippr2hyxi7nU/0rdaxXVY5lfOB0I7Q6WaofxH0+zu0Gl70uIh9tgkrAGOfS+vL4fd/Fw1McCPn+RP+c/LJJ5/wzjvvkJ2dTa9evZgwYQJ5eXmMGTOGtWvXYoxh7NixNGjQgLVr13LTTTfh5+fHihUrTksIVRvyy1+kJFgnaXUg+wQg4FPzzPuKm0+Byaa02P9je6y5B6w/oG4z2+5EklPTEJj3tLXX50+0aYn2+9KnCnMR2t8AIVGFEUJgiw3W8LcTd93mMNqpGa2aDN/9FVb+z0Y6ZabA7/+xuRY3Tik6vs9HwYIX7O+bpkFYN/s7cZ3N7/DwLpyw8wXajnlw8UNWI/GpbQXY5f+1x1oOtk70Ld/BwpegWX87Qa6bbvs8tse+fUffWnQctULgyrcLt69yeeu+4o2ibSP7nFntq+qCpzdc/W7ZbaKG2JDiWvUgtDMMeREmdIP5z8B1/3P7EFWQgFWrq6JypysN28OwV077tI0bNzJr1iyWLFmCl5cXY8eOZfr06TRv3pykpCQ2bLDjPH78OEFBQbz99ttMmDCBTp06Ve34zyZH4+x3yj47KZ1rch3WmVu7IdxSYlDh6ZE/sWamwPE91sbtSkIs/G9A0X0jPrNFBeN+AYyt8fTTeDv5Z6aAeNi3zq0/2HyFk0fh53/Au93tOhk3OashbJgJs+6FGz6G3b9D1zsLr9F5tNWS5rgsqObla0NWizPkRSsQm/a04xKxzuyEFbD6EwhoBKO/saax+N9tP3uXWdNX+kGoXSyiLGowIDYT3MPL3p+IffveMttOigXtlHKJ6G2Fdcsh1hRXJ8JGjP3+ui27X1YyZRWggqSaMX/+fFauXElMjJ1QMzIyaNKkCUOGDGHbtm389a9/Zfjw4Qwe/Cf5B8t12MkVKlYi/GwQO8m+WHhssZO2b2Dl+8p12Am4fls4vMm+bRcXJFu+s5PpNR9YTeL7h2HL93bC3jHXRuZ0u8dmOW/70eYghLSy7ZO2WS2u21irbexaCCs/tNds0t0uBpWXA1+PtU75qEGF1/XwhFu/tefk06AdBJVQm65upC334d+wUKMK7QibnfnASdth09c2FNeRaU0wC1+2eR1ph07VNAPD4I6frFYV0grqt3b26XwhWjrB+kZCoir54C8wvP3grl+KhoD3ecRqtqHuf8lUQQKV0hzchTGGO+64g3/+85+nHFu/fj0//vgjb731Fl999RUTJ05072CO7YFdC2wmrisnk2Hd53by8vQ+s2sc32PLSUDlBIkjC1Z8CNGjKz7hb/zKRvqUNEmdTIYFL1qnbso+G24Z0Aiy020IqSuHt1rzS/H8AVcSVlhhNOw1+OY+K0g8vK2JponTPLRjHoT3tLWiwAqRuJ/BkW01ktaXFWZaL50ANQLsm7pPTRv2CnYiuehy22bnL9Y5HxJltYFLxsOiV+wk37RY0U+/OtD2GipESLEcjIYdbJhpq+H2Wc190goI71rQ6y82FHX7XDuGkiaz8B6n7suPvvKsUbJmpJROvjDOx6cWdL75rFxane3VjIEDBzJjxgySkmws/dGjR9m7dy9HjhzBGMMNN9zAc889x+rVdhlRf39/0tLSqn4gxti32O/+CqmJRY+t+tiGF66oAkGW7x9BKidIlr5jy0usLrmw5SnsWWKjkqbfbKOFivPrC9anMPJzm/ew/guYdgN8PtIK1nwcWTB9JHx5W9nRUtvnWm2j1VDrLN06B2bcWmhOOr4PDm8uGm3UcojN5v7+Ycg8bn0W+fvzHDZCKz9KqTheNWxNp5wM2LMUej8E/f8OHUdZf4NXjYo9p4oQNdhqE0Nfhsucvo9Dm+3k5VPTahSbZlmHb0V9X7XrW4f6gKdP1dyUaotqJNWM9u3b88wzzzBw4EDy8vLw9vbm/fffx9PTkzvvvBNjDCLCq6/aqJkxY8Zw1113Vb2zfeNXtugd2LfoAJdErh0/2++Fr0D7G22Jh8qSn0QW2rFoMb6KkJpoS3ODfavvNa7s9nm5NpvYx9+ahFZ8CD3vLzx+cIMVkl3vtj6uFgPscxBP6wCf91Sh72HZe7b+k4+/7fPO+SWHie742WobvoH2HtdOs/sT19lEvXz/iWsJjhYDAYG1n9pQznw/QVg3209mSuGbe0k0uwQe31F03zUVWOv8dAnrAuNW2N91IuDRYqHEl4y3Ppqck4W5HRXhVi2fd76hgqQa4FpGHmDUqFGMGnXqug1r1pxa9vrGG2/kxhtvrLrBrP3Mmiiy0qy9/NAmGybaaqg9fjLZJoq1vdY6Rd/sYE0/Iz63b8vfPmCjZ0p6Y175P+scHjXDRuds+NKW2KgRAI06WV/B7t+s0/i274qGfZbE/GfsNdtcZd/086OTSmP1FCssrp9k73PeU7YKaz6OTKuF9P+73Y4aYgVJ17ussPz1BVtgD7HXajXcXnvWPfBqhBU+t8y0ZiZwahubYJDTTNmwAzANOtxkNZ0dP9tnGNS0qJmtZl0I6wr7Y22Ybb5PwtMLmg+wvoiGLoUIqyuBjW0G9q//PL2McuW8QwWJUpTVU2yyWMeR0O0umHZj0To/O3+15bJ7PmBDTXcttELhxyesqejAaluI7o55p76hr5xkJ9YFL1ptIDvdvu2HdrC29ZNHYfkHdp2InQugzZWUyt7ldjLu85itibT527LPyThmV55r2tsKwfBesOxda6Jypf311m8Atq/U/VaQeNUApLCKrbcv9HjAhltmHLMCd81Um4dxibOGUr62kW+26nCjdXh3v9dmdf/2mvURDXzu1JDgIS9Byl5bFsSV/v9nNZYzCQA4m/R60GpzLYee65EobkQFyflCXq6dqPMzWk8HY+wbdE6GNae42quPbLMF3zw8C7WNPo/a3ASwmsW+5Tb6aPdC+yZfM9g6eT087boPdSNtaCpYh/TOX+2bfr75pWEHO1Ee3mTDQvNrJzW9GPYsdlZ1dWYs56/LsGOeDW9N2m6diMbYyTcr1R5f+Ar4N7KRKZ4+UCPQJum55k+4sukb62/If8MPCIXBpwY0FMHbz/afT9/HSm7X4z77nZVq8zCCm9v73PClU9toaY/XrFu4zkTUIBvKW7dZ4fmuNOlqP8UJiTq/Ipm8akDvv5zrUShu5oIWJPn+hvOC9IM2Oa1Bu9Iny9LISsMcjbOZ4x+MhAdjrQko7hf49Fo7uQ16vlDbcI3dD+0IG2faiKMNzkzlzqOLjqHrXbBmmjW9jJphS28scomE8w0q9F9c+yF8fbeN6okeDe/0KNRIwFZr9Q2yZp+FL8Nv/7Jms+Rd1qnuyvWTbGQKWNPb+i9suGxpdLvHvSahwS9A3K/WmZ9Pz3ElJyBedKUVJENfqVoHuKKcA8S4lkf4kxITE2NiY4tG1uzevRt/f3+Cg4PPD2GStMOagupEFl2iswKYY3s5mnSItAwHkV8PtZE8lz4F7/Wyb/we3nD/Mjtpx82Hx3YUCopdi2CK01zUcRT0uNdG6hTXjHIyALH7HVk2LBasKeizmwBjhcVf11vNwDfITrAnk62PJDUB3uxoTV1DXrQajnhYwRYUbhPbwmLs2g5gz3FdBCgnw7lWdyl4eNly3O7+W59IsuYwAMSuJ+FVSgBEce1QUaoZIrLKGFNulvAFq5GEhYWRkJDAkSNHzvVQyscYOzmZPEg8aU0kYKN3vHwL32jzHLasuG9AoTnLNwDSEvHNOU5Y96usMFj6js06TtoOV7xlneuf32QnttaXFdU28t/gfYPsG3et4JLHmO9gBjseV2d7t7Gw/D3rvBYp9EFA4b34NwLE5ha0u94KEi9fGP6adeB7eMOwf5Vu1vH2Kz0k9mxSK8R+KoIKEeVPwgUrSLy9vYmMjCy/YXXg6E6Ycb2dWP3qwiObbYTTt6PtBPxgrHWQT73aOr8vfsSWHdky29Yw2rXA1jjy9rZv9CcO2xLcvR60uQU1/OGPN+wk3WVM0WvXrGv3RfYtXYiUR7/x1qlcvG6SK14+0O1uO97a9aDH/TbvovMt1qwV0Pj88g0oygXEBWvaciuuhfnyn++ZmFQ2fg0zx1gb/4oPbGjstw9YB3zqfuvjaNgBvrrTluJOP2i1k4AwazICeGhjxVazUxRFcVJR05ZbM9tFZKiIbBOROBEZX8LxcBFZICJrRGS9iAx37r9ZRNa6fPJEpJPz2EJnn/nHTiPT6SyQlwcTYuCPN+32/wbC/GfPrM/8shq9/wIIfHIFHN8L17xvcxL+eNMKkXoXwZ1zreYS1BTumm81mPptVYgoiuI23GbaEhFP4B1gEJAArBSR2caYzS7NngJmGGPeE5E22PXdI4wx04Bpzn7aA98aY1yXY7vZuXZ79ePAamtW2vmrNeXsj7WF6QY+W3mt5OB6a+YJDIOR0+2iNcEtrLmpUbTNnM7NtuGygY1hzBybZxAQarOEPS5YC6aiKGcBd84w3YA4Y8wuABGZDlwFuAoSAwQ4fwcCB0roZyTwuRvHWbXkr/qWuN5+wJqfDm2ya1z4BUG9VhXvzzjXschfzKZVscSuGrUhpphfw9XpXFYpDUVRlCrAnaatxoBr8aQE5z5XngVuEZEErDbyYAn93MSpguRjp1nraSkldldExopIrIjEntXIrPw8hoxkWxk1n1WTrTP8x7+dXn/b59qM75IqpSqKolQD3ClISprgi3v2RwKTjTFhwHBgqogUjElEugMnjTEbXc652RjTHujj/IymBIwxE40xMcaYmHr1zqCo4OmQdtCpPVxmt9dNt9FGDTvYNSJyTkLi2qJLm5aFI8uGwYa0tMURFUVRqiHuNG0lAK4e3jBONV3dCQwFMMYsFRFfIATIX7x7BMW0EWPMfud3moh8hjWhFVsX9ByRXxX34odh+0828a5pL1sv6eB6m0x4bLctl16a8zt2kq03BVbwHN8Lt3xdelKboijKOcadGslKIEpEIkXEBysUZhdrsxcYACAiFwG+wBHntgdwAzA9v7GIeIlIiPO3N3A5sJHqwo65Nq8jLKbQDxLa0S4M1eN+uMIZyeVaBLE4SyZA9kl7fqPOMPhFW85cURSlmuI2jcQY4xCRccBcwBOYZIzZJCLPA7HGmNnAo8CHIvIw1ux1uylMbOkLJOQ7653UAOY6hYgnMB/40F33UCIp+21J7OKVbR3ZsHMhtLu2cO3pw5vtd2CYXfwn+6Qt+5G4zq5ml09Opl0ONf2wXZ9j2GvQfexZvS1FUZTK4ta4UGPMHKwT3XXfP1x+bwZ6Fz/PeWwh0KPYvhOAe1exL4t9K2DSELhywqlLWO5dCtlphSXDw7rC+hlFlxj1qWnrVLlqJHm5MHm4LXfS2enuafknWY9dUZQLAl1qt6Lk5cGcx229q63fn3p8xzxbzjzyErsdfSvcv7ToyoJgNZSD6wu313wK+1fZ3JMFL1lBo0uMKopyHqGCpKKs+8xGXNVtZutZ5WTYjPJj8fb49rkQcbHN6wDw9C45XyS0o01QTDtkK9r+8jw06WEjvXKz7DoViqIo5xGa8lxRts6xQmToK/DZjbbW1cavrM+kx71wdAd0vbP8fiL72O/l79vw3pNHYfTXNhM9ZR90HOHe+1AURaliVJBUlPSD1uQU2Re8/KwQARupVbeZ/R1VAd9Gw/bQYQQsnWDNZF1uK8xEv/d3twxdURTFnagvAct4AAAgAElEQVRpq6KkHYLaDey6F5F9AbHO8WPxNtkwuIVdYrUiDHzWFmH0rgWXPu2+MSuKopwFVCOpCMbY9TtqN7Dbg56DTqOgcTSsmWod5T0eqHh/AaFwy0xbTLGiiyApiqJUU1SQVISTyTbPI39Fu/oX2Q/Y0u1Htpy+k7xpr6odo6IoyjlCTVsVIf2g/c7XSFxpew3Uqq+CQVGUCxYVJBUhzSlISlpju+9j8Jc1heumK4qiXGCoIKkI6Yfsd0kaiYdnYe6IoijKBYgKkopQlkaiKIpygaOCpCKkHwYff/Cpda5HoiiKUu1QQVIR0g+CfwlmLUVRFEUFSYVIOwS11aylKIpSEipIKoJqJIqiKKWigqQiqEaiKIpSKipIyiMrDXJOQO3653okiqJUQ9KzHOxLPnnWr2uMYdryPcQnnTjr1y6OCpLySD9svzX0V1GUEnhy1gaumLCYnNy8s3rdT5bE8+SsjYz/en35jd2MWwWJiAwVkW0iEici40s4Hi4iC0RkjYisF5Hhzv0RIpIhImudn/ddzukiIhucfb4lIuLOeyDzuP32DXLrZRRFOf9ISs9izoZEjp/MYWV8coXOOZHl4LPle8ly5Fb6urHxybw4ZwvBtXxYtiuZVXuOcSg1kxNZDgASUzIKfp8N3CZIRMQTeAcYBrQBRopIm2LNngJmGGM6AyOAd12O7TTGdHJ+7nXZ/x4wFohyfoa66x4AyHaqrD413XoZRVHOP76MTSAn1+DpISzcdqTUdtsOpvHG/O04cvOYtnwP/zdrA499uZ68PFPqOSezHSSfyD5F05m2fA+jPlxOaKAfsx+8mDo1vXlg2mp6vPwLff+1gL9OX8PFry7g9o9XlNl/VeJOjaQbEGeM2WWMyQamA1cVa2OAAOfvQOBAWR2KSCgQYIxZaowxwBTg6qoddjFyMuy3tyYjKopi2XwglTfmb2fq0ni6RdalZ7Ngft16mN1JJ5izIbFI2/3HMxj90XLemL+DpbuO8tv2JHy8PPhu3QH+8/P2gnZxh9OY/MdutiSm8uFvu+j43Dyi//kzV7y9GDvdwZbEVJ6ctZGezYP59oHeNA7y495LmpOUnsWtPZrSrF4tvlt3gF7Ng1kZf4wpS+PPyvNwZxn5xsA+l+0EoHuxNs8C80TkQaAWMNDlWKSIrAFSgaeMMb87+0wo1mfjki4uImOxmgvh4eGVv4scpyPL26/yfSiKcs4xxvD+ol30bRlC20aBZ9TXE1+tY+P+VDw9hGevbMu+Yxn88/vNXDVhMamZDt4c0Ymk9Gw+WLSTtEwHXh6Cn7cnX6/ez4r4ZG7t0ZTUzBwmLIijWb1afL8+kV+3Hi5yjUFtGtAgoAafLtvL0l1H6dU8hI//2I2vtwdvjuhEUE0fAMb2bcbonk2p6eOFMYacXIO3p3D7xyt59adtDLioAU3qutei4k5BUpLvorieNRKYbIz5t4j0BKaKSDsgEQg3xhwVkS7ANyLStoJ92p3GTAQmAsTExFRev1PTlqJUCcYYvl+fSN+oegTW9Abs2/oP6w/gIcJVnRpTz79GQduUjJyCybIqWLj9CK/+tJU5GwKZPa43JblX07Mc1K5ROC2uTziOt6cHF4UGEHc4jfSsXDwENu5P5bkr23Jrz6aICLuTTvDP7zfj7+tNs3q1eezLdeTkGno2CyaqQW2ujQ7jf7/vYtaa/QD0bVmPbpF1WZ+QwiMz1uHj5cHjQ1oxtF1D/ohLwt/Xi6s7NSbLkcd36xKZtnwvrRr4883aA9zQJazIcxERavp4Ffz28bL39fK17Xl97jZ8vT2r7BmWhjsFSQLQxGU7jFNNV3fi9HEYY5aKiC8QYow5DGQ5968SkZ1AS2efYeX0WbXkOAWJmrYU5YzYejCNBz9fQ5+oED4Z0w0PD+HpbzYWvIn/sCGRmff2wtND+HTZHl74YQuL/3ZpgXApzsb9KTz25TrSMh30bB7MK9e2x8vTgyxHLhMX7aJVQ3/6t66Pt6cHeXmG137aho+XBxv2pzB300GGtgst0t/kP3bz0pytfHZ3d2Ii6vL9+gM8NH0tDQJ8+e2J/twzdRV7k0/SvnEgft6eXBPduEAYRYbUYvKYrrQJDSDPwHXvLaFvyxBeuLo9nh62zfD2oXy/PpEaXh50i6yLr7cn793Shf/8vJ17+jajXWOrJTWvV1hN3Nfbk+uiw5i6LJ7k9GyyHXmM6R1RoefdKMiP/9zU6bT+RpXFnYJkJRAlIpHAfqwzfVSxNnuBAcBkEbkI8AWOiEg9INkYkysizbBO9V3GmGQRSRORHsBy4FbgbTfeg4sgUdOWcv6yeu8xAny9aFHf/7TOW7brKBeFBhDo533GY1ix20Y1/b4jibd/jWNgm/r8uvUwDw2Mokmdmjz65To+/mM3Y3pHMvH3XWQ58oiNT2ZY+6ITflJ6FgdTMhkzeSWeInRqEsTMVQn4eHnw/JVtefzL9cxeZ98vW9Svzdf392L+5kNsTkzl9Rs68v6inTw+cz2PfbmeAF8vOofX4erOjXnlp61k5+bx7HebuLVHBOO/Xk/DAF/2H8/gtbnb2HnkBLVreLF673FuimlCgG/RZ9KvVWGu2e9P9MfDo6jG079Vffy8PYmJqFOgJUSG1OLtkZ3LfG6juoczZWk82w+l8fdhrU/7b3g2cJsgMcY4RGQcMBfwBCYZYzaJyPNArDFmNvAo8KGIPIw1Ud1ujDEi0hd4XkQcQC5wrzEmP7buPmAy4Af86Py4j3zTlreatpTzj7TMHB77ch1zNx0iqn5tfn7kEpJPZPPZ8j38tj2J569uS+uGAQXtdxxK4/nvN3N9lzB8vT25Z+oqhrdvyLs3dznjsayIT6ZRoC/dIuvy3/nbmbZ8D7VreDGmdyQBvl78uDGRf83dRsKxDPYl2yCXVXuOFREknyyJ59nvNmEM+Pt68fV9vYhq4M+rP23lvYU7mRmbQHZuHo8Nbkl4cC0e/mItd38Sy7qE43QOD+Kazo1pFOjLOwvjaBZSm9TMHBZuO8IPGxLxr+HFI8Nb8tKcrTzx1Xr6RIUwYVQ0A/69iPcX7cTf14tZ9/fmv/O3c2+/5mXea3EhAuDn48kHo7sQGuh7Ws+tRf3a/PZEf0Jq18DHq3qm/rl1zXZjzBxgTrF9/3D5vRnoXcJ5XwFfldJnLNCuakdaBjknwMsPPKrnH1CpPDm5eXh7lv93fXb2JuZtOkj7sECeu7IdDZ0TwZK4JDYdSOXuvs1Izcxh79GTBeaJskjPcvDugjhmrzvAf2/qRNeIupUa/+x1B/jf77uYPKYbdWsV2swPHM9g6rI9jOvfgom/7WLe5kP0iQrh9x1J7DiUxpOzNrIiPhlvT+Hf87bz1ojOvPrTVg6lZrJw2xEyHbn8viOJmj6e+Hh58OPGg8QdTudElgM/H09aNij6RmyMYcrSPfx3/nYyc3IZ0LoBb4zoVPBsHbl5eHoIK3Yn06t5MK/f0JGGgX68v2gn4/q3KNB2/nV9R0Z/tJzJS+JpHORHg4AarNp7jMycXH7aeJD9xzN4fd42+rWsx/D2ocRE1CUyxJqcHx/cijahAazac4ymwTW5vVcEIsKB4xm88uNWwuvW5MNbY/D0EHq1CKFXi5CC8R8/mc1Hi3cTHV6Hfq3qsXrPcXy9PXj1+g7U8PLkxpgw3l24k+uiw2hRvzbvjIqu1N8LrG+kMjQKqt4WEckPK/szExMTY2JjYyt38g+Pwsav4W+7q3ZQyjnl27X7eWTGOvq1rMejg1vRplFAie0SUzLo8+oCWtSvze6kEwxt15A3R3Rmd9IJrnh7MelZDj4e05X3Fu5k1Z5jLHi0H+HBJWuvxhhmxO7jtbnbSUrPok5Nbwww896eJZor9iWf5LcdR+jfqv4pE0lGdi59X1vAkbQsrurUiH9d34HDqVk0qVuT+6etYs6Gg1zfJYy5mw5ycYsQnr2yLT1e/oUBreszf8thnr68DakZObz5yw76RIWwOC6J5vVqExlSi6cva8Pz329m1Z5kJt3elZEfLiOkdg0SjlktoUvTOkwY1ZnQQD/Ssxz87av1/LA+kYtbhNA4yI8vYvdxU0wTXrmuPct2JXP3lFhu69WUdxbs5IWr23FLj6YA7D16ksZ1/Ap8CAApGTk8OWsDw9uHsj4hhY8W7+L2XhF8+Pvugmt/emd3/Hwq5kDOyzNMX7mPPlEhlY5cOpiSyWNfruOla9qX+rf9syIiq4wxMeW2U0FSDrPug/jf4eGNVTsoxe1sOpBCeN2a1PDy5I352/kjLgkDTB/bgzEfryTucDp5xhDg5828h/tyMCWTgymZXNQooMD+/a+ftvL+op0serw/n63Yy/uLdjJxdAz/nreNg6mZ+Pt6cTQ9m5PZNkv55u7hvHhNe4wxfPDbLuZuOkhGdi5T7uzG7LUHeOGHLUSHB/GPK9pSt6YP17z7BykZOVzauj4vXNOO+v6+pGc5eGrWBr5Za+38QTW9eWtE54K32ZPZDj7+I57X5m5jcJsGzNt8iABfL9KyHNzRO5KPFu8mNNCXxJRMAL4bdzHtwwK54f0lrIw/hn8NL5b+3wByHHn0fvVXTmbn8pdLW/DI4FYFz84YQ5YjD19vT57/bjOT/tjNHb0jaVzHjzd+3k5gTW9GdG3C16v3E3/0BI8Pac09fZvh4SH8Z9423vo1juHtG7Iy/hhH0rIK+p33cN9TNJrS+HnzIe6eYv9vh7ZtyJOXXUSjoKKCR3EvFRUkbjVt/SnIOaH+kfOQ7YfSuPztxYTXrUmTOjVZHJdEdHgQq/ce5835O1gRn8xDA1oS3TSI0R+t4OEv1vLLlsNkOfLw8fTgtRs60DeqHp+t2MugNjYO/56+zfh02R7unhKLn7cn790STW6e4c5PYukTFUJYnZp8GZvAXwdEsTL+GK/8uJWOYYHsSjrBozPWsXbvcfq1qsfHt3ctiPb55oHefLp8D1OX7uGOySt5ZFBLXvh+C/FHT3Bfv+b0b1Wfp7/ZyH2frmLFkwOZumwPr/y4FYD+reoxYVQ0909bTQ0vD1Izc/ho8W6Canrz7QO9GTFxGc3r16Z9mDW3DWsXysr4Y9zYtYkNca0B44e1Zt2+FP46sGWR5yciBQ7h8cNaM6JbkwIB0DWiDrdNWsHr87bTvF4tPru7Bz2aBRec+/Cglvj6ePL63G14e3ow7a7uPPzFWnJy82jhEpFUHl2a1gHA00N4fGgrt+dCKJVHNZLymHaDLdx4z6KqHZRyWuTmGZbvPkpGdi4dmwQRUrsGeXmGmasS+HT5Hp65oi1dmtZh84FUWtSvzTOzN/L16v3UqenDobRMXry6PaO6h3PjB0sLoocWPNaPyJBajJ0Sy7zNh2jXOICHBrTkw993sSI+Gf8aXpzIzmXGPT0LJrVv1+5nZXwyD/RvQWigH8YYFmw7THR4HVIzHPT/90KaBtck5WQOYXX8+Oq+Xvxv8W5e+XEr3p7C3If60qyEyXTB1sPcNSWW3DxD4yA/Xr+hIz2b28k5Nj6Z699fyivXtue/87fTIMCXKzs24rIOoYQGFpq8sh15vD5vG9HhQQxtF0pmTi6eHlLgqzh2Iptnv9vE/w2/iAYBp+fwLU5mTi5Zjrwyo7nWJxwnJ9fQpWkd4g6ncTQ9m+4uAqci3Pj+Uto2DuCZK9qe0XiVyqGmLRfOSJB8fBlgYMyccpteKDhy80hMycQYCK7tQ60ap6fYpmTkkHIyp8i56VkOrn9vCS3q1+ala9sT4OtNZk4uv249bM0+P2zm02V7AQgN9OXbcb15YuZ6Fm47gpeHEFbHj1t6NOWFH7bQo1ld1uw9zrXRYfxtaCsSjmUUOMEXbT/CbZNW0CEskNnjLgbgUGom05bv5a4+kQXXffTLdZzIcjB+WOsiUU3lsWj7EZ6dvYn9xzP4btzFtGrojyM3jwc/X0OXpnW4q0+zUs/9aWMiCccyuKVH0yJJZMYY+r++kOQT2aRmOpg4uguD21441aiNMSUmDyruRwWJC2ckSCb2g5ohcMvMKh3T+crfv97A16sTyHLYQnIi0KqBP2+P7ExUBWzfK+OTGf3RcjJz8giu5cMPf+lDw0BfnvpmA9OW78VDhPC6Nfnmgd58+NsuJiyIo05Nb46dzGFM7wh6NQ/hgWmr8fPxJCUjh2evaENUA39u/t9yANqEBrD1YCp5Bn5+uO8pYzLG8PS3G7mkZX0GtXHPqpfZjjyOZ2RT3//M3vpdmfDrDl6ft52GAb4s/lt/vCoQbaYoZ4r6SKqKnIzTTkbMyc3Dy0P+FG9RxhjeXbiTHs3q4uftxecr9jK0bUP6taqHl6cHB45nMGXpHm7/eCWz7u9F/TJMJjuPpHP3lFgaBfpxd99mPPfdJp6ctYGh7Rry6bK93HlxJANa1+fmj5bz0g9bmLMxka4RdcjJNQy8qDZPX9bGZkNffhFPf7uJv1zagtt7RwJwf7/mbNifwvu3dGFFfDLxSSdKFGwiwgtXt3fb8wLw8fKoUiECcE10GG/+soObu4erEFGqHSpIyiP7JPhUvDxKXp7h0n8vpH+r+jx/lU13McaQcCzjnDsL0zJzyM0zp1W/6OvV+3lt7jZCA33p1TwEHy8PXrmufZE++reqz40fLGXwG79xZcdGdI2oS6MgP3Jy89hxOJ16tX3o27Ie90xdhacIk8d0Izy4JieyHLzwwxZ+2XqYTk2CeHRwS2r6eDGiaxM+X2Hrff7j8rYFzuJ8RveMoF+r+oTVKRTwTwxtXWQ8tOJPReMgP359tN9pJ7MpytlABUl5VDBqa0NCChEhNUlMyWRfsn1LH9K2Ib1bhPDuwp28Pm8b3427uNyENWMMxpScGQtWUOUfc/3tev6ny/bQKMiPARcVmm5OZju47r0l1PDy5LsHLy5yzsGUTD5ZGs9PGw8ytm8zRnaz1ZIPp2Xy/PebiQypxe6kE3y1OoFroxufIojahwXyxT09mPjbLqav3MeUpXtOGXfjID8OpGTw6Z3dC2Lxx/SO5HBaFi3q1ea6LmEFYZ2PDW7FD+sTiW5a5xQhks+5FsrnggvxnpXzAxUk5VEB09aqPce4/v0l3N4roqDgWn3/Gjwxcz2PDWnJm/N3YAxMW76Xl6891aySlpkDgL+vN09/u5G1+44zfWxPatewZaHnbzlM14g6eHoIl7+9mKs6NebWnk257r0l9GwWzMvXtkdEyM0z/PP7zUxeEo+Plwez7u9F20aBGGP4x7eb2H4oHbCJbvmT0oJth3n4i7WkZuTQKMiPJ2dtoF7tGlwcFcJ9n64mMyeXj26L4Y35O5i97gA3dy+5JH+HsCAmjIomy5HLjkPpJKVn4ekhRATX4ps1+/nP/O08NKAlvV0yij09hP8bftEpfQXXrsEPf+lzSi0jRVGqJ+psL4u8PHi+DlzyN+j/fyU2yczJ5bK3fmfnkRM0DLB1hJbtOsrEW2O4e0osR9KyqFvLh+jwOizdmcTyJweS48jj6W83En/0BPX9ffkjLokGAb68fkNHbpq4FGPgqk6NeOOmTvy8+RBjp65iUJsGRIfX4dWfbA5Bywa12XE4HWNghDMvYM6GRA6kZHJLj3B+3nwIb08P+kSFsHx3MruOnODa6MZ8vXo/T1/ehtYN/Xn5xy1s3J9K64b+vHNzNA0DfBkxcRkb9qfQKNCXxNRM3h0VzbD2oaSczGHJziSGtmtYKd9PSkZOlRT+UxTl7KFRWy5UWpBkn4CXGsHA5+Dih0ps8uIPm/nw991cFx3GV6sT8PH0YFDbBrwzKpoTWQ6mLN1D5/AgfLw8uPbdJfRvVY+tB21MfUxEHQ4czyAmoi7frNmPhwg1vD0Y0bUJH/5uM4nnbznEwZRMsnPzqOnjScewIFIycticmMpL17RnfcJxpq/ch4+nBz2bBzOyWxOGtG1I7J5jPP7lOtKzcmkWUosbYsK4NjqMYW/+hpeHB/uPZxBU05sxvSK4qWt4QcmJlJM5TF0Wz/frExnVPZxbe0acwZNXFOV8RqO2qoKCZXZLtk3P33yID3/fzS09wnliaGu+W3eA7Nw8ujmL8NWq4cV9ziqhxhiiw4NYsvMoHcIC+WB0FzqEBRX01aqBPy/O2cJfBrTgvn4tyHbkMekPW19o0u0xPPfdZvYcPclDA6OICKnFyvhkLmsfyshuTRh3aQsaBPgWKUDYNaIuCx/vf8qYB7VpwDsLduLj5cHXt/cqsvYBQGBNb8ZdGsW4S6Mq/9wURbmgUEFSFtnOZXadqyOmZORw9Tt/8MwVbejcpA6PzVxHm9AAnrqsDb7envSJCuGXrYdLrOYqIsy8txd5xpQYvnlXn0iimwbRqYn1hTx3VTt6Ng8m4VgGl7ZuQFBNH5bEJdEtsi4iwuUdGhWcG1an4k7YYe1CeWfBTh4Z1PIUIaIoilIZVJCURU7RtUhW7z3G7qQTzmJ5DTl+Modpd3UvyEK+q08zatbwolXDkhPzPDwEjxJXC7aCpkvTogLIdQW36PA6RIfXOdM7ol3jQBY93o9wjQBSFKWKUEFSFsUEycaEFAA2HUhlx6F0BrSuT9tGheGpPZsHF9RHqs40DdZlgxVFqTpUkJRF/uqITtPW+v22LLkjN48DKZnc37/FORycoihK9UAFSVkUaCT2DX5DQgrdm9Xlig6NWLPvWEFFWEVRlAsZtxbtEZGhIrJNROJEZHwJx8NFZIGIrBGR9SIy3Ll/kIisEpENzu9LXc5Z6OxzrfNT3203UCBI/DiclsnB1EzaNw5kYJsGPD6kddnnKoqiXCC4TSMREU/gHWAQkACsFJHZznXa83kKmGGMeU9E2mDXd48AkoArjDEHRKQdMBdo7HLezc61292Li2lr437rH3EN2VUURVHcq5F0A+KMMbuMMdnAdOCqYm0MkL/YQyBwAMAYs8YYc8C5fxPgKyI13DjWknExbW1ISEUE2paytreiKMqFijsFSWNgn8t2AkW1CoBngVtEJAGrjTxYQj/XAWuMMVku+z52mrWellLqdYjIWBGJFZHYI0eOVO4O8vNIvP3YfiiNiOBap72Ik6Ioyp8ddwqSkib44vVYRgKTjTFhwHBgqogUjElE2gKvAve4nHOzMaY90Mf5GV3SxY0xE40xMcaYmHr16lXuDlwy24+kZVHf/+wrRYqiKNUddwqSBKCJy3YYTtOVC3cCMwCMMUsBXyAEQETCgFnArcaYnfknGGP2O7/TgM+wJjT3kHMCvPzAw4Ok9CxCVJAoiqKcgjsFyUogSkQiRcQHGAHMLtZmLzAAQEQuwgqSIyISBPwA/N0Y80d+YxHxEpF8QeMNXA5sdNsdZJ8sKCF/JD2LerVVkCiKohTHbYLEGOMAxmEjrrZgo7M2icjzInKls9mjwN0isg74HLjd2HLE44AWwNPFwnxrAHNFZD2wFtgPfOiueyAnA3xqkZmTS1qmg3qqkSiKopxCuZ5jEYkEEo0xmc5tP6CBMSa+vHONMXOwTnTXff9w+b0Z6F3CeS8AL5TSbZfyrltlOFdHTEq3fv6Q2hVfolZRFOVCoSIayZdAnst2rnPfnx+naSspPRuAEDVtKYqinEJFYlm9nHkgABhjsp0+jz8//f4OjkyS0vI1EhUkiqIoxamIRnLExaeBiFyFzTz/8xPWBSJ6F5q21EeiKIpyChXRSO4FponIBOd2AnCr+4ZU/VAfiaIoSumUK0icORw9RKQ2do33NPcPq3qRlJ5NgK8XNbw8z/VQFEVRqh3lmrZE5CURCTLGpBtj0kSkjoiUFlH1p+RImiYjKoqilEZFfCTDjDHH8zeMMcew5UwuGI6kZ6mjXVEUpRQqIkg8XSvvOvNILqhZNUmz2hVFUUqlIs72T4FfRORj5/YY4BP3Dan6kZSWRUgLdbQriqKUREWc7f9yliQZiK3o+xPQ1N0Dqy5kOXJJ1fIoiqIopVLRWlsHsdnt12GLLG5x24iqGUc1q11RFKVMStVIRKQltmLvSOAo8AU2/Lf/WRpbteD4yRwAgmp6n+ORKIqiVE/KMm1tBX7Hrp0eByAiD5+VUVUjcvPsWlxeHu6suK8oinL+UtbseB3WpLVARD4UkQGUvOrhnxpHnq1X6eV5wd26oihKhShVkBhjZhljbgJaAwuBh4EGIvKeiAw+S+M75zhUI1EURSmTcmdHY8wJY8w0Y8zl2OVy1wLj3T6yaoIj1woSTw/VSBRFUUritF6zjTHJxpgPjDGXumtA1Y0CH4mathRFUUpE7TXlUOAjUY1EURSlRNwqSERkqIhsE5E4ETnFHCYi4SKyQETWiMh6ERnucuzvzvO2iciQivZZ1WjUlqIoStm4bXYUEU/gHWAY0AYYKSJtijV7CphhjOmMzVl513luG+d2W2Ao8K6IeFawzyolR30kiqIoZeLO1+xuQJwxZpdzqd7pwFXF2hggwPk7EDjg/H0VMN0Yk2WM2Q3EOfurSJ9VivpIFEVRysadgqQxsM9lO8G5z5VngVtEJAGYAzxYzrkV6bNKyfeRqEaiKIpSMu4UJCXNvKbY9khgsjEmDLvGyVQR8Sjj3Ir0aS8uMlZEYkUk9siRI6cx7KLkayTe6iNRFEUpEXfOjglAE5ftMApNV/ncCcwAMMYsBXyBkDLOrUifOPubaIyJMcbE1KtXr9I3UZBHoqYtRVGUEnGnIFkJRIlIpIj4YJ3ns4u12YutJoyIXIQVJEec7UaISA0RiQSigBUV7LNKKcxsV0GiKIpSEhVZ2KpSGGMcIjIOmAt4ApOMMZtE5Hkg1hgzG3gU+NBZDNIAtxtjDLBJRGYAmwEH8IAxJhegpD7ddQ8AueojURRFKRO3CRIAY8wcrBPddd8/XH5vBnqXcu6LwIsV6dOdONRHoiiKUiY6O5ZDvrNdfSSKoiglo4KkHPITEtVHoiiKUjIqSMpBfSSKoihlo4KkHDRqS1EUpWxUkJRDbp7B00MQUUGiKIpSEipIyiEn16hZS17IeDgAAA5ySURBVFEUpQxUkJRDbl6emrUURVHKQAVJOTjyVCNRFEUpCxUk5ZCbZ/D21MekKIpSGjpDloP6SBRFUcpGBUk5qI9EURSlbFSQlIP6SBRFUcpGBUk55OYZ1UgURVHKQAVJOTjyDF7qbFcURSkVnSHLwZGrPhJFUZSyUEFSDrnqI1EURSkTFSTl4FAfiaIoSpmoICkH1UgURVHKRgVJOeTk5qmzXVEUpQzcOkOKyFAR2SYicSIyvoTj/xWRtc7PdhE57tzf32X/WhHJFJGrnccmi8hul2Od3HkPGv6rKIpSNl7u6lhEPIF3gEFAArBSRGYbYzbntzHGPOzS/kGgs3P/AqCTc39dIA6Y59L948aYme4auyuOPIOvtwoSRVGU0nCnRtINiDPG7DLGZAPTgavKaD8S+LyE/dcDPxpjTrphjOWiGomiKErZuFOQNAb2uWwnOPedgog0BSKBX0s4PIJTBcyLIrLeaRqrUUqfY0UkVkRijxw5cvqjd+LI1YRERVGUsnDnDFnSa7wppe0IYKYxJrdIByKhQHtgrsvuvwOtga5AXeBvJXVojJlojIkxxsTUq1fvdMdegEOLNiqKopSJOwVJAtDEZTsMOFBK25K0DoAbgVnGmJz8HcaYRGPJAj7GmtDchhZtVBRFKRt3CpKVQJSIRIqID1ZYzC7eSERaAXWApSX0cYrfxKmlICICXA1srOJxF0F9JIqiKGXjtqgtY4xDRMZhzVKewCRjzCYReR6INcbkC5WRwHRjTBGzl4hEYDWaRcW6niYi9bCms7XAve66B7A+Ek8P9ZEoiqKUhtsECYAxZg4wp9i+fxTbfraUc+MpwTlvjLm06kZYPo68PLw9VSNRFEUpDX3VLgctkaIoilI2KkjK4f/bu/dYOcoyjuPfny2tKCIFqkEupUhFMWrBY2O8kHgHotRboA0JF0kIBFQwEkowhBhNRKMYlEhKQNAgRRFCEy9AADGGUjjgKbRA20PBUFvggFY0EOjZ8/jHvAvTw84M7Z6ZWeD3STY7++zsnGffnTPPvvPOzvikjWZm5VxIKnQ8RmJmVspbyApbPUZiZlbKhaSCx0jMzMq5kFTwGImZWTkXkhITE0EEHiMxMyvhLWSJ8YnsN5LTPUZiZlbIhaTE+MQEgHdtmZmVcCEp0e2ReLDdzKyYC0mJTift2nIhMTMr5EJS4sUeiS9sZWZWyFvIEt0xkp3cIzEzK+RCUmK84zESM7MqLiQlOj7818yskgtJiZeO2nIzmZkV8RayxIs9Eu/aMjMr5EJSYmvHP0g0M6tSayGRdLiktZJGJS3p8fyFkkbSbZ2kLbnnOrnnluficyWtlLRe0jWSZtSVv8dIzMyq1VZIJE0DLgaOAA4GFks6OD9PRJwZEfMjYj7wM+C63NPPdZ+LiKNy8QuACyNiHvBv4KS63oPHSMzMqtW5hVwAjEbEhoh4AVgGLCyZfzFwddkCJQn4JHBtCl0JfHEKcu3JYyRmZtXqLCR7A4/lHm9MsZeRNAeYC9yaC79R0rCkOyV1i8UewJaIGH8Fyzw5vX54bGxsh97AeBoj8e9IzMyKTa9x2b22vlEw7yLg2ojo5GL7RcQmSQcAt0q6H3jmlS4zIpYCSwGGhoaK/m6p7q4tX2rXzKxYnT2SjcC+ucf7AJsK5l3EpN1aEbEp3W8A/gIcAjwF7CapWwDLltm3jsdIzMwq1bmFvBuYl46ymkFWLJZPnknSQcAsYEUuNkvSzDS9J/BR4IGICOA24Ktp1uOBG+p6A+MeIzEzq1RbIUnjGKcDNwIPAr+NiDWSvispfxTWYmBZKhJd7wGGJa0iKxw/iIgH0nNnA9+SNEo2ZnJZXe/BYyRmZtXqHCMhIv4I/HFS7LxJj8/v8bo7gPcVLHMD2RFhtfMYiZlZNe/8L+ExEjOzat5ClvAYiZlZNReSEp0Jj5GYmVVxISmx1ddsNzOr5EJS4qWTNrqZzMyKeAtZ4qWTNrpHYmZWxIWkRHeMxLu2zMyKuZCU6I6RuEdiZlbMhaRE58UfJLqZzMyKeAtZojtG4g6JmVkxF5ISnYkJpr9BZNfTMjOzXlxISoxPhMdHzMwquJCUGO+Ej9gyM6vgQlKiMxH+MaKZWQVvJUuMpzESMzMr5kJSouMxEjOzSi4kJbZ6jMTMrJILSQmPkZiZVat1KynpcElrJY1KWtLj+QsljaTbOklbUny+pBWS1ki6T9IxuddcIemR3Ovm15X/+IR7JGZmVWq7ZrukacDFwGeAjcDdkpZHxAPdeSLizNz8XwcOSQ+fBY6LiPWS3gHcI+nGiNiSnj8rIq6tK/euzsSEx0jMzCrU2SNZAIxGxIaIeAFYBiwsmX8xcDVARKyLiPVpehPwJDC7xlx72trxYLuZWZU6C8newGO5xxtT7GUkzQHmArf2eG4BMAN4OBf+ftrldaGkmQXLPFnSsKThsbGxHXoD2RiJC4mZWZk6C0mvLXAUzLsIuDYiOtssQNoL+DVwYkRMpPA5wLuBDwG7A2f3WmBELI2IoYgYmj17xzozH5wzi48d2HhHyMzsVaW2MRKyHsi+ucf7AJsK5l0EnJYPSNoV+APwnYi4sxuPiM1p8nlJvwS+PWUZT3LaJw6sa9FmZq8ZdfZI7gbmSZoraQZZsVg+eSZJBwGzgBW52AzgeuBXEfG7SfPvle4FfBFYXds7MDOzSrX1SCJiXNLpwI3ANODyiFgj6bvAcER0i8piYFlE5Hd7HQ0cBuwh6YQUOyEiRoCrJM0m23U2ApxS13swM7Nq2nb7/do0NDQUw8PDbadhZvaqIumeiBiqms8/2zYzs764kJiZWV9cSMzMrC8uJGZm1hcXEjMz68vr4qgtSWPAP3bw5XsCT01hOlNlUPOCwc3NeW0f57X9BjW3Hc1rTkRUnt7jdVFI+iFp+JUc/ta0Qc0LBjc357V9nNf2G9Tc6s7Lu7bMzKwvLiRmZtYXF5JqS9tOoMCg5gWDm5vz2j7Oa/sNam615uUxEjMz64t7JGZm1hcXEjMz64sLSQlJh0taK2lU0pIW89hX0m2SHpS0RtI3U/x8Sf+UNJJuR7aQ26OS7k9/fzjFdpd0s6T16X5WwzkdlGuTEUnPSDqjrfaSdLmkJyWtzsV6tpEyF6V17j5Jhzac148kPZT+9vWSdkvx/SU9l2u7SxrOq/Czk3ROaq+1kj7XcF7X5HJ6VNJIijfZXkXbh+bWsYjwrceN7BoqDwMHkF0zfhVwcEu57AUcmqbfAqwDDgbOB77dcjs9Cuw5KfZDYEmaXgJc0PLn+Dgwp632Iru2zqHA6qo2Ao4E/kR2vZ0PAysbzuuzwPQ0fUEur/3z87XQXj0/u/R/sAqYCcxN/7PTmspr0vM/Bs5rob2Ktg+NrWPukRRbAIxGxIaIeAFYBixsI5GI2BwR96bp/wIPAnu3kcsrtBC4Mk1fSXYly7Z8Cng4Inb0zAZ9i4i/Av+aFC5qo4VkVwaNyC4xvVv3qqBN5BURN0XEeHp4J9klshtV0F5FFpJdGO/5iHgEGCX73200r3TF1qOBq+v422VKtg+NrWMuJMX2Bh7LPd7IAGy8Je0PHAKsTKHTU/f08qZ3ISUB3CTpHkknp9jbI2IzZCs58LYW8upaxLb/3G23V1dRGw3Sevc1sm+uXXMl/V3S7ZI+3kI+vT67QWmvjwNPRMT6XKzx9pq0fWhsHXMhKaYesVaPlZa0C/B74IyIeAb4BfBOYD6wmaxr3bSPRsShwBHAaZIOayGHniTNAI4CfpdCg9BeVQZivZN0LjAOXJVCm4H9IuIQ4FvAbyTt2mBKRZ/dQLQX2SXD819YGm+vHtuHwll7xPpqMxeSYhuBfXOP9wE2tZQLknYiW0muiojrACLiiYjoRMQEcCk1denLRMSmdP8kcH3K4YluVzndP9l0XskRwL0R8UTKsfX2yilqo9bXO0nHA58Hjo20Uz3tOno6Td9DNhbxrqZyKvnsBqG9pgNfBq7pxppur17bBxpcx1xIit0NzJM0N32zXQQsbyORtP/1MuDBiPhJLp7fr/klYPXk19ac15slvaU7TTZQu5qsnY5Psx0P3NBkXjnbfEtsu70mKWqj5cBx6ciaDwP/6e6eaIKkw4GzgaMi4tlcfLakaWn6AGAesKHBvIo+u+XAIkkzJc1Ned3VVF7Jp4GHImJjN9BkexVtH2hyHWviqIJX643s6IZ1ZN8mzm0xj4+RdT3vA0bS7Ujg18D9Kb4c2KvhvA4gO2JmFbCm20bAHsAtwPp0v3sLbfYm4GngrblYK+1FVsw2A1vJvg2eVNRGZLsdLk7r3P3AUMN5jZLtP++uZ5ekeb+SPuNVwL3AFxrOq/CzA85N7bUWOKLJvFL8CuCUSfM22V5F24fG1jGfIsXMzPriXVtmZtYXFxIzM+uLC4mZmfXFhcTMzPriQmJmZn1xITGbApI62vaMw1N2tuh0Jtk2f/NiVmp62wmYvUY8FxHz207CrA3ukZjVKF2j4gJJd6XbgSk+R9It6SSEt0jaL8Xfruw6IKvS7SNpUdMkXZquN3GTpJ1be1Nmk7iQmE2NnSft2jom99wzEbEA+Dnw0xT7OdmpvN9PdmLEi1L8IuD2iPgA2bUv1qT4PODiiHgvsIXsl9NmA8G/bDebApL+FxG79Ig/CnwyIjakE+s9HhF7SHqK7DQfW1N8c0TsKWkM2Ccins8tY3/g5oiYlx6fDewUEd+r/52ZVXOPxKx+UTBdNE8vz+emO3h80waIC4lZ/Y7J3a9I03eQnVEa4Fjgb2n6FuBUAEnTGr7mh9kO8bcas6mxs6SR3OM/R0T3EOCZklaSfXFbnGLfAC6XdBYwBpyY4t8Elko6iazncSrZGWfNBpbHSMxqlMZIhiLiqbZzMauLd22ZmVlf3CMxM7O+uEdiZmZ9cSExM7O+uJCYmVlfXEjMzKwvLiRmZtaX/wPRFYK6bCM/yAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, kernel_initializer='normal', input_dim=len(X[0]), activation='relu'))\n",
    "model.add(Dense(10, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adamax',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X, y.values, epochs=200, validation_split = 0.1)\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### Prever relação do AJUSTE ATUAL com  ABERTURA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T17:28:53.573733Z",
     "start_time": "2019-09-13T17:28:53.513766Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Número Negócios</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Var pontos</th>\n",
       "      <th>Dif_contratos</th>\n",
       "      <th>Dif_minmax</th>\n",
       "      <th>Dif_abert_ultimo</th>\n",
       "      <th>Dif_abert_ajuste</th>\n",
       "      <th>Dif_abert_min</th>\n",
       "      <th>Dif_abert_max</th>\n",
       "      <th>Dif_abert_medio</th>\n",
       "      <th>Dif_ajuste_ultimo</th>\n",
       "      <th>Dif_ajuste_medio</th>\n",
       "      <th>Média</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29/07/2019</td>\n",
       "      <td>271.92</td>\n",
       "      <td>42.939771</td>\n",
       "      <td>145520</td>\n",
       "      <td>132520</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>7.5</td>\n",
       "      <td>-16.5</td>\n",
       "      <td>-4.499</td>\n",
       "      <td>2.797</td>\n",
       "      <td>-4.702</td>\n",
       "      <td>3.785600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26/07/2019</td>\n",
       "      <td>321.28</td>\n",
       "      <td>58.414828</td>\n",
       "      <td>125890</td>\n",
       "      <td>23510</td>\n",
       "      <td>34.5</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-9.755</td>\n",
       "      <td>19.0</td>\n",
       "      <td>-15.5</td>\n",
       "      <td>4.970</td>\n",
       "      <td>-5.755</td>\n",
       "      <td>-4.785</td>\n",
       "      <td>3.776534</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25/07/2019</td>\n",
       "      <td>416.51</td>\n",
       "      <td>72.105906</td>\n",
       "      <td>129780</td>\n",
       "      <td>15894</td>\n",
       "      <td>50.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>14.834</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-39.0</td>\n",
       "      <td>-16.490</td>\n",
       "      <td>3.334</td>\n",
       "      <td>-1.656</td>\n",
       "      <td>3.779853</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24/07/2019</td>\n",
       "      <td>261.37</td>\n",
       "      <td>50.725253</td>\n",
       "      <td>31160</td>\n",
       "      <td>-7529</td>\n",
       "      <td>25.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.356</td>\n",
       "      <td>13.5</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>4.779</td>\n",
       "      <td>-3.644</td>\n",
       "      <td>7.135</td>\n",
       "      <td>3.769510</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23/07/2019</td>\n",
       "      <td>335.86</td>\n",
       "      <td>59.121713</td>\n",
       "      <td>356000</td>\n",
       "      <td>-2908</td>\n",
       "      <td>39.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>27.972</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>-22.634</td>\n",
       "      <td>-2.028</td>\n",
       "      <td>5.338</td>\n",
       "      <td>3.767201</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Data  Número Negócios     Volume  Var pontos  Dif_contratos  \\\n",
       "0  29/07/2019           271.92  42.939771      145520         132520   \n",
       "1  26/07/2019           321.28  58.414828      125890          23510   \n",
       "2  25/07/2019           416.51  72.105906      129780          15894   \n",
       "3  24/07/2019           261.37  50.725253       31160          -7529   \n",
       "4  23/07/2019           335.86  59.121713      356000          -2908   \n",
       "\n",
       "   Dif_minmax  Dif_abert_ultimo  Dif_abert_ajuste  Dif_abert_min  \\\n",
       "0        24.0              -3.0            -0.203            7.5   \n",
       "1        34.5              -4.0            -9.755           19.0   \n",
       "2        50.0              11.5            14.834           11.0   \n",
       "3        25.5               6.0             2.356           13.5   \n",
       "4        39.0              30.0            27.972            2.0   \n",
       "\n",
       "   Dif_abert_max  Dif_abert_medio  Dif_ajuste_ultimo  Dif_ajuste_medio  \\\n",
       "0          -16.5           -4.499              2.797            -4.702   \n",
       "1          -15.5            4.970             -5.755            -4.785   \n",
       "2          -39.0          -16.490              3.334            -1.656   \n",
       "3          -12.0            4.779             -3.644             7.135   \n",
       "4          -37.0          -22.634             -2.028             5.338   \n",
       "\n",
       "      Média  target  \n",
       "0  3.785600       0  \n",
       "1  3.776534       1  \n",
       "2  3.779853       1  \n",
       "3  3.769510       1  \n",
       "4  3.767201       0  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_abert_old = df.copy()\n",
    "\n",
    "#1 se o Ajuste for maior que a abertura\n",
    "\n",
    "df_abert_old['target'] = df_abert_old.Ajuste.shift(-1) - df_abert_old.Abertura.shift(-1)\n",
    "df_abert_old['target'] = df_abert_old['target'].apply(lambda x: 1 if x > 0 else 0)\n",
    "df_abert_old = df_abert_old.drop(len(df_abert)-1)\n",
    "\n",
    "df_abert_old['Média'] = (df_abert_old['Último Preço'] + df_abert_old['Abertura'] + df_abert_old['Máximo'] + df_abert_old['Mínimo'] + df_abert_old['Médio'] + df_abert_old['Ajuste'] + df_abert_old['Última oferta de compra']+ df_abert_old['Última oferta de venda'])/8\n",
    "df_abert_old = df_abert_old.drop(columns = ['Último Preço','Abertura','Máximo','Mínimo','Médio','Última oferta de compra','Última oferta de venda','Contratos Negociados', 'Ajuste'])\n",
    "\n",
    "\n",
    "df_change = df_abert_old[['target']]\n",
    "df_abert_old = df_abert_old.drop(columns = 'target')\n",
    "df_abert_old['target'] = df_change\n",
    "\n",
    "df_abert_old.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T17:28:57.433743Z",
     "start_time": "2019-09-13T17:28:57.401745Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "\n",
    "df_abert_old.iloc[:,1:-1]  = sc.fit_transform(df_abert_old.iloc[:,1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T17:28:58.225464Z",
     "start_time": "2019-09-13T17:28:58.157469Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_moeda = pd.read_csv('moedas_features.csv')\n",
    "\n",
    "sc = StandardScaler()\n",
    "df_moeda.iloc[:,1:] = sc.fit_transform(df_moeda.iloc[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T17:28:58.379194Z",
     "start_time": "2019-09-13T17:28:58.355229Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "dataset = pca.fit_transform(df_moeda.iloc[:,1:])\n",
    "df_moeda_pca = pd.DataFrame(dataset)\n",
    "df_moeda_pca['Data'] = df_moeda.iloc[:,0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T17:28:58.557388Z",
     "start_time": "2019-09-13T17:28:58.541376Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_abert = pd.merge(df_moeda_pca, df_abert_old, on = 'Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T17:28:58.778463Z",
     "start_time": "2019-09-13T17:28:58.756476Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.73655682,  1.39392987,  0.42006285, ..., -0.21276328,\n",
       "        -0.19602005,  2.00409008],\n",
       "       [ 1.0995634 ,  0.54193776,  0.47238026, ..., -0.19968062,\n",
       "        -0.19427555,  1.96205815],\n",
       "       [ 0.82993688,  1.11635787,  0.1381659 , ..., -0.23787811,\n",
       "        -0.20287215,  1.9713729 ],\n",
       "       ...,\n",
       "       [ 2.64784845,  0.94006301,  0.91821312, ..., -0.21481031,\n",
       "        -0.22199328, -0.57127243],\n",
       "       [ 2.91379724,  0.57835414, -1.47655902, ..., -0.20866022,\n",
       "        -0.21725796, -0.55684205],\n",
       "       [ 2.26871311,  1.88815856,  0.42042375, ..., -0.20874836,\n",
       "        -0.2036275 , -0.55139601]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df_abert[['target']]\n",
    "X = df_abert.drop(columns = ['Data','target'])\n",
    "X_columns = df_abert.drop(columns = ['Data','target'])\n",
    "\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "#X = X.values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T17:28:59.301553Z",
     "start_time": "2019-09-13T17:28:59.293539Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T17:29:00.025689Z",
     "start_time": "2019-09-13T17:28:59.994709Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\choice\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\choice\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5693606755126659"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression().fit(x_train, y_train)\n",
    "\n",
    "predictions = clf.predict(x_test)\n",
    "\n",
    "probas = clf.predict_proba(x_test) \n",
    "\n",
    "\n",
    "score = clf.score(x_test, y_test)\n",
    "\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T17:29:03.158833Z",
     "start_time": "2019-09-13T17:29:03.006916Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\choice\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "c:\\users\\choice\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.49939686369119424"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = RandomForestClassifier()\n",
    "r.fit(x_train, y_train)  \n",
    "\n",
    "predictions = r.predict(x_test)\n",
    "\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T17:29:03.468828Z",
     "start_time": "2019-09-13T17:29:03.200807Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = X_columns.columns\n",
    "importances = r.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T14:45:23.054788Z",
     "start_time": "2019-09-13T14:44:47.451149Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0913 11:44:47.458145   968 deprecation_wrapper.py:119] From c:\\users\\choice\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0913 11:44:47.497122   968 deprecation_wrapper.py:119] From c:\\users\\choice\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0913 11:44:47.501122   968 deprecation_wrapper.py:119] From c:\\users\\choice\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "W0913 11:44:47.551094   968 deprecation_wrapper.py:119] From c:\\users\\choice\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0913 11:44:47.579077   968 deprecation_wrapper.py:119] From c:\\users\\choice\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0913 11:44:47.607060   968 deprecation_wrapper.py:119] From c:\\users\\choice\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0913 11:44:47.614060   968 deprecation.py:323] From c:\\users\\choice\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3730 samples, validate on 415 samples\n",
      "Epoch 1/200\n",
      "3730/3730 [==============================] - 0s 118us/step - loss: 0.6926 - acc: 0.5107 - val_loss: 0.6917 - val_acc: 0.5084\n",
      "Epoch 2/200\n",
      "3730/3730 [==============================] - 0s 55us/step - loss: 0.6911 - acc: 0.5308 - val_loss: 0.6912 - val_acc: 0.4940\n",
      "Epoch 3/200\n",
      "3730/3730 [==============================] - 0s 45us/step - loss: 0.6898 - acc: 0.5426 - val_loss: 0.6908 - val_acc: 0.5157\n",
      "Epoch 4/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.6884 - acc: 0.5448 - val_loss: 0.6908 - val_acc: 0.5181\n",
      "Epoch 5/200\n",
      "3730/3730 [==============================] - 0s 55us/step - loss: 0.6870 - acc: 0.5512 - val_loss: 0.6910 - val_acc: 0.5229\n",
      "Epoch 6/200\n",
      "3730/3730 [==============================] - 0s 41us/step - loss: 0.6861 - acc: 0.5542 - val_loss: 0.6913 - val_acc: 0.5036\n",
      "Epoch 7/200\n",
      "3730/3730 [==============================] - 0s 53us/step - loss: 0.6857 - acc: 0.5534 - val_loss: 0.6917 - val_acc: 0.5157\n",
      "Epoch 8/200\n",
      "3730/3730 [==============================] - 0s 50us/step - loss: 0.6848 - acc: 0.5598 - val_loss: 0.6923 - val_acc: 0.5036\n",
      "Epoch 9/200\n",
      "3730/3730 [==============================] - 0s 45us/step - loss: 0.6844 - acc: 0.5560 - val_loss: 0.6927 - val_acc: 0.5012\n",
      "Epoch 10/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.6841 - acc: 0.5560 - val_loss: 0.6928 - val_acc: 0.5012\n",
      "Epoch 11/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.6836 - acc: 0.5574 - val_loss: 0.6932 - val_acc: 0.4988\n",
      "Epoch 12/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.6833 - acc: 0.5627 - val_loss: 0.6937 - val_acc: 0.4916\n",
      "Epoch 13/200\n",
      "3730/3730 [==============================] - 0s 42us/step - loss: 0.6829 - acc: 0.5614 - val_loss: 0.6938 - val_acc: 0.4940\n",
      "Epoch 14/200\n",
      "3730/3730 [==============================] - 0s 42us/step - loss: 0.6828 - acc: 0.5681 - val_loss: 0.6942 - val_acc: 0.4892\n",
      "Epoch 15/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.6823 - acc: 0.5646 - val_loss: 0.6946 - val_acc: 0.4867\n",
      "Epoch 16/200\n",
      "3730/3730 [==============================] - 0s 52us/step - loss: 0.6822 - acc: 0.5641 - val_loss: 0.6950 - val_acc: 0.4892\n",
      "Epoch 17/200\n",
      "3730/3730 [==============================] - ETA: 0s - loss: 0.6814 - acc: 0.561 - 0s 43us/step - loss: 0.6819 - acc: 0.5611 - val_loss: 0.6951 - val_acc: 0.4892\n",
      "Epoch 18/200\n",
      "3730/3730 [==============================] - 0s 43us/step - loss: 0.6816 - acc: 0.5676 - val_loss: 0.6948 - val_acc: 0.4867\n",
      "Epoch 19/200\n",
      "3730/3730 [==============================] - 0s 42us/step - loss: 0.6816 - acc: 0.5662 - val_loss: 0.6956 - val_acc: 0.4988\n",
      "Epoch 20/200\n",
      "3730/3730 [==============================] - 0s 40us/step - loss: 0.6813 - acc: 0.5654 - val_loss: 0.6959 - val_acc: 0.4916\n",
      "Epoch 21/200\n",
      "3730/3730 [==============================] - 0s 45us/step - loss: 0.6809 - acc: 0.5641 - val_loss: 0.6961 - val_acc: 0.4940\n",
      "Epoch 22/200\n",
      "3730/3730 [==============================] - 0s 45us/step - loss: 0.6808 - acc: 0.5710 - val_loss: 0.6962 - val_acc: 0.4867\n",
      "Epoch 23/200\n",
      "3730/3730 [==============================] - 0s 46us/step - loss: 0.6805 - acc: 0.5697 - val_loss: 0.6965 - val_acc: 0.4867\n",
      "Epoch 24/200\n",
      "3730/3730 [==============================] - 0s 50us/step - loss: 0.6805 - acc: 0.5668 - val_loss: 0.6968 - val_acc: 0.4892\n",
      "Epoch 25/200\n",
      "3730/3730 [==============================] - 0s 43us/step - loss: 0.6805 - acc: 0.5668 - val_loss: 0.6979 - val_acc: 0.4916\n",
      "Epoch 26/200\n",
      "3730/3730 [==============================] - 0s 52us/step - loss: 0.6799 - acc: 0.5684 - val_loss: 0.6975 - val_acc: 0.4964\n",
      "Epoch 27/200\n",
      "3730/3730 [==============================] - 0s 50us/step - loss: 0.6796 - acc: 0.5668 - val_loss: 0.6986 - val_acc: 0.4964\n",
      "Epoch 28/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.6794 - acc: 0.5643 - val_loss: 0.6984 - val_acc: 0.4940\n",
      "Epoch 29/200\n",
      "3730/3730 [==============================] - 0s 53us/step - loss: 0.6793 - acc: 0.5678 - val_loss: 0.6987 - val_acc: 0.4940\n",
      "Epoch 30/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.6792 - acc: 0.5670 - val_loss: 0.6988 - val_acc: 0.4892\n",
      "Epoch 31/200\n",
      "3730/3730 [==============================] - 0s 42us/step - loss: 0.6795 - acc: 0.5702 - val_loss: 0.6988 - val_acc: 0.4940\n",
      "Epoch 32/200\n",
      "3730/3730 [==============================] - 0s 42us/step - loss: 0.6790 - acc: 0.5676 - val_loss: 0.6996 - val_acc: 0.4940\n",
      "Epoch 33/200\n",
      "3730/3730 [==============================] - 0s 42us/step - loss: 0.6787 - acc: 0.5732 - val_loss: 0.6990 - val_acc: 0.5012\n",
      "Epoch 34/200\n",
      "3730/3730 [==============================] - 0s 44us/step - loss: 0.6785 - acc: 0.5705 - val_loss: 0.6997 - val_acc: 0.4964\n",
      "Epoch 35/200\n",
      "3730/3730 [==============================] - 0s 53us/step - loss: 0.6783 - acc: 0.5721 - val_loss: 0.7000 - val_acc: 0.4988\n",
      "Epoch 36/200\n",
      "3730/3730 [==============================] - 0s 52us/step - loss: 0.6781 - acc: 0.5721 - val_loss: 0.7003 - val_acc: 0.4964\n",
      "Epoch 37/200\n",
      "3730/3730 [==============================] - 0s 53us/step - loss: 0.6779 - acc: 0.5740 - val_loss: 0.7003 - val_acc: 0.4916\n",
      "Epoch 38/200\n",
      "3730/3730 [==============================] - 0s 51us/step - loss: 0.6781 - acc: 0.5721 - val_loss: 0.7004 - val_acc: 0.4916\n",
      "Epoch 39/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.6773 - acc: 0.5772 - val_loss: 0.7008 - val_acc: 0.4988\n",
      "Epoch 40/200\n",
      "3730/3730 [==============================] - 0s 53us/step - loss: 0.6776 - acc: 0.5713 - val_loss: 0.7002 - val_acc: 0.4964\n",
      "Epoch 41/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.6776 - acc: 0.5718 - val_loss: 0.7009 - val_acc: 0.4988\n",
      "Epoch 42/200\n",
      "3730/3730 [==============================] - 0s 42us/step - loss: 0.6773 - acc: 0.5743 - val_loss: 0.7008 - val_acc: 0.4964\n",
      "Epoch 43/200\n",
      "3730/3730 [==============================] - 0s 43us/step - loss: 0.6772 - acc: 0.5748 - val_loss: 0.7004 - val_acc: 0.4988\n",
      "Epoch 44/200\n",
      "3730/3730 [==============================] - 0s 44us/step - loss: 0.6772 - acc: 0.5721 - val_loss: 0.7018 - val_acc: 0.4964\n",
      "Epoch 45/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.6771 - acc: 0.5748 - val_loss: 0.7004 - val_acc: 0.4988\n",
      "Epoch 46/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.6768 - acc: 0.5748 - val_loss: 0.7018 - val_acc: 0.4964\n",
      "Epoch 47/200\n",
      "3730/3730 [==============================] - 0s 51us/step - loss: 0.6767 - acc: 0.5735 - val_loss: 0.7008 - val_acc: 0.5012\n",
      "Epoch 48/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.6770 - acc: 0.5718 - val_loss: 0.7019 - val_acc: 0.4916\n",
      "Epoch 49/200\n",
      "3730/3730 [==============================] - ETA: 0s - loss: 0.6774 - acc: 0.574 - 0s 54us/step - loss: 0.6766 - acc: 0.5743 - val_loss: 0.7017 - val_acc: 0.4964\n",
      "Epoch 50/200\n",
      "3730/3730 [==============================] - ETA: 0s - loss: 0.6759 - acc: 0.574 - 0s 53us/step - loss: 0.6766 - acc: 0.5753 - val_loss: 0.7010 - val_acc: 0.4988\n",
      "Epoch 51/200\n",
      "3730/3730 [==============================] - 0s 59us/step - loss: 0.6765 - acc: 0.5708 - val_loss: 0.7015 - val_acc: 0.5012\n",
      "Epoch 52/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.6764 - acc: 0.5775 - val_loss: 0.7017 - val_acc: 0.5012\n",
      "Epoch 53/200\n",
      "3730/3730 [==============================] - 0s 58us/step - loss: 0.6763 - acc: 0.5740 - val_loss: 0.7022 - val_acc: 0.4988\n",
      "Epoch 54/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.6764 - acc: 0.5767 - val_loss: 0.7019 - val_acc: 0.5012\n",
      "Epoch 55/200\n",
      "3730/3730 [==============================] - 0s 51us/step - loss: 0.6763 - acc: 0.5772 - val_loss: 0.7026 - val_acc: 0.5012\n",
      "Epoch 56/200\n",
      "3730/3730 [==============================] - 0s 50us/step - loss: 0.6760 - acc: 0.5697 - val_loss: 0.7019 - val_acc: 0.5060\n",
      "Epoch 57/200\n",
      "3730/3730 [==============================] - 0s 42us/step - loss: 0.6761 - acc: 0.5783 - val_loss: 0.7023 - val_acc: 0.5036\n",
      "Epoch 58/200\n",
      "3730/3730 [==============================] - 0s 53us/step - loss: 0.6759 - acc: 0.5761 - val_loss: 0.7023 - val_acc: 0.5012\n",
      "Epoch 59/200\n",
      "3730/3730 [==============================] - 0s 45us/step - loss: 0.6759 - acc: 0.5753 - val_loss: 0.7025 - val_acc: 0.4988\n",
      "Epoch 60/200\n",
      "3730/3730 [==============================] - 0s 50us/step - loss: 0.6755 - acc: 0.5804 - val_loss: 0.7034 - val_acc: 0.4964\n",
      "Epoch 61/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.6760 - acc: 0.5759 - val_loss: 0.7026 - val_acc: 0.4988\n",
      "Epoch 62/200\n",
      "3730/3730 [==============================] - 0s 42us/step - loss: 0.6754 - acc: 0.5761 - val_loss: 0.7028 - val_acc: 0.5012\n",
      "Epoch 63/200\n",
      "3730/3730 [==============================] - 0s 42us/step - loss: 0.6754 - acc: 0.5769 - val_loss: 0.7029 - val_acc: 0.4964\n",
      "Epoch 64/200\n",
      "3730/3730 [==============================] - 0s 53us/step - loss: 0.6755 - acc: 0.5759 - val_loss: 0.7034 - val_acc: 0.4988\n",
      "Epoch 65/200\n",
      "3730/3730 [==============================] - ETA: 0s - loss: 0.6757 - acc: 0.572 - 0s 54us/step - loss: 0.6756 - acc: 0.5745 - val_loss: 0.7035 - val_acc: 0.4964\n",
      "Epoch 66/200\n",
      "3730/3730 [==============================] - 0s 53us/step - loss: 0.6754 - acc: 0.5743 - val_loss: 0.7026 - val_acc: 0.4940\n",
      "Epoch 67/200\n",
      "3730/3730 [==============================] - 0s 53us/step - loss: 0.6755 - acc: 0.5796 - val_loss: 0.7031 - val_acc: 0.4988\n",
      "Epoch 68/200\n",
      "3730/3730 [==============================] - ETA: 0s - loss: 0.6725 - acc: 0.590 - 0s 43us/step - loss: 0.6753 - acc: 0.5780 - val_loss: 0.7033 - val_acc: 0.4988\n",
      "Epoch 69/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.6748 - acc: 0.5799 - val_loss: 0.7042 - val_acc: 0.4964\n",
      "Epoch 70/200\n",
      "3730/3730 [==============================] - 0s 40us/step - loss: 0.6747 - acc: 0.5775 - val_loss: 0.7055 - val_acc: 0.4916\n",
      "Epoch 71/200\n",
      "3730/3730 [==============================] - 0s 55us/step - loss: 0.6747 - acc: 0.5804 - val_loss: 0.7042 - val_acc: 0.4940\n",
      "Epoch 72/200\n",
      "3730/3730 [==============================] - 0s 40us/step - loss: 0.6748 - acc: 0.5842 - val_loss: 0.7047 - val_acc: 0.4964\n",
      "Epoch 73/200\n",
      "3730/3730 [==============================] - 0s 38us/step - loss: 0.6746 - acc: 0.5826 - val_loss: 0.7042 - val_acc: 0.4940\n",
      "Epoch 74/200\n",
      "3730/3730 [==============================] - 0s 38us/step - loss: 0.6746 - acc: 0.5831 - val_loss: 0.7038 - val_acc: 0.4940\n",
      "Epoch 75/200\n",
      "3730/3730 [==============================] - 0s 41us/step - loss: 0.6744 - acc: 0.5788 - val_loss: 0.7053 - val_acc: 0.4916\n",
      "Epoch 76/200\n",
      "3730/3730 [==============================] - 0s 50us/step - loss: 0.6743 - acc: 0.5807 - val_loss: 0.7050 - val_acc: 0.4964\n",
      "Epoch 77/200\n",
      "3730/3730 [==============================] - 0s 44us/step - loss: 0.6743 - acc: 0.5775 - val_loss: 0.7039 - val_acc: 0.4964\n",
      "Epoch 78/200\n",
      "3730/3730 [==============================] - 0s 39us/step - loss: 0.6743 - acc: 0.5826 - val_loss: 0.7051 - val_acc: 0.4940\n",
      "Epoch 79/200\n",
      "3730/3730 [==============================] - 0s 39us/step - loss: 0.6741 - acc: 0.5777 - val_loss: 0.7054 - val_acc: 0.4916\n",
      "Epoch 80/200\n",
      "3730/3730 [==============================] - 0s 39us/step - loss: 0.6740 - acc: 0.5753 - val_loss: 0.7053 - val_acc: 0.4940\n",
      "Epoch 81/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.6742 - acc: 0.5836 - val_loss: 0.7057 - val_acc: 0.4988\n",
      "Epoch 82/200\n",
      "3730/3730 [==============================] - 0s 41us/step - loss: 0.6739 - acc: 0.5815 - val_loss: 0.7072 - val_acc: 0.4916\n",
      "Epoch 83/200\n",
      "3730/3730 [==============================] - 0s 45us/step - loss: 0.6739 - acc: 0.5807 - val_loss: 0.7061 - val_acc: 0.4964\n",
      "Epoch 84/200\n",
      "3730/3730 [==============================] - 0s 43us/step - loss: 0.6737 - acc: 0.5820 - val_loss: 0.7063 - val_acc: 0.4940\n",
      "Epoch 85/200\n",
      "3730/3730 [==============================] - 0s 39us/step - loss: 0.6738 - acc: 0.5853 - val_loss: 0.7070 - val_acc: 0.4940\n",
      "Epoch 86/200\n",
      "3730/3730 [==============================] - 0s 38us/step - loss: 0.6736 - acc: 0.5828 - val_loss: 0.7061 - val_acc: 0.4940\n",
      "Epoch 87/200\n",
      "3730/3730 [==============================] - 0s 38us/step - loss: 0.6735 - acc: 0.5855 - val_loss: 0.7075 - val_acc: 0.4940\n",
      "Epoch 88/200\n",
      "3730/3730 [==============================] - 0s 38us/step - loss: 0.6736 - acc: 0.5810 - val_loss: 0.7069 - val_acc: 0.4940\n",
      "Epoch 89/200\n",
      "3730/3730 [==============================] - 0s 37us/step - loss: 0.6733 - acc: 0.5807 - val_loss: 0.7083 - val_acc: 0.4988\n",
      "Epoch 90/200\n",
      "3730/3730 [==============================] - 0s 39us/step - loss: 0.6734 - acc: 0.5839 - val_loss: 0.7083 - val_acc: 0.4964\n",
      "Epoch 91/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.6734 - acc: 0.5761 - val_loss: 0.7074 - val_acc: 0.4916\n",
      "Epoch 92/200\n",
      "3730/3730 [==============================] - 0s 43us/step - loss: 0.6731 - acc: 0.5812 - val_loss: 0.7070 - val_acc: 0.4916\n",
      "Epoch 93/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.6731 - acc: 0.5826 - val_loss: 0.7073 - val_acc: 0.4916\n",
      "Epoch 94/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.6730 - acc: 0.5826 - val_loss: 0.7085 - val_acc: 0.4892\n",
      "Epoch 95/200\n",
      "3730/3730 [==============================] - 0s 51us/step - loss: 0.6731 - acc: 0.5794 - val_loss: 0.7075 - val_acc: 0.4892\n",
      "Epoch 96/200\n",
      "3730/3730 [==============================] - 0s 39us/step - loss: 0.6729 - acc: 0.5788 - val_loss: 0.7079 - val_acc: 0.4892\n",
      "Epoch 97/200\n",
      "3730/3730 [==============================] - 0s 51us/step - loss: 0.6727 - acc: 0.5812 - val_loss: 0.7076 - val_acc: 0.4892\n",
      "Epoch 98/200\n",
      "3730/3730 [==============================] - 0s 41us/step - loss: 0.6726 - acc: 0.5786 - val_loss: 0.7088 - val_acc: 0.4867\n",
      "Epoch 99/200\n",
      "3730/3730 [==============================] - 0s 37us/step - loss: 0.6724 - acc: 0.5796 - val_loss: 0.7076 - val_acc: 0.4892\n",
      "Epoch 100/200\n",
      "3730/3730 [==============================] - 0s 38us/step - loss: 0.6726 - acc: 0.5831 - val_loss: 0.7097 - val_acc: 0.4867\n",
      "Epoch 101/200\n",
      "3730/3730 [==============================] - 0s 37us/step - loss: 0.6726 - acc: 0.5836 - val_loss: 0.7091 - val_acc: 0.4892\n",
      "Epoch 102/200\n",
      "3730/3730 [==============================] - 0s 39us/step - loss: 0.6725 - acc: 0.5807 - val_loss: 0.7087 - val_acc: 0.4916\n",
      "Epoch 103/200\n",
      "3730/3730 [==============================] - 0s 39us/step - loss: 0.6723 - acc: 0.5828 - val_loss: 0.7101 - val_acc: 0.4892\n",
      "Epoch 104/200\n",
      "3730/3730 [==============================] - 0s 45us/step - loss: 0.6725 - acc: 0.5794 - val_loss: 0.7103 - val_acc: 0.4892\n",
      "Epoch 105/200\n",
      "3730/3730 [==============================] - 0s 52us/step - loss: 0.6721 - acc: 0.5831 - val_loss: 0.7085 - val_acc: 0.4964\n",
      "Epoch 106/200\n",
      "3730/3730 [==============================] - 0s 53us/step - loss: 0.6721 - acc: 0.5834 - val_loss: 0.7085 - val_acc: 0.4940\n",
      "Epoch 107/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.6720 - acc: 0.5831 - val_loss: 0.7101 - val_acc: 0.4867\n",
      "Epoch 108/200\n",
      "3730/3730 [==============================] - 0s 39us/step - loss: 0.6722 - acc: 0.5834 - val_loss: 0.7094 - val_acc: 0.4940\n",
      "Epoch 109/200\n",
      "3730/3730 [==============================] - 0s 39us/step - loss: 0.6722 - acc: 0.5820 - val_loss: 0.7105 - val_acc: 0.4892\n",
      "Epoch 110/200\n",
      "3730/3730 [==============================] - 0s 37us/step - loss: 0.6720 - acc: 0.5855 - val_loss: 0.7107 - val_acc: 0.4892\n",
      "Epoch 111/200\n",
      "3730/3730 [==============================] - 0s 38us/step - loss: 0.6716 - acc: 0.5879 - val_loss: 0.7117 - val_acc: 0.4916\n",
      "Epoch 112/200\n",
      "3730/3730 [==============================] - 0s 37us/step - loss: 0.6717 - acc: 0.5810 - val_loss: 0.7115 - val_acc: 0.4867\n",
      "Epoch 113/200\n",
      "3730/3730 [==============================] - 0s 37us/step - loss: 0.6717 - acc: 0.5820 - val_loss: 0.7118 - val_acc: 0.4867\n",
      "Epoch 114/200\n",
      "3730/3730 [==============================] - 0s 37us/step - loss: 0.6715 - acc: 0.5861 - val_loss: 0.7110 - val_acc: 0.4964\n",
      "Epoch 115/200\n",
      "3730/3730 [==============================] - 0s 42us/step - loss: 0.6712 - acc: 0.5863 - val_loss: 0.7122 - val_acc: 0.4892\n",
      "Epoch 116/200\n",
      "3730/3730 [==============================] - 0s 41us/step - loss: 0.6712 - acc: 0.5853 - val_loss: 0.7121 - val_acc: 0.4940\n",
      "Epoch 117/200\n",
      "3730/3730 [==============================] - 0s 45us/step - loss: 0.6713 - acc: 0.5836 - val_loss: 0.7128 - val_acc: 0.4916\n",
      "Epoch 118/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3730/3730 [==============================] - 0s 58us/step - loss: 0.6711 - acc: 0.5828 - val_loss: 0.7130 - val_acc: 0.4819\n",
      "Epoch 119/200\n",
      "3730/3730 [==============================] - 0s 50us/step - loss: 0.6711 - acc: 0.5847 - val_loss: 0.7125 - val_acc: 0.4843\n",
      "Epoch 120/200\n",
      "3730/3730 [==============================] - 0s 46us/step - loss: 0.6708 - acc: 0.5890 - val_loss: 0.7144 - val_acc: 0.4819\n",
      "Epoch 121/200\n",
      "3730/3730 [==============================] - 0s 55us/step - loss: 0.6709 - acc: 0.5874 - val_loss: 0.7145 - val_acc: 0.4892\n",
      "Epoch 122/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.6707 - acc: 0.5850 - val_loss: 0.7128 - val_acc: 0.4843\n",
      "Epoch 123/200\n",
      "3730/3730 [==============================] - 0s 46us/step - loss: 0.6705 - acc: 0.5885 - val_loss: 0.7149 - val_acc: 0.4964\n",
      "Epoch 124/200\n",
      "3730/3730 [==============================] - 0s 55us/step - loss: 0.6705 - acc: 0.5866 - val_loss: 0.7141 - val_acc: 0.4916\n",
      "Epoch 125/200\n",
      "3730/3730 [==============================] - 0s 43us/step - loss: 0.6705 - acc: 0.5871 - val_loss: 0.7139 - val_acc: 0.4916\n",
      "Epoch 126/200\n",
      "3730/3730 [==============================] - 0s 54us/step - loss: 0.6702 - acc: 0.5922 - val_loss: 0.7143 - val_acc: 0.4771\n",
      "Epoch 127/200\n",
      "3730/3730 [==============================] - 0s 44us/step - loss: 0.6702 - acc: 0.5879 - val_loss: 0.7145 - val_acc: 0.4795\n",
      "Epoch 128/200\n",
      "3730/3730 [==============================] - 0s 45us/step - loss: 0.6703 - acc: 0.5893 - val_loss: 0.7133 - val_acc: 0.4892\n",
      "Epoch 129/200\n",
      "3730/3730 [==============================] - 0s 54us/step - loss: 0.6700 - acc: 0.5861 - val_loss: 0.7146 - val_acc: 0.4940\n",
      "Epoch 130/200\n",
      "3730/3730 [==============================] - 0s 43us/step - loss: 0.6697 - acc: 0.5858 - val_loss: 0.7144 - val_acc: 0.4867\n",
      "Epoch 131/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.6695 - acc: 0.5917 - val_loss: 0.7150 - val_acc: 0.4867\n",
      "Epoch 132/200\n",
      "3730/3730 [==============================] - 0s 53us/step - loss: 0.6695 - acc: 0.5909 - val_loss: 0.7152 - val_acc: 0.4867\n",
      "Epoch 133/200\n",
      "3730/3730 [==============================] - 0s 41us/step - loss: 0.6696 - acc: 0.5930 - val_loss: 0.7153 - val_acc: 0.4892\n",
      "Epoch 134/200\n",
      "3730/3730 [==============================] - 0s 42us/step - loss: 0.6694 - acc: 0.5901 - val_loss: 0.7159 - val_acc: 0.4892\n",
      "Epoch 135/200\n",
      "3730/3730 [==============================] - 0s 42us/step - loss: 0.6694 - acc: 0.5933 - val_loss: 0.7151 - val_acc: 0.4892\n",
      "Epoch 136/200\n",
      "3730/3730 [==============================] - 0s 41us/step - loss: 0.6692 - acc: 0.5917 - val_loss: 0.7156 - val_acc: 0.4916\n",
      "Epoch 137/200\n",
      "3730/3730 [==============================] - 0s 41us/step - loss: 0.6689 - acc: 0.5895 - val_loss: 0.7162 - val_acc: 0.4916\n",
      "Epoch 138/200\n",
      "3730/3730 [==============================] - 0s 43us/step - loss: 0.6691 - acc: 0.5920 - val_loss: 0.7169 - val_acc: 0.4964\n",
      "Epoch 139/200\n",
      "3730/3730 [==============================] - 0s 41us/step - loss: 0.6691 - acc: 0.5922 - val_loss: 0.7159 - val_acc: 0.4964\n",
      "Epoch 140/200\n",
      "3730/3730 [==============================] - 0s 42us/step - loss: 0.6689 - acc: 0.5946 - val_loss: 0.7173 - val_acc: 0.4988\n",
      "Epoch 141/200\n",
      "3730/3730 [==============================] - 0s 42us/step - loss: 0.6689 - acc: 0.5922 - val_loss: 0.7156 - val_acc: 0.4988\n",
      "Epoch 142/200\n",
      "3730/3730 [==============================] - 0s 42us/step - loss: 0.6688 - acc: 0.5936 - val_loss: 0.7162 - val_acc: 0.4988\n",
      "Epoch 143/200\n",
      "3730/3730 [==============================] - 0s 42us/step - loss: 0.6686 - acc: 0.5954 - val_loss: 0.7158 - val_acc: 0.4940\n",
      "Epoch 144/200\n",
      "3730/3730 [==============================] - 0s 41us/step - loss: 0.6682 - acc: 0.5944 - val_loss: 0.7165 - val_acc: 0.5036\n",
      "Epoch 145/200\n",
      "3730/3730 [==============================] - 0s 44us/step - loss: 0.6684 - acc: 0.5914 - val_loss: 0.7156 - val_acc: 0.4964\n",
      "Epoch 146/200\n",
      "3730/3730 [==============================] - 0s 44us/step - loss: 0.6682 - acc: 0.5922 - val_loss: 0.7176 - val_acc: 0.5012\n",
      "Epoch 147/200\n",
      "3730/3730 [==============================] - 0s 41us/step - loss: 0.6683 - acc: 0.5952 - val_loss: 0.7178 - val_acc: 0.4988\n",
      "Epoch 148/200\n",
      "3730/3730 [==============================] - 0s 45us/step - loss: 0.6679 - acc: 0.5925 - val_loss: 0.7170 - val_acc: 0.5036\n",
      "Epoch 149/200\n",
      "3730/3730 [==============================] - 0s 54us/step - loss: 0.6678 - acc: 0.5946 - val_loss: 0.7170 - val_acc: 0.5084\n",
      "Epoch 150/200\n",
      "3730/3730 [==============================] - 0s 52us/step - loss: 0.6678 - acc: 0.5954 - val_loss: 0.7183 - val_acc: 0.5060\n",
      "Epoch 151/200\n",
      "3730/3730 [==============================] - 0s 45us/step - loss: 0.6677 - acc: 0.5989 - val_loss: 0.7186 - val_acc: 0.5036\n",
      "Epoch 152/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.6678 - acc: 0.5938 - val_loss: 0.7193 - val_acc: 0.5036\n",
      "Epoch 153/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.6678 - acc: 0.5962 - val_loss: 0.7174 - val_acc: 0.4988\n",
      "Epoch 154/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.6676 - acc: 0.5920 - val_loss: 0.7180 - val_acc: 0.5084\n",
      "Epoch 155/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.6671 - acc: 0.5954 - val_loss: 0.7193 - val_acc: 0.5060\n",
      "Epoch 156/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.6673 - acc: 0.5925 - val_loss: 0.7201 - val_acc: 0.5036\n",
      "Epoch 157/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.6675 - acc: 0.5922 - val_loss: 0.7188 - val_acc: 0.5060\n",
      "Epoch 158/200\n",
      "3730/3730 [==============================] - 0s 44us/step - loss: 0.6672 - acc: 0.5973 - val_loss: 0.7176 - val_acc: 0.5060\n",
      "Epoch 159/200\n",
      "3730/3730 [==============================] - 0s 43us/step - loss: 0.6669 - acc: 0.5930 - val_loss: 0.7195 - val_acc: 0.5060\n",
      "Epoch 160/200\n",
      "3730/3730 [==============================] - 0s 45us/step - loss: 0.6670 - acc: 0.5941 - val_loss: 0.7190 - val_acc: 0.5084\n",
      "Epoch 161/200\n",
      "3730/3730 [==============================] - 0s 42us/step - loss: 0.6670 - acc: 0.5944 - val_loss: 0.7214 - val_acc: 0.4988\n",
      "Epoch 162/200\n",
      "3730/3730 [==============================] - 0s 42us/step - loss: 0.6671 - acc: 0.5954 - val_loss: 0.7200 - val_acc: 0.5133\n",
      "Epoch 163/200\n",
      "3730/3730 [==============================] - 0s 42us/step - loss: 0.6663 - acc: 0.5995 - val_loss: 0.7196 - val_acc: 0.5108\n",
      "Epoch 164/200\n",
      "3730/3730 [==============================] - 0s 45us/step - loss: 0.6668 - acc: 0.5973 - val_loss: 0.7202 - val_acc: 0.5060\n",
      "Epoch 165/200\n",
      "3730/3730 [==============================] - 0s 42us/step - loss: 0.6668 - acc: 0.5962 - val_loss: 0.7197 - val_acc: 0.5108\n",
      "Epoch 166/200\n",
      "3730/3730 [==============================] - 0s 42us/step - loss: 0.6669 - acc: 0.5952 - val_loss: 0.7210 - val_acc: 0.5133\n",
      "Epoch 167/200\n",
      "3730/3730 [==============================] - 0s 46us/step - loss: 0.6665 - acc: 0.5928 - val_loss: 0.7192 - val_acc: 0.5133\n",
      "Epoch 168/200\n",
      "3730/3730 [==============================] - 0s 52us/step - loss: 0.6666 - acc: 0.5949 - val_loss: 0.7205 - val_acc: 0.5108\n",
      "Epoch 169/200\n",
      "3730/3730 [==============================] - 0s 52us/step - loss: 0.6662 - acc: 0.5944 - val_loss: 0.7216 - val_acc: 0.5012\n",
      "Epoch 170/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.6663 - acc: 0.5962 - val_loss: 0.7207 - val_acc: 0.5012\n",
      "Epoch 171/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.6659 - acc: 0.5987 - val_loss: 0.7211 - val_acc: 0.5133\n",
      "Epoch 172/200\n",
      "3730/3730 [==============================] - 0s 40us/step - loss: 0.6658 - acc: 0.5957 - val_loss: 0.7221 - val_acc: 0.5036\n",
      "Epoch 173/200\n",
      "3730/3730 [==============================] - 0s 51us/step - loss: 0.6660 - acc: 0.5968 - val_loss: 0.7207 - val_acc: 0.5108\n",
      "Epoch 174/200\n",
      "3730/3730 [==============================] - 0s 42us/step - loss: 0.6660 - acc: 0.5957 - val_loss: 0.7220 - val_acc: 0.5060\n",
      "Epoch 175/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.6661 - acc: 0.5989 - val_loss: 0.7230 - val_acc: 0.5060\n",
      "Epoch 176/200\n",
      "3730/3730 [==============================] - 0s 50us/step - loss: 0.6656 - acc: 0.5968 - val_loss: 0.7229 - val_acc: 0.5084\n",
      "Epoch 177/200\n",
      "3730/3730 [==============================] - 0s 51us/step - loss: 0.6655 - acc: 0.5946 - val_loss: 0.7231 - val_acc: 0.5060\n",
      "Epoch 178/200\n",
      "3730/3730 [==============================] - 0s 51us/step - loss: 0.6655 - acc: 0.5971 - val_loss: 0.7244 - val_acc: 0.5060\n",
      "Epoch 179/200\n",
      "3730/3730 [==============================] - 0s 50us/step - loss: 0.6659 - acc: 0.5944 - val_loss: 0.7251 - val_acc: 0.5084\n",
      "Epoch 180/200\n",
      "3730/3730 [==============================] - 0s 50us/step - loss: 0.6653 - acc: 0.5979 - val_loss: 0.7227 - val_acc: 0.5084\n",
      "Epoch 181/200\n",
      "3730/3730 [==============================] - 0s 40us/step - loss: 0.6656 - acc: 0.5968 - val_loss: 0.7241 - val_acc: 0.5084\n",
      "Epoch 182/200\n",
      "3730/3730 [==============================] - 0s 37us/step - loss: 0.6652 - acc: 0.5968 - val_loss: 0.7266 - val_acc: 0.5108\n",
      "Epoch 183/200\n",
      "3730/3730 [==============================] - 0s 38us/step - loss: 0.6657 - acc: 0.5995 - val_loss: 0.7255 - val_acc: 0.5060\n",
      "Epoch 184/200\n",
      "3730/3730 [==============================] - 0s 38us/step - loss: 0.6652 - acc: 0.5960 - val_loss: 0.7253 - val_acc: 0.5084\n",
      "Epoch 185/200\n",
      "3730/3730 [==============================] - 0s 41us/step - loss: 0.6652 - acc: 0.5995 - val_loss: 0.7257 - val_acc: 0.5108\n",
      "Epoch 186/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.6651 - acc: 0.5971 - val_loss: 0.7259 - val_acc: 0.5012\n",
      "Epoch 187/200\n",
      "3730/3730 [==============================] - 0s 42us/step - loss: 0.6649 - acc: 0.5954 - val_loss: 0.7248 - val_acc: 0.5108\n",
      "Epoch 188/200\n",
      "3730/3730 [==============================] - 0s 39us/step - loss: 0.6650 - acc: 0.5987 - val_loss: 0.7259 - val_acc: 0.5133\n",
      "Epoch 189/200\n",
      "3730/3730 [==============================] - 0s 39us/step - loss: 0.6650 - acc: 0.5941 - val_loss: 0.7295 - val_acc: 0.5012\n",
      "Epoch 190/200\n",
      "3730/3730 [==============================] - 0s 37us/step - loss: 0.6648 - acc: 0.5960 - val_loss: 0.7262 - val_acc: 0.5060\n",
      "Epoch 191/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.6651 - acc: 0.5979 - val_loss: 0.7281 - val_acc: 0.5084\n",
      "Epoch 192/200\n",
      "3730/3730 [==============================] - 0s 44us/step - loss: 0.6646 - acc: 0.5987 - val_loss: 0.7263 - val_acc: 0.5060\n",
      "Epoch 193/200\n",
      "3730/3730 [==============================] - 0s 45us/step - loss: 0.6647 - acc: 0.5976 - val_loss: 0.7271 - val_acc: 0.5084\n",
      "Epoch 194/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.6644 - acc: 0.5973 - val_loss: 0.7275 - val_acc: 0.5108\n",
      "Epoch 195/200\n",
      "3730/3730 [==============================] - 0s 54us/step - loss: 0.6646 - acc: 0.5981 - val_loss: 0.7276 - val_acc: 0.5108\n",
      "Epoch 196/200\n",
      "3730/3730 [==============================] - 0s 45us/step - loss: 0.6642 - acc: 0.6000 - val_loss: 0.7286 - val_acc: 0.5084\n",
      "Epoch 197/200\n",
      "3730/3730 [==============================] - 0s 59us/step - loss: 0.6643 - acc: 0.5965 - val_loss: 0.7275 - val_acc: 0.5108\n",
      "Epoch 198/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.6647 - acc: 0.5954 - val_loss: 0.7281 - val_acc: 0.5133\n",
      "Epoch 199/200\n",
      "3730/3730 [==============================] - 0s 55us/step - loss: 0.6642 - acc: 0.5944 - val_loss: 0.7292 - val_acc: 0.5108\n",
      "Epoch 200/200\n",
      "3730/3730 [==============================] - 0s 50us/step - loss: 0.6644 - acc: 0.5971 - val_loss: 0.7285 - val_acc: 0.5133\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(8, kernel_initializer='normal', input_dim=len(X[0]), activation='relu'))\n",
    "model.add(Dense(8, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adamax',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X, y.values, epochs=200, validation_split = 0.1)\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### Prever relação do AJUSTE ATUAL com ÚLTIMO PREÇO anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T17:29:16.112984Z",
     "start_time": "2019-09-13T17:29:16.054019Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Número Negócios</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Var pontos</th>\n",
       "      <th>Dif_contratos</th>\n",
       "      <th>Dif_minmax</th>\n",
       "      <th>Dif_abert_ultimo</th>\n",
       "      <th>Dif_abert_ajuste</th>\n",
       "      <th>Dif_abert_min</th>\n",
       "      <th>Dif_abert_max</th>\n",
       "      <th>Dif_abert_medio</th>\n",
       "      <th>Dif_ajuste_ultimo</th>\n",
       "      <th>Dif_ajuste_medio</th>\n",
       "      <th>Média</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29/07/2019</td>\n",
       "      <td>271.92</td>\n",
       "      <td>42.939771</td>\n",
       "      <td>145520</td>\n",
       "      <td>132520</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>7.5</td>\n",
       "      <td>-16.5</td>\n",
       "      <td>-4.499</td>\n",
       "      <td>2.797</td>\n",
       "      <td>-4.702</td>\n",
       "      <td>3.785600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26/07/2019</td>\n",
       "      <td>321.28</td>\n",
       "      <td>58.414828</td>\n",
       "      <td>125890</td>\n",
       "      <td>23510</td>\n",
       "      <td>34.5</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-9.755</td>\n",
       "      <td>19.0</td>\n",
       "      <td>-15.5</td>\n",
       "      <td>4.970</td>\n",
       "      <td>-5.755</td>\n",
       "      <td>-4.785</td>\n",
       "      <td>3.776534</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25/07/2019</td>\n",
       "      <td>416.51</td>\n",
       "      <td>72.105906</td>\n",
       "      <td>129780</td>\n",
       "      <td>15894</td>\n",
       "      <td>50.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>14.834</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-39.0</td>\n",
       "      <td>-16.490</td>\n",
       "      <td>3.334</td>\n",
       "      <td>-1.656</td>\n",
       "      <td>3.779853</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24/07/2019</td>\n",
       "      <td>261.37</td>\n",
       "      <td>50.725253</td>\n",
       "      <td>31160</td>\n",
       "      <td>-7529</td>\n",
       "      <td>25.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.356</td>\n",
       "      <td>13.5</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>4.779</td>\n",
       "      <td>-3.644</td>\n",
       "      <td>7.135</td>\n",
       "      <td>3.769510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23/07/2019</td>\n",
       "      <td>335.86</td>\n",
       "      <td>59.121713</td>\n",
       "      <td>356000</td>\n",
       "      <td>-2908</td>\n",
       "      <td>39.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>27.972</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>-22.634</td>\n",
       "      <td>-2.028</td>\n",
       "      <td>5.338</td>\n",
       "      <td>3.767201</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Data  Número Negócios     Volume  Var pontos  Dif_contratos  \\\n",
       "0  29/07/2019           271.92  42.939771      145520         132520   \n",
       "1  26/07/2019           321.28  58.414828      125890          23510   \n",
       "2  25/07/2019           416.51  72.105906      129780          15894   \n",
       "3  24/07/2019           261.37  50.725253       31160          -7529   \n",
       "4  23/07/2019           335.86  59.121713      356000          -2908   \n",
       "\n",
       "   Dif_minmax  Dif_abert_ultimo  Dif_abert_ajuste  Dif_abert_min  \\\n",
       "0        24.0              -3.0            -0.203            7.5   \n",
       "1        34.5              -4.0            -9.755           19.0   \n",
       "2        50.0              11.5            14.834           11.0   \n",
       "3        25.5               6.0             2.356           13.5   \n",
       "4        39.0              30.0            27.972            2.0   \n",
       "\n",
       "   Dif_abert_max  Dif_abert_medio  Dif_ajuste_ultimo  Dif_ajuste_medio  \\\n",
       "0          -16.5           -4.499              2.797            -4.702   \n",
       "1          -15.5            4.970             -5.755            -4.785   \n",
       "2          -39.0          -16.490              3.334            -1.656   \n",
       "3          -12.0            4.779             -3.644             7.135   \n",
       "4          -37.0          -22.634             -2.028             5.338   \n",
       "\n",
       "      Média  target  \n",
       "0  3.785600       0  \n",
       "1  3.776534       1  \n",
       "2  3.779853       0  \n",
       "3  3.769510       0  \n",
       "4  3.767201       0  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_abert_old = df.copy()\n",
    "\n",
    "#1 se o Ajuste for maior que o último preço do dia anterior\n",
    "\n",
    "df_abert_old['target'] = df_abert_old.Ajuste.shift(-1) - df_abert_old['Último Preço']\n",
    "df_abert_old['target'] = df_abert_old['target'].apply(lambda x: 1 if x > 0 else 0)\n",
    "df_abert_old = df_abert_old.drop(len(df_abert)-1)\n",
    "\n",
    "df_abert_old['Média'] = (df_abert_old['Último Preço'] + df_abert_old['Abertura'] + df_abert_old['Máximo'] + df_abert_old['Mínimo'] + df_abert_old['Médio'] + df_abert_old['Ajuste'] + df_abert_old['Última oferta de compra']+ df_abert_old['Última oferta de venda'])/8\n",
    "df_abert_old = df_abert_old.drop(columns = ['Último Preço','Abertura','Máximo','Mínimo','Médio','Última oferta de compra','Última oferta de venda','Contratos Negociados', 'Ajuste'])\n",
    "\n",
    "\n",
    "df_change = df_abert_old[['target']]\n",
    "df_abert_old = df_abert_old.drop(columns = 'target')\n",
    "df_abert_old['target'] = df_change\n",
    "\n",
    "df_abert_old.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T17:29:16.307177Z",
     "start_time": "2019-09-13T17:29:16.208802Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "\n",
    "df_abert_old.iloc[:,1:-1]  = sc.fit_transform(df_abert_old.iloc[:,1:-1])\n",
    "df_moeda = pd.read_csv('moedas_features.csv')\n",
    "\n",
    "sc = StandardScaler()\n",
    "df_moeda.iloc[:,1:] = sc.fit_transform(df_moeda.iloc[:,1:])\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "dataset = pca.fit_transform(df_moeda.iloc[:,1:])\n",
    "df_moeda_pca = pd.DataFrame(dataset)\n",
    "df_moeda_pca['Data'] = df_moeda.iloc[:,0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T17:29:16.387003Z",
     "start_time": "2019-09-13T17:29:16.372015Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_abert = pd.merge(df_moeda_pca, df_abert_old, on = 'Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T17:29:17.456572Z",
     "start_time": "2019-09-13T17:29:17.435564Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.73655684,  1.39392986,  0.42006268, ..., -0.21276328,\n",
       "        -0.19602005,  2.00409008],\n",
       "       [ 1.09956342,  0.54193774,  0.47238007, ..., -0.19968062,\n",
       "        -0.19427555,  1.96205815],\n",
       "       [ 0.82993689,  1.11635785,  0.13816578, ..., -0.23787811,\n",
       "        -0.20287215,  1.9713729 ],\n",
       "       ...,\n",
       "       [ 2.64784844,  0.94006302,  0.91821313, ..., -0.21481031,\n",
       "        -0.22199328, -0.57127243],\n",
       "       [ 2.9137972 ,  0.57835409, -1.47655845, ..., -0.20866022,\n",
       "        -0.21725796, -0.55684205],\n",
       "       [ 2.26871309,  1.88815858,  0.42042403, ..., -0.20874836,\n",
       "        -0.2036275 , -0.55139601]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df_abert[['target']]\n",
    "X = df_abert.drop(columns = ['Data','target'])\n",
    "X_columns = df_abert.drop(columns = ['Data','target'])\n",
    "\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "#X = X.values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T17:29:17.819776Z",
     "start_time": "2019-09-13T17:29:17.812760Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T17:29:18.573770Z",
     "start_time": "2019-09-13T17:29:18.539769Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\choice\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\choice\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8612786489746683"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression().fit(x_train, y_train)\n",
    "\n",
    "predictions = clf.predict(x_test)\n",
    "\n",
    "probas = clf.predict_proba(x_test) \n",
    "\n",
    "\n",
    "score = clf.score(x_test, y_test)\n",
    "\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T17:29:20.525632Z",
     "start_time": "2019-09-13T17:29:20.395692Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\choice\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "c:\\users\\choice\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8624849215922799"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = RandomForestClassifier()\n",
    "r.fit(x_train, y_train)  \n",
    "\n",
    "predictions = r.predict(x_test)\n",
    "\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T17:29:21.816247Z",
     "start_time": "2019-09-13T17:29:21.571371Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = X_columns.columns\n",
    "importances = r.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T17:30:45.072829Z",
     "start_time": "2019-09-13T17:30:06.052107Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3730 samples, validate on 415 samples\n",
      "Epoch 1/200\n",
      "3730/3730 [==============================] - 1s 177us/step - loss: 0.6389 - acc: 0.6898 - val_loss: 0.5174 - val_acc: 0.8169\n",
      "Epoch 2/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.4885 - acc: 0.8225 - val_loss: 0.4043 - val_acc: 0.8771\n",
      "Epoch 3/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.4202 - acc: 0.8335 - val_loss: 0.3461 - val_acc: 0.8892\n",
      "Epoch 4/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.3906 - acc: 0.8408 - val_loss: 0.3198 - val_acc: 0.8940\n",
      "Epoch 5/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.3778 - acc: 0.8453 - val_loss: 0.3085 - val_acc: 0.8819\n",
      "Epoch 6/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.3707 - acc: 0.8466 - val_loss: 0.3002 - val_acc: 0.8843\n",
      "Epoch 7/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.3649 - acc: 0.8483 - val_loss: 0.2942 - val_acc: 0.8867\n",
      "Epoch 8/200\n",
      "3730/3730 [==============================] - 0s 50us/step - loss: 0.3603 - acc: 0.8534 - val_loss: 0.2908 - val_acc: 0.8940\n",
      "Epoch 9/200\n",
      "3730/3730 [==============================] - 0s 57us/step - loss: 0.3572 - acc: 0.8539 - val_loss: 0.2853 - val_acc: 0.8916\n",
      "Epoch 10/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.3539 - acc: 0.8517 - val_loss: 0.2815 - val_acc: 0.8916\n",
      "Epoch 11/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.3516 - acc: 0.8531 - val_loss: 0.2779 - val_acc: 0.8867\n",
      "Epoch 12/200\n",
      "3730/3730 [==============================] - 0s 53us/step - loss: 0.3491 - acc: 0.8558 - val_loss: 0.2746 - val_acc: 0.8916\n",
      "Epoch 13/200\n",
      "3730/3730 [==============================] - 0s 55us/step - loss: 0.3476 - acc: 0.8536 - val_loss: 0.2743 - val_acc: 0.8916\n",
      "Epoch 14/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.3458 - acc: 0.8560 - val_loss: 0.2710 - val_acc: 0.8916\n",
      "Epoch 15/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.3437 - acc: 0.8574 - val_loss: 0.2681 - val_acc: 0.8964\n",
      "Epoch 16/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.3429 - acc: 0.8576 - val_loss: 0.2675 - val_acc: 0.8988\n",
      "Epoch 17/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.3420 - acc: 0.8566 - val_loss: 0.2680 - val_acc: 0.8964\n",
      "Epoch 18/200\n",
      "3730/3730 [==============================] - 0s 62us/step - loss: 0.3404 - acc: 0.8560 - val_loss: 0.2658 - val_acc: 0.8964\n",
      "Epoch 19/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.3395 - acc: 0.8560 - val_loss: 0.2651 - val_acc: 0.8964\n",
      "Epoch 20/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.3381 - acc: 0.8534 - val_loss: 0.2670 - val_acc: 0.8988\n",
      "Epoch 21/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.3382 - acc: 0.8558 - val_loss: 0.2643 - val_acc: 0.8988\n",
      "Epoch 22/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.3380 - acc: 0.8539 - val_loss: 0.2636 - val_acc: 0.8988\n",
      "Epoch 23/200\n",
      "3730/3730 [==============================] - ETA: 0s - loss: 0.3433 - acc: 0.852 - 0s 53us/step - loss: 0.3370 - acc: 0.8555 - val_loss: 0.2658 - val_acc: 0.8940\n",
      "Epoch 24/200\n",
      "3730/3730 [==============================] - 0s 52us/step - loss: 0.3365 - acc: 0.8550 - val_loss: 0.2644 - val_acc: 0.8940\n",
      "Epoch 25/200\n",
      "3730/3730 [==============================] - 0s 56us/step - loss: 0.3358 - acc: 0.8531 - val_loss: 0.2635 - val_acc: 0.8964\n",
      "Epoch 26/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.3348 - acc: 0.8547 - val_loss: 0.2639 - val_acc: 0.8988\n",
      "Epoch 27/200\n",
      "3730/3730 [==============================] - 0s 58us/step - loss: 0.3338 - acc: 0.8544 - val_loss: 0.2638 - val_acc: 0.8964\n",
      "Epoch 28/200\n",
      "3730/3730 [==============================] - 0s 51us/step - loss: 0.3338 - acc: 0.8547 - val_loss: 0.2638 - val_acc: 0.8964\n",
      "Epoch 29/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.3330 - acc: 0.8534 - val_loss: 0.2623 - val_acc: 0.8964\n",
      "Epoch 30/200\n",
      "3730/3730 [==============================] - 0s 50us/step - loss: 0.3327 - acc: 0.8552 - val_loss: 0.2637 - val_acc: 0.8988\n",
      "Epoch 31/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.3316 - acc: 0.8547 - val_loss: 0.2644 - val_acc: 0.8964\n",
      "Epoch 32/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.3316 - acc: 0.8558 - val_loss: 0.2624 - val_acc: 0.8940\n",
      "Epoch 33/200\n",
      "3730/3730 [==============================] - 0s 58us/step - loss: 0.3313 - acc: 0.8542 - val_loss: 0.2632 - val_acc: 0.8916\n",
      "Epoch 34/200\n",
      "3730/3730 [==============================] - 0s 51us/step - loss: 0.3310 - acc: 0.8582 - val_loss: 0.2635 - val_acc: 0.8940\n",
      "Epoch 35/200\n",
      "3730/3730 [==============================] - 0s 50us/step - loss: 0.3305 - acc: 0.8544 - val_loss: 0.2636 - val_acc: 0.8940\n",
      "Epoch 36/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.3302 - acc: 0.8563 - val_loss: 0.2656 - val_acc: 0.8940\n",
      "Epoch 37/200\n",
      "3730/3730 [==============================] - 0s 52us/step - loss: 0.3295 - acc: 0.8550 - val_loss: 0.2629 - val_acc: 0.8940\n",
      "Epoch 38/200\n",
      "3730/3730 [==============================] - 0s 61us/step - loss: 0.3300 - acc: 0.8584 - val_loss: 0.2651 - val_acc: 0.8940\n",
      "Epoch 39/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.3291 - acc: 0.8555 - val_loss: 0.2627 - val_acc: 0.8892\n",
      "Epoch 40/200\n",
      "3730/3730 [==============================] - 0s 50us/step - loss: 0.3290 - acc: 0.8558 - val_loss: 0.2631 - val_acc: 0.8892\n",
      "Epoch 41/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.3287 - acc: 0.8560 - val_loss: 0.2640 - val_acc: 0.8916\n",
      "Epoch 42/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.3286 - acc: 0.8576 - val_loss: 0.2636 - val_acc: 0.8964\n",
      "Epoch 43/200\n",
      "3730/3730 [==============================] - 0s 54us/step - loss: 0.3284 - acc: 0.8579 - val_loss: 0.2628 - val_acc: 0.8964\n",
      "Epoch 44/200\n",
      "3730/3730 [==============================] - 0s 54us/step - loss: 0.3281 - acc: 0.8558 - val_loss: 0.2619 - val_acc: 0.8916\n",
      "Epoch 45/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.3271 - acc: 0.8592 - val_loss: 0.2644 - val_acc: 0.8988\n",
      "Epoch 46/200\n",
      "3730/3730 [==============================] - 0s 50us/step - loss: 0.3272 - acc: 0.8571 - val_loss: 0.2611 - val_acc: 0.8964\n",
      "Epoch 47/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.3279 - acc: 0.8579 - val_loss: 0.2639 - val_acc: 0.8988\n",
      "Epoch 48/200\n",
      "3730/3730 [==============================] - 0s 50us/step - loss: 0.3270 - acc: 0.8566 - val_loss: 0.2624 - val_acc: 0.9012\n",
      "Epoch 49/200\n",
      "3730/3730 [==============================] - 0s 54us/step - loss: 0.3267 - acc: 0.8566 - val_loss: 0.2619 - val_acc: 0.9036\n",
      "Epoch 50/200\n",
      "3730/3730 [==============================] - 0s 52us/step - loss: 0.3269 - acc: 0.8598 - val_loss: 0.2626 - val_acc: 0.8964\n",
      "Epoch 51/200\n",
      "3730/3730 [==============================] - 0s 50us/step - loss: 0.3271 - acc: 0.8595 - val_loss: 0.2634 - val_acc: 0.8988\n",
      "Epoch 52/200\n",
      "3730/3730 [==============================] - 0s 50us/step - loss: 0.3262 - acc: 0.8595 - val_loss: 0.2619 - val_acc: 0.8988\n",
      "Epoch 53/200\n",
      "3730/3730 [==============================] - 0s 51us/step - loss: 0.3268 - acc: 0.8590 - val_loss: 0.2628 - val_acc: 0.8988\n",
      "Epoch 54/200\n",
      "3730/3730 [==============================] - 0s 51us/step - loss: 0.3260 - acc: 0.8614 - val_loss: 0.2615 - val_acc: 0.8964\n",
      "Epoch 55/200\n",
      "3730/3730 [==============================] - 0s 54us/step - loss: 0.3259 - acc: 0.8576 - val_loss: 0.2616 - val_acc: 0.8940\n",
      "Epoch 56/200\n",
      "3730/3730 [==============================] - 0s 53us/step - loss: 0.3258 - acc: 0.8590 - val_loss: 0.2631 - val_acc: 0.8988\n",
      "Epoch 57/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.3261 - acc: 0.8579 - val_loss: 0.2645 - val_acc: 0.9012\n",
      "Epoch 58/200\n",
      "3730/3730 [==============================] - 0s 50us/step - loss: 0.3255 - acc: 0.8576 - val_loss: 0.2630 - val_acc: 0.8940\n",
      "Epoch 59/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.3248 - acc: 0.8571 - val_loss: 0.2630 - val_acc: 0.8988\n",
      "Epoch 60/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.3259 - acc: 0.8592 - val_loss: 0.2635 - val_acc: 0.8940\n",
      "Epoch 61/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.3253 - acc: 0.8592 - val_loss: 0.2649 - val_acc: 0.8988\n",
      "Epoch 62/200\n",
      "3730/3730 [==============================] - 0s 51us/step - loss: 0.3253 - acc: 0.8574 - val_loss: 0.2638 - val_acc: 0.8988\n",
      "Epoch 63/200\n",
      "3730/3730 [==============================] - ETA: 0s - loss: 0.3234 - acc: 0.860 - 0s 54us/step - loss: 0.3252 - acc: 0.8592 - val_loss: 0.2643 - val_acc: 0.8988\n",
      "Epoch 64/200\n",
      "3730/3730 [==============================] - 0s 51us/step - loss: 0.3246 - acc: 0.8582 - val_loss: 0.2652 - val_acc: 0.9012\n",
      "Epoch 65/200\n",
      "3730/3730 [==============================] - 0s 56us/step - loss: 0.3241 - acc: 0.8592 - val_loss: 0.2639 - val_acc: 0.9012\n",
      "Epoch 66/200\n",
      "3730/3730 [==============================] - 0s 50us/step - loss: 0.3247 - acc: 0.8587 - val_loss: 0.2656 - val_acc: 0.8964\n",
      "Epoch 67/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.3239 - acc: 0.8590 - val_loss: 0.2659 - val_acc: 0.8988\n",
      "Epoch 68/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.3245 - acc: 0.8601 - val_loss: 0.2656 - val_acc: 0.9012\n",
      "Epoch 69/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.3240 - acc: 0.8603 - val_loss: 0.2649 - val_acc: 0.8940\n",
      "Epoch 70/200\n",
      "3730/3730 [==============================] - 0s 53us/step - loss: 0.3240 - acc: 0.8606 - val_loss: 0.2658 - val_acc: 0.8988\n",
      "Epoch 71/200\n",
      "3730/3730 [==============================] - 0s 50us/step - loss: 0.3237 - acc: 0.8587 - val_loss: 0.2672 - val_acc: 0.8988\n",
      "Epoch 72/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.3237 - acc: 0.8601 - val_loss: 0.2652 - val_acc: 0.8940\n",
      "Epoch 73/200\n",
      "3730/3730 [==============================] - 0s 51us/step - loss: 0.3235 - acc: 0.8590 - val_loss: 0.2663 - val_acc: 0.8916\n",
      "Epoch 74/200\n",
      "3730/3730 [==============================] - ETA: 0s - loss: 0.3064 - acc: 0.869 - 0s 55us/step - loss: 0.3228 - acc: 0.8609 - val_loss: 0.2682 - val_acc: 0.8940\n",
      "Epoch 75/200\n",
      "3730/3730 [==============================] - 0s 50us/step - loss: 0.3230 - acc: 0.8606 - val_loss: 0.2672 - val_acc: 0.8940\n",
      "Epoch 76/200\n",
      "3730/3730 [==============================] - 0s 55us/step - loss: 0.3228 - acc: 0.8601 - val_loss: 0.2698 - val_acc: 0.8940\n",
      "Epoch 77/200\n",
      "3730/3730 [==============================] - 0s 51us/step - loss: 0.3231 - acc: 0.8603 - val_loss: 0.2667 - val_acc: 0.8916\n",
      "Epoch 78/200\n",
      "3730/3730 [==============================] - 0s 52us/step - loss: 0.3226 - acc: 0.8598 - val_loss: 0.2657 - val_acc: 0.8916\n",
      "Epoch 79/200\n",
      "3730/3730 [==============================] - 0s 53us/step - loss: 0.3228 - acc: 0.8598 - val_loss: 0.2672 - val_acc: 0.8940\n",
      "Epoch 80/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.3233 - acc: 0.8614 - val_loss: 0.2684 - val_acc: 0.8916\n",
      "Epoch 81/200\n",
      "3730/3730 [==============================] - 0s 57us/step - loss: 0.3228 - acc: 0.8625 - val_loss: 0.2680 - val_acc: 0.8916\n",
      "Epoch 82/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.3220 - acc: 0.8611 - val_loss: 0.2686 - val_acc: 0.8940\n",
      "Epoch 83/200\n",
      "3730/3730 [==============================] - 0s 53us/step - loss: 0.3229 - acc: 0.8598 - val_loss: 0.2674 - val_acc: 0.8892\n",
      "Epoch 84/200\n",
      "3730/3730 [==============================] - 0s 53us/step - loss: 0.3217 - acc: 0.8614 - val_loss: 0.2692 - val_acc: 0.8916\n",
      "Epoch 85/200\n",
      "3730/3730 [==============================] - 0s 56us/step - loss: 0.3218 - acc: 0.8595 - val_loss: 0.2687 - val_acc: 0.8892\n",
      "Epoch 86/200\n",
      "3730/3730 [==============================] - 0s 51us/step - loss: 0.3219 - acc: 0.8598 - val_loss: 0.2691 - val_acc: 0.8916\n",
      "Epoch 87/200\n",
      "3730/3730 [==============================] - 0s 54us/step - loss: 0.3216 - acc: 0.8643 - val_loss: 0.2694 - val_acc: 0.8916\n",
      "Epoch 88/200\n",
      "3730/3730 [==============================] - 0s 54us/step - loss: 0.3219 - acc: 0.8611 - val_loss: 0.2685 - val_acc: 0.8892\n",
      "Epoch 89/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.3216 - acc: 0.8606 - val_loss: 0.2703 - val_acc: 0.8916\n",
      "Epoch 90/200\n",
      "3730/3730 [==============================] - 0s 53us/step - loss: 0.3213 - acc: 0.8627 - val_loss: 0.2697 - val_acc: 0.8916\n",
      "Epoch 91/200\n",
      "3730/3730 [==============================] - 0s 50us/step - loss: 0.3216 - acc: 0.8609 - val_loss: 0.2701 - val_acc: 0.8916\n",
      "Epoch 92/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.3212 - acc: 0.8619 - val_loss: 0.2696 - val_acc: 0.8916\n",
      "Epoch 93/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.3213 - acc: 0.8627 - val_loss: 0.2685 - val_acc: 0.8892\n",
      "Epoch 94/200\n",
      "3730/3730 [==============================] - 0s 50us/step - loss: 0.3211 - acc: 0.8614 - val_loss: 0.2692 - val_acc: 0.8916\n",
      "Epoch 95/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.3213 - acc: 0.8627 - val_loss: 0.2709 - val_acc: 0.8867\n",
      "Epoch 96/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.3209 - acc: 0.8619 - val_loss: 0.2681 - val_acc: 0.8916\n",
      "Epoch 97/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.3211 - acc: 0.8633 - val_loss: 0.2698 - val_acc: 0.8892\n",
      "Epoch 98/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.3207 - acc: 0.8617 - val_loss: 0.2688 - val_acc: 0.8867\n",
      "Epoch 99/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.3207 - acc: 0.8625 - val_loss: 0.2687 - val_acc: 0.8867\n",
      "Epoch 100/200\n",
      "3730/3730 [==============================] - 0s 50us/step - loss: 0.3205 - acc: 0.8619 - val_loss: 0.2682 - val_acc: 0.8916\n",
      "Epoch 101/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.3209 - acc: 0.8617 - val_loss: 0.2688 - val_acc: 0.8916\n",
      "Epoch 102/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.3204 - acc: 0.8625 - val_loss: 0.2710 - val_acc: 0.8892\n",
      "Epoch 103/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.3205 - acc: 0.8630 - val_loss: 0.2710 - val_acc: 0.8867\n",
      "Epoch 104/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.3210 - acc: 0.8625 - val_loss: 0.2713 - val_acc: 0.8867\n",
      "Epoch 105/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.3203 - acc: 0.8641 - val_loss: 0.2694 - val_acc: 0.8892\n",
      "Epoch 106/200\n",
      "3730/3730 [==============================] - 0s 50us/step - loss: 0.3206 - acc: 0.8606 - val_loss: 0.2715 - val_acc: 0.8867\n",
      "Epoch 107/200\n",
      "3730/3730 [==============================] - 0s 50us/step - loss: 0.3201 - acc: 0.8601 - val_loss: 0.2687 - val_acc: 0.8940\n",
      "Epoch 108/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.3207 - acc: 0.8625 - val_loss: 0.2705 - val_acc: 0.8892\n",
      "Epoch 109/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.3202 - acc: 0.8633 - val_loss: 0.2712 - val_acc: 0.8867\n",
      "Epoch 110/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.3200 - acc: 0.8638 - val_loss: 0.2710 - val_acc: 0.8867\n",
      "Epoch 111/200\n",
      "3730/3730 [==============================] - 0s 50us/step - loss: 0.3205 - acc: 0.8625 - val_loss: 0.2686 - val_acc: 0.8916\n",
      "Epoch 112/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.3206 - acc: 0.8617 - val_loss: 0.2734 - val_acc: 0.8867\n",
      "Epoch 113/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.3200 - acc: 0.8630 - val_loss: 0.2701 - val_acc: 0.8867\n",
      "Epoch 114/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.3201 - acc: 0.8638 - val_loss: 0.2732 - val_acc: 0.8892\n",
      "Epoch 115/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.3204 - acc: 0.8617 - val_loss: 0.2696 - val_acc: 0.8940\n",
      "Epoch 116/200\n",
      "3730/3730 [==============================] - 0s 50us/step - loss: 0.3198 - acc: 0.8646 - val_loss: 0.2721 - val_acc: 0.8867\n",
      "Epoch 117/200\n",
      "3730/3730 [==============================] - 0s 51us/step - loss: 0.3202 - acc: 0.8630 - val_loss: 0.2700 - val_acc: 0.8892\n",
      "Epoch 118/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.3200 - acc: 0.8646 - val_loss: 0.2705 - val_acc: 0.8867\n",
      "Epoch 119/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.3199 - acc: 0.8643 - val_loss: 0.2721 - val_acc: 0.8892\n",
      "Epoch 120/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.3203 - acc: 0.8630 - val_loss: 0.2732 - val_acc: 0.8892\n",
      "Epoch 121/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.3197 - acc: 0.8617 - val_loss: 0.2701 - val_acc: 0.8867\n",
      "Epoch 122/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.3200 - acc: 0.8649 - val_loss: 0.2701 - val_acc: 0.8867\n",
      "Epoch 123/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.3198 - acc: 0.8611 - val_loss: 0.2719 - val_acc: 0.8892\n",
      "Epoch 124/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.3196 - acc: 0.8646 - val_loss: 0.2723 - val_acc: 0.8867\n",
      "Epoch 125/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.3200 - acc: 0.8638 - val_loss: 0.2726 - val_acc: 0.8892\n",
      "Epoch 126/200\n",
      "3730/3730 [==============================] - 0s 46us/step - loss: 0.3199 - acc: 0.8622 - val_loss: 0.2714 - val_acc: 0.8892\n",
      "Epoch 127/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.3200 - acc: 0.8627 - val_loss: 0.2714 - val_acc: 0.8892\n",
      "Epoch 128/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.3197 - acc: 0.8622 - val_loss: 0.2693 - val_acc: 0.8940\n",
      "Epoch 129/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.3193 - acc: 0.8635 - val_loss: 0.2695 - val_acc: 0.8916\n",
      "Epoch 130/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.3193 - acc: 0.8643 - val_loss: 0.2685 - val_acc: 0.8916\n",
      "Epoch 131/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.3196 - acc: 0.8619 - val_loss: 0.2702 - val_acc: 0.8940\n",
      "Epoch 132/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.3193 - acc: 0.8619 - val_loss: 0.2697 - val_acc: 0.8940\n",
      "Epoch 133/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.3198 - acc: 0.8651 - val_loss: 0.2719 - val_acc: 0.8916\n",
      "Epoch 134/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.3191 - acc: 0.8614 - val_loss: 0.2704 - val_acc: 0.8916\n",
      "Epoch 135/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.3193 - acc: 0.8643 - val_loss: 0.2722 - val_acc: 0.8940\n",
      "Epoch 136/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.3191 - acc: 0.8633 - val_loss: 0.2697 - val_acc: 0.8940\n",
      "Epoch 137/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.3191 - acc: 0.8611 - val_loss: 0.2693 - val_acc: 0.8964\n",
      "Epoch 138/200\n",
      "3730/3730 [==============================] - 0s 50us/step - loss: 0.3193 - acc: 0.8654 - val_loss: 0.2710 - val_acc: 0.8964\n",
      "Epoch 139/200\n",
      "3730/3730 [==============================] - 0s 50us/step - loss: 0.3190 - acc: 0.8627 - val_loss: 0.2697 - val_acc: 0.8940\n",
      "Epoch 140/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.3191 - acc: 0.8603 - val_loss: 0.2695 - val_acc: 0.8964\n",
      "Epoch 141/200\n",
      "3730/3730 [==============================] - 0s 50us/step - loss: 0.3194 - acc: 0.8635 - val_loss: 0.2699 - val_acc: 0.8916\n",
      "Epoch 142/200\n",
      "3730/3730 [==============================] - 0s 50us/step - loss: 0.3184 - acc: 0.8630 - val_loss: 0.2694 - val_acc: 0.8940\n",
      "Epoch 143/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.3188 - acc: 0.8638 - val_loss: 0.2683 - val_acc: 0.8940\n",
      "Epoch 144/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.3186 - acc: 0.8649 - val_loss: 0.2707 - val_acc: 0.8916\n",
      "Epoch 145/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.3191 - acc: 0.8627 - val_loss: 0.2706 - val_acc: 0.8916\n",
      "Epoch 146/200\n",
      "3730/3730 [==============================] - 0s 52us/step - loss: 0.3186 - acc: 0.8617 - val_loss: 0.2730 - val_acc: 0.8916\n",
      "Epoch 147/200\n",
      "3730/3730 [==============================] - 0s 71us/step - loss: 0.3187 - acc: 0.8654 - val_loss: 0.2730 - val_acc: 0.8916\n",
      "Epoch 148/200\n",
      "3730/3730 [==============================] - 0s 88us/step - loss: 0.3192 - acc: 0.8606 - val_loss: 0.2692 - val_acc: 0.8940\n",
      "Epoch 149/200\n",
      "3730/3730 [==============================] - 0s 54us/step - loss: 0.3192 - acc: 0.8646 - val_loss: 0.2698 - val_acc: 0.8916\n",
      "Epoch 150/200\n",
      "3730/3730 [==============================] - 0s 83us/step - loss: 0.3188 - acc: 0.8638 - val_loss: 0.2707 - val_acc: 0.8964\n",
      "Epoch 151/200\n",
      "3730/3730 [==============================] - 0s 80us/step - loss: 0.3184 - acc: 0.8641 - val_loss: 0.2710 - val_acc: 0.8964\n",
      "Epoch 152/200\n",
      "3730/3730 [==============================] - 0s 60us/step - loss: 0.3184 - acc: 0.8657 - val_loss: 0.2696 - val_acc: 0.8940\n",
      "Epoch 153/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.3181 - acc: 0.8649 - val_loss: 0.2725 - val_acc: 0.8892\n",
      "Epoch 154/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.3186 - acc: 0.8635 - val_loss: 0.2703 - val_acc: 0.8940\n",
      "Epoch 155/200\n",
      "3730/3730 [==============================] - 0s 60us/step - loss: 0.3184 - acc: 0.8630 - val_loss: 0.2713 - val_acc: 0.8964\n",
      "Epoch 156/200\n",
      "3730/3730 [==============================] - 0s 51us/step - loss: 0.3184 - acc: 0.8633 - val_loss: 0.2727 - val_acc: 0.8940\n",
      "Epoch 157/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.3183 - acc: 0.8651 - val_loss: 0.2735 - val_acc: 0.8892\n",
      "Epoch 158/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.3185 - acc: 0.8633 - val_loss: 0.2718 - val_acc: 0.8964\n",
      "Epoch 159/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.3181 - acc: 0.8643 - val_loss: 0.2701 - val_acc: 0.8916\n",
      "Epoch 160/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.3181 - acc: 0.8627 - val_loss: 0.2723 - val_acc: 0.8940\n",
      "Epoch 161/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.3173 - acc: 0.8643 - val_loss: 0.2749 - val_acc: 0.8867\n",
      "Epoch 162/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.3186 - acc: 0.8641 - val_loss: 0.2745 - val_acc: 0.8892\n",
      "Epoch 163/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.3181 - acc: 0.8633 - val_loss: 0.2698 - val_acc: 0.8940\n",
      "Epoch 164/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.3176 - acc: 0.8651 - val_loss: 0.2734 - val_acc: 0.8916\n",
      "Epoch 165/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.3178 - acc: 0.8649 - val_loss: 0.2725 - val_acc: 0.8940\n",
      "Epoch 166/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.3178 - acc: 0.8654 - val_loss: 0.2725 - val_acc: 0.8940\n",
      "Epoch 167/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.3174 - acc: 0.8635 - val_loss: 0.2696 - val_acc: 0.8916\n",
      "Epoch 168/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.3176 - acc: 0.8635 - val_loss: 0.2716 - val_acc: 0.8940\n",
      "Epoch 169/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.3179 - acc: 0.8635 - val_loss: 0.2736 - val_acc: 0.8916\n",
      "Epoch 170/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.3175 - acc: 0.8649 - val_loss: 0.2746 - val_acc: 0.8916\n",
      "Epoch 171/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.3181 - acc: 0.8638 - val_loss: 0.2753 - val_acc: 0.8867\n",
      "Epoch 172/200\n",
      "3730/3730 [==============================] - 0s 46us/step - loss: 0.3174 - acc: 0.8619 - val_loss: 0.2748 - val_acc: 0.8916\n",
      "Epoch 173/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.3174 - acc: 0.8638 - val_loss: 0.2735 - val_acc: 0.8916\n",
      "Epoch 174/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.3170 - acc: 0.8649 - val_loss: 0.2765 - val_acc: 0.8867\n",
      "Epoch 175/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.3180 - acc: 0.8635 - val_loss: 0.2715 - val_acc: 0.8916\n",
      "Epoch 176/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.3172 - acc: 0.8627 - val_loss: 0.2726 - val_acc: 0.8940\n",
      "Epoch 177/200\n",
      "3730/3730 [==============================] - 0s 50us/step - loss: 0.3175 - acc: 0.8651 - val_loss: 0.2714 - val_acc: 0.8940\n",
      "Epoch 178/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.3178 - acc: 0.8630 - val_loss: 0.2716 - val_acc: 0.8940\n",
      "Epoch 179/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.3168 - acc: 0.8630 - val_loss: 0.2726 - val_acc: 0.8940\n",
      "Epoch 180/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.3169 - acc: 0.8633 - val_loss: 0.2727 - val_acc: 0.8940\n",
      "Epoch 181/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.3167 - acc: 0.8619 - val_loss: 0.2737 - val_acc: 0.8916\n",
      "Epoch 182/200\n",
      "3730/3730 [==============================] - 0s 46us/step - loss: 0.3165 - acc: 0.8638 - val_loss: 0.2707 - val_acc: 0.8964\n",
      "Epoch 183/200\n",
      "3730/3730 [==============================] - 0s 46us/step - loss: 0.3169 - acc: 0.8654 - val_loss: 0.2707 - val_acc: 0.8916\n",
      "Epoch 184/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.3170 - acc: 0.8643 - val_loss: 0.2757 - val_acc: 0.8916\n",
      "Epoch 185/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.3164 - acc: 0.8633 - val_loss: 0.2710 - val_acc: 0.8916\n",
      "Epoch 186/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.3163 - acc: 0.8660 - val_loss: 0.2713 - val_acc: 0.8916\n",
      "Epoch 187/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.3172 - acc: 0.8633 - val_loss: 0.2713 - val_acc: 0.8916\n",
      "Epoch 188/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.3174 - acc: 0.8646 - val_loss: 0.2706 - val_acc: 0.8988\n",
      "Epoch 189/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.3160 - acc: 0.8649 - val_loss: 0.2739 - val_acc: 0.8916\n",
      "Epoch 190/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.3164 - acc: 0.8638 - val_loss: 0.2743 - val_acc: 0.8916\n",
      "Epoch 191/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.3163 - acc: 0.8630 - val_loss: 0.2742 - val_acc: 0.8916\n",
      "Epoch 192/200\n",
      "3730/3730 [==============================] - 0s 46us/step - loss: 0.3160 - acc: 0.8635 - val_loss: 0.2716 - val_acc: 0.8916\n",
      "Epoch 193/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.3164 - acc: 0.8654 - val_loss: 0.2705 - val_acc: 0.8916\n",
      "Epoch 194/200\n",
      "3730/3730 [==============================] - 0s 44us/step - loss: 0.3156 - acc: 0.8633 - val_loss: 0.2718 - val_acc: 0.8916\n",
      "Epoch 195/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.3159 - acc: 0.8651 - val_loss: 0.2704 - val_acc: 0.8940\n",
      "Epoch 196/200\n",
      "3730/3730 [==============================] - 0s 45us/step - loss: 0.3161 - acc: 0.8643 - val_loss: 0.2715 - val_acc: 0.8940\n",
      "Epoch 197/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.3156 - acc: 0.8643 - val_loss: 0.2735 - val_acc: 0.8940\n",
      "Epoch 198/200\n",
      "3730/3730 [==============================] - 0s 46us/step - loss: 0.3164 - acc: 0.8638 - val_loss: 0.2748 - val_acc: 0.8916\n",
      "Epoch 199/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.3159 - acc: 0.8649 - val_loss: 0.2721 - val_acc: 0.8964\n",
      "Epoch 200/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.3158 - acc: 0.8649 - val_loss: 0.2705 - val_acc: 0.8940\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(8, kernel_initializer='normal', input_dim=len(X[0]), activation='relu'))\n",
    "model.add(Dense(8, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adamax',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X, y.values, epochs=200, validation_split = 0.1)\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prever se o Ajuste do dia seguinte será maior que a abertura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T18:22:25.553832Z",
     "start_time": "2019-11-08T18:22:25.456888Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Número Negócios</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Var pontos</th>\n",
       "      <th>Dif_contratos</th>\n",
       "      <th>Dif_minmax</th>\n",
       "      <th>Dif_abert_ultimo</th>\n",
       "      <th>Dif_abert_ajuste</th>\n",
       "      <th>Dif_abert_min</th>\n",
       "      <th>Dif_abert_max</th>\n",
       "      <th>Dif_abert_medio</th>\n",
       "      <th>Dif_ajuste_ultimo</th>\n",
       "      <th>Dif_ajuste_medio</th>\n",
       "      <th>Dif_ultimacomp_ultimavend</th>\n",
       "      <th>Média</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29/07/2019</td>\n",
       "      <td>271.92</td>\n",
       "      <td>42.939771</td>\n",
       "      <td>145520</td>\n",
       "      <td>132520</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>7.5</td>\n",
       "      <td>-16.5</td>\n",
       "      <td>-4.499</td>\n",
       "      <td>2.797</td>\n",
       "      <td>-4.702</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.785600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26/07/2019</td>\n",
       "      <td>321.28</td>\n",
       "      <td>58.414828</td>\n",
       "      <td>125890</td>\n",
       "      <td>23510</td>\n",
       "      <td>34.5</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-9.755</td>\n",
       "      <td>19.0</td>\n",
       "      <td>-15.5</td>\n",
       "      <td>4.970</td>\n",
       "      <td>-5.755</td>\n",
       "      <td>-4.785</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.776534</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25/07/2019</td>\n",
       "      <td>416.51</td>\n",
       "      <td>72.105906</td>\n",
       "      <td>129780</td>\n",
       "      <td>15894</td>\n",
       "      <td>50.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>14.834</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-39.0</td>\n",
       "      <td>-16.490</td>\n",
       "      <td>3.334</td>\n",
       "      <td>-1.656</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.779853</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24/07/2019</td>\n",
       "      <td>261.37</td>\n",
       "      <td>50.725253</td>\n",
       "      <td>31160</td>\n",
       "      <td>-7529</td>\n",
       "      <td>25.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.356</td>\n",
       "      <td>13.5</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>4.779</td>\n",
       "      <td>-3.644</td>\n",
       "      <td>7.135</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.769510</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23/07/2019</td>\n",
       "      <td>335.86</td>\n",
       "      <td>59.121713</td>\n",
       "      <td>356000</td>\n",
       "      <td>-2908</td>\n",
       "      <td>39.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>27.972</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>-22.634</td>\n",
       "      <td>-2.028</td>\n",
       "      <td>5.338</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.767201</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Data  Número Negócios     Volume  Var pontos  Dif_contratos  \\\n",
       "0  29/07/2019           271.92  42.939771      145520         132520   \n",
       "1  26/07/2019           321.28  58.414828      125890          23510   \n",
       "2  25/07/2019           416.51  72.105906      129780          15894   \n",
       "3  24/07/2019           261.37  50.725253       31160          -7529   \n",
       "4  23/07/2019           335.86  59.121713      356000          -2908   \n",
       "\n",
       "   Dif_minmax  Dif_abert_ultimo  Dif_abert_ajuste  Dif_abert_min  \\\n",
       "0        24.0              -3.0            -0.203            7.5   \n",
       "1        34.5              -4.0            -9.755           19.0   \n",
       "2        50.0              11.5            14.834           11.0   \n",
       "3        25.5               6.0             2.356           13.5   \n",
       "4        39.0              30.0            27.972            2.0   \n",
       "\n",
       "   Dif_abert_max  Dif_abert_medio  Dif_ajuste_ultimo  Dif_ajuste_medio  \\\n",
       "0          -16.5           -4.499              2.797            -4.702   \n",
       "1          -15.5            4.970             -5.755            -4.785   \n",
       "2          -39.0          -16.490              3.334            -1.656   \n",
       "3          -12.0            4.779             -3.644             7.135   \n",
       "4          -37.0          -22.634             -2.028             5.338   \n",
       "\n",
       "   Dif_ultimacomp_ultimavend     Média  target  \n",
       "0                        0.5  3.785600       0  \n",
       "1                        1.5  3.776534       1  \n",
       "2                        1.0  3.779853       1  \n",
       "3                        2.0  3.769510       1  \n",
       "4                        2.0  3.767201       0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_abert_old = df.copy()\n",
    "\n",
    "#1 se o Ajuste for maior que o último preço do dia anterior\n",
    "\n",
    "df_abert_old['target'] = df_abert_old.Ajuste.shift(-1) - df_abert_old.Abertura.shift(-1)\n",
    "df_abert_old['target'] = df_abert_old['target'].apply(lambda x: 1 if x > 0 else 0)\n",
    "df_abert_old = df_abert_old.drop(len(df_abert_old)-1)\n",
    "\n",
    "df_abert_old['Média'] = (df_abert_old['Último Preço'] + df_abert_old['Abertura'] + df_abert_old['Máximo'] + df_abert_old['Mínimo'] + df_abert_old['Médio'] + df_abert_old['Ajuste'] + df_abert_old['Última oferta de compra']+ df_abert_old['Última oferta de venda'])/8\n",
    "df_abert_old = df_abert_old.drop(columns = ['Último Preço','Abertura','Máximo','Mínimo','Médio','Última oferta de compra','Última oferta de venda','Contratos Negociados', 'Ajuste'])\n",
    "\n",
    "\n",
    "df_change = df_abert_old[['target']]\n",
    "df_abert_old = df_abert_old.drop(columns = 'target')\n",
    "df_abert_old['target'] = df_change\n",
    "\n",
    "df_abert_old.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T19:28:12.714830Z",
     "start_time": "2019-11-08T19:28:12.560903Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>Data</th>\n",
       "      <th>Número Negócios</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Var pontos</th>\n",
       "      <th>Dif_contratos</th>\n",
       "      <th>Dif_minmax</th>\n",
       "      <th>Dif_abert_ultimo</th>\n",
       "      <th>Dif_abert_ajuste</th>\n",
       "      <th>Dif_abert_min</th>\n",
       "      <th>Dif_abert_max</th>\n",
       "      <th>Dif_abert_medio</th>\n",
       "      <th>Dif_ajuste_ultimo</th>\n",
       "      <th>Dif_ajuste_medio</th>\n",
       "      <th>Dif_ultimacomp_ultimavend</th>\n",
       "      <th>Média</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.498562</td>\n",
       "      <td>2.807394</td>\n",
       "      <td>0.723413</td>\n",
       "      <td>14/06/2019</td>\n",
       "      <td>2.865806</td>\n",
       "      <td>2.604802</td>\n",
       "      <td>1.099741</td>\n",
       "      <td>-0.181456</td>\n",
       "      <td>1.312772</td>\n",
       "      <td>1.557008</td>\n",
       "      <td>-0.120086</td>\n",
       "      <td>-0.332730</td>\n",
       "      <td>-2.054306</td>\n",
       "      <td>-1.942393</td>\n",
       "      <td>-0.196860</td>\n",
       "      <td>-0.178976</td>\n",
       "      <td>-0.012160</td>\n",
       "      <td>2.178146</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.236543</td>\n",
       "      <td>1.093142</td>\n",
       "      <td>0.813228</td>\n",
       "      <td>13/06/2019</td>\n",
       "      <td>2.062037</td>\n",
       "      <td>2.314525</td>\n",
       "      <td>-0.649702</td>\n",
       "      <td>-0.483898</td>\n",
       "      <td>-0.004895</td>\n",
       "      <td>-0.058399</td>\n",
       "      <td>-0.185457</td>\n",
       "      <td>0.076259</td>\n",
       "      <td>0.075808</td>\n",
       "      <td>0.280717</td>\n",
       "      <td>-0.182751</td>\n",
       "      <td>-0.177095</td>\n",
       "      <td>-0.011628</td>\n",
       "      <td>2.136805</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.688401</td>\n",
       "      <td>2.248905</td>\n",
       "      <td>0.239471</td>\n",
       "      <td>12/06/2019</td>\n",
       "      <td>2.507796</td>\n",
       "      <td>2.487949</td>\n",
       "      <td>-0.637429</td>\n",
       "      <td>-0.153140</td>\n",
       "      <td>0.440513</td>\n",
       "      <td>0.335603</td>\n",
       "      <td>-0.207233</td>\n",
       "      <td>0.785175</td>\n",
       "      <td>0.125346</td>\n",
       "      <td>0.694302</td>\n",
       "      <td>-0.223947</td>\n",
       "      <td>-0.186366</td>\n",
       "      <td>-0.012160</td>\n",
       "      <td>2.145966</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.172415</td>\n",
       "      <td>1.142010</td>\n",
       "      <td>0.374627</td>\n",
       "      <td>11/06/2019</td>\n",
       "      <td>1.687787</td>\n",
       "      <td>1.586883</td>\n",
       "      <td>0.608505</td>\n",
       "      <td>-0.243561</td>\n",
       "      <td>0.459072</td>\n",
       "      <td>-0.964603</td>\n",
       "      <td>-0.258565</td>\n",
       "      <td>1.303229</td>\n",
       "      <td>0.571184</td>\n",
       "      <td>1.353412</td>\n",
       "      <td>-0.211306</td>\n",
       "      <td>-0.217783</td>\n",
       "      <td>-0.011628</td>\n",
       "      <td>2.150522</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.012424</td>\n",
       "      <td>1.412341</td>\n",
       "      <td>1.183180</td>\n",
       "      <td>10/06/2019</td>\n",
       "      <td>1.377238</td>\n",
       "      <td>1.242523</td>\n",
       "      <td>-0.457664</td>\n",
       "      <td>-0.009270</td>\n",
       "      <td>0.069339</td>\n",
       "      <td>-0.334200</td>\n",
       "      <td>-0.229955</td>\n",
       "      <td>0.676111</td>\n",
       "      <td>0.521646</td>\n",
       "      <td>0.804634</td>\n",
       "      <td>-0.213709</td>\n",
       "      <td>-0.205765</td>\n",
       "      <td>-0.010034</td>\n",
       "      <td>2.179742</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2        Data  Número Negócios    Volume  \\\n",
       "0  1.498562  2.807394  0.723413  14/06/2019         2.865806  2.604802   \n",
       "1  2.236543  1.093142  0.813228  13/06/2019         2.062037  2.314525   \n",
       "2  1.688401  2.248905  0.239471  12/06/2019         2.507796  2.487949   \n",
       "3  2.172415  1.142010  0.374627  11/06/2019         1.687787  1.586883   \n",
       "4  2.012424  1.412341  1.183180  10/06/2019         1.377238  1.242523   \n",
       "\n",
       "   Var pontos  Dif_contratos  Dif_minmax  Dif_abert_ultimo  Dif_abert_ajuste  \\\n",
       "0    1.099741      -0.181456    1.312772          1.557008         -0.120086   \n",
       "1   -0.649702      -0.483898   -0.004895         -0.058399         -0.185457   \n",
       "2   -0.637429      -0.153140    0.440513          0.335603         -0.207233   \n",
       "3    0.608505      -0.243561    0.459072         -0.964603         -0.258565   \n",
       "4   -0.457664      -0.009270    0.069339         -0.334200         -0.229955   \n",
       "\n",
       "   Dif_abert_min  Dif_abert_max  Dif_abert_medio  Dif_ajuste_ultimo  \\\n",
       "0      -0.332730      -2.054306        -1.942393          -0.196860   \n",
       "1       0.076259       0.075808         0.280717          -0.182751   \n",
       "2       0.785175       0.125346         0.694302          -0.223947   \n",
       "3       1.303229       0.571184         1.353412          -0.211306   \n",
       "4       0.676111       0.521646         0.804634          -0.213709   \n",
       "\n",
       "   Dif_ajuste_medio  Dif_ultimacomp_ultimavend     Média  target  \n",
       "0         -0.178976                  -0.012160  2.178146       1  \n",
       "1         -0.177095                  -0.011628  2.136805       0  \n",
       "2         -0.186366                  -0.012160  2.145966       0  \n",
       "3         -0.217783                  -0.011628  2.150522       0  \n",
       "4         -0.205765                  -0.010034  2.179742       0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = StandardScaler()\n",
    "df_abert_old.iloc[:,1:-1]  = sc.fit_transform(df_abert_old.iloc[:,1:-1])\n",
    "\n",
    "\n",
    "\n",
    "df_moeda = pd.read_csv('moedas_features.csv')\n",
    "\n",
    "sc = StandardScaler()\n",
    "df_moeda.iloc[:,1:] = sc.fit_transform(df_moeda.iloc[:,1:])\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "dataset = pca.fit_transform(df_moeda.iloc[:,1:])\n",
    "df_moeda_pca = pd.DataFrame(dataset)\n",
    "df_moeda_pca['Data'] = df_moeda.iloc[:,0:1]\n",
    "\n",
    "df_abert = pd.merge(df_moeda_pca, df_abert_old, on = 'Data')\n",
    "\n",
    "df_abert.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T19:28:58.463272Z",
     "start_time": "2019-11-08T19:28:58.455278Z"
    }
   },
   "outputs": [],
   "source": [
    "df_abert = df_abert.set_index('Data')\n",
    "index = df_abert.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T19:29:04.135868Z",
     "start_time": "2019-11-08T19:29:04.116878Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.73532848,  1.39379165,  0.41961081, ..., -0.19596445,\n",
       "        -0.01402039,  2.00404183],\n",
       "       [ 1.09805362,  0.54176439,  0.471919  , ..., -0.19421976,\n",
       "        -0.01355552,  1.96200735],\n",
       "       [ 0.82863614,  1.1162082 ,  0.13776346, ..., -0.20281729,\n",
       "        -0.01402039,  1.97132267],\n",
       "       ...,\n",
       "       [ 2.64513827,  0.93990606,  0.917673  , ..., -0.22194049,\n",
       "        -0.01448526, -0.5714771 ],\n",
       "       [ 2.91088089,  0.5781823 , -1.47667767, ..., -0.21720465,\n",
       "        -0.01448526, -0.55704584],\n",
       "       [ 2.26629688,  1.88804074,  0.41997129, ..., -0.20357272,\n",
       "        -0.01448526, -0.55159947]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df_abert[['target']]\n",
    "X = df_abert.drop(columns = ['target'])\n",
    "X_columns = df_abert.drop(columns = ['target'])\n",
    "\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "#X = X.values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T19:29:23.718377Z",
     "start_time": "2019-11-08T19:29:23.713381Z"
    }
   },
   "outputs": [],
   "source": [
    "df_final = pd.DataFrame(X,index = index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T19:29:31.077956Z",
     "start_time": "2019-11-08T19:29:31.000003Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df_final, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T19:29:37.013374Z",
     "start_time": "2019-11-08T19:29:36.663099Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\choice\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "c:\\users\\choice\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5325301204819277"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = RandomForestClassifier()\n",
    "r.fit(x_train, y_train)  \n",
    "\n",
    "predictions = r.predict(x_test)\n",
    "\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T19:33:53.039192Z",
     "start_time": "2019-11-08T19:33:21.420048Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3731 samples, validate on 415 samples\n",
      "Epoch 1/500\n",
      "3731/3731 [==============================] - 1s 163us/step - loss: 0.6931 - acc: 0.5004 - val_loss: 0.6931 - val_acc: 0.5157\n",
      "Epoch 2/500\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.6922 - acc: 0.5109 - val_loss: 0.6921 - val_acc: 0.5157\n",
      "Epoch 3/500\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.6905 - acc: 0.5109 - val_loss: 0.6918 - val_acc: 0.5157\n",
      "Epoch 4/500\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.6889 - acc: 0.5344 - val_loss: 0.6916 - val_acc: 0.5373\n",
      "Epoch 5/500\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.6878 - acc: 0.5551 - val_loss: 0.6918 - val_acc: 0.5108\n",
      "Epoch 6/500\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.6868 - acc: 0.5553 - val_loss: 0.6919 - val_acc: 0.5084\n",
      "Epoch 7/500\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.6861 - acc: 0.5548 - val_loss: 0.6923 - val_acc: 0.5060\n",
      "Epoch 8/500\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.6855 - acc: 0.5620 - val_loss: 0.6925 - val_acc: 0.5108\n",
      "Epoch 9/500\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.6850 - acc: 0.5612 - val_loss: 0.6935 - val_acc: 0.4988\n",
      "Epoch 10/500\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.6846 - acc: 0.5580 - val_loss: 0.6929 - val_acc: 0.5060\n",
      "Epoch 11/500\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.6842 - acc: 0.5637 - val_loss: 0.6939 - val_acc: 0.5084\n",
      "Epoch 12/500\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.6838 - acc: 0.5567 - val_loss: 0.6945 - val_acc: 0.5084\n",
      "Epoch 13/500\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.6835 - acc: 0.5594 - val_loss: 0.6947 - val_acc: 0.5108\n",
      "Epoch 14/500\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.6834 - acc: 0.5615 - val_loss: 0.6951 - val_acc: 0.5060\n",
      "Epoch 15/500\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.6827 - acc: 0.5655 - val_loss: 0.6946 - val_acc: 0.5181\n",
      "Epoch 16/500\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.6823 - acc: 0.5677 - val_loss: 0.6955 - val_acc: 0.5084\n",
      "Epoch 17/500\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.6822 - acc: 0.5594 - val_loss: 0.6966 - val_acc: 0.5036\n",
      "Epoch 18/500\n",
      "3731/3731 [==============================] - 0s 59us/step - loss: 0.6820 - acc: 0.5701 - val_loss: 0.6969 - val_acc: 0.5060\n",
      "Epoch 19/500\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.6816 - acc: 0.5674 - val_loss: 0.6966 - val_acc: 0.5108\n",
      "Epoch 20/500\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.6812 - acc: 0.5677 - val_loss: 0.6971 - val_acc: 0.5133\n",
      "Epoch 21/500\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.6809 - acc: 0.5698 - val_loss: 0.6980 - val_acc: 0.5157\n",
      "Epoch 22/500\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.6810 - acc: 0.5634 - val_loss: 0.6985 - val_acc: 0.5133\n",
      "Epoch 23/500\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.6805 - acc: 0.5741 - val_loss: 0.6992 - val_acc: 0.5133\n",
      "Epoch 24/500\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.6802 - acc: 0.5722 - val_loss: 0.6997 - val_acc: 0.5133\n",
      "Epoch 25/500\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.6798 - acc: 0.5706 - val_loss: 0.6994 - val_acc: 0.5229\n",
      "Epoch 26/500\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.6798 - acc: 0.5704 - val_loss: 0.7005 - val_acc: 0.5036\n",
      "Epoch 27/500\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.6794 - acc: 0.5701 - val_loss: 0.7007 - val_acc: 0.5205\n",
      "Epoch 28/500\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.6794 - acc: 0.5690 - val_loss: 0.7004 - val_acc: 0.5205\n",
      "Epoch 29/500\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.6793 - acc: 0.5655 - val_loss: 0.7008 - val_acc: 0.5157\n",
      "Epoch 30/500\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.6792 - acc: 0.5687 - val_loss: 0.7003 - val_acc: 0.5253\n",
      "Epoch 31/500\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.6788 - acc: 0.5679 - val_loss: 0.7002 - val_acc: 0.5277\n",
      "Epoch 32/500\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.6787 - acc: 0.5741 - val_loss: 0.7006 - val_acc: 0.5133\n",
      "Epoch 33/500\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.6783 - acc: 0.5679 - val_loss: 0.7008 - val_acc: 0.5133\n",
      "Epoch 34/500\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.6784 - acc: 0.5714 - val_loss: 0.7003 - val_acc: 0.5181\n",
      "Epoch 35/500\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.6780 - acc: 0.5661 - val_loss: 0.7010 - val_acc: 0.5108\n",
      "Epoch 36/500\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.6780 - acc: 0.5685 - val_loss: 0.7012 - val_acc: 0.5229\n",
      "Epoch 37/500\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.6777 - acc: 0.5706 - val_loss: 0.7005 - val_acc: 0.5133\n",
      "Epoch 38/500\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.6775 - acc: 0.5712 - val_loss: 0.6996 - val_acc: 0.5108\n",
      "Epoch 39/500\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.6774 - acc: 0.5685 - val_loss: 0.7006 - val_acc: 0.5036\n",
      "Epoch 40/500\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.6773 - acc: 0.5706 - val_loss: 0.7013 - val_acc: 0.5060\n",
      "Epoch 41/500\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.6770 - acc: 0.5704 - val_loss: 0.7011 - val_acc: 0.5108\n",
      "Epoch 42/500\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.6767 - acc: 0.5789 - val_loss: 0.7004 - val_acc: 0.5181\n",
      "Epoch 43/500\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.6770 - acc: 0.5733 - val_loss: 0.7007 - val_acc: 0.5060\n",
      "Epoch 44/500\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.6764 - acc: 0.5746 - val_loss: 0.6998 - val_acc: 0.5301\n",
      "Epoch 45/500\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.6766 - acc: 0.5744 - val_loss: 0.7007 - val_acc: 0.5181\n",
      "Epoch 46/500\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.6764 - acc: 0.5725 - val_loss: 0.7007 - val_acc: 0.5157\n",
      "Epoch 47/500\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.6761 - acc: 0.5741 - val_loss: 0.7009 - val_acc: 0.5229\n",
      "Epoch 48/500\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.6758 - acc: 0.5760 - val_loss: 0.7011 - val_acc: 0.5253\n",
      "Epoch 49/500\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.6756 - acc: 0.5763 - val_loss: 0.7011 - val_acc: 0.5229\n",
      "Epoch 50/500\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.6756 - acc: 0.5754 - val_loss: 0.7012 - val_acc: 0.5205\n",
      "Epoch 51/500\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.6755 - acc: 0.5771 - val_loss: 0.7021 - val_acc: 0.5157\n",
      "Epoch 52/500\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.6755 - acc: 0.5725 - val_loss: 0.7027 - val_acc: 0.5084\n",
      "Epoch 53/500\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.6756 - acc: 0.5795 - val_loss: 0.7018 - val_acc: 0.5108\n",
      "Epoch 54/500\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.6753 - acc: 0.5800 - val_loss: 0.7020 - val_acc: 0.5181\n",
      "Epoch 55/500\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.6748 - acc: 0.5779 - val_loss: 0.7028 - val_acc: 0.5181\n",
      "Epoch 56/500\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.6748 - acc: 0.5797 - val_loss: 0.7031 - val_acc: 0.5108\n",
      "Epoch 57/500\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.6748 - acc: 0.5813 - val_loss: 0.7031 - val_acc: 0.5157\n",
      "Epoch 58/500\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.6748 - acc: 0.5813 - val_loss: 0.7038 - val_acc: 0.5157\n",
      "Epoch 59/500\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.6748 - acc: 0.5768 - val_loss: 0.7031 - val_acc: 0.5181\n",
      "Epoch 60/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.6743 - acc: 0.5816 - val_loss: 0.7036 - val_acc: 0.5181\n",
      "Epoch 61/500\n",
      "3731/3731 [==============================] - 0s 65us/step - loss: 0.6745 - acc: 0.5830 - val_loss: 0.7045 - val_acc: 0.5133\n",
      "Epoch 62/500\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.6744 - acc: 0.5779 - val_loss: 0.7044 - val_acc: 0.5205\n",
      "Epoch 63/500\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.6741 - acc: 0.5754 - val_loss: 0.7040 - val_acc: 0.5229\n",
      "Epoch 64/500\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.6744 - acc: 0.5800 - val_loss: 0.7049 - val_acc: 0.5205\n",
      "Epoch 65/500\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.6740 - acc: 0.5816 - val_loss: 0.7052 - val_acc: 0.5181\n",
      "Epoch 66/500\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.6741 - acc: 0.5803 - val_loss: 0.7055 - val_acc: 0.5205\n",
      "Epoch 67/500\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.6739 - acc: 0.5859 - val_loss: 0.7051 - val_acc: 0.5133\n",
      "Epoch 68/500\n",
      "3731/3731 [==============================] - 0s 59us/step - loss: 0.6738 - acc: 0.5760 - val_loss: 0.7049 - val_acc: 0.5205\n",
      "Epoch 69/500\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.6739 - acc: 0.5832 - val_loss: 0.7048 - val_acc: 0.5229\n",
      "Epoch 70/500\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.6738 - acc: 0.5736 - val_loss: 0.7050 - val_acc: 0.5157\n",
      "Epoch 71/500\n",
      "3731/3731 [==============================] - 0s 56us/step - loss: 0.6735 - acc: 0.5768 - val_loss: 0.7046 - val_acc: 0.5205\n",
      "Epoch 72/500\n",
      "3731/3731 [==============================] - 0s 57us/step - loss: 0.6738 - acc: 0.5781 - val_loss: 0.7046 - val_acc: 0.5181\n",
      "Epoch 73/500\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.6735 - acc: 0.5765 - val_loss: 0.7062 - val_acc: 0.5133\n",
      "Epoch 74/500\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.6736 - acc: 0.5741 - val_loss: 0.7053 - val_acc: 0.5181\n",
      "Epoch 75/500\n",
      "3731/3731 [==============================] - 0s 63us/step - loss: 0.6735 - acc: 0.5813 - val_loss: 0.7055 - val_acc: 0.5229\n",
      "Epoch 76/500\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.6736 - acc: 0.5800 - val_loss: 0.7060 - val_acc: 0.5229\n",
      "Epoch 77/500\n",
      "3731/3731 [==============================] - 0s 56us/step - loss: 0.6731 - acc: 0.5787 - val_loss: 0.7061 - val_acc: 0.5133\n",
      "Epoch 78/500\n",
      "3731/3731 [==============================] - 0s 62us/step - loss: 0.6731 - acc: 0.5789 - val_loss: 0.7062 - val_acc: 0.5157\n",
      "Epoch 79/500\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.6736 - acc: 0.5771 - val_loss: 0.7062 - val_acc: 0.5181\n",
      "Epoch 80/500\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.6734 - acc: 0.5797 - val_loss: 0.7053 - val_acc: 0.5157\n",
      "Epoch 81/500\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.6731 - acc: 0.5813 - val_loss: 0.7054 - val_acc: 0.5205\n",
      "Epoch 82/500\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.6733 - acc: 0.5789 - val_loss: 0.7060 - val_acc: 0.5181\n",
      "Epoch 83/500\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.6737 - acc: 0.5773 - val_loss: 0.7053 - val_acc: 0.5133\n",
      "Epoch 84/500\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.6729 - acc: 0.5787 - val_loss: 0.7059 - val_acc: 0.5157\n",
      "Epoch 85/500\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.6732 - acc: 0.5795 - val_loss: 0.7049 - val_acc: 0.5133\n",
      "Epoch 86/500\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.6729 - acc: 0.5824 - val_loss: 0.7062 - val_acc: 0.5253\n",
      "Epoch 87/500\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.6734 - acc: 0.5805 - val_loss: 0.7053 - val_acc: 0.5108\n",
      "Epoch 88/500\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.6729 - acc: 0.5832 - val_loss: 0.7056 - val_acc: 0.5181\n",
      "Epoch 89/500\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.6729 - acc: 0.5813 - val_loss: 0.7052 - val_acc: 0.5253\n",
      "Epoch 90/500\n",
      "3731/3731 [==============================] - 0s 60us/step - loss: 0.6727 - acc: 0.5784 - val_loss: 0.7053 - val_acc: 0.5253\n",
      "Epoch 91/500\n",
      "3731/3731 [==============================] - 0s 56us/step - loss: 0.6729 - acc: 0.5811 - val_loss: 0.7051 - val_acc: 0.5229\n",
      "Epoch 92/500\n",
      "3731/3731 [==============================] - 0s 59us/step - loss: 0.6731 - acc: 0.5816 - val_loss: 0.7054 - val_acc: 0.5229\n",
      "Epoch 93/500\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.6728 - acc: 0.5787 - val_loss: 0.7050 - val_acc: 0.5157\n",
      "Epoch 94/500\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.6729 - acc: 0.5824 - val_loss: 0.7064 - val_acc: 0.5205\n",
      "Epoch 95/500\n",
      "3731/3731 [==============================] - 0s 56us/step - loss: 0.6727 - acc: 0.5835 - val_loss: 0.7066 - val_acc: 0.5277\n",
      "Epoch 96/500\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.6726 - acc: 0.5840 - val_loss: 0.7065 - val_acc: 0.5253\n",
      "Epoch 97/500\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.6726 - acc: 0.5830 - val_loss: 0.7058 - val_acc: 0.5133\n",
      "Epoch 98/500\n",
      "3731/3731 [==============================] - 0s 53us/step - loss: 0.6722 - acc: 0.5827 - val_loss: 0.7065 - val_acc: 0.5301\n",
      "Epoch 99/500\n",
      "3731/3731 [==============================] - 0s 64us/step - loss: 0.6724 - acc: 0.5864 - val_loss: 0.7068 - val_acc: 0.5229\n",
      "Epoch 100/500\n",
      "3731/3731 [==============================] - 0s 59us/step - loss: 0.6723 - acc: 0.5835 - val_loss: 0.7086 - val_acc: 0.5253\n",
      "Epoch 101/500\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.6732 - acc: 0.5821 - val_loss: 0.7060 - val_acc: 0.5277\n",
      "Epoch 102/500\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.6724 - acc: 0.5843 - val_loss: 0.7066 - val_acc: 0.5253\n",
      "Epoch 103/500\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.6725 - acc: 0.5821 - val_loss: 0.7059 - val_acc: 0.5229\n",
      "Epoch 104/500\n",
      "3731/3731 [==============================] - 0s 62us/step - loss: 0.6723 - acc: 0.5813 - val_loss: 0.7072 - val_acc: 0.5277\n",
      "Epoch 105/500\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.6719 - acc: 0.5843 - val_loss: 0.7075 - val_acc: 0.5205\n",
      "Epoch 106/500\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.6724 - acc: 0.5811 - val_loss: 0.7060 - val_acc: 0.5253\n",
      "Epoch 107/500\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.6721 - acc: 0.5821 - val_loss: 0.7057 - val_acc: 0.5157\n",
      "Epoch 108/500\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.6722 - acc: 0.5897 - val_loss: 0.7070 - val_acc: 0.5229\n",
      "Epoch 109/500\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.6721 - acc: 0.5824 - val_loss: 0.7060 - val_acc: 0.5181\n",
      "Epoch 110/500\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.6722 - acc: 0.5830 - val_loss: 0.7068 - val_acc: 0.5181\n",
      "Epoch 111/500\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.6725 - acc: 0.5835 - val_loss: 0.7071 - val_acc: 0.5229\n",
      "Epoch 112/500\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.6719 - acc: 0.5808 - val_loss: 0.7078 - val_acc: 0.5325\n",
      "Epoch 113/500\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.6718 - acc: 0.5883 - val_loss: 0.7081 - val_acc: 0.5157\n",
      "Epoch 114/500\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.6721 - acc: 0.5830 - val_loss: 0.7068 - val_acc: 0.5277\n",
      "Epoch 115/500\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.6720 - acc: 0.5838 - val_loss: 0.7075 - val_acc: 0.5205\n",
      "Epoch 116/500\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.6732 - acc: 0.5840 - val_loss: 0.7069 - val_acc: 0.5253\n",
      "Epoch 117/500\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.6723 - acc: 0.5880 - val_loss: 0.7060 - val_acc: 0.5133\n",
      "Epoch 118/500\n",
      "3731/3731 [==============================] - 0s 50us/step - loss: 0.6720 - acc: 0.5843 - val_loss: 0.7068 - val_acc: 0.5229\n",
      "Epoch 119/500\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.6719 - acc: 0.5848 - val_loss: 0.7085 - val_acc: 0.5277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/500\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.6720 - acc: 0.5875 - val_loss: 0.7075 - val_acc: 0.5325\n",
      "Epoch 121/500\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.6719 - acc: 0.5905 - val_loss: 0.7065 - val_acc: 0.5253\n",
      "Epoch 122/500\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.6719 - acc: 0.5840 - val_loss: 0.7079 - val_acc: 0.5205\n",
      "Epoch 123/500\n",
      "3731/3731 [==============================] - 0s 49us/step - loss: 0.6719 - acc: 0.5878 - val_loss: 0.7078 - val_acc: 0.5253\n",
      "Epoch 124/500\n",
      "3731/3731 [==============================] - 0s 65us/step - loss: 0.6718 - acc: 0.5862 - val_loss: 0.7074 - val_acc: 0.5205\n",
      "Epoch 125/500\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.6721 - acc: 0.5889 - val_loss: 0.7067 - val_acc: 0.5253\n",
      "Epoch 126/500\n",
      "3731/3731 [==============================] - 0s 47us/step - loss: 0.6724 - acc: 0.5811 - val_loss: 0.7065 - val_acc: 0.5301\n",
      "Epoch 127/500\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.6718 - acc: 0.5846 - val_loss: 0.7065 - val_acc: 0.5157\n",
      "Epoch 128/500\n",
      "3731/3731 [==============================] - 0s 68us/step - loss: 0.6719 - acc: 0.5830 - val_loss: 0.7062 - val_acc: 0.5253\n",
      "Epoch 129/500\n",
      "3731/3731 [==============================] - 0s 65us/step - loss: 0.6717 - acc: 0.5867 - val_loss: 0.7074 - val_acc: 0.5301\n",
      "Epoch 130/500\n",
      "3731/3731 [==============================] - ETA: 0s - loss: 0.6732 - acc: 0.585 - 0s 68us/step - loss: 0.6722 - acc: 0.5851 - val_loss: 0.7075 - val_acc: 0.5181\n",
      "Epoch 131/500\n",
      "3731/3731 [==============================] - 0s 69us/step - loss: 0.6721 - acc: 0.5864 - val_loss: 0.7074 - val_acc: 0.5253\n",
      "Epoch 132/500\n",
      "3731/3731 [==============================] - 0s 75us/step - loss: 0.6717 - acc: 0.5875 - val_loss: 0.7074 - val_acc: 0.5277\n",
      "Epoch 133/500\n",
      "3731/3731 [==============================] - 0s 75us/step - loss: 0.6723 - acc: 0.5856 - val_loss: 0.7064 - val_acc: 0.5253\n",
      "Epoch 134/500\n",
      "3731/3731 [==============================] - 0s 59us/step - loss: 0.6717 - acc: 0.5862 - val_loss: 0.7065 - val_acc: 0.5229\n",
      "Epoch 135/500\n",
      "3731/3731 [==============================] - 0s 58us/step - loss: 0.6717 - acc: 0.5821 - val_loss: 0.7059 - val_acc: 0.5253\n",
      "Epoch 136/500\n",
      "3731/3731 [==============================] - 0s 56us/step - loss: 0.6715 - acc: 0.5889 - val_loss: 0.7078 - val_acc: 0.5325\n",
      "Epoch 137/500\n",
      "3731/3731 [==============================] - 0s 56us/step - loss: 0.6714 - acc: 0.5886 - val_loss: 0.7078 - val_acc: 0.5253\n",
      "Epoch 138/500\n",
      "3731/3731 [==============================] - 0s 64us/step - loss: 0.6719 - acc: 0.5846 - val_loss: 0.7066 - val_acc: 0.5229\n",
      "Epoch 139/500\n",
      "3731/3731 [==============================] - 0s 48us/step - loss: 0.6716 - acc: 0.5910 - val_loss: 0.7082 - val_acc: 0.5229\n",
      "Epoch 140/500\n",
      "3731/3731 [==============================] - 0s 60us/step - loss: 0.6717 - acc: 0.5859 - val_loss: 0.7071 - val_acc: 0.5181\n",
      "Epoch 141/500\n",
      "3731/3731 [==============================] - 0s 73us/step - loss: 0.6716 - acc: 0.5913 - val_loss: 0.7076 - val_acc: 0.5205\n",
      "Epoch 142/500\n",
      "3731/3731 [==============================] - 0s 65us/step - loss: 0.6715 - acc: 0.5880 - val_loss: 0.7074 - val_acc: 0.5181\n",
      "Epoch 143/500\n",
      "3731/3731 [==============================] - 0s 61us/step - loss: 0.6717 - acc: 0.5835 - val_loss: 0.7074 - val_acc: 0.5229\n",
      "Epoch 144/500\n",
      "3731/3731 [==============================] - 0s 54us/step - loss: 0.6717 - acc: 0.5862 - val_loss: 0.7062 - val_acc: 0.5205\n",
      "Epoch 145/500\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.6716 - acc: 0.5862 - val_loss: 0.7056 - val_acc: 0.5205\n",
      "Epoch 146/500\n",
      "3731/3731 [==============================] - 0s 65us/step - loss: 0.6715 - acc: 0.5891 - val_loss: 0.7067 - val_acc: 0.5253\n",
      "Epoch 147/500\n",
      "3731/3731 [==============================] - 0s 64us/step - loss: 0.6719 - acc: 0.5867 - val_loss: 0.7060 - val_acc: 0.5205\n",
      "Epoch 148/500\n",
      "3731/3731 [==============================] - 0s 58us/step - loss: 0.6713 - acc: 0.5915 - val_loss: 0.7065 - val_acc: 0.5253\n",
      "Epoch 149/500\n",
      "3731/3731 [==============================] - 0s 51us/step - loss: 0.6715 - acc: 0.5880 - val_loss: 0.7063 - val_acc: 0.5205\n",
      "Epoch 150/500\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.6715 - acc: 0.5891 - val_loss: 0.7060 - val_acc: 0.5181\n",
      "Epoch 151/500\n",
      "3731/3731 [==============================] - 0s 58us/step - loss: 0.6714 - acc: 0.5883 - val_loss: 0.7066 - val_acc: 0.5253\n",
      "Epoch 152/500\n",
      "3731/3731 [==============================] - 0s 52us/step - loss: 0.6717 - acc: 0.5840 - val_loss: 0.7070 - val_acc: 0.5253\n",
      "Epoch 153/500\n",
      "3731/3731 [==============================] - 0s 55us/step - loss: 0.6713 - acc: 0.5867 - val_loss: 0.7070 - val_acc: 0.5205\n",
      "Epoch 154/500\n",
      " 736/3731 [====>.........................] - ETA: 0s - loss: 0.6785 - acc: 0.5707"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-f091285e7e62>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\choice\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\choice\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\choice\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\choice\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\choice\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(4, kernel_initializer='normal', input_dim=len(X[0]), activation='relu'))\n",
    "model.add(Dense(4, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X, y.values, epochs=500, validation_split = 0.1)\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
