{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T20:06:47.353336Z",
     "start_time": "2019-08-16T20:06:29.574902Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T20:06:53.188998Z",
     "start_time": "2019-08-16T20:06:47.357334Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Conv2D\n",
    "from time import time\n",
    "from keras.callbacks import TensorBoard, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T20:06:55.049305Z",
     "start_time": "2019-08-16T20:06:53.192994Z"
    }
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_hdf('df_dataDOL1.hdf', key='hdf')\n",
    "df2 = pd.read_hdf('df_dataDOL2.hdf', key='hdf')\n",
    "df3 = pd.read_hdf('df_dataDOL3.hdf', key='hdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T20:06:55.067295Z",
     "start_time": "2019-08-16T20:06:55.053305Z"
    }
   },
   "outputs": [],
   "source": [
    "df_total = pd.concat([df1,df2,df3],  ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T20:06:56.441436Z",
     "start_time": "2019-08-16T20:06:56.374473Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Contratos Abertos</th>\n",
       "      <th>Contratos Fechados</th>\n",
       "      <th>Número Negócios</th>\n",
       "      <th>Contratos Negociados</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Abertura</th>\n",
       "      <th>Mínimo</th>\n",
       "      <th>Máximo</th>\n",
       "      <th>Médio</th>\n",
       "      <th>Último Preço</th>\n",
       "      <th>Ajuste</th>\n",
       "      <th>Var pontos</th>\n",
       "      <th>Última oferta de compra</th>\n",
       "      <th>Última oferta de venda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29/07/2019</td>\n",
       "      <td>851537</td>\n",
       "      <td>719017</td>\n",
       "      <td>27192</td>\n",
       "      <td>226625</td>\n",
       "      <td>42939771125</td>\n",
       "      <td>3.7850</td>\n",
       "      <td>3.7775</td>\n",
       "      <td>3.8015</td>\n",
       "      <td>3.789499</td>\n",
       "      <td>3.7820</td>\n",
       "      <td>3.784797</td>\n",
       "      <td>145520</td>\n",
       "      <td>3.7820</td>\n",
       "      <td>3.7825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26/07/2019</td>\n",
       "      <td>875047</td>\n",
       "      <td>851537</td>\n",
       "      <td>32128</td>\n",
       "      <td>309480</td>\n",
       "      <td>58414828000</td>\n",
       "      <td>3.7800</td>\n",
       "      <td>3.7610</td>\n",
       "      <td>3.7955</td>\n",
       "      <td>3.775030</td>\n",
       "      <td>3.7760</td>\n",
       "      <td>3.770245</td>\n",
       "      <td>125890</td>\n",
       "      <td>3.7765</td>\n",
       "      <td>3.7780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25/07/2019</td>\n",
       "      <td>890941</td>\n",
       "      <td>875047</td>\n",
       "      <td>41651</td>\n",
       "      <td>381060</td>\n",
       "      <td>72105906125</td>\n",
       "      <td>3.7680</td>\n",
       "      <td>3.7570</td>\n",
       "      <td>3.8070</td>\n",
       "      <td>3.784490</td>\n",
       "      <td>3.7795</td>\n",
       "      <td>3.782834</td>\n",
       "      <td>129780</td>\n",
       "      <td>3.7795</td>\n",
       "      <td>3.7805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24/07/2019</td>\n",
       "      <td>883412</td>\n",
       "      <td>890941</td>\n",
       "      <td>26137</td>\n",
       "      <td>269620</td>\n",
       "      <td>50725252625</td>\n",
       "      <td>3.7675</td>\n",
       "      <td>3.7540</td>\n",
       "      <td>3.7795</td>\n",
       "      <td>3.762721</td>\n",
       "      <td>3.7735</td>\n",
       "      <td>3.769856</td>\n",
       "      <td>31160</td>\n",
       "      <td>3.7735</td>\n",
       "      <td>3.7755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23/07/2019</td>\n",
       "      <td>880504</td>\n",
       "      <td>883412</td>\n",
       "      <td>33586</td>\n",
       "      <td>313840</td>\n",
       "      <td>59121712875</td>\n",
       "      <td>3.7450</td>\n",
       "      <td>3.7430</td>\n",
       "      <td>3.7820</td>\n",
       "      <td>3.767634</td>\n",
       "      <td>3.7750</td>\n",
       "      <td>3.772972</td>\n",
       "      <td>356000</td>\n",
       "      <td>3.7750</td>\n",
       "      <td>3.7770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Data  Contratos Abertos  Contratos Fechados  Número Negócios  \\\n",
       "0  29/07/2019             851537              719017            27192   \n",
       "1  26/07/2019             875047              851537            32128   \n",
       "2  25/07/2019             890941              875047            41651   \n",
       "3  24/07/2019             883412              890941            26137   \n",
       "4  23/07/2019             880504              883412            33586   \n",
       "\n",
       "   Contratos Negociados       Volume  Abertura  Mínimo  Máximo     Médio  \\\n",
       "0                226625  42939771125    3.7850  3.7775  3.8015  3.789499   \n",
       "1                309480  58414828000    3.7800  3.7610  3.7955  3.775030   \n",
       "2                381060  72105906125    3.7680  3.7570  3.8070  3.784490   \n",
       "3                269620  50725252625    3.7675  3.7540  3.7795  3.762721   \n",
       "4                313840  59121712875    3.7450  3.7430  3.7820  3.767634   \n",
       "\n",
       "   Último Preço    Ajuste  Var pontos  Última oferta de compra  \\\n",
       "0        3.7820  3.784797      145520                   3.7820   \n",
       "1        3.7760  3.770245      125890                   3.7765   \n",
       "2        3.7795  3.782834      129780                   3.7795   \n",
       "3        3.7735  3.769856       31160                   3.7735   \n",
       "4        3.7750  3.772972      356000                   3.7750   \n",
       "\n",
       "   Última oferta de venda  \n",
       "0                  3.7825  \n",
       "1                  3.7780  \n",
       "2                  3.7805  \n",
       "3                  3.7755  \n",
       "4                  3.7770  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features criadas:\n",
    "\n",
    "-- Diferença entre Contratos abertos e fechados\n",
    "-- Diferença entre Máximo e mínimo\n",
    "-- Diferença entre Abertura e ùltima oferta de compra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score models :\n",
    "    adamax 32 -- 0.66\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T20:07:00.795537Z",
     "start_time": "2019-08-16T20:07:00.616638Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Número Negócios</th>\n",
       "      <th>Contratos Negociados</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Abertura</th>\n",
       "      <th>Mínimo</th>\n",
       "      <th>Máximo</th>\n",
       "      <th>Médio</th>\n",
       "      <th>Último Preço</th>\n",
       "      <th>Ajuste</th>\n",
       "      <th>Var pontos</th>\n",
       "      <th>Última oferta de compra</th>\n",
       "      <th>Última oferta de venda</th>\n",
       "      <th>Dif_contratos</th>\n",
       "      <th>Dif_minmax</th>\n",
       "      <th>Dif_abert_ultimo</th>\n",
       "      <th>Dif_abert_ajuste</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29/07/2019</td>\n",
       "      <td>271.92</td>\n",
       "      <td>22.6625</td>\n",
       "      <td>42.939771</td>\n",
       "      <td>3.7850</td>\n",
       "      <td>3.7775</td>\n",
       "      <td>3.8015</td>\n",
       "      <td>3.789499</td>\n",
       "      <td>3.7820</td>\n",
       "      <td>3.784797</td>\n",
       "      <td>145520</td>\n",
       "      <td>3.7820</td>\n",
       "      <td>3.7825</td>\n",
       "      <td>132520</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-0.203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26/07/2019</td>\n",
       "      <td>321.28</td>\n",
       "      <td>30.9480</td>\n",
       "      <td>58.414828</td>\n",
       "      <td>3.7800</td>\n",
       "      <td>3.7610</td>\n",
       "      <td>3.7955</td>\n",
       "      <td>3.775030</td>\n",
       "      <td>3.7760</td>\n",
       "      <td>3.770245</td>\n",
       "      <td>125890</td>\n",
       "      <td>3.7765</td>\n",
       "      <td>3.7780</td>\n",
       "      <td>23510</td>\n",
       "      <td>34.5</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-9.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25/07/2019</td>\n",
       "      <td>416.51</td>\n",
       "      <td>38.1060</td>\n",
       "      <td>72.105906</td>\n",
       "      <td>3.7680</td>\n",
       "      <td>3.7570</td>\n",
       "      <td>3.8070</td>\n",
       "      <td>3.784490</td>\n",
       "      <td>3.7795</td>\n",
       "      <td>3.782834</td>\n",
       "      <td>129780</td>\n",
       "      <td>3.7795</td>\n",
       "      <td>3.7805</td>\n",
       "      <td>15894</td>\n",
       "      <td>50.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>14.834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24/07/2019</td>\n",
       "      <td>261.37</td>\n",
       "      <td>26.9620</td>\n",
       "      <td>50.725253</td>\n",
       "      <td>3.7675</td>\n",
       "      <td>3.7540</td>\n",
       "      <td>3.7795</td>\n",
       "      <td>3.762721</td>\n",
       "      <td>3.7735</td>\n",
       "      <td>3.769856</td>\n",
       "      <td>31160</td>\n",
       "      <td>3.7735</td>\n",
       "      <td>3.7755</td>\n",
       "      <td>-7529</td>\n",
       "      <td>25.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23/07/2019</td>\n",
       "      <td>335.86</td>\n",
       "      <td>31.3840</td>\n",
       "      <td>59.121713</td>\n",
       "      <td>3.7450</td>\n",
       "      <td>3.7430</td>\n",
       "      <td>3.7820</td>\n",
       "      <td>3.767634</td>\n",
       "      <td>3.7750</td>\n",
       "      <td>3.772972</td>\n",
       "      <td>356000</td>\n",
       "      <td>3.7750</td>\n",
       "      <td>3.7770</td>\n",
       "      <td>-2908</td>\n",
       "      <td>39.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>27.972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Data  Número Negócios  Contratos Negociados     Volume  Abertura  \\\n",
       "0  29/07/2019           271.92               22.6625  42.939771    3.7850   \n",
       "1  26/07/2019           321.28               30.9480  58.414828    3.7800   \n",
       "2  25/07/2019           416.51               38.1060  72.105906    3.7680   \n",
       "3  24/07/2019           261.37               26.9620  50.725253    3.7675   \n",
       "4  23/07/2019           335.86               31.3840  59.121713    3.7450   \n",
       "\n",
       "   Mínimo  Máximo     Médio  Último Preço    Ajuste  Var pontos  \\\n",
       "0  3.7775  3.8015  3.789499        3.7820  3.784797      145520   \n",
       "1  3.7610  3.7955  3.775030        3.7760  3.770245      125890   \n",
       "2  3.7570  3.8070  3.784490        3.7795  3.782834      129780   \n",
       "3  3.7540  3.7795  3.762721        3.7735  3.769856       31160   \n",
       "4  3.7430  3.7820  3.767634        3.7750  3.772972      356000   \n",
       "\n",
       "   Última oferta de compra  Última oferta de venda  Dif_contratos  Dif_minmax  \\\n",
       "0                   3.7820                  3.7825         132520        24.0   \n",
       "1                   3.7765                  3.7780          23510        34.5   \n",
       "2                   3.7795                  3.7805          15894        50.0   \n",
       "3                   3.7735                  3.7755          -7529        25.5   \n",
       "4                   3.7750                  3.7770          -2908        39.0   \n",
       "\n",
       "   Dif_abert_ultimo  Dif_abert_ajuste  \n",
       "0              -3.0            -0.203  \n",
       "1              -4.0            -9.755  \n",
       "2              11.5            14.834  \n",
       "3               6.0             2.356  \n",
       "4              30.0            27.972  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_total.copy()\n",
    "\n",
    "df['Dif_contratos'] = df['Contratos Abertos'] -df['Contratos Fechados']\n",
    "df['Dif_minmax'] = (df['Máximo'] - df['Mínimo'])*1000\n",
    "df['Dif_abert_ultimo'] = (df['Último Preço'] - df['Abertura'])*1000\n",
    "df['Dif_abert_ajuste'] = (df['Ajuste'] - df['Abertura'])*1000\n",
    "\n",
    "df['Contratos Negociados'] = df['Contratos Negociados']/10000\n",
    "df['Número Negócios'] = df['Número Negócios']/100\n",
    "df['Volume'] = df['Volume']/1000000000\n",
    "\n",
    "df = df.drop(columns = ['Contratos Abertos', 'Contratos Fechados'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T22:01:29.390766Z",
     "start_time": "2019-08-16T22:01:28.217739Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Var pontos_SP</th>\n",
       "      <th>var_abert_ultimo_SP</th>\n",
       "      <th>var_abert_ajuste_SP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29/07/2019</td>\n",
       "      <td>275</td>\n",
       "      <td>-0.00500</td>\n",
       "      <td>-0.00475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26/07/2019</td>\n",
       "      <td>1800</td>\n",
       "      <td>0.00925</td>\n",
       "      <td>0.00925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25/07/2019</td>\n",
       "      <td>1500</td>\n",
       "      <td>-0.02000</td>\n",
       "      <td>-0.01950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24/07/2019</td>\n",
       "      <td>1350</td>\n",
       "      <td>0.01775</td>\n",
       "      <td>0.02025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23/07/2019</td>\n",
       "      <td>1900</td>\n",
       "      <td>0.00600</td>\n",
       "      <td>0.01025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22/07/2019</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.00550</td>\n",
       "      <td>0.00350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19/07/2019</td>\n",
       "      <td>2350</td>\n",
       "      <td>-0.02900</td>\n",
       "      <td>-0.02900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18/07/2019</td>\n",
       "      <td>1250</td>\n",
       "      <td>0.02375</td>\n",
       "      <td>0.01425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17/07/2019</td>\n",
       "      <td>2200</td>\n",
       "      <td>-0.02775</td>\n",
       "      <td>-0.02425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16/07/2019</td>\n",
       "      <td>1025</td>\n",
       "      <td>-0.01475</td>\n",
       "      <td>-0.01450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15/07/2019</td>\n",
       "      <td>175</td>\n",
       "      <td>-0.00175</td>\n",
       "      <td>-0.00400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12/07/2019</td>\n",
       "      <td>1150</td>\n",
       "      <td>0.00700</td>\n",
       "      <td>0.00550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11/07/2019</td>\n",
       "      <td>650</td>\n",
       "      <td>-0.00075</td>\n",
       "      <td>-0.00200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10/07/2019</td>\n",
       "      <td>1900</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.02225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>08/07/2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>-0.00725</td>\n",
       "      <td>-0.00550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>05/07/2019</td>\n",
       "      <td>975</td>\n",
       "      <td>0.00225</td>\n",
       "      <td>-0.00475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>04/07/2019</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00225</td>\n",
       "      <td>-0.00125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>03/07/2019</td>\n",
       "      <td>2075</td>\n",
       "      <td>0.01525</td>\n",
       "      <td>0.01475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>02/07/2019</td>\n",
       "      <td>1175</td>\n",
       "      <td>0.01475</td>\n",
       "      <td>0.01350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>01/07/2019</td>\n",
       "      <td>2350</td>\n",
       "      <td>-0.00775</td>\n",
       "      <td>-0.01075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>28/06/2019</td>\n",
       "      <td>1325</td>\n",
       "      <td>0.01675</td>\n",
       "      <td>0.00700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>27/06/2019</td>\n",
       "      <td>1300</td>\n",
       "      <td>0.01425</td>\n",
       "      <td>0.00850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>26/06/2019</td>\n",
       "      <td>400</td>\n",
       "      <td>-0.01875</td>\n",
       "      <td>-0.01725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>25/06/2019</td>\n",
       "      <td>3000</td>\n",
       "      <td>-0.02900</td>\n",
       "      <td>-0.02725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24/06/2019</td>\n",
       "      <td>150</td>\n",
       "      <td>-0.00625</td>\n",
       "      <td>-0.00525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>21/06/2019</td>\n",
       "      <td>2490</td>\n",
       "      <td>0.00900</td>\n",
       "      <td>0.00540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>19/06/2019</td>\n",
       "      <td>725</td>\n",
       "      <td>0.00300</td>\n",
       "      <td>0.00725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>18/06/2019</td>\n",
       "      <td>2975</td>\n",
       "      <td>0.01375</td>\n",
       "      <td>0.01150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>17/06/2019</td>\n",
       "      <td>150</td>\n",
       "      <td>-0.00075</td>\n",
       "      <td>-0.00325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>14/06/2019</td>\n",
       "      <td>400</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.00250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1654</th>\n",
       "      <td>13/11/2012</td>\n",
       "      <td>725</td>\n",
       "      <td>0.01325</td>\n",
       "      <td>0.00475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655</th>\n",
       "      <td>12/11/2012</td>\n",
       "      <td>250</td>\n",
       "      <td>-0.00150</td>\n",
       "      <td>-0.00050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1656</th>\n",
       "      <td>09/11/2012</td>\n",
       "      <td>425</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.00375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>08/11/2012</td>\n",
       "      <td>1425</td>\n",
       "      <td>-0.00875</td>\n",
       "      <td>-0.00900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1658</th>\n",
       "      <td>07/11/2012</td>\n",
       "      <td>3175</td>\n",
       "      <td>-0.03275</td>\n",
       "      <td>-0.03275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1659</th>\n",
       "      <td>06/11/2012</td>\n",
       "      <td>1400</td>\n",
       "      <td>0.00850</td>\n",
       "      <td>0.00850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1660</th>\n",
       "      <td>05/11/2012</td>\n",
       "      <td>975</td>\n",
       "      <td>0.00525</td>\n",
       "      <td>0.00475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661</th>\n",
       "      <td>01/11/2012</td>\n",
       "      <td>1425</td>\n",
       "      <td>0.01575</td>\n",
       "      <td>0.01575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1662</th>\n",
       "      <td>31/10/2012</td>\n",
       "      <td>250</td>\n",
       "      <td>-0.00850</td>\n",
       "      <td>-0.00850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663</th>\n",
       "      <td>30/10/2012</td>\n",
       "      <td>250</td>\n",
       "      <td>-0.00125</td>\n",
       "      <td>-0.00125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664</th>\n",
       "      <td>29/10/2012</td>\n",
       "      <td>75</td>\n",
       "      <td>0.00350</td>\n",
       "      <td>0.00900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1665</th>\n",
       "      <td>26/10/2012</td>\n",
       "      <td>150</td>\n",
       "      <td>0.01175</td>\n",
       "      <td>0.01150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1666</th>\n",
       "      <td>25/10/2012</td>\n",
       "      <td>375</td>\n",
       "      <td>-0.00650</td>\n",
       "      <td>-0.00625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667</th>\n",
       "      <td>24/10/2012</td>\n",
       "      <td>450</td>\n",
       "      <td>-0.00950</td>\n",
       "      <td>-0.00900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1668</th>\n",
       "      <td>23/10/2012</td>\n",
       "      <td>1750</td>\n",
       "      <td>-0.00750</td>\n",
       "      <td>-0.00750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669</th>\n",
       "      <td>22/10/2012</td>\n",
       "      <td>100</td>\n",
       "      <td>-0.00425</td>\n",
       "      <td>-0.00425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>19/10/2012</td>\n",
       "      <td>2750</td>\n",
       "      <td>-0.02375</td>\n",
       "      <td>-0.02425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1671</th>\n",
       "      <td>18/10/2012</td>\n",
       "      <td>550</td>\n",
       "      <td>-0.00350</td>\n",
       "      <td>-0.00350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>17/10/2012</td>\n",
       "      <td>775</td>\n",
       "      <td>0.00500</td>\n",
       "      <td>0.00500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>16/10/2012</td>\n",
       "      <td>1375</td>\n",
       "      <td>0.00600</td>\n",
       "      <td>0.00575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>15/10/2012</td>\n",
       "      <td>700</td>\n",
       "      <td>0.00700</td>\n",
       "      <td>0.00650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1675</th>\n",
       "      <td>11/10/2012</td>\n",
       "      <td>225</td>\n",
       "      <td>-0.00300</td>\n",
       "      <td>-0.00325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1676</th>\n",
       "      <td>10/10/2012</td>\n",
       "      <td>975</td>\n",
       "      <td>-0.01025</td>\n",
       "      <td>-0.01050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>09/10/2012</td>\n",
       "      <td>1375</td>\n",
       "      <td>-0.01650</td>\n",
       "      <td>-0.01600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>08/10/2012</td>\n",
       "      <td>575</td>\n",
       "      <td>0.00050</td>\n",
       "      <td>-0.00050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>05/10/2012</td>\n",
       "      <td>75</td>\n",
       "      <td>-0.00325</td>\n",
       "      <td>-0.00275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>04/10/2012</td>\n",
       "      <td>1150</td>\n",
       "      <td>0.00525</td>\n",
       "      <td>0.00525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>03/10/2012</td>\n",
       "      <td>375</td>\n",
       "      <td>0.00400</td>\n",
       "      <td>0.00375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>02/10/2012</td>\n",
       "      <td>400</td>\n",
       "      <td>-0.00325</td>\n",
       "      <td>-0.00350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>01/10/2012</td>\n",
       "      <td>275</td>\n",
       "      <td>-0.00525</td>\n",
       "      <td>-0.00275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1684 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Data  Var pontos_SP  var_abert_ultimo_SP  var_abert_ajuste_SP\n",
       "0     29/07/2019            275             -0.00500             -0.00475\n",
       "1     26/07/2019           1800              0.00925              0.00925\n",
       "2     25/07/2019           1500             -0.02000             -0.01950\n",
       "3     24/07/2019           1350              0.01775              0.02025\n",
       "4     23/07/2019           1900              0.00600              0.01025\n",
       "5     22/07/2019           1500              0.00550              0.00350\n",
       "6     19/07/2019           2350             -0.02900             -0.02900\n",
       "7     18/07/2019           1250              0.02375              0.01425\n",
       "8     17/07/2019           2200             -0.02775             -0.02425\n",
       "9     16/07/2019           1025             -0.01475             -0.01450\n",
       "10    15/07/2019            175             -0.00175             -0.00400\n",
       "11    12/07/2019           1150              0.00700              0.00550\n",
       "12    11/07/2019            650             -0.00075             -0.00200\n",
       "13    10/07/2019           1900              0.02250              0.02225\n",
       "14    08/07/2019           1200             -0.00725             -0.00550\n",
       "15    05/07/2019            975              0.00225             -0.00475\n",
       "16    04/07/2019              0              0.00225             -0.00125\n",
       "17    03/07/2019           2075              0.01525              0.01475\n",
       "18    02/07/2019           1175              0.01475              0.01350\n",
       "19    01/07/2019           2350             -0.00775             -0.01075\n",
       "20    28/06/2019           1325              0.01675              0.00700\n",
       "21    27/06/2019           1300              0.01425              0.00850\n",
       "22    26/06/2019            400             -0.01875             -0.01725\n",
       "23    25/06/2019           3000             -0.02900             -0.02725\n",
       "24    24/06/2019            150             -0.00625             -0.00525\n",
       "25    21/06/2019           2490              0.00900              0.00540\n",
       "26    19/06/2019            725              0.00300              0.00725\n",
       "27    18/06/2019           2975              0.01375              0.01150\n",
       "28    17/06/2019            150             -0.00075             -0.00325\n",
       "29    14/06/2019            400              0.00100              0.00250\n",
       "...          ...            ...                  ...                  ...\n",
       "1654  13/11/2012            725              0.01325              0.00475\n",
       "1655  12/11/2012            250             -0.00150             -0.00050\n",
       "1656  09/11/2012            425              0.01000              0.00375\n",
       "1657  08/11/2012           1425             -0.00875             -0.00900\n",
       "1658  07/11/2012           3175             -0.03275             -0.03275\n",
       "1659  06/11/2012           1400              0.00850              0.00850\n",
       "1660  05/11/2012            975              0.00525              0.00475\n",
       "1661  01/11/2012           1425              0.01575              0.01575\n",
       "1662  31/10/2012            250             -0.00850             -0.00850\n",
       "1663  30/10/2012            250             -0.00125             -0.00125\n",
       "1664  29/10/2012             75              0.00350              0.00900\n",
       "1665  26/10/2012            150              0.01175              0.01150\n",
       "1666  25/10/2012            375             -0.00650             -0.00625\n",
       "1667  24/10/2012            450             -0.00950             -0.00900\n",
       "1668  23/10/2012           1750             -0.00750             -0.00750\n",
       "1669  22/10/2012            100             -0.00425             -0.00425\n",
       "1670  19/10/2012           2750             -0.02375             -0.02425\n",
       "1671  18/10/2012            550             -0.00350             -0.00350\n",
       "1672  17/10/2012            775              0.00500              0.00500\n",
       "1673  16/10/2012           1375              0.00600              0.00575\n",
       "1674  15/10/2012            700              0.00700              0.00650\n",
       "1675  11/10/2012            225             -0.00300             -0.00325\n",
       "1676  10/10/2012            975             -0.01025             -0.01050\n",
       "1677  09/10/2012           1375             -0.01650             -0.01600\n",
       "1678  08/10/2012            575              0.00050             -0.00050\n",
       "1679  05/10/2012             75             -0.00325             -0.00275\n",
       "1680  04/10/2012           1150              0.00525              0.00525\n",
       "1681  03/10/2012            375              0.00400              0.00375\n",
       "1682  02/10/2012            400             -0.00325             -0.00350\n",
       "1683  01/10/2012            275             -0.00525             -0.00275\n",
       "\n",
       "[1684 rows x 4 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Features para adicionar\n",
    "\n",
    "df_sp = pd.read_hdf('df_S&P500.hdf', key = 'hdf')\n",
    "df_sp = df_sp[['Data', 'Contratos Negociados', 'Abertura', 'Último Preço', 'Ajuste', 'Var pontos']]\n",
    "df_sp['var_abert_ultimo'] = df_sp['Último Preço'] - df_sp['Abertura']\n",
    "df_sp['var_abert_ajuste'] = df_sp['Ajuste'] - df_sp['Abertura']\n",
    "\n",
    "df_sp = df_sp.drop(columns = ['Abertura','Contratos Negociados', 'Último Preço', 'Ajuste'])\n",
    "df_sp.columns = ['Data', 'Var pontos_SP', 'var_abert_ultimo_SP', 'var_abert_ajuste_SP']\n",
    "df_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T22:01:34.453457Z",
     "start_time": "2019-08-16T22:01:34.426472Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.merge(df, df_sp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prever relação de abertura com último preço do dia anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T22:01:38.552411Z",
     "start_time": "2019-08-16T22:01:38.544399Z"
    }
   },
   "outputs": [],
   "source": [
    "df_abert = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T22:01:38.818174Z",
     "start_time": "2019-08-16T22:01:38.799164Z"
    }
   },
   "outputs": [],
   "source": [
    "#1 se a abertura do dia seguinte é maior que o fechamento e 0 se a abertura do dia seguinte é menor que o último preço\n",
    "\n",
    "df_abert['target'] = df_abert.Abertura.shift(-1) - df_abert['Último Preço']\n",
    "df_abert['target'] = df_abert['target'].apply(lambda x: 1 if x > 0 else 0)\n",
    "df_abert = df_abert.drop(len(df_abert)-1)\n",
    "\n",
    "df_abert = df_abert.drop(columns = 'Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T22:01:39.332164Z",
     "start_time": "2019-08-16T22:01:39.287167Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.33583836e-01, -4.91815127e-01, -6.24144569e-02, ...,\n",
       "        -7.36537836e-01, -4.12293109e-01, -9.75296064e-02],\n",
       "       [ 5.08041840e-01,  1.78861789e-01,  6.36623283e-01, ...,\n",
       "         4.59954927e-01,  5.81168416e-01,  3.73325958e-02],\n",
       "       [ 1.23048178e+00,  7.58272250e-01,  1.25507531e+00, ...,\n",
       "         2.24579301e-01, -1.45804208e+00, -2.39616569e-01],\n",
       "       ...,\n",
       "       [-1.31046156e+00, -7.07333478e-01, -1.08559737e+00, ...,\n",
       "        -5.00255952e-02,  3.02302023e-01, -1.19946198e-03],\n",
       "       [-1.30712361e+00, -8.64692228e-01, -1.17247559e+00, ...,\n",
       "        -6.58079294e-01,  2.15156275e-01, -1.56489836e-02],\n",
       "       [-1.16040526e+00, -7.18390682e-01, -1.08871829e+00, ...,\n",
       "        -6.38464659e-01, -2.90289062e-01, -8.54883383e-02]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_abert.loc[:, df_abert.columns != 'target']\n",
    "y = df_abert[['target']]\n",
    "\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T22:01:42.372352Z",
     "start_time": "2019-08-16T22:01:42.362356Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T22:01:42.774020Z",
     "start_time": "2019-08-16T22:01:42.748054Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\choice\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\choice\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6913946587537092"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression().fit(x_train, y_train)\n",
    "\n",
    "predictions = clf.predict(x_test)\n",
    "\n",
    "probas = clf.predict_proba(x_test) \n",
    "\n",
    "\n",
    "score = clf.score(x_test, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T20:20:49.033935Z",
     "start_time": "2019-08-16T20:20:48.998935Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-bd5c427b35a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\".3f\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinewidths\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msquare\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Blues_r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Actual label'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Predicted label'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'metrics' is not defined"
     ]
    }
   ],
   "source": [
    "cm = metrics.confusion_matrix(y_test, predictions)\n",
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "all_sample_title = 'Accuracy Score: {0}'.format(score)\n",
    "plt.title(all_sample_title, size = 15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T20:20:52.356498Z",
     "start_time": "2019-08-16T20:20:52.351498Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6913946587537092"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T21:55:40.105385Z",
     "start_time": "2019-08-16T21:54:33.772152Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1346 samples, validate on 337 samples\n",
      "Epoch 1/600\n",
      "1346/1346 [==============================] - 2s 2ms/step - loss: 0.6928 - acc: 0.5141 - val_loss: 0.6938 - val_acc: 0.4629\n",
      "Epoch 2/600\n",
      "1346/1346 [==============================] - 0s 71us/step - loss: 0.6910 - acc: 0.5921 - val_loss: 0.6944 - val_acc: 0.4688\n",
      "Epoch 3/600\n",
      "1346/1346 [==============================] - 0s 64us/step - loss: 0.6867 - acc: 0.6166 - val_loss: 0.6951 - val_acc: 0.4777\n",
      "Epoch 4/600\n",
      "1346/1346 [==============================] - 0s 60us/step - loss: 0.6800 - acc: 0.6337 - val_loss: 0.6962 - val_acc: 0.4807\n",
      "Epoch 5/600\n",
      "1346/1346 [==============================] - 0s 65us/step - loss: 0.6716 - acc: 0.6367 - val_loss: 0.6965 - val_acc: 0.4926\n",
      "Epoch 6/600\n",
      "1346/1346 [==============================] - 0s 71us/step - loss: 0.6629 - acc: 0.6486 - val_loss: 0.6988 - val_acc: 0.4896\n",
      "Epoch 7/600\n",
      "1346/1346 [==============================] - 0s 65us/step - loss: 0.6533 - acc: 0.6553 - val_loss: 0.6995 - val_acc: 0.4985\n",
      "Epoch 8/600\n",
      "1346/1346 [==============================] - 0s 61us/step - loss: 0.6442 - acc: 0.6672 - val_loss: 0.6994 - val_acc: 0.5015\n",
      "Epoch 9/600\n",
      "1346/1346 [==============================] - 0s 58us/step - loss: 0.6350 - acc: 0.6828 - val_loss: 0.6971 - val_acc: 0.5163\n",
      "Epoch 10/600\n",
      "1346/1346 [==============================] - 0s 65us/step - loss: 0.6265 - acc: 0.6872 - val_loss: 0.6928 - val_acc: 0.5282\n",
      "Epoch 11/600\n",
      "1346/1346 [==============================] - 0s 64us/step - loss: 0.6183 - acc: 0.6947 - val_loss: 0.6861 - val_acc: 0.5371\n",
      "Epoch 12/600\n",
      "1346/1346 [==============================] - 0s 57us/step - loss: 0.6104 - acc: 0.6991 - val_loss: 0.6729 - val_acc: 0.5460\n",
      "Epoch 13/600\n",
      "1346/1346 [==============================] - 0s 61us/step - loss: 0.6042 - acc: 0.7051 - val_loss: 0.6658 - val_acc: 0.5579\n",
      "Epoch 14/600\n",
      "1346/1346 [==============================] - 0s 64us/step - loss: 0.5975 - acc: 0.7036 - val_loss: 0.6606 - val_acc: 0.5757\n",
      "Epoch 15/600\n",
      "1346/1346 [==============================] - 0s 56us/step - loss: 0.5938 - acc: 0.7140 - val_loss: 0.6552 - val_acc: 0.5786\n",
      "Epoch 16/600\n",
      "1346/1346 [==============================] - 0s 60us/step - loss: 0.5905 - acc: 0.7058 - val_loss: 0.6458 - val_acc: 0.5816\n",
      "Epoch 17/600\n",
      "1346/1346 [==============================] - 0s 56us/step - loss: 0.5872 - acc: 0.7132 - val_loss: 0.6505 - val_acc: 0.5757\n",
      "Epoch 18/600\n",
      "1346/1346 [==============================] - 0s 59us/step - loss: 0.5843 - acc: 0.7125 - val_loss: 0.6501 - val_acc: 0.5697\n",
      "Epoch 19/600\n",
      "1346/1346 [==============================] - 0s 62us/step - loss: 0.5821 - acc: 0.7132 - val_loss: 0.6430 - val_acc: 0.5846\n",
      "Epoch 20/600\n",
      "1346/1346 [==============================] - 0s 66us/step - loss: 0.5805 - acc: 0.7110 - val_loss: 0.6324 - val_acc: 0.6113\n",
      "Epoch 21/600\n",
      "1346/1346 [==============================] - 0s 59us/step - loss: 0.5791 - acc: 0.7088 - val_loss: 0.6329 - val_acc: 0.6113\n",
      "Epoch 22/600\n",
      "1346/1346 [==============================] - 0s 56us/step - loss: 0.5777 - acc: 0.7110 - val_loss: 0.6280 - val_acc: 0.6113\n",
      "Epoch 23/600\n",
      "1346/1346 [==============================] - 0s 60us/step - loss: 0.5763 - acc: 0.7103 - val_loss: 0.6286 - val_acc: 0.6113\n",
      "Epoch 24/600\n",
      "1346/1346 [==============================] - 0s 56us/step - loss: 0.5754 - acc: 0.7095 - val_loss: 0.6291 - val_acc: 0.6142\n",
      "Epoch 25/600\n",
      "1346/1346 [==============================] - 0s 61us/step - loss: 0.5752 - acc: 0.7110 - val_loss: 0.6367 - val_acc: 0.5964\n",
      "Epoch 26/600\n",
      "1346/1346 [==============================] - 0s 57us/step - loss: 0.5736 - acc: 0.7110 - val_loss: 0.6332 - val_acc: 0.5964\n",
      "Epoch 27/600\n",
      "1346/1346 [==============================] - 0s 59us/step - loss: 0.5733 - acc: 0.7147 - val_loss: 0.6226 - val_acc: 0.6172\n",
      "Epoch 28/600\n",
      "1346/1346 [==============================] - 0s 59us/step - loss: 0.5728 - acc: 0.7147 - val_loss: 0.6263 - val_acc: 0.6202\n",
      "Epoch 29/600\n",
      "1346/1346 [==============================] - 0s 58us/step - loss: 0.5722 - acc: 0.7103 - val_loss: 0.6438 - val_acc: 0.5668\n",
      "Epoch 30/600\n",
      "1346/1346 [==============================] - 0s 61us/step - loss: 0.5716 - acc: 0.7117 - val_loss: 0.6379 - val_acc: 0.5875\n",
      "Epoch 31/600\n",
      "1346/1346 [==============================] - 0s 79us/step - loss: 0.5712 - acc: 0.7132 - val_loss: 0.6369 - val_acc: 0.5875\n",
      "Epoch 32/600\n",
      "1346/1346 [==============================] - 0s 92us/step - loss: 0.5706 - acc: 0.7132 - val_loss: 0.6315 - val_acc: 0.6053\n",
      "Epoch 33/600\n",
      "1346/1346 [==============================] - 0s 75us/step - loss: 0.5700 - acc: 0.7125 - val_loss: 0.6359 - val_acc: 0.5875\n",
      "Epoch 34/600\n",
      "1346/1346 [==============================] - 0s 63us/step - loss: 0.5691 - acc: 0.7177 - val_loss: 0.6218 - val_acc: 0.6172\n",
      "Epoch 35/600\n",
      "1346/1346 [==============================] - 0s 64us/step - loss: 0.5688 - acc: 0.7132 - val_loss: 0.6252 - val_acc: 0.5935\n",
      "Epoch 36/600\n",
      "1346/1346 [==============================] - 0s 61us/step - loss: 0.5680 - acc: 0.7117 - val_loss: 0.6265 - val_acc: 0.5846\n",
      "Epoch 37/600\n",
      "1346/1346 [==============================] - 0s 58us/step - loss: 0.5678 - acc: 0.7140 - val_loss: 0.6253 - val_acc: 0.5935\n",
      "Epoch 38/600\n",
      "1346/1346 [==============================] - 0s 59us/step - loss: 0.5675 - acc: 0.7132 - val_loss: 0.6255 - val_acc: 0.5964\n",
      "Epoch 39/600\n",
      "1346/1346 [==============================] - 0s 60us/step - loss: 0.5672 - acc: 0.7125 - val_loss: 0.6243 - val_acc: 0.5994\n",
      "Epoch 40/600\n",
      "1346/1346 [==============================] - 0s 68us/step - loss: 0.5665 - acc: 0.7103 - val_loss: 0.6287 - val_acc: 0.5846\n",
      "Epoch 41/600\n",
      "1346/1346 [==============================] - 0s 83us/step - loss: 0.5667 - acc: 0.7162 - val_loss: 0.6252 - val_acc: 0.6083\n",
      "Epoch 42/600\n",
      "1346/1346 [==============================] - 0s 59us/step - loss: 0.5665 - acc: 0.7184 - val_loss: 0.6328 - val_acc: 0.5757\n",
      "Epoch 43/600\n",
      "1346/1346 [==============================] - 0s 59us/step - loss: 0.5655 - acc: 0.7140 - val_loss: 0.6286 - val_acc: 0.5816\n",
      "Epoch 44/600\n",
      "1346/1346 [==============================] - 0s 60us/step - loss: 0.5649 - acc: 0.7177 - val_loss: 0.6288 - val_acc: 0.5816\n",
      "Epoch 45/600\n",
      "1346/1346 [==============================] - 0s 58us/step - loss: 0.5657 - acc: 0.7117 - val_loss: 0.6229 - val_acc: 0.6113\n",
      "Epoch 46/600\n",
      "1346/1346 [==============================] - 0s 60us/step - loss: 0.5647 - acc: 0.7147 - val_loss: 0.6247 - val_acc: 0.5994\n",
      "Epoch 47/600\n",
      "1346/1346 [==============================] - 0s 59us/step - loss: 0.5646 - acc: 0.7162 - val_loss: 0.6280 - val_acc: 0.5757\n",
      "Epoch 48/600\n",
      "1346/1346 [==============================] - 0s 61us/step - loss: 0.5642 - acc: 0.7140 - val_loss: 0.6282 - val_acc: 0.5816\n",
      "Epoch 49/600\n",
      "1346/1346 [==============================] - 0s 60us/step - loss: 0.5642 - acc: 0.7125 - val_loss: 0.6257 - val_acc: 0.5846\n",
      "Epoch 50/600\n",
      "1346/1346 [==============================] - 0s 75us/step - loss: 0.5640 - acc: 0.7192 - val_loss: 0.6272 - val_acc: 0.5846\n",
      "Epoch 51/600\n",
      "1346/1346 [==============================] - 0s 59us/step - loss: 0.5636 - acc: 0.7169 - val_loss: 0.6311 - val_acc: 0.5697\n",
      "Epoch 52/600\n",
      "1346/1346 [==============================] - 0s 59us/step - loss: 0.5638 - acc: 0.7177 - val_loss: 0.6297 - val_acc: 0.5727\n",
      "Epoch 53/600\n",
      "1346/1346 [==============================] - 0s 62us/step - loss: 0.5629 - acc: 0.7147 - val_loss: 0.6288 - val_acc: 0.5846\n",
      "Epoch 54/600\n",
      "1346/1346 [==============================] - 0s 64us/step - loss: 0.5625 - acc: 0.7192 - val_loss: 0.6221 - val_acc: 0.6083\n",
      "Epoch 55/600\n",
      "1346/1346 [==============================] - 0s 62us/step - loss: 0.5628 - acc: 0.7184 - val_loss: 0.6239 - val_acc: 0.5994\n",
      "Epoch 56/600\n",
      "1346/1346 [==============================] - 0s 68us/step - loss: 0.5622 - acc: 0.7192 - val_loss: 0.6253 - val_acc: 0.5964\n",
      "Epoch 57/600\n",
      "1346/1346 [==============================] - 0s 63us/step - loss: 0.5619 - acc: 0.7169 - val_loss: 0.6320 - val_acc: 0.5697\n",
      "Epoch 58/600\n",
      "1346/1346 [==============================] - 0s 61us/step - loss: 0.5615 - acc: 0.7192 - val_loss: 0.6211 - val_acc: 0.6142\n",
      "Epoch 59/600\n",
      "1346/1346 [==============================] - 0s 67us/step - loss: 0.5610 - acc: 0.7236 - val_loss: 0.6406 - val_acc: 0.5668\n",
      "Epoch 60/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1346/1346 [==============================] - 0s 62us/step - loss: 0.5608 - acc: 0.7184 - val_loss: 0.6306 - val_acc: 0.5638\n",
      "Epoch 61/600\n",
      "1346/1346 [==============================] - 0s 64us/step - loss: 0.5610 - acc: 0.7192 - val_loss: 0.6196 - val_acc: 0.6142\n",
      "Epoch 62/600\n",
      "1346/1346 [==============================] - 0s 87us/step - loss: 0.5602 - acc: 0.7184 - val_loss: 0.6279 - val_acc: 0.5875\n",
      "Epoch 63/600\n",
      "1346/1346 [==============================] - 0s 90us/step - loss: 0.5604 - acc: 0.7229 - val_loss: 0.6230 - val_acc: 0.6142\n",
      "Epoch 64/600\n",
      "1346/1346 [==============================] - 0s 104us/step - loss: 0.5597 - acc: 0.7177 - val_loss: 0.6367 - val_acc: 0.5697\n",
      "Epoch 65/600\n",
      "1346/1346 [==============================] - 0s 103us/step - loss: 0.5597 - acc: 0.7199 - val_loss: 0.6346 - val_acc: 0.5638\n",
      "Epoch 66/600\n",
      "1346/1346 [==============================] - 0s 102us/step - loss: 0.5592 - acc: 0.7169 - val_loss: 0.6306 - val_acc: 0.5905\n",
      "Epoch 67/600\n",
      "1346/1346 [==============================] - 0s 90us/step - loss: 0.5591 - acc: 0.7192 - val_loss: 0.6332 - val_acc: 0.5727\n",
      "Epoch 68/600\n",
      "1346/1346 [==============================] - 0s 67us/step - loss: 0.5585 - acc: 0.7140 - val_loss: 0.6312 - val_acc: 0.5816\n",
      "Epoch 69/600\n",
      "1346/1346 [==============================] - 0s 72us/step - loss: 0.5586 - acc: 0.7169 - val_loss: 0.6331 - val_acc: 0.5757\n",
      "Epoch 70/600\n",
      "1346/1346 [==============================] - 0s 76us/step - loss: 0.5583 - acc: 0.7169 - val_loss: 0.6415 - val_acc: 0.5668\n",
      "Epoch 71/600\n",
      "1346/1346 [==============================] - 0s 73us/step - loss: 0.5583 - acc: 0.7244 - val_loss: 0.6241 - val_acc: 0.5994\n",
      "Epoch 72/600\n",
      "1346/1346 [==============================] - 0s 73us/step - loss: 0.5579 - acc: 0.7266 - val_loss: 0.6358 - val_acc: 0.5727\n",
      "Epoch 73/600\n",
      "1346/1346 [==============================] - 0s 70us/step - loss: 0.5579 - acc: 0.7199 - val_loss: 0.6364 - val_acc: 0.5757\n",
      "Epoch 74/600\n",
      "1346/1346 [==============================] - 0s 72us/step - loss: 0.5572 - acc: 0.7236 - val_loss: 0.6348 - val_acc: 0.5757\n",
      "Epoch 75/600\n",
      "1346/1346 [==============================] - 0s 66us/step - loss: 0.5575 - acc: 0.7184 - val_loss: 0.6309 - val_acc: 0.5816\n",
      "Epoch 76/600\n",
      "1346/1346 [==============================] - 0s 122us/step - loss: 0.5568 - acc: 0.7244 - val_loss: 0.6349 - val_acc: 0.5786\n",
      "Epoch 77/600\n",
      "1346/1346 [==============================] - 0s 103us/step - loss: 0.5570 - acc: 0.7244 - val_loss: 0.6388 - val_acc: 0.5638\n",
      "Epoch 78/600\n",
      "1346/1346 [==============================] - 0s 77us/step - loss: 0.5565 - acc: 0.7214 - val_loss: 0.6346 - val_acc: 0.5846\n",
      "Epoch 79/600\n",
      "1346/1346 [==============================] - 0s 72us/step - loss: 0.5561 - acc: 0.7177 - val_loss: 0.6334 - val_acc: 0.5816\n",
      "Epoch 80/600\n",
      "1346/1346 [==============================] - 0s 75us/step - loss: 0.5558 - acc: 0.7184 - val_loss: 0.6379 - val_acc: 0.5757\n",
      "Epoch 81/600\n",
      "1346/1346 [==============================] - 0s 101us/step - loss: 0.5561 - acc: 0.7259 - val_loss: 0.6363 - val_acc: 0.5757\n",
      "Epoch 82/600\n",
      "1346/1346 [==============================] - 0s 74us/step - loss: 0.5568 - acc: 0.7184 - val_loss: 0.6288 - val_acc: 0.5905\n",
      "Epoch 83/600\n",
      "1346/1346 [==============================] - 0s 63us/step - loss: 0.5553 - acc: 0.7177 - val_loss: 0.6356 - val_acc: 0.5786\n",
      "Epoch 84/600\n",
      "1346/1346 [==============================] - 0s 87us/step - loss: 0.5556 - acc: 0.7147 - val_loss: 0.6207 - val_acc: 0.6053\n",
      "Epoch 85/600\n",
      "1346/1346 [==============================] - 0s 76us/step - loss: 0.5550 - acc: 0.7140 - val_loss: 0.6228 - val_acc: 0.5964\n",
      "Epoch 86/600\n",
      "1346/1346 [==============================] - 0s 68us/step - loss: 0.5552 - acc: 0.7155 - val_loss: 0.6216 - val_acc: 0.5994\n",
      "Epoch 87/600\n",
      "1346/1346 [==============================] - 0s 71us/step - loss: 0.5544 - acc: 0.7229 - val_loss: 0.6345 - val_acc: 0.5757\n",
      "Epoch 88/600\n",
      "1346/1346 [==============================] - 0s 65us/step - loss: 0.5549 - acc: 0.7184 - val_loss: 0.6486 - val_acc: 0.5608\n",
      "Epoch 89/600\n",
      "1346/1346 [==============================] - 0s 70us/step - loss: 0.5546 - acc: 0.7192 - val_loss: 0.6363 - val_acc: 0.5786\n",
      "Epoch 90/600\n",
      "1346/1346 [==============================] - 0s 59us/step - loss: 0.5550 - acc: 0.7281 - val_loss: 0.6335 - val_acc: 0.5786\n",
      "Epoch 91/600\n",
      "1346/1346 [==============================] - 0s 61us/step - loss: 0.5538 - acc: 0.7162 - val_loss: 0.6318 - val_acc: 0.5816\n",
      "Epoch 92/600\n",
      "1346/1346 [==============================] - 0s 69us/step - loss: 0.5535 - acc: 0.7147 - val_loss: 0.6309 - val_acc: 0.5875\n",
      "Epoch 93/600\n",
      "1346/1346 [==============================] - 0s 73us/step - loss: 0.5535 - acc: 0.7207 - val_loss: 0.6285 - val_acc: 0.5964\n",
      "Epoch 94/600\n",
      "1346/1346 [==============================] - 0s 73us/step - loss: 0.5533 - acc: 0.7184 - val_loss: 0.6363 - val_acc: 0.5786\n",
      "Epoch 95/600\n",
      "1346/1346 [==============================] - 0s 79us/step - loss: 0.5528 - acc: 0.7221 - val_loss: 0.6353 - val_acc: 0.5816\n",
      "Epoch 96/600\n",
      "1346/1346 [==============================] - 0s 65us/step - loss: 0.5528 - acc: 0.7162 - val_loss: 0.6265 - val_acc: 0.5935\n",
      "Epoch 97/600\n",
      "1346/1346 [==============================] - 0s 62us/step - loss: 0.5527 - acc: 0.7177 - val_loss: 0.6242 - val_acc: 0.5964\n",
      "Epoch 98/600\n",
      "1346/1346 [==============================] - 0s 65us/step - loss: 0.5526 - acc: 0.7192 - val_loss: 0.6358 - val_acc: 0.5875\n",
      "Epoch 99/600\n",
      "1346/1346 [==============================] - 0s 70us/step - loss: 0.5527 - acc: 0.7177 - val_loss: 0.6282 - val_acc: 0.5964\n",
      "Epoch 100/600\n",
      "1346/1346 [==============================] - 0s 59us/step - loss: 0.5520 - acc: 0.7155 - val_loss: 0.6187 - val_acc: 0.6113\n",
      "Epoch 101/600\n",
      "1346/1346 [==============================] - 0s 59us/step - loss: 0.5519 - acc: 0.7177 - val_loss: 0.6213 - val_acc: 0.5994\n",
      "Epoch 102/600\n",
      "1346/1346 [==============================] - 0s 65us/step - loss: 0.5520 - acc: 0.7214 - val_loss: 0.6251 - val_acc: 0.6024\n",
      "Epoch 103/600\n",
      "1346/1346 [==============================] - 0s 71us/step - loss: 0.5520 - acc: 0.7207 - val_loss: 0.6310 - val_acc: 0.5964\n",
      "Epoch 104/600\n",
      "1346/1346 [==============================] - 0s 65us/step - loss: 0.5520 - acc: 0.7199 - val_loss: 0.6186 - val_acc: 0.6142\n",
      "Epoch 105/600\n",
      "1346/1346 [==============================] - 0s 66us/step - loss: 0.5514 - acc: 0.7199 - val_loss: 0.6248 - val_acc: 0.5994\n",
      "Epoch 106/600\n",
      "1346/1346 [==============================] - 0s 68us/step - loss: 0.5513 - acc: 0.7177 - val_loss: 0.6197 - val_acc: 0.6113\n",
      "Epoch 107/600\n",
      "1346/1346 [==============================] - 0s 71us/step - loss: 0.5516 - acc: 0.7199 - val_loss: 0.6247 - val_acc: 0.6083\n",
      "Epoch 108/600\n",
      "1346/1346 [==============================] - 0s 76us/step - loss: 0.5510 - acc: 0.7207 - val_loss: 0.6372 - val_acc: 0.5875\n",
      "Epoch 109/600\n",
      "1346/1346 [==============================] - 0s 88us/step - loss: 0.5510 - acc: 0.7184 - val_loss: 0.6353 - val_acc: 0.5875\n",
      "Epoch 110/600\n",
      "1346/1346 [==============================] - 0s 79us/step - loss: 0.5505 - acc: 0.7207 - val_loss: 0.6241 - val_acc: 0.6024\n",
      "Epoch 111/600\n",
      "1346/1346 [==============================] - 0s 79us/step - loss: 0.5507 - acc: 0.7207 - val_loss: 0.6193 - val_acc: 0.6113\n",
      "Epoch 112/600\n",
      "1346/1346 [==============================] - 0s 69us/step - loss: 0.5503 - acc: 0.7221 - val_loss: 0.6249 - val_acc: 0.6053\n",
      "Epoch 113/600\n",
      "1346/1346 [==============================] - 0s 74us/step - loss: 0.5505 - acc: 0.7221 - val_loss: 0.6224 - val_acc: 0.6083\n",
      "Epoch 114/600\n",
      "1346/1346 [==============================] - 0s 86us/step - loss: 0.5513 - acc: 0.7259 - val_loss: 0.6082 - val_acc: 0.6291\n",
      "Epoch 115/600\n",
      "1346/1346 [==============================] - 0s 79us/step - loss: 0.5503 - acc: 0.7192 - val_loss: 0.6185 - val_acc: 0.6083\n",
      "Epoch 116/600\n",
      "1346/1346 [==============================] - 0s 91us/step - loss: 0.5512 - acc: 0.7162 - val_loss: 0.6240 - val_acc: 0.6024\n",
      "Epoch 117/600\n",
      "1346/1346 [==============================] - 0s 112us/step - loss: 0.5496 - acc: 0.7155 - val_loss: 0.6219 - val_acc: 0.6113\n",
      "Epoch 118/600\n",
      "1346/1346 [==============================] - 0s 86us/step - loss: 0.5501 - acc: 0.7266 - val_loss: 0.6340 - val_acc: 0.5905\n",
      "Epoch 119/600\n",
      "1346/1346 [==============================] - 0s 70us/step - loss: 0.5498 - acc: 0.7184 - val_loss: 0.6314 - val_acc: 0.5964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/600\n",
      "1346/1346 [==============================] - 0s 71us/step - loss: 0.5493 - acc: 0.7192 - val_loss: 0.6213 - val_acc: 0.6142\n",
      "Epoch 121/600\n",
      "1346/1346 [==============================] - 0s 71us/step - loss: 0.5514 - acc: 0.7214 - val_loss: 0.6330 - val_acc: 0.5905\n",
      "Epoch 122/600\n",
      "1346/1346 [==============================] - 0s 65us/step - loss: 0.5495 - acc: 0.7214 - val_loss: 0.6257 - val_acc: 0.6053\n",
      "Epoch 123/600\n",
      "1346/1346 [==============================] - 0s 66us/step - loss: 0.5497 - acc: 0.7184 - val_loss: 0.6430 - val_acc: 0.5816\n",
      "Epoch 124/600\n",
      "1346/1346 [==============================] - 0s 68us/step - loss: 0.5496 - acc: 0.7192 - val_loss: 0.6389 - val_acc: 0.5786\n",
      "Epoch 125/600\n",
      "1346/1346 [==============================] - 0s 70us/step - loss: 0.5494 - acc: 0.7221 - val_loss: 0.6292 - val_acc: 0.5964\n",
      "Epoch 126/600\n",
      "1346/1346 [==============================] - 0s 82us/step - loss: 0.5495 - acc: 0.7221 - val_loss: 0.6257 - val_acc: 0.6053\n",
      "Epoch 127/600\n",
      "1346/1346 [==============================] - 0s 71us/step - loss: 0.5491 - acc: 0.7199 - val_loss: 0.6280 - val_acc: 0.5994\n",
      "Epoch 128/600\n",
      "1346/1346 [==============================] - 0s 65us/step - loss: 0.5491 - acc: 0.7169 - val_loss: 0.6273 - val_acc: 0.5935\n",
      "Epoch 129/600\n",
      "1346/1346 [==============================] - 0s 76us/step - loss: 0.5492 - acc: 0.7199 - val_loss: 0.6294 - val_acc: 0.5994\n",
      "Epoch 130/600\n",
      "1346/1346 [==============================] - 0s 76us/step - loss: 0.5485 - acc: 0.7207 - val_loss: 0.6219 - val_acc: 0.6053\n",
      "Epoch 131/600\n",
      "1346/1346 [==============================] - 0s 85us/step - loss: 0.5487 - acc: 0.7192 - val_loss: 0.6153 - val_acc: 0.6261\n",
      "Epoch 132/600\n",
      "1346/1346 [==============================] - 0s 72us/step - loss: 0.5490 - acc: 0.7214 - val_loss: 0.6207 - val_acc: 0.6083\n",
      "Epoch 133/600\n",
      "1346/1346 [==============================] - 0s 68us/step - loss: 0.5487 - acc: 0.7192 - val_loss: 0.6179 - val_acc: 0.6172\n",
      "Epoch 134/600\n",
      "1346/1346 [==============================] - 0s 68us/step - loss: 0.5483 - acc: 0.7184 - val_loss: 0.6245 - val_acc: 0.6083\n",
      "Epoch 135/600\n",
      "1346/1346 [==============================] - 0s 72us/step - loss: 0.5488 - acc: 0.7207 - val_loss: 0.6188 - val_acc: 0.6113\n",
      "Epoch 136/600\n",
      "1346/1346 [==============================] - 0s 74us/step - loss: 0.5481 - acc: 0.7214 - val_loss: 0.6073 - val_acc: 0.6291\n",
      "Epoch 137/600\n",
      "1346/1346 [==============================] - 0s 65us/step - loss: 0.5478 - acc: 0.7214 - val_loss: 0.6168 - val_acc: 0.6202\n",
      "Epoch 138/600\n",
      "1346/1346 [==============================] - 0s 73us/step - loss: 0.5476 - acc: 0.7177 - val_loss: 0.6132 - val_acc: 0.6231\n",
      "Epoch 139/600\n",
      "1346/1346 [==============================] - 0s 91us/step - loss: 0.5477 - acc: 0.7199 - val_loss: 0.6242 - val_acc: 0.6024\n",
      "Epoch 140/600\n",
      "1346/1346 [==============================] - 0s 85us/step - loss: 0.5475 - acc: 0.7192 - val_loss: 0.6190 - val_acc: 0.6142\n",
      "Epoch 141/600\n",
      "1346/1346 [==============================] - 0s 82us/step - loss: 0.5477 - acc: 0.7184 - val_loss: 0.6196 - val_acc: 0.6113\n",
      "Epoch 142/600\n",
      "1346/1346 [==============================] - 0s 65us/step - loss: 0.5479 - acc: 0.7229 - val_loss: 0.6150 - val_acc: 0.6172\n",
      "Epoch 143/600\n",
      "1346/1346 [==============================] - 0s 72us/step - loss: 0.5470 - acc: 0.7207 - val_loss: 0.6108 - val_acc: 0.6261\n",
      "Epoch 144/600\n",
      "1346/1346 [==============================] - 0s 63us/step - loss: 0.5476 - acc: 0.7192 - val_loss: 0.6172 - val_acc: 0.6202\n",
      "Epoch 145/600\n",
      "1346/1346 [==============================] - 0s 68us/step - loss: 0.5481 - acc: 0.7184 - val_loss: 0.6379 - val_acc: 0.5846\n",
      "Epoch 146/600\n",
      "1346/1346 [==============================] - 0s 71us/step - loss: 0.5469 - acc: 0.7207 - val_loss: 0.6275 - val_acc: 0.5964\n",
      "Epoch 147/600\n",
      "1346/1346 [==============================] - 0s 80us/step - loss: 0.5470 - acc: 0.7184 - val_loss: 0.6186 - val_acc: 0.6202\n",
      "Epoch 148/600\n",
      "1346/1346 [==============================] - 0s 71us/step - loss: 0.5475 - acc: 0.7251 - val_loss: 0.6080 - val_acc: 0.6261\n",
      "Epoch 149/600\n",
      "1346/1346 [==============================] - 0s 88us/step - loss: 0.5471 - acc: 0.7199 - val_loss: 0.6168 - val_acc: 0.6261\n",
      "Epoch 150/600\n",
      "1346/1346 [==============================] - 0s 62us/step - loss: 0.5471 - acc: 0.7177 - val_loss: 0.6223 - val_acc: 0.6083\n",
      "Epoch 151/600\n",
      "1346/1346 [==============================] - 0s 78us/step - loss: 0.5472 - acc: 0.7199 - val_loss: 0.6227 - val_acc: 0.6083\n",
      "Epoch 152/600\n",
      "1346/1346 [==============================] - 0s 74us/step - loss: 0.5465 - acc: 0.7221 - val_loss: 0.6167 - val_acc: 0.6231\n",
      "Epoch 153/600\n",
      "1346/1346 [==============================] - 0s 70us/step - loss: 0.5462 - acc: 0.7184 - val_loss: 0.6134 - val_acc: 0.6291\n",
      "Epoch 154/600\n",
      "1346/1346 [==============================] - 0s 82us/step - loss: 0.5465 - acc: 0.7184 - val_loss: 0.6112 - val_acc: 0.6261\n",
      "Epoch 155/600\n",
      "1346/1346 [==============================] - 0s 84us/step - loss: 0.5465 - acc: 0.7155 - val_loss: 0.6111 - val_acc: 0.6261\n",
      "Epoch 156/600\n",
      "1346/1346 [==============================] - 0s 76us/step - loss: 0.5459 - acc: 0.7207 - val_loss: 0.6129 - val_acc: 0.6172\n",
      "Epoch 157/600\n",
      "1346/1346 [==============================] - 0s 76us/step - loss: 0.5458 - acc: 0.7199 - val_loss: 0.6132 - val_acc: 0.6231\n",
      "Epoch 158/600\n",
      "1346/1346 [==============================] - 0s 73us/step - loss: 0.5458 - acc: 0.7155 - val_loss: 0.6136 - val_acc: 0.6202\n",
      "Epoch 159/600\n",
      "1346/1346 [==============================] - 0s 70us/step - loss: 0.5454 - acc: 0.7221 - val_loss: 0.6177 - val_acc: 0.6202\n",
      "Epoch 160/600\n",
      "1346/1346 [==============================] - 0s 81us/step - loss: 0.5459 - acc: 0.7207 - val_loss: 0.6213 - val_acc: 0.6083\n",
      "Epoch 161/600\n",
      "1346/1346 [==============================] - 0s 76us/step - loss: 0.5451 - acc: 0.7199 - val_loss: 0.6136 - val_acc: 0.6172\n",
      "Epoch 162/600\n",
      "1346/1346 [==============================] - 0s 82us/step - loss: 0.5450 - acc: 0.7199 - val_loss: 0.6141 - val_acc: 0.6172\n",
      "Epoch 163/600\n",
      "1346/1346 [==============================] - 0s 61us/step - loss: 0.5449 - acc: 0.7184 - val_loss: 0.6122 - val_acc: 0.6172\n",
      "Epoch 164/600\n",
      "1346/1346 [==============================] - 0s 65us/step - loss: 0.5446 - acc: 0.7214 - val_loss: 0.6126 - val_acc: 0.6202\n",
      "Epoch 165/600\n",
      "1346/1346 [==============================] - 0s 71us/step - loss: 0.5453 - acc: 0.7266 - val_loss: 0.6082 - val_acc: 0.6202\n",
      "Epoch 166/600\n",
      "1346/1346 [==============================] - 0s 71us/step - loss: 0.5447 - acc: 0.7207 - val_loss: 0.6105 - val_acc: 0.6202\n",
      "Epoch 167/600\n",
      "1346/1346 [==============================] - 0s 73us/step - loss: 0.5458 - acc: 0.7236 - val_loss: 0.6335 - val_acc: 0.5964\n",
      "Epoch 168/600\n",
      "1346/1346 [==============================] - 0s 71us/step - loss: 0.5451 - acc: 0.7229 - val_loss: 0.6121 - val_acc: 0.6172\n",
      "Epoch 169/600\n",
      "1346/1346 [==============================] - 0s 103us/step - loss: 0.5446 - acc: 0.7214 - val_loss: 0.6172 - val_acc: 0.6202\n",
      "Epoch 170/600\n",
      "1346/1346 [==============================] - 0s 97us/step - loss: 0.5444 - acc: 0.7244 - val_loss: 0.6239 - val_acc: 0.6053\n",
      "Epoch 171/600\n",
      "1346/1346 [==============================] - 0s 79us/step - loss: 0.5446 - acc: 0.7214 - val_loss: 0.6129 - val_acc: 0.6231\n",
      "Epoch 172/600\n",
      "1346/1346 [==============================] - 0s 64us/step - loss: 0.5442 - acc: 0.7236 - val_loss: 0.6143 - val_acc: 0.6202\n",
      "Epoch 173/600\n",
      "1346/1346 [==============================] - 0s 59us/step - loss: 0.5443 - acc: 0.7184 - val_loss: 0.6108 - val_acc: 0.6231\n",
      "Epoch 174/600\n",
      "1346/1346 [==============================] - 0s 80us/step - loss: 0.5451 - acc: 0.7236 - val_loss: 0.6039 - val_acc: 0.6350\n",
      "Epoch 175/600\n",
      "1346/1346 [==============================] - 0s 74us/step - loss: 0.5448 - acc: 0.7273 - val_loss: 0.6073 - val_acc: 0.6231\n",
      "Epoch 176/600\n",
      "1346/1346 [==============================] - 0s 71us/step - loss: 0.5436 - acc: 0.7244 - val_loss: 0.6122 - val_acc: 0.6172\n",
      "Epoch 177/600\n",
      "1346/1346 [==============================] - 0s 81us/step - loss: 0.5437 - acc: 0.7207 - val_loss: 0.6084 - val_acc: 0.6202\n",
      "Epoch 178/600\n",
      "1346/1346 [==============================] - 0s 74us/step - loss: 0.5443 - acc: 0.7229 - val_loss: 0.6073 - val_acc: 0.6261\n",
      "Epoch 179/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1346/1346 [==============================] - 0s 78us/step - loss: 0.5447 - acc: 0.7214 - val_loss: 0.6242 - val_acc: 0.6053\n",
      "Epoch 180/600\n",
      "1346/1346 [==============================] - 0s 62us/step - loss: 0.5434 - acc: 0.7229 - val_loss: 0.6221 - val_acc: 0.6113\n",
      "Epoch 181/600\n",
      "1346/1346 [==============================] - 0s 73us/step - loss: 0.5435 - acc: 0.7251 - val_loss: 0.6172 - val_acc: 0.6202\n",
      "Epoch 182/600\n",
      "1346/1346 [==============================] - 0s 76us/step - loss: 0.5435 - acc: 0.7229 - val_loss: 0.6173 - val_acc: 0.6202\n",
      "Epoch 183/600\n",
      "1346/1346 [==============================] - 0s 79us/step - loss: 0.5432 - acc: 0.7251 - val_loss: 0.6020 - val_acc: 0.6409\n",
      "Epoch 184/600\n",
      "1346/1346 [==============================] - 0s 77us/step - loss: 0.5440 - acc: 0.7236 - val_loss: 0.6059 - val_acc: 0.6350\n",
      "Epoch 185/600\n",
      "1346/1346 [==============================] - 0s 90us/step - loss: 0.5432 - acc: 0.7266 - val_loss: 0.6170 - val_acc: 0.6231\n",
      "Epoch 186/600\n",
      "1346/1346 [==============================] - 0s 85us/step - loss: 0.5431 - acc: 0.7207 - val_loss: 0.6171 - val_acc: 0.6172\n",
      "Epoch 187/600\n",
      "1346/1346 [==============================] - 0s 65us/step - loss: 0.5430 - acc: 0.7221 - val_loss: 0.6176 - val_acc: 0.6142\n",
      "Epoch 188/600\n",
      "1346/1346 [==============================] - 0s 64us/step - loss: 0.5445 - acc: 0.7221 - val_loss: 0.6013 - val_acc: 0.6380\n",
      "Epoch 189/600\n",
      "1346/1346 [==============================] - 0s 63us/step - loss: 0.5450 - acc: 0.7221 - val_loss: 0.6239 - val_acc: 0.6024\n",
      "Epoch 190/600\n",
      "1346/1346 [==============================] - 0s 76us/step - loss: 0.5429 - acc: 0.7266 - val_loss: 0.6084 - val_acc: 0.6261\n",
      "Epoch 191/600\n",
      "1346/1346 [==============================] - 0s 73us/step - loss: 0.5426 - acc: 0.7259 - val_loss: 0.6146 - val_acc: 0.6142\n",
      "Epoch 192/600\n",
      "1346/1346 [==============================] - 0s 75us/step - loss: 0.5428 - acc: 0.7259 - val_loss: 0.5974 - val_acc: 0.6380\n",
      "Epoch 193/600\n",
      "1346/1346 [==============================] - 0s 74us/step - loss: 0.5425 - acc: 0.7244 - val_loss: 0.6136 - val_acc: 0.6142\n",
      "Epoch 194/600\n",
      "1346/1346 [==============================] - 0s 66us/step - loss: 0.5431 - acc: 0.7214 - val_loss: 0.6095 - val_acc: 0.6172\n",
      "Epoch 195/600\n",
      "1346/1346 [==============================] - 0s 67us/step - loss: 0.5434 - acc: 0.7281 - val_loss: 0.5992 - val_acc: 0.6469\n",
      "Epoch 196/600\n",
      "1346/1346 [==============================] - 0s 72us/step - loss: 0.5436 - acc: 0.7266 - val_loss: 0.6078 - val_acc: 0.6202\n",
      "Epoch 197/600\n",
      "1346/1346 [==============================] - 0s 73us/step - loss: 0.5429 - acc: 0.7236 - val_loss: 0.6121 - val_acc: 0.6142\n",
      "Epoch 198/600\n",
      "1346/1346 [==============================] - 0s 64us/step - loss: 0.5427 - acc: 0.7244 - val_loss: 0.6126 - val_acc: 0.6172\n",
      "Epoch 199/600\n",
      "1346/1346 [==============================] - 0s 65us/step - loss: 0.5430 - acc: 0.7266 - val_loss: 0.6171 - val_acc: 0.6113\n",
      "Epoch 200/600\n",
      "1346/1346 [==============================] - 0s 74us/step - loss: 0.5427 - acc: 0.7251 - val_loss: 0.6357 - val_acc: 0.5964\n",
      "Epoch 201/600\n",
      "1346/1346 [==============================] - ETA: 0s - loss: 0.5445 - acc: 0.717 - 0s 72us/step - loss: 0.5428 - acc: 0.7251 - val_loss: 0.6186 - val_acc: 0.6024\n",
      "Epoch 202/600\n",
      "1346/1346 [==============================] - 0s 64us/step - loss: 0.5424 - acc: 0.7251 - val_loss: 0.6098 - val_acc: 0.6172\n",
      "Epoch 203/600\n",
      "1346/1346 [==============================] - 0s 71us/step - loss: 0.5426 - acc: 0.7311 - val_loss: 0.6169 - val_acc: 0.6113\n",
      "Epoch 204/600\n",
      "1346/1346 [==============================] - 0s 69us/step - loss: 0.5423 - acc: 0.7259 - val_loss: 0.6131 - val_acc: 0.6202\n",
      "Epoch 205/600\n",
      "1346/1346 [==============================] - 0s 64us/step - loss: 0.5425 - acc: 0.7251 - val_loss: 0.6130 - val_acc: 0.6172\n",
      "Epoch 206/600\n",
      "1346/1346 [==============================] - 0s 59us/step - loss: 0.5421 - acc: 0.7251 - val_loss: 0.6079 - val_acc: 0.6261\n",
      "Epoch 207/600\n",
      "1346/1346 [==============================] - 0s 59us/step - loss: 0.5426 - acc: 0.7266 - val_loss: 0.6146 - val_acc: 0.6172\n",
      "Epoch 208/600\n",
      "1346/1346 [==============================] - 0s 58us/step - loss: 0.5426 - acc: 0.7251 - val_loss: 0.6128 - val_acc: 0.6231\n",
      "Epoch 209/600\n",
      "1346/1346 [==============================] - 0s 59us/step - loss: 0.5425 - acc: 0.7244 - val_loss: 0.5980 - val_acc: 0.6439\n",
      "Epoch 210/600\n",
      "1346/1346 [==============================] - 0s 65us/step - loss: 0.5421 - acc: 0.7244 - val_loss: 0.6197 - val_acc: 0.6142\n",
      "Epoch 211/600\n",
      "1346/1346 [==============================] - 0s 64us/step - loss: 0.5421 - acc: 0.7273 - val_loss: 0.6135 - val_acc: 0.6172\n",
      "Epoch 212/600\n",
      "1346/1346 [==============================] - 0s 69us/step - loss: 0.5418 - acc: 0.7266 - val_loss: 0.6154 - val_acc: 0.6142\n",
      "Epoch 213/600\n",
      "1346/1346 [==============================] - 0s 59us/step - loss: 0.5421 - acc: 0.7236 - val_loss: 0.6148 - val_acc: 0.6202\n",
      "Epoch 214/600\n",
      "1346/1346 [==============================] - 0s 65us/step - loss: 0.5416 - acc: 0.7251 - val_loss: 0.6135 - val_acc: 0.6202\n",
      "Epoch 215/600\n",
      "1346/1346 [==============================] - 0s 67us/step - loss: 0.5425 - acc: 0.7236 - val_loss: 0.6198 - val_acc: 0.6113\n",
      "Epoch 216/600\n",
      "1346/1346 [==============================] - 0s 66us/step - loss: 0.5427 - acc: 0.7244 - val_loss: 0.6165 - val_acc: 0.6172\n",
      "Epoch 217/600\n",
      "1346/1346 [==============================] - 0s 75us/step - loss: 0.5433 - acc: 0.7192 - val_loss: 0.6260 - val_acc: 0.5935\n",
      "Epoch 218/600\n",
      "1346/1346 [==============================] - 0s 82us/step - loss: 0.5422 - acc: 0.7266 - val_loss: 0.6245 - val_acc: 0.5994\n",
      "Epoch 219/600\n",
      "1346/1346 [==============================] - 0s 63us/step - loss: 0.5418 - acc: 0.7229 - val_loss: 0.6130 - val_acc: 0.6172\n",
      "Epoch 220/600\n",
      "1346/1346 [==============================] - 0s 94us/step - loss: 0.5417 - acc: 0.7229 - val_loss: 0.6153 - val_acc: 0.6172\n",
      "Epoch 221/600\n",
      "1346/1346 [==============================] - 0s 64us/step - loss: 0.5422 - acc: 0.7244 - val_loss: 0.6291 - val_acc: 0.5994\n",
      "Epoch 222/600\n",
      "1346/1346 [==============================] - 0s 73us/step - loss: 0.5423 - acc: 0.7244 - val_loss: 0.6183 - val_acc: 0.6142\n",
      "Epoch 223/600\n",
      "1346/1346 [==============================] - 0s 62us/step - loss: 0.5424 - acc: 0.7244 - val_loss: 0.6278 - val_acc: 0.6024\n",
      "Epoch 224/600\n",
      "1346/1346 [==============================] - 0s 73us/step - loss: 0.5431 - acc: 0.7229 - val_loss: 0.6149 - val_acc: 0.6202\n",
      "Epoch 225/600\n",
      "1346/1346 [==============================] - 0s 82us/step - loss: 0.5423 - acc: 0.7221 - val_loss: 0.6126 - val_acc: 0.6261\n",
      "Epoch 226/600\n",
      "1346/1346 [==============================] - 0s 69us/step - loss: 0.5417 - acc: 0.7229 - val_loss: 0.6143 - val_acc: 0.6172\n",
      "Epoch 227/600\n",
      "1346/1346 [==============================] - 0s 75us/step - loss: 0.5412 - acc: 0.7244 - val_loss: 0.6151 - val_acc: 0.6172\n",
      "Epoch 228/600\n",
      "1346/1346 [==============================] - 0s 74us/step - loss: 0.5418 - acc: 0.7259 - val_loss: 0.6099 - val_acc: 0.6231\n",
      "Epoch 229/600\n",
      "1346/1346 [==============================] - 0s 68us/step - loss: 0.5416 - acc: 0.7273 - val_loss: 0.6067 - val_acc: 0.6291\n",
      "Epoch 230/600\n",
      "1346/1346 [==============================] - 0s 79us/step - loss: 0.5419 - acc: 0.7229 - val_loss: 0.6073 - val_acc: 0.6261\n",
      "Epoch 231/600\n",
      "1346/1346 [==============================] - 0s 72us/step - loss: 0.5419 - acc: 0.7259 - val_loss: 0.6121 - val_acc: 0.6202\n",
      "Epoch 232/600\n",
      "1346/1346 [==============================] - 0s 74us/step - loss: 0.5414 - acc: 0.7244 - val_loss: 0.6219 - val_acc: 0.6024\n",
      "Epoch 233/600\n",
      "1346/1346 [==============================] - 0s 86us/step - loss: 0.5432 - acc: 0.7221 - val_loss: 0.6142 - val_acc: 0.6172\n",
      "Epoch 234/600\n",
      "1346/1346 [==============================] - 0s 78us/step - loss: 0.5424 - acc: 0.7221 - val_loss: 0.6232 - val_acc: 0.5994\n",
      "Epoch 235/600\n",
      "1346/1346 [==============================] - 0s 102us/step - loss: 0.5415 - acc: 0.7236 - val_loss: 0.6115 - val_acc: 0.6202\n",
      "Epoch 236/600\n",
      "1346/1346 [==============================] - 0s 124us/step - loss: 0.5413 - acc: 0.7214 - val_loss: 0.6286 - val_acc: 0.5994\n",
      "Epoch 237/600\n",
      "1346/1346 [==============================] - 0s 82us/step - loss: 0.5410 - acc: 0.7251 - val_loss: 0.6131 - val_acc: 0.6113\n",
      "Epoch 238/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1346/1346 [==============================] - 0s 77us/step - loss: 0.5409 - acc: 0.7236 - val_loss: 0.6046 - val_acc: 0.6320\n",
      "Epoch 239/600\n",
      "1346/1346 [==============================] - 0s 97us/step - loss: 0.5413 - acc: 0.7273 - val_loss: 0.6153 - val_acc: 0.6142\n",
      "Epoch 240/600\n",
      "1346/1346 [==============================] - 0s 72us/step - loss: 0.5411 - acc: 0.7236 - val_loss: 0.6143 - val_acc: 0.6172\n",
      "Epoch 241/600\n",
      "1346/1346 [==============================] - 0s 76us/step - loss: 0.5415 - acc: 0.7244 - val_loss: 0.6119 - val_acc: 0.6172\n",
      "Epoch 242/600\n",
      "1346/1346 [==============================] - 0s 85us/step - loss: 0.5411 - acc: 0.7214 - val_loss: 0.6139 - val_acc: 0.6172\n",
      "Epoch 243/600\n",
      "1346/1346 [==============================] - 0s 96us/step - loss: 0.5411 - acc: 0.7177 - val_loss: 0.6188 - val_acc: 0.6083\n",
      "Epoch 244/600\n",
      "1346/1346 [==============================] - 0s 101us/step - loss: 0.5410 - acc: 0.7251 - val_loss: 0.6267 - val_acc: 0.6053\n",
      "Epoch 245/600\n",
      "1346/1346 [==============================] - 0s 104us/step - loss: 0.5408 - acc: 0.7281 - val_loss: 0.6137 - val_acc: 0.6202\n",
      "Epoch 246/600\n",
      "1346/1346 [==============================] - 0s 111us/step - loss: 0.5406 - acc: 0.7221 - val_loss: 0.6224 - val_acc: 0.6113\n",
      "Epoch 247/600\n",
      "1346/1346 [==============================] - 0s 94us/step - loss: 0.5406 - acc: 0.7221 - val_loss: 0.6261 - val_acc: 0.6083\n",
      "Epoch 248/600\n",
      "1346/1346 [==============================] - 0s 74us/step - loss: 0.5405 - acc: 0.7244 - val_loss: 0.6161 - val_acc: 0.6172\n",
      "Epoch 249/600\n",
      "1346/1346 [==============================] - 0s 85us/step - loss: 0.5406 - acc: 0.7281 - val_loss: 0.5996 - val_acc: 0.6380\n",
      "Epoch 250/600\n",
      "1346/1346 [==============================] - 0s 101us/step - loss: 0.5405 - acc: 0.7244 - val_loss: 0.6205 - val_acc: 0.6083\n",
      "Epoch 251/600\n",
      "1346/1346 [==============================] - 0s 99us/step - loss: 0.5405 - acc: 0.7229 - val_loss: 0.6159 - val_acc: 0.6142\n",
      "Epoch 252/600\n",
      "1346/1346 [==============================] - 0s 71us/step - loss: 0.5410 - acc: 0.7288 - val_loss: 0.6104 - val_acc: 0.6202\n",
      "Epoch 253/600\n",
      "1346/1346 [==============================] - 0s 65us/step - loss: 0.5403 - acc: 0.7229 - val_loss: 0.6196 - val_acc: 0.6113\n",
      "Epoch 254/600\n",
      "1346/1346 [==============================] - 0s 80us/step - loss: 0.5410 - acc: 0.7244 - val_loss: 0.6184 - val_acc: 0.6113\n",
      "Epoch 255/600\n",
      "1346/1346 [==============================] - 0s 95us/step - loss: 0.5407 - acc: 0.7236 - val_loss: 0.6233 - val_acc: 0.6083\n",
      "Epoch 256/600\n",
      "1346/1346 [==============================] - 0s 91us/step - loss: 0.5404 - acc: 0.7251 - val_loss: 0.6213 - val_acc: 0.6083\n",
      "Epoch 257/600\n",
      "1346/1346 [==============================] - 0s 88us/step - loss: 0.5400 - acc: 0.7236 - val_loss: 0.6176 - val_acc: 0.6202\n",
      "Epoch 258/600\n",
      "1346/1346 [==============================] - 0s 97us/step - loss: 0.5398 - acc: 0.7236 - val_loss: 0.6094 - val_acc: 0.6261\n",
      "Epoch 259/600\n",
      "1346/1346 [==============================] - 0s 94us/step - loss: 0.5407 - acc: 0.7281 - val_loss: 0.6237 - val_acc: 0.6083\n",
      "Epoch 260/600\n",
      "1346/1346 [==============================] - 0s 81us/step - loss: 0.5404 - acc: 0.7214 - val_loss: 0.6325 - val_acc: 0.5994\n",
      "Epoch 261/600\n",
      "1346/1346 [==============================] - 0s 67us/step - loss: 0.5411 - acc: 0.7296 - val_loss: 0.6283 - val_acc: 0.6024\n",
      "Epoch 262/600\n",
      "1346/1346 [==============================] - 0s 65us/step - loss: 0.5403 - acc: 0.7259 - val_loss: 0.6084 - val_acc: 0.6202\n",
      "Epoch 263/600\n",
      "1346/1346 [==============================] - 0s 71us/step - loss: 0.5402 - acc: 0.7229 - val_loss: 0.6100 - val_acc: 0.6231\n",
      "Epoch 264/600\n",
      "1346/1346 [==============================] - 0s 67us/step - loss: 0.5401 - acc: 0.7273 - val_loss: 0.6172 - val_acc: 0.6142\n",
      "Epoch 265/600\n",
      "1346/1346 [==============================] - 0s 61us/step - loss: 0.5396 - acc: 0.7214 - val_loss: 0.6091 - val_acc: 0.6231\n",
      "Epoch 266/600\n",
      "1346/1346 [==============================] - 0s 61us/step - loss: 0.5400 - acc: 0.7303 - val_loss: 0.6152 - val_acc: 0.6172\n",
      "Epoch 267/600\n",
      "1346/1346 [==============================] - 0s 61us/step - loss: 0.5395 - acc: 0.7244 - val_loss: 0.6114 - val_acc: 0.6202\n",
      "Epoch 268/600\n",
      "1346/1346 [==============================] - 0s 58us/step - loss: 0.5396 - acc: 0.7236 - val_loss: 0.6198 - val_acc: 0.6083\n",
      "Epoch 269/600\n",
      "1346/1346 [==============================] - 0s 71us/step - loss: 0.5394 - acc: 0.7229 - val_loss: 0.6203 - val_acc: 0.6083\n",
      "Epoch 270/600\n",
      "1346/1346 [==============================] - 0s 62us/step - loss: 0.5402 - acc: 0.7221 - val_loss: 0.6274 - val_acc: 0.6053\n",
      "Epoch 271/600\n",
      "1346/1346 [==============================] - 0s 76us/step - loss: 0.5399 - acc: 0.7229 - val_loss: 0.6183 - val_acc: 0.6142\n",
      "Epoch 272/600\n",
      "1346/1346 [==============================] - 0s 76us/step - loss: 0.5399 - acc: 0.7273 - val_loss: 0.6048 - val_acc: 0.6231\n",
      "Epoch 273/600\n",
      "1346/1346 [==============================] - 0s 77us/step - loss: 0.5401 - acc: 0.7221 - val_loss: 0.6124 - val_acc: 0.6142\n",
      "Epoch 274/600\n",
      "1346/1346 [==============================] - 0s 69us/step - loss: 0.5398 - acc: 0.7229 - val_loss: 0.6103 - val_acc: 0.6172\n",
      "Epoch 275/600\n",
      "1346/1346 [==============================] - 0s 69us/step - loss: 0.5398 - acc: 0.7266 - val_loss: 0.6201 - val_acc: 0.6083\n",
      "Epoch 276/600\n",
      "1346/1346 [==============================] - 0s 67us/step - loss: 0.5395 - acc: 0.7214 - val_loss: 0.6198 - val_acc: 0.6083\n",
      "Epoch 277/600\n",
      "1346/1346 [==============================] - 0s 71us/step - loss: 0.5392 - acc: 0.7251 - val_loss: 0.6185 - val_acc: 0.6083\n",
      "Epoch 278/600\n",
      "1346/1346 [==============================] - 0s 61us/step - loss: 0.5393 - acc: 0.7244 - val_loss: 0.6182 - val_acc: 0.6083\n",
      "Epoch 279/600\n",
      "1346/1346 [==============================] - 0s 71us/step - loss: 0.5402 - acc: 0.7184 - val_loss: 0.6165 - val_acc: 0.6113\n",
      "Epoch 280/600\n",
      "1346/1346 [==============================] - 0s 65us/step - loss: 0.5392 - acc: 0.7281 - val_loss: 0.6259 - val_acc: 0.6053\n",
      "Epoch 281/600\n",
      "1346/1346 [==============================] - 0s 65us/step - loss: 0.5391 - acc: 0.7229 - val_loss: 0.6195 - val_acc: 0.6113\n",
      "Epoch 282/600\n",
      "1346/1346 [==============================] - 0s 68us/step - loss: 0.5394 - acc: 0.7236 - val_loss: 0.6145 - val_acc: 0.6231\n",
      "Epoch 283/600\n",
      "1346/1346 [==============================] - 0s 76us/step - loss: 0.5394 - acc: 0.7259 - val_loss: 0.6151 - val_acc: 0.6231\n",
      "Epoch 284/600\n",
      "1346/1346 [==============================] - 0s 78us/step - loss: 0.5395 - acc: 0.7281 - val_loss: 0.6173 - val_acc: 0.6172\n",
      "Epoch 285/600\n",
      "1346/1346 [==============================] - 0s 75us/step - loss: 0.5396 - acc: 0.7288 - val_loss: 0.6251 - val_acc: 0.6083\n",
      "Epoch 286/600\n",
      "1346/1346 [==============================] - 0s 73us/step - loss: 0.5398 - acc: 0.7221 - val_loss: 0.6261 - val_acc: 0.6083\n",
      "Epoch 287/600\n",
      "1346/1346 [==============================] - 0s 74us/step - loss: 0.5415 - acc: 0.7199 - val_loss: 0.6415 - val_acc: 0.5964\n",
      "Epoch 288/600\n",
      "1346/1346 [==============================] - ETA: 0s - loss: 0.5396 - acc: 0.722 - 0s 72us/step - loss: 0.5398 - acc: 0.7214 - val_loss: 0.6322 - val_acc: 0.6053\n",
      "Epoch 289/600\n",
      "1346/1346 [==============================] - 0s 65us/step - loss: 0.5395 - acc: 0.7192 - val_loss: 0.6149 - val_acc: 0.6113\n",
      "Epoch 290/600\n",
      "1346/1346 [==============================] - 0s 65us/step - loss: 0.5396 - acc: 0.7221 - val_loss: 0.6193 - val_acc: 0.6113\n",
      "Epoch 291/600\n",
      "1346/1346 [==============================] - 0s 71us/step - loss: 0.5394 - acc: 0.7207 - val_loss: 0.6290 - val_acc: 0.6083\n",
      "Epoch 292/600\n",
      "1346/1346 [==============================] - 0s 78us/step - loss: 0.5387 - acc: 0.7221 - val_loss: 0.6293 - val_acc: 0.6083\n",
      "Epoch 293/600\n",
      "1346/1346 [==============================] - 0s 78us/step - loss: 0.5395 - acc: 0.7244 - val_loss: 0.6308 - val_acc: 0.6053\n",
      "Epoch 294/600\n",
      "1346/1346 [==============================] - 0s 88us/step - loss: 0.5388 - acc: 0.7207 - val_loss: 0.6214 - val_acc: 0.6113\n",
      "Epoch 295/600\n",
      "1346/1346 [==============================] - 0s 74us/step - loss: 0.5393 - acc: 0.7229 - val_loss: 0.6136 - val_acc: 0.6231\n",
      "Epoch 296/600\n",
      "1346/1346 [==============================] - 0s 74us/step - loss: 0.5400 - acc: 0.7236 - val_loss: 0.6215 - val_acc: 0.6113\n",
      "Epoch 297/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1346/1346 [==============================] - 0s 82us/step - loss: 0.5390 - acc: 0.7229 - val_loss: 0.6195 - val_acc: 0.6083\n",
      "Epoch 298/600\n",
      "1346/1346 [==============================] - 0s 74us/step - loss: 0.5397 - acc: 0.7192 - val_loss: 0.6378 - val_acc: 0.5994\n",
      "Epoch 299/600\n",
      "1346/1346 [==============================] - 0s 76us/step - loss: 0.5386 - acc: 0.7184 - val_loss: 0.6274 - val_acc: 0.6113\n",
      "Epoch 300/600\n",
      "1346/1346 [==============================] - 0s 71us/step - loss: 0.5391 - acc: 0.7199 - val_loss: 0.6276 - val_acc: 0.6113\n",
      "Epoch 301/600\n",
      "1346/1346 [==============================] - 0s 66us/step - loss: 0.5390 - acc: 0.7221 - val_loss: 0.6253 - val_acc: 0.6113\n",
      "Epoch 302/600\n",
      "1346/1346 [==============================] - 0s 62us/step - loss: 0.5391 - acc: 0.7199 - val_loss: 0.6363 - val_acc: 0.5994\n",
      "Epoch 303/600\n",
      "1346/1346 [==============================] - 0s 62us/step - loss: 0.5390 - acc: 0.7221 - val_loss: 0.6210 - val_acc: 0.6202\n",
      "Epoch 304/600\n",
      "1346/1346 [==============================] - 0s 67us/step - loss: 0.5389 - acc: 0.7251 - val_loss: 0.6176 - val_acc: 0.6202\n",
      "Epoch 305/600\n",
      "1346/1346 [==============================] - 0s 69us/step - loss: 0.5386 - acc: 0.7236 - val_loss: 0.6213 - val_acc: 0.6172\n",
      "Epoch 306/600\n",
      "1346/1346 [==============================] - 0s 68us/step - loss: 0.5392 - acc: 0.7214 - val_loss: 0.6125 - val_acc: 0.6142\n",
      "Epoch 307/600\n",
      "1346/1346 [==============================] - 0s 74us/step - loss: 0.5390 - acc: 0.7214 - val_loss: 0.6175 - val_acc: 0.6261\n",
      "Epoch 308/600\n",
      "1346/1346 [==============================] - 0s 68us/step - loss: 0.5386 - acc: 0.7229 - val_loss: 0.6133 - val_acc: 0.6231\n",
      "Epoch 309/600\n",
      "1346/1346 [==============================] - 0s 68us/step - loss: 0.5390 - acc: 0.7251 - val_loss: 0.6151 - val_acc: 0.6172\n",
      "Epoch 310/600\n",
      "1346/1346 [==============================] - 0s 67us/step - loss: 0.5389 - acc: 0.7221 - val_loss: 0.6238 - val_acc: 0.6202\n",
      "Epoch 311/600\n",
      "1346/1346 [==============================] - 0s 68us/step - loss: 0.5387 - acc: 0.7236 - val_loss: 0.6163 - val_acc: 0.6261\n",
      "Epoch 312/600\n",
      "1346/1346 [==============================] - 0s 66us/step - loss: 0.5387 - acc: 0.7229 - val_loss: 0.6156 - val_acc: 0.6261\n",
      "Epoch 313/600\n",
      "1346/1346 [==============================] - 0s 67us/step - loss: 0.5390 - acc: 0.7251 - val_loss: 0.6058 - val_acc: 0.6231\n",
      "Epoch 314/600\n",
      "1346/1346 [==============================] - 0s 62us/step - loss: 0.5401 - acc: 0.7184 - val_loss: 0.6182 - val_acc: 0.6172\n",
      "Epoch 315/600\n",
      "1346/1346 [==============================] - 0s 65us/step - loss: 0.5396 - acc: 0.7192 - val_loss: 0.6287 - val_acc: 0.6053\n",
      "Epoch 316/600\n",
      "1346/1346 [==============================] - 0s 62us/step - loss: 0.5386 - acc: 0.7192 - val_loss: 0.6074 - val_acc: 0.6261\n",
      "Epoch 317/600\n",
      "1346/1346 [==============================] - 0s 65us/step - loss: 0.5390 - acc: 0.7244 - val_loss: 0.6228 - val_acc: 0.6142\n",
      "Epoch 318/600\n",
      "1346/1346 [==============================] - 0s 69us/step - loss: 0.5385 - acc: 0.7207 - val_loss: 0.6182 - val_acc: 0.6231\n",
      "Epoch 319/600\n",
      "1346/1346 [==============================] - 0s 65us/step - loss: 0.5385 - acc: 0.7199 - val_loss: 0.6204 - val_acc: 0.6142\n",
      "Epoch 320/600\n",
      "1346/1346 [==============================] - 0s 61us/step - loss: 0.5389 - acc: 0.7184 - val_loss: 0.6239 - val_acc: 0.6083\n",
      "Epoch 321/600\n",
      "1346/1346 [==============================] - 0s 64us/step - loss: 0.5394 - acc: 0.7221 - val_loss: 0.6115 - val_acc: 0.6202\n",
      "Epoch 322/600\n",
      "1346/1346 [==============================] - 0s 59us/step - loss: 0.5388 - acc: 0.7214 - val_loss: 0.6224 - val_acc: 0.6113\n",
      "Epoch 323/600\n",
      "1346/1346 [==============================] - 0s 64us/step - loss: 0.5392 - acc: 0.7229 - val_loss: 0.6207 - val_acc: 0.6142\n",
      "Epoch 324/600\n",
      "1346/1346 [==============================] - 0s 59us/step - loss: 0.5389 - acc: 0.7207 - val_loss: 0.6306 - val_acc: 0.6083\n",
      "Epoch 325/600\n",
      "1346/1346 [==============================] - 0s 59us/step - loss: 0.5382 - acc: 0.7236 - val_loss: 0.6137 - val_acc: 0.6202\n",
      "Epoch 326/600\n",
      "1346/1346 [==============================] - 0s 60us/step - loss: 0.5390 - acc: 0.7244 - val_loss: 0.6068 - val_acc: 0.6261\n",
      "Epoch 327/600\n",
      "1346/1346 [==============================] - 0s 59us/step - loss: 0.5392 - acc: 0.7207 - val_loss: 0.6108 - val_acc: 0.6261\n",
      "Epoch 328/600\n",
      "1346/1346 [==============================] - 0s 67us/step - loss: 0.5379 - acc: 0.7266 - val_loss: 0.6059 - val_acc: 0.6261\n",
      "Epoch 329/600\n",
      "1346/1346 [==============================] - 0s 70us/step - loss: 0.5384 - acc: 0.7244 - val_loss: 0.6142 - val_acc: 0.6231\n",
      "Epoch 330/600\n",
      "1346/1346 [==============================] - 0s 71us/step - loss: 0.5377 - acc: 0.7221 - val_loss: 0.6162 - val_acc: 0.6172\n",
      "Epoch 331/600\n",
      "1346/1346 [==============================] - 0s 74us/step - loss: 0.5380 - acc: 0.7281 - val_loss: 0.6193 - val_acc: 0.6291\n",
      "Epoch 332/600\n",
      "1346/1346 [==============================] - 0s 79us/step - loss: 0.5382 - acc: 0.7251 - val_loss: 0.6176 - val_acc: 0.6261\n",
      "Epoch 333/600\n",
      "1346/1346 [==============================] - 0s 64us/step - loss: 0.5397 - acc: 0.7221 - val_loss: 0.6121 - val_acc: 0.6291\n",
      "Epoch 334/600\n",
      "1346/1346 [==============================] - 0s 71us/step - loss: 0.5376 - acc: 0.7236 - val_loss: 0.6105 - val_acc: 0.6291\n",
      "Epoch 335/600\n",
      "1346/1346 [==============================] - 0s 66us/step - loss: 0.5381 - acc: 0.7244 - val_loss: 0.6072 - val_acc: 0.6291\n",
      "Epoch 336/600\n",
      "1346/1346 [==============================] - 0s 62us/step - loss: 0.5383 - acc: 0.7311 - val_loss: 0.6026 - val_acc: 0.6261\n",
      "Epoch 337/600\n",
      "1346/1346 [==============================] - 0s 63us/step - loss: 0.5380 - acc: 0.7266 - val_loss: 0.6130 - val_acc: 0.6291\n",
      "Epoch 338/600\n",
      "1346/1346 [==============================] - 0s 65us/step - loss: 0.5381 - acc: 0.7199 - val_loss: 0.6283 - val_acc: 0.6053\n",
      "Epoch 339/600\n",
      "1346/1346 [==============================] - 0s 64us/step - loss: 0.5380 - acc: 0.7214 - val_loss: 0.6157 - val_acc: 0.6202\n",
      "Epoch 340/600\n",
      "1346/1346 [==============================] - 0s 65us/step - loss: 0.5378 - acc: 0.7214 - val_loss: 0.6105 - val_acc: 0.6202\n",
      "Epoch 341/600\n",
      "1346/1346 [==============================] - 0s 70us/step - loss: 0.5380 - acc: 0.7281 - val_loss: 0.6172 - val_acc: 0.6231\n",
      "Epoch 342/600\n",
      "1346/1346 [==============================] - 0s 60us/step - loss: 0.5398 - acc: 0.7177 - val_loss: 0.6539 - val_acc: 0.6024\n",
      "Epoch 343/600\n",
      "1346/1346 [==============================] - 0s 68us/step - loss: 0.5380 - acc: 0.7214 - val_loss: 0.6171 - val_acc: 0.6202\n",
      "Epoch 344/600\n",
      "1346/1346 [==============================] - 0s 79us/step - loss: 0.5395 - acc: 0.7244 - val_loss: 0.6194 - val_acc: 0.6113\n",
      "Epoch 345/600\n",
      "1346/1346 [==============================] - 0s 65us/step - loss: 0.5379 - acc: 0.7236 - val_loss: 0.6118 - val_acc: 0.6202\n",
      "Epoch 346/600\n",
      "1346/1346 [==============================] - 0s 71us/step - loss: 0.5376 - acc: 0.7251 - val_loss: 0.6077 - val_acc: 0.6291\n",
      "Epoch 347/600\n",
      "1346/1346 [==============================] - 0s 76us/step - loss: 0.5379 - acc: 0.7273 - val_loss: 0.5870 - val_acc: 0.6617\n",
      "Epoch 348/600\n",
      "1346/1346 [==============================] - 0s 61us/step - loss: 0.5374 - acc: 0.7266 - val_loss: 0.6070 - val_acc: 0.6320\n",
      "Epoch 349/600\n",
      "1346/1346 [==============================] - 0s 68us/step - loss: 0.5373 - acc: 0.7259 - val_loss: 0.6124 - val_acc: 0.6320\n",
      "Epoch 350/600\n",
      "1346/1346 [==============================] - 0s 65us/step - loss: 0.5375 - acc: 0.7236 - val_loss: 0.6111 - val_acc: 0.6291\n",
      "Epoch 351/600\n",
      "1346/1346 [==============================] - 0s 60us/step - loss: 0.5379 - acc: 0.7266 - val_loss: 0.6021 - val_acc: 0.6380\n",
      "Epoch 352/600\n",
      "1346/1346 [==============================] - 0s 61us/step - loss: 0.5376 - acc: 0.7207 - val_loss: 0.6050 - val_acc: 0.6350\n",
      "Epoch 353/600\n",
      "1346/1346 [==============================] - 0s 64us/step - loss: 0.5368 - acc: 0.7259 - val_loss: 0.6017 - val_acc: 0.6409\n",
      "Epoch 354/600\n",
      "1346/1346 [==============================] - 0s 61us/step - loss: 0.5375 - acc: 0.7244 - val_loss: 0.6068 - val_acc: 0.6320\n",
      "Epoch 355/600\n",
      "1346/1346 [==============================] - 0s 65us/step - loss: 0.5378 - acc: 0.7229 - val_loss: 0.6072 - val_acc: 0.6291\n",
      "Epoch 356/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1346/1346 [==============================] - 0s 64us/step - loss: 0.5368 - acc: 0.7214 - val_loss: 0.6078 - val_acc: 0.6320\n",
      "Epoch 357/600\n",
      "1346/1346 [==============================] - 0s 61us/step - loss: 0.5368 - acc: 0.7251 - val_loss: 0.6029 - val_acc: 0.6409\n",
      "Epoch 358/600\n",
      "1346/1346 [==============================] - 0s 60us/step - loss: 0.5373 - acc: 0.7199 - val_loss: 0.6073 - val_acc: 0.6320\n",
      "Epoch 359/600\n",
      "1346/1346 [==============================] - 0s 64us/step - loss: 0.5381 - acc: 0.7177 - val_loss: 0.6084 - val_acc: 0.6261\n",
      "Epoch 360/600\n",
      "1346/1346 [==============================] - 0s 124us/step - loss: 0.5379 - acc: 0.7184 - val_loss: 0.6124 - val_acc: 0.6261\n",
      "Epoch 361/600\n",
      "1346/1346 [==============================] - 0s 69us/step - loss: 0.5373 - acc: 0.7221 - val_loss: 0.5967 - val_acc: 0.6439\n",
      "Epoch 362/600\n",
      "1346/1346 [==============================] - 0s 59us/step - loss: 0.5373 - acc: 0.7221 - val_loss: 0.6011 - val_acc: 0.6350\n",
      "Epoch 363/600\n",
      "1346/1346 [==============================] - 0s 60us/step - loss: 0.5386 - acc: 0.7229 - val_loss: 0.5883 - val_acc: 0.6677\n",
      "Epoch 364/600\n",
      "1346/1346 [==============================] - 0s 61us/step - loss: 0.5363 - acc: 0.7214 - val_loss: 0.6156 - val_acc: 0.6320\n",
      "Epoch 365/600\n",
      "1346/1346 [==============================] - 0s 69us/step - loss: 0.5363 - acc: 0.7184 - val_loss: 0.6157 - val_acc: 0.6320\n",
      "Epoch 366/600\n",
      "1346/1346 [==============================] - 0s 70us/step - loss: 0.5365 - acc: 0.7251 - val_loss: 0.6036 - val_acc: 0.6320\n",
      "Epoch 367/600\n",
      "1346/1346 [==============================] - 0s 77us/step - loss: 0.5364 - acc: 0.7207 - val_loss: 0.6069 - val_acc: 0.6291\n",
      "Epoch 368/600\n",
      "1346/1346 [==============================] - 0s 72us/step - loss: 0.5368 - acc: 0.7177 - val_loss: 0.6124 - val_acc: 0.6350\n",
      "Epoch 369/600\n",
      "1346/1346 [==============================] - 0s 71us/step - loss: 0.5375 - acc: 0.7236 - val_loss: 0.6079 - val_acc: 0.6291\n",
      "Epoch 370/600\n",
      "1346/1346 [==============================] - 0s 80us/step - loss: 0.5367 - acc: 0.7184 - val_loss: 0.6224 - val_acc: 0.6261\n",
      "Epoch 371/600\n",
      "1346/1346 [==============================] - 0s 76us/step - loss: 0.5366 - acc: 0.7184 - val_loss: 0.6137 - val_acc: 0.6350\n",
      "Epoch 372/600\n",
      "1346/1346 [==============================] - 0s 94us/step - loss: 0.5367 - acc: 0.7214 - val_loss: 0.6169 - val_acc: 0.6350\n",
      "Epoch 373/600\n",
      "1346/1346 [==============================] - 0s 82us/step - loss: 0.5364 - acc: 0.7244 - val_loss: 0.6046 - val_acc: 0.6409\n",
      "Epoch 374/600\n",
      "1346/1346 [==============================] - 0s 70us/step - loss: 0.5363 - acc: 0.7184 - val_loss: 0.6172 - val_acc: 0.6320\n",
      "Epoch 375/600\n",
      "1346/1346 [==============================] - 0s 80us/step - loss: 0.5363 - acc: 0.7184 - val_loss: 0.5933 - val_acc: 0.6469\n",
      "Epoch 376/600\n",
      "1346/1346 [==============================] - 0s 83us/step - loss: 0.5360 - acc: 0.7207 - val_loss: 0.6076 - val_acc: 0.6320\n",
      "Epoch 377/600\n",
      "1346/1346 [==============================] - 0s 78us/step - loss: 0.5362 - acc: 0.7236 - val_loss: 0.5985 - val_acc: 0.6409\n",
      "Epoch 378/600\n",
      "1346/1346 [==============================] - 0s 60us/step - loss: 0.5365 - acc: 0.7214 - val_loss: 0.6037 - val_acc: 0.6380\n",
      "Epoch 379/600\n",
      "1346/1346 [==============================] - 0s 72us/step - loss: 0.5370 - acc: 0.7184 - val_loss: 0.5921 - val_acc: 0.6588\n",
      "Epoch 380/600\n",
      "1346/1346 [==============================] - 0s 67us/step - loss: 0.5355 - acc: 0.7192 - val_loss: 0.6095 - val_acc: 0.6320\n",
      "Epoch 381/600\n",
      "1346/1346 [==============================] - 0s 102us/step - loss: 0.5357 - acc: 0.7169 - val_loss: 0.6167 - val_acc: 0.6320\n",
      "Epoch 382/600\n",
      "1346/1346 [==============================] - 0s 88us/step - loss: 0.5357 - acc: 0.7236 - val_loss: 0.6040 - val_acc: 0.6320\n",
      "Epoch 383/600\n",
      "1346/1346 [==============================] - 0s 109us/step - loss: 0.5363 - acc: 0.7251 - val_loss: 0.6089 - val_acc: 0.6320\n",
      "Epoch 384/600\n",
      "1346/1346 [==============================] - 0s 78us/step - loss: 0.5369 - acc: 0.7229 - val_loss: 0.6105 - val_acc: 0.6261\n",
      "Epoch 385/600\n",
      "1346/1346 [==============================] - 0s 108us/step - loss: 0.5367 - acc: 0.7244 - val_loss: 0.6060 - val_acc: 0.6320\n",
      "Epoch 386/600\n",
      "1346/1346 [==============================] - 0s 108us/step - loss: 0.5362 - acc: 0.7169 - val_loss: 0.6126 - val_acc: 0.6320\n",
      "Epoch 387/600\n",
      "1346/1346 [==============================] - 0s 91us/step - loss: 0.5363 - acc: 0.7236 - val_loss: 0.6007 - val_acc: 0.6291\n",
      "Epoch 388/600\n",
      "1346/1346 [==============================] - 0s 90us/step - loss: 0.5356 - acc: 0.7229 - val_loss: 0.6018 - val_acc: 0.6320\n",
      "Epoch 389/600\n",
      "1346/1346 [==============================] - 0s 83us/step - loss: 0.5355 - acc: 0.7259 - val_loss: 0.6087 - val_acc: 0.6350\n",
      "Epoch 390/600\n",
      "1346/1346 [==============================] - 0s 85us/step - loss: 0.5355 - acc: 0.7236 - val_loss: 0.5998 - val_acc: 0.6350\n",
      "Epoch 391/600\n",
      "1346/1346 [==============================] - 0s 87us/step - loss: 0.5355 - acc: 0.7229 - val_loss: 0.6080 - val_acc: 0.6320\n",
      "Epoch 392/600\n",
      "1346/1346 [==============================] - 0s 105us/step - loss: 0.5356 - acc: 0.7214 - val_loss: 0.6126 - val_acc: 0.6291\n",
      "Epoch 393/600\n",
      "1346/1346 [==============================] - 0s 129us/step - loss: 0.5364 - acc: 0.7229 - val_loss: 0.5857 - val_acc: 0.6677\n",
      "Epoch 394/600\n",
      "1346/1346 [==============================] - 0s 85us/step - loss: 0.5350 - acc: 0.7221 - val_loss: 0.6021 - val_acc: 0.6380\n",
      "Epoch 395/600\n",
      "1346/1346 [==============================] - 0s 82us/step - loss: 0.5354 - acc: 0.7266 - val_loss: 0.6041 - val_acc: 0.6380\n",
      "Epoch 396/600\n",
      "1346/1346 [==============================] - 0s 82us/step - loss: 0.5357 - acc: 0.7214 - val_loss: 0.6027 - val_acc: 0.6350\n",
      "Epoch 397/600\n",
      "1346/1346 [==============================] - 0s 76us/step - loss: 0.5359 - acc: 0.7259 - val_loss: 0.6016 - val_acc: 0.6291\n",
      "Epoch 398/600\n",
      "1346/1346 [==============================] - 0s 68us/step - loss: 0.5354 - acc: 0.7259 - val_loss: 0.5989 - val_acc: 0.6380\n",
      "Epoch 399/600\n",
      "1346/1346 [==============================] - 0s 65us/step - loss: 0.5353 - acc: 0.7251 - val_loss: 0.6045 - val_acc: 0.6409\n",
      "Epoch 400/600\n",
      "1346/1346 [==============================] - 0s 71us/step - loss: 0.5348 - acc: 0.7221 - val_loss: 0.6087 - val_acc: 0.6350\n",
      "Epoch 401/600\n",
      "1346/1346 [==============================] - 0s 74us/step - loss: 0.5354 - acc: 0.7259 - val_loss: 0.6005 - val_acc: 0.6350\n",
      "Epoch 402/600\n",
      "1346/1346 [==============================] - 0s 66us/step - loss: 0.5360 - acc: 0.7251 - val_loss: 0.6020 - val_acc: 0.6320\n",
      "Epoch 403/600\n",
      "1346/1346 [==============================] - 0s 65us/step - loss: 0.5354 - acc: 0.7207 - val_loss: 0.6045 - val_acc: 0.6409\n",
      "Epoch 404/600\n",
      "1346/1346 [==============================] - 0s 65us/step - loss: 0.5353 - acc: 0.7273 - val_loss: 0.6023 - val_acc: 0.6409\n",
      "Epoch 405/600\n",
      "1346/1346 [==============================] - 0s 66us/step - loss: 0.5348 - acc: 0.7207 - val_loss: 0.6078 - val_acc: 0.6320\n",
      "Epoch 406/600\n",
      "1346/1346 [==============================] - 0s 69us/step - loss: 0.5353 - acc: 0.7214 - val_loss: 0.5992 - val_acc: 0.6409\n",
      "Epoch 407/600\n",
      "1346/1346 [==============================] - 0s 76us/step - loss: 0.5349 - acc: 0.7207 - val_loss: 0.6003 - val_acc: 0.6380\n",
      "Epoch 408/600\n",
      "1346/1346 [==============================] - 0s 79us/step - loss: 0.5345 - acc: 0.7229 - val_loss: 0.6060 - val_acc: 0.6350\n",
      "Epoch 409/600\n",
      "1346/1346 [==============================] - 0s 74us/step - loss: 0.5348 - acc: 0.7199 - val_loss: 0.6073 - val_acc: 0.6320\n",
      "Epoch 410/600\n",
      "1346/1346 [==============================] - 0s 70us/step - loss: 0.5348 - acc: 0.7207 - val_loss: 0.5967 - val_acc: 0.6439\n",
      "Epoch 411/600\n",
      "1346/1346 [==============================] - 0s 74us/step - loss: 0.5346 - acc: 0.7184 - val_loss: 0.6037 - val_acc: 0.6409\n",
      "Epoch 412/600\n",
      "1346/1346 [==============================] - ETA: 0s - loss: 0.5475 - acc: 0.713 - 0s 76us/step - loss: 0.5348 - acc: 0.7221 - val_loss: 0.6039 - val_acc: 0.6320\n",
      "Epoch 413/600\n",
      "1346/1346 [==============================] - 0s 63us/step - loss: 0.5357 - acc: 0.7207 - val_loss: 0.6068 - val_acc: 0.6350\n",
      "Epoch 414/600\n",
      "1346/1346 [==============================] - 0s 70us/step - loss: 0.5349 - acc: 0.7192 - val_loss: 0.6092 - val_acc: 0.6350\n",
      "Epoch 415/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1346/1346 [==============================] - 0s 78us/step - loss: 0.5343 - acc: 0.7177 - val_loss: 0.6016 - val_acc: 0.6409\n",
      "Epoch 416/600\n",
      "1346/1346 [==============================] - 0s 84us/step - loss: 0.5348 - acc: 0.7273 - val_loss: 0.6040 - val_acc: 0.6380\n",
      "Epoch 417/600\n",
      "1346/1346 [==============================] - 0s 76us/step - loss: 0.5352 - acc: 0.7207 - val_loss: 0.6025 - val_acc: 0.6409\n",
      "Epoch 418/600\n",
      "1346/1346 [==============================] - 0s 71us/step - loss: 0.5341 - acc: 0.7207 - val_loss: 0.5978 - val_acc: 0.6439\n",
      "Epoch 419/600\n",
      "1346/1346 [==============================] - 0s 95us/step - loss: 0.5340 - acc: 0.7177 - val_loss: 0.6022 - val_acc: 0.6380\n",
      "Epoch 420/600\n",
      "1346/1346 [==============================] - 0s 105us/step - loss: 0.5339 - acc: 0.7177 - val_loss: 0.5997 - val_acc: 0.6528\n",
      "Epoch 421/600\n",
      "1346/1346 [==============================] - 0s 115us/step - loss: 0.5355 - acc: 0.7169 - val_loss: 0.5928 - val_acc: 0.6558\n",
      "Epoch 422/600\n",
      "1346/1346 [==============================] - 0s 106us/step - loss: 0.5336 - acc: 0.7236 - val_loss: 0.5990 - val_acc: 0.6528\n",
      "Epoch 423/600\n",
      "1346/1346 [==============================] - 0s 105us/step - loss: 0.5336 - acc: 0.7207 - val_loss: 0.6057 - val_acc: 0.6439\n",
      "Epoch 424/600\n",
      "1346/1346 [==============================] - 0s 85us/step - loss: 0.5338 - acc: 0.7169 - val_loss: 0.6054 - val_acc: 0.6320\n",
      "Epoch 425/600\n",
      "1346/1346 [==============================] - 0s 89us/step - loss: 0.5336 - acc: 0.7221 - val_loss: 0.6054 - val_acc: 0.6469\n",
      "Epoch 426/600\n",
      "1346/1346 [==============================] - 0s 77us/step - loss: 0.5339 - acc: 0.7192 - val_loss: 0.6021 - val_acc: 0.6469\n",
      "Epoch 427/600\n",
      "1346/1346 [==============================] - 0s 79us/step - loss: 0.5337 - acc: 0.7221 - val_loss: 0.5995 - val_acc: 0.6499\n",
      "Epoch 428/600\n",
      "1346/1346 [==============================] - 0s 74us/step - loss: 0.5337 - acc: 0.7251 - val_loss: 0.6111 - val_acc: 0.6320\n",
      "Epoch 429/600\n",
      "1346/1346 [==============================] - 0s 98us/step - loss: 0.5336 - acc: 0.7169 - val_loss: 0.6114 - val_acc: 0.6350\n",
      "Epoch 430/600\n",
      "1346/1346 [==============================] - 0s 90us/step - loss: 0.5332 - acc: 0.7207 - val_loss: 0.6020 - val_acc: 0.6469\n",
      "Epoch 431/600\n",
      "1346/1346 [==============================] - 0s 64us/step - loss: 0.5337 - acc: 0.7184 - val_loss: 0.6062 - val_acc: 0.6409\n",
      "Epoch 432/600\n",
      "1346/1346 [==============================] - 0s 64us/step - loss: 0.5334 - acc: 0.7229 - val_loss: 0.5969 - val_acc: 0.6558\n",
      "Epoch 433/600\n",
      "1346/1346 [==============================] - 0s 64us/step - loss: 0.5333 - acc: 0.7192 - val_loss: 0.6067 - val_acc: 0.6439\n",
      "Epoch 434/600\n",
      "1346/1346 [==============================] - 0s 63us/step - loss: 0.5339 - acc: 0.7155 - val_loss: 0.5956 - val_acc: 0.6588\n",
      "Epoch 435/600\n",
      "1346/1346 [==============================] - 0s 63us/step - loss: 0.5337 - acc: 0.7229 - val_loss: 0.5931 - val_acc: 0.6677\n",
      "Epoch 436/600\n",
      "1346/1346 [==============================] - 0s 76us/step - loss: 0.5336 - acc: 0.7177 - val_loss: 0.6034 - val_acc: 0.6439\n",
      "Epoch 437/600\n",
      "1346/1346 [==============================] - 0s 95us/step - loss: 0.5337 - acc: 0.7244 - val_loss: 0.6016 - val_acc: 0.6469\n",
      "Epoch 438/600\n",
      "1346/1346 [==============================] - 0s 132us/step - loss: 0.5331 - acc: 0.7199 - val_loss: 0.5936 - val_acc: 0.6677\n",
      "Epoch 439/600\n",
      "1346/1346 [==============================] - 0s 117us/step - loss: 0.5334 - acc: 0.7251 - val_loss: 0.6027 - val_acc: 0.6499\n",
      "Epoch 440/600\n",
      "1346/1346 [==============================] - 0s 120us/step - loss: 0.5333 - acc: 0.7221 - val_loss: 0.5995 - val_acc: 0.6588\n",
      "Epoch 441/600\n",
      "1346/1346 [==============================] - 0s 138us/step - loss: 0.5333 - acc: 0.7162 - val_loss: 0.5958 - val_acc: 0.6558\n",
      "Epoch 442/600\n",
      "1346/1346 [==============================] - 0s 134us/step - loss: 0.5336 - acc: 0.7199 - val_loss: 0.5927 - val_acc: 0.6647\n",
      "Epoch 443/600\n",
      "1346/1346 [==============================] - 0s 108us/step - loss: 0.5336 - acc: 0.7207 - val_loss: 0.5957 - val_acc: 0.6588\n",
      "Epoch 444/600\n",
      "1346/1346 [==============================] - 0s 126us/step - loss: 0.5332 - acc: 0.7184 - val_loss: 0.6123 - val_acc: 0.6409\n",
      "Epoch 445/600\n",
      "1346/1346 [==============================] - 0s 125us/step - loss: 0.5327 - acc: 0.7140 - val_loss: 0.5929 - val_acc: 0.6647\n",
      "Epoch 446/600\n",
      "1346/1346 [==============================] - 0s 82us/step - loss: 0.5333 - acc: 0.7169 - val_loss: 0.6011 - val_acc: 0.6617\n",
      "Epoch 447/600\n",
      "1346/1346 [==============================] - 0s 97us/step - loss: 0.5331 - acc: 0.7259 - val_loss: 0.5936 - val_acc: 0.6647\n",
      "Epoch 448/600\n",
      "1346/1346 [==============================] - 0s 101us/step - loss: 0.5329 - acc: 0.7207 - val_loss: 0.6063 - val_acc: 0.6409\n",
      "Epoch 449/600\n",
      "1346/1346 [==============================] - 0s 109us/step - loss: 0.5334 - acc: 0.7162 - val_loss: 0.6198 - val_acc: 0.6320\n",
      "Epoch 450/600\n",
      "1346/1346 [==============================] - 0s 105us/step - loss: 0.5344 - acc: 0.7117 - val_loss: 0.6081 - val_acc: 0.6469\n",
      "Epoch 451/600\n",
      "1346/1346 [==============================] - 0s 103us/step - loss: 0.5336 - acc: 0.7199 - val_loss: 0.5934 - val_acc: 0.6677\n",
      "Epoch 452/600\n",
      "1346/1346 [==============================] - 0s 94us/step - loss: 0.5332 - acc: 0.7214 - val_loss: 0.6063 - val_acc: 0.6469\n",
      "Epoch 453/600\n",
      "1346/1346 [==============================] - 0s 140us/step - loss: 0.5333 - acc: 0.7207 - val_loss: 0.6072 - val_acc: 0.6439\n",
      "Epoch 454/600\n",
      "1346/1346 [==============================] - 0s 95us/step - loss: 0.5333 - acc: 0.7169 - val_loss: 0.6084 - val_acc: 0.6380\n",
      "Epoch 455/600\n",
      "1346/1346 [==============================] - 0s 78us/step - loss: 0.5326 - acc: 0.7192 - val_loss: 0.6026 - val_acc: 0.6469\n",
      "Epoch 456/600\n",
      "1346/1346 [==============================] - 0s 74us/step - loss: 0.5330 - acc: 0.7184 - val_loss: 0.5937 - val_acc: 0.6647\n",
      "Epoch 457/600\n",
      "1346/1346 [==============================] - 0s 76us/step - loss: 0.5334 - acc: 0.7132 - val_loss: 0.6060 - val_acc: 0.6439\n",
      "Epoch 458/600\n",
      "1346/1346 [==============================] - 0s 79us/step - loss: 0.5332 - acc: 0.7184 - val_loss: 0.6126 - val_acc: 0.6320\n",
      "Epoch 459/600\n",
      "1346/1346 [==============================] - 0s 83us/step - loss: 0.5327 - acc: 0.7162 - val_loss: 0.6090 - val_acc: 0.6409\n",
      "Epoch 460/600\n",
      "1346/1346 [==============================] - 0s 77us/step - loss: 0.5325 - acc: 0.7177 - val_loss: 0.6061 - val_acc: 0.6409\n",
      "Epoch 461/600\n",
      "1346/1346 [==============================] - 0s 78us/step - loss: 0.5326 - acc: 0.7162 - val_loss: 0.6042 - val_acc: 0.6439\n",
      "Epoch 462/600\n",
      "1346/1346 [==============================] - 0s 79us/step - loss: 0.5329 - acc: 0.7155 - val_loss: 0.5983 - val_acc: 0.6617\n",
      "Epoch 463/600\n",
      "1346/1346 [==============================] - 0s 82us/step - loss: 0.5341 - acc: 0.7184 - val_loss: 0.6024 - val_acc: 0.6469\n",
      "Epoch 464/600\n",
      "1346/1346 [==============================] - 0s 102us/step - loss: 0.5323 - acc: 0.7162 - val_loss: 0.6112 - val_acc: 0.6320\n",
      "Epoch 465/600\n",
      "1346/1346 [==============================] - 0s 94us/step - loss: 0.5321 - acc: 0.7147 - val_loss: 0.5981 - val_acc: 0.6499\n",
      "Epoch 466/600\n",
      "1346/1346 [==============================] - 0s 102us/step - loss: 0.5325 - acc: 0.7177 - val_loss: 0.6006 - val_acc: 0.6499\n",
      "Epoch 467/600\n",
      "1346/1346 [==============================] - 0s 99us/step - loss: 0.5321 - acc: 0.7184 - val_loss: 0.5980 - val_acc: 0.6499\n",
      "Epoch 468/600\n",
      "1346/1346 [==============================] - 0s 98us/step - loss: 0.5327 - acc: 0.7199 - val_loss: 0.5926 - val_acc: 0.6736\n",
      "Epoch 469/600\n",
      "1346/1346 [==============================] - 0s 100us/step - loss: 0.5324 - acc: 0.7169 - val_loss: 0.6050 - val_acc: 0.6439\n",
      "Epoch 470/600\n",
      "1346/1346 [==============================] - 0s 99us/step - loss: 0.5340 - acc: 0.7162 - val_loss: 0.6171 - val_acc: 0.6350\n",
      "Epoch 471/600\n",
      "1346/1346 [==============================] - 0s 97us/step - loss: 0.5336 - acc: 0.7214 - val_loss: 0.5918 - val_acc: 0.6736\n",
      "Epoch 472/600\n",
      "1346/1346 [==============================] - 0s 80us/step - loss: 0.5331 - acc: 0.7177 - val_loss: 0.6019 - val_acc: 0.6469\n",
      "Epoch 473/600\n",
      "1346/1346 [==============================] - 0s 82us/step - loss: 0.5327 - acc: 0.7147 - val_loss: 0.6025 - val_acc: 0.6439\n",
      "Epoch 474/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1346/1346 [==============================] - 0s 97us/step - loss: 0.5324 - acc: 0.7147 - val_loss: 0.6108 - val_acc: 0.6409\n",
      "Epoch 475/600\n",
      "1346/1346 [==============================] - 0s 85us/step - loss: 0.5331 - acc: 0.7110 - val_loss: 0.6044 - val_acc: 0.6528\n",
      "Epoch 476/600\n",
      "1346/1346 [==============================] - 0s 82us/step - loss: 0.5334 - acc: 0.7125 - val_loss: 0.6146 - val_acc: 0.6350\n",
      "Epoch 477/600\n",
      "1346/1346 [==============================] - 0s 77us/step - loss: 0.5320 - acc: 0.7177 - val_loss: 0.5978 - val_acc: 0.6647\n",
      "Epoch 478/600\n",
      "1346/1346 [==============================] - 0s 91us/step - loss: 0.5322 - acc: 0.7155 - val_loss: 0.5980 - val_acc: 0.6528\n",
      "Epoch 479/600\n",
      "1346/1346 [==============================] - 0s 108us/step - loss: 0.5332 - acc: 0.7162 - val_loss: 0.6120 - val_acc: 0.6380\n",
      "Epoch 480/600\n",
      "1346/1346 [==============================] - 0s 101us/step - loss: 0.5325 - acc: 0.7169 - val_loss: 0.6019 - val_acc: 0.6499\n",
      "Epoch 481/600\n",
      "1346/1346 [==============================] - 0s 91us/step - loss: 0.5326 - acc: 0.7207 - val_loss: 0.6157 - val_acc: 0.6380\n",
      "Epoch 482/600\n",
      "1346/1346 [==============================] - 0s 107us/step - loss: 0.5325 - acc: 0.7199 - val_loss: 0.6080 - val_acc: 0.6380\n",
      "Epoch 483/600\n",
      "1346/1346 [==============================] - 0s 96us/step - loss: 0.5322 - acc: 0.7169 - val_loss: 0.6027 - val_acc: 0.6439\n",
      "Epoch 484/600\n",
      "1346/1346 [==============================] - 0s 89us/step - loss: 0.5326 - acc: 0.7177 - val_loss: 0.6069 - val_acc: 0.6380\n",
      "Epoch 485/600\n",
      "1346/1346 [==============================] - 0s 65us/step - loss: 0.5326 - acc: 0.7221 - val_loss: 0.5945 - val_acc: 0.6736\n",
      "Epoch 486/600\n",
      "1346/1346 [==============================] - 0s 84us/step - loss: 0.5326 - acc: 0.7147 - val_loss: 0.5964 - val_acc: 0.6677\n",
      "Epoch 487/600\n",
      "1346/1346 [==============================] - 0s 94us/step - loss: 0.5326 - acc: 0.7147 - val_loss: 0.6125 - val_acc: 0.6380\n",
      "Epoch 488/600\n",
      "1346/1346 [==============================] - 0s 94us/step - loss: 0.5320 - acc: 0.7162 - val_loss: 0.5999 - val_acc: 0.6558\n",
      "Epoch 489/600\n",
      "1346/1346 [==============================] - 0s 69us/step - loss: 0.5326 - acc: 0.7155 - val_loss: 0.5935 - val_acc: 0.6736\n",
      "Epoch 490/600\n",
      "1346/1346 [==============================] - 0s 68us/step - loss: 0.5329 - acc: 0.7207 - val_loss: 0.5890 - val_acc: 0.6736\n",
      "Epoch 491/600\n",
      "1346/1346 [==============================] - 0s 78us/step - loss: 0.5331 - acc: 0.7147 - val_loss: 0.6390 - val_acc: 0.6231\n",
      "Epoch 492/600\n",
      "1346/1346 [==============================] - 0s 59us/step - loss: 0.5330 - acc: 0.7147 - val_loss: 0.6191 - val_acc: 0.6409\n",
      "Epoch 493/600\n",
      "1346/1346 [==============================] - 0s 60us/step - loss: 0.5321 - acc: 0.7199 - val_loss: 0.5994 - val_acc: 0.6617\n",
      "Epoch 494/600\n",
      "1346/1346 [==============================] - 0s 94us/step - loss: 0.5324 - acc: 0.7147 - val_loss: 0.5958 - val_acc: 0.6647\n",
      "Epoch 495/600\n",
      "1346/1346 [==============================] - 0s 100us/step - loss: 0.5325 - acc: 0.7147 - val_loss: 0.6062 - val_acc: 0.6409\n",
      "Epoch 496/600\n",
      "1346/1346 [==============================] - 0s 96us/step - loss: 0.5329 - acc: 0.7162 - val_loss: 0.6008 - val_acc: 0.6558\n",
      "Epoch 497/600\n",
      "1346/1346 [==============================] - 0s 97us/step - loss: 0.5325 - acc: 0.7229 - val_loss: 0.6098 - val_acc: 0.6320\n",
      "Epoch 498/600\n",
      "1346/1346 [==============================] - 0s 94us/step - loss: 0.5324 - acc: 0.7192 - val_loss: 0.6024 - val_acc: 0.6499\n",
      "Epoch 499/600\n",
      "1346/1346 [==============================] - 0s 94us/step - loss: 0.5325 - acc: 0.7207 - val_loss: 0.6060 - val_acc: 0.6380\n",
      "Epoch 500/600\n",
      "1346/1346 [==============================] - 0s 85us/step - loss: 0.5313 - acc: 0.7169 - val_loss: 0.6050 - val_acc: 0.6439\n",
      "Epoch 501/600\n",
      "1346/1346 [==============================] - 0s 69us/step - loss: 0.5327 - acc: 0.7177 - val_loss: 0.6152 - val_acc: 0.6469\n",
      "Epoch 502/600\n",
      "1346/1346 [==============================] - 0s 72us/step - loss: 0.5323 - acc: 0.7162 - val_loss: 0.5967 - val_acc: 0.6647\n",
      "Epoch 503/600\n",
      "1346/1346 [==============================] - 0s 66us/step - loss: 0.5320 - acc: 0.7169 - val_loss: 0.6018 - val_acc: 0.6528\n",
      "Epoch 504/600\n",
      "1346/1346 [==============================] - 0s 68us/step - loss: 0.5318 - acc: 0.7155 - val_loss: 0.6040 - val_acc: 0.6528\n",
      "Epoch 505/600\n",
      "1346/1346 [==============================] - 0s 75us/step - loss: 0.5332 - acc: 0.7103 - val_loss: 0.6072 - val_acc: 0.6528\n",
      "Epoch 506/600\n",
      "1346/1346 [==============================] - ETA: 0s - loss: 0.5388 - acc: 0.718 - 0s 71us/step - loss: 0.5321 - acc: 0.7236 - val_loss: 0.5960 - val_acc: 0.6706\n",
      "Epoch 507/600\n",
      "1346/1346 [==============================] - 0s 77us/step - loss: 0.5325 - acc: 0.7192 - val_loss: 0.6047 - val_acc: 0.6439\n",
      "Epoch 508/600\n",
      "1346/1346 [==============================] - 0s 77us/step - loss: 0.5324 - acc: 0.7155 - val_loss: 0.6056 - val_acc: 0.6469\n",
      "Epoch 509/600\n",
      "1346/1346 [==============================] - 0s 69us/step - loss: 0.5321 - acc: 0.7125 - val_loss: 0.6016 - val_acc: 0.6528\n",
      "Epoch 510/600\n",
      "1346/1346 [==============================] - 0s 74us/step - loss: 0.5316 - acc: 0.7162 - val_loss: 0.5925 - val_acc: 0.6736\n",
      "Epoch 511/600\n",
      "1346/1346 [==============================] - 0s 77us/step - loss: 0.5324 - acc: 0.7155 - val_loss: 0.5881 - val_acc: 0.6766\n",
      "Epoch 512/600\n",
      "1346/1346 [==============================] - 0s 74us/step - loss: 0.5329 - acc: 0.7162 - val_loss: 0.5899 - val_acc: 0.6706\n",
      "Epoch 513/600\n",
      "1346/1346 [==============================] - 0s 73us/step - loss: 0.5322 - acc: 0.7184 - val_loss: 0.5993 - val_acc: 0.6588\n",
      "Epoch 514/600\n",
      "1346/1346 [==============================] - 0s 76us/step - loss: 0.5318 - acc: 0.7207 - val_loss: 0.6004 - val_acc: 0.6558\n",
      "Epoch 515/600\n",
      "1346/1346 [==============================] - 0s 75us/step - loss: 0.5321 - acc: 0.7162 - val_loss: 0.6033 - val_acc: 0.6380\n",
      "Epoch 516/600\n",
      "1346/1346 [==============================] - 0s 76us/step - loss: 0.5315 - acc: 0.7177 - val_loss: 0.6036 - val_acc: 0.6469\n",
      "Epoch 517/600\n",
      "1346/1346 [==============================] - 0s 76us/step - loss: 0.5318 - acc: 0.7169 - val_loss: 0.6153 - val_acc: 0.6350\n",
      "Epoch 518/600\n",
      "1346/1346 [==============================] - 0s 75us/step - loss: 0.5316 - acc: 0.7140 - val_loss: 0.6079 - val_acc: 0.6409\n",
      "Epoch 519/600\n",
      "1346/1346 [==============================] - 0s 77us/step - loss: 0.5319 - acc: 0.7169 - val_loss: 0.6060 - val_acc: 0.6409\n",
      "Epoch 520/600\n",
      "1346/1346 [==============================] - 0s 79us/step - loss: 0.5320 - acc: 0.7184 - val_loss: 0.6118 - val_acc: 0.6409\n",
      "Epoch 521/600\n",
      "1346/1346 [==============================] - 0s 76us/step - loss: 0.5313 - acc: 0.7162 - val_loss: 0.6004 - val_acc: 0.6617\n",
      "Epoch 522/600\n",
      "1346/1346 [==============================] - 0s 72us/step - loss: 0.5314 - acc: 0.7132 - val_loss: 0.6088 - val_acc: 0.6439\n",
      "Epoch 523/600\n",
      "1346/1346 [==============================] - 0s 73us/step - loss: 0.5316 - acc: 0.7132 - val_loss: 0.6017 - val_acc: 0.6647\n",
      "Epoch 524/600\n",
      "1346/1346 [==============================] - 0s 76us/step - loss: 0.5315 - acc: 0.7147 - val_loss: 0.6128 - val_acc: 0.6380\n",
      "Epoch 525/600\n",
      "1346/1346 [==============================] - 0s 74us/step - loss: 0.5329 - acc: 0.7162 - val_loss: 0.5979 - val_acc: 0.6617\n",
      "Epoch 526/600\n",
      "1346/1346 [==============================] - 0s 90us/step - loss: 0.5313 - acc: 0.7229 - val_loss: 0.6034 - val_acc: 0.6499\n",
      "Epoch 527/600\n",
      "1346/1346 [==============================] - 0s 97us/step - loss: 0.5311 - acc: 0.7140 - val_loss: 0.6099 - val_acc: 0.6409\n",
      "Epoch 528/600\n",
      "1346/1346 [==============================] - 0s 80us/step - loss: 0.5311 - acc: 0.7207 - val_loss: 0.6023 - val_acc: 0.6588\n",
      "Epoch 529/600\n",
      "1346/1346 [==============================] - 0s 94us/step - loss: 0.5320 - acc: 0.7192 - val_loss: 0.6114 - val_acc: 0.6439\n",
      "Epoch 530/600\n",
      "1346/1346 [==============================] - 0s 85us/step - loss: 0.5326 - acc: 0.7095 - val_loss: 0.6138 - val_acc: 0.6439\n",
      "Epoch 531/600\n",
      "1346/1346 [==============================] - 0s 86us/step - loss: 0.5313 - acc: 0.7169 - val_loss: 0.6006 - val_acc: 0.6617\n",
      "Epoch 532/600\n",
      "1346/1346 [==============================] - 0s 91us/step - loss: 0.5316 - acc: 0.7117 - val_loss: 0.5989 - val_acc: 0.6617\n",
      "Epoch 533/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1346/1346 [==============================] - 0s 88us/step - loss: 0.5312 - acc: 0.7169 - val_loss: 0.5999 - val_acc: 0.6617\n",
      "Epoch 534/600\n",
      "1346/1346 [==============================] - 0s 79us/step - loss: 0.5308 - acc: 0.7169 - val_loss: 0.5988 - val_acc: 0.6617\n",
      "Epoch 535/600\n",
      "1346/1346 [==============================] - 0s 79us/step - loss: 0.5305 - acc: 0.7169 - val_loss: 0.5957 - val_acc: 0.6617\n",
      "Epoch 536/600\n",
      "1346/1346 [==============================] - 0s 81us/step - loss: 0.5313 - acc: 0.7147 - val_loss: 0.5974 - val_acc: 0.6677\n",
      "Epoch 537/600\n",
      "1346/1346 [==============================] - 0s 73us/step - loss: 0.5315 - acc: 0.7132 - val_loss: 0.6040 - val_acc: 0.6558\n",
      "Epoch 538/600\n",
      "1346/1346 [==============================] - 0s 74us/step - loss: 0.5306 - acc: 0.7169 - val_loss: 0.6049 - val_acc: 0.6469\n",
      "Epoch 539/600\n",
      "1346/1346 [==============================] - 0s 74us/step - loss: 0.5322 - acc: 0.7147 - val_loss: 0.5976 - val_acc: 0.6647\n",
      "Epoch 540/600\n",
      "1346/1346 [==============================] - 0s 71us/step - loss: 0.5308 - acc: 0.7177 - val_loss: 0.6099 - val_acc: 0.6439\n",
      "Epoch 541/600\n",
      "1346/1346 [==============================] - 0s 78us/step - loss: 0.5311 - acc: 0.7192 - val_loss: 0.6062 - val_acc: 0.6439\n",
      "Epoch 542/600\n",
      "1346/1346 [==============================] - 0s 79us/step - loss: 0.5311 - acc: 0.7140 - val_loss: 0.6169 - val_acc: 0.6409\n",
      "Epoch 543/600\n",
      "1346/1346 [==============================] - 0s 78us/step - loss: 0.5335 - acc: 0.7169 - val_loss: 0.6090 - val_acc: 0.6409\n",
      "Epoch 544/600\n",
      "1346/1346 [==============================] - 0s 79us/step - loss: 0.5314 - acc: 0.7147 - val_loss: 0.6000 - val_acc: 0.6617\n",
      "Epoch 545/600\n",
      "1346/1346 [==============================] - 0s 71us/step - loss: 0.5309 - acc: 0.7229 - val_loss: 0.6006 - val_acc: 0.6617\n",
      "Epoch 546/600\n",
      "1346/1346 [==============================] - 0s 64us/step - loss: 0.5311 - acc: 0.7162 - val_loss: 0.6051 - val_acc: 0.6439\n",
      "Epoch 547/600\n",
      "1346/1346 [==============================] - 0s 82us/step - loss: 0.5311 - acc: 0.7132 - val_loss: 0.6064 - val_acc: 0.6439\n",
      "Epoch 548/600\n",
      "1346/1346 [==============================] - 0s 117us/step - loss: 0.5304 - acc: 0.7140 - val_loss: 0.6043 - val_acc: 0.6528\n",
      "Epoch 549/600\n",
      "1346/1346 [==============================] - 0s 61us/step - loss: 0.5306 - acc: 0.7177 - val_loss: 0.5945 - val_acc: 0.6677\n",
      "Epoch 550/600\n",
      "1346/1346 [==============================] - 0s 69us/step - loss: 0.5308 - acc: 0.7155 - val_loss: 0.6023 - val_acc: 0.6558\n",
      "Epoch 551/600\n",
      "1346/1346 [==============================] - 0s 59us/step - loss: 0.5302 - acc: 0.7184 - val_loss: 0.5984 - val_acc: 0.6647\n",
      "Epoch 552/600\n",
      "1346/1346 [==============================] - 0s 71us/step - loss: 0.5308 - acc: 0.7192 - val_loss: 0.5955 - val_acc: 0.6647\n",
      "Epoch 553/600\n",
      "1346/1346 [==============================] - 0s 64us/step - loss: 0.5306 - acc: 0.7199 - val_loss: 0.6004 - val_acc: 0.6617\n",
      "Epoch 554/600\n",
      "1346/1346 [==============================] - 0s 72us/step - loss: 0.5301 - acc: 0.7192 - val_loss: 0.5928 - val_acc: 0.6677\n",
      "Epoch 555/600\n",
      "1346/1346 [==============================] - 0s 77us/step - loss: 0.5309 - acc: 0.7132 - val_loss: 0.5999 - val_acc: 0.6558\n",
      "Epoch 556/600\n",
      "1346/1346 [==============================] - 0s 97us/step - loss: 0.5308 - acc: 0.7192 - val_loss: 0.6113 - val_acc: 0.6558\n",
      "Epoch 557/600\n",
      "1346/1346 [==============================] - 0s 87us/step - loss: 0.5309 - acc: 0.7214 - val_loss: 0.6020 - val_acc: 0.6558\n",
      "Epoch 558/600\n",
      "1346/1346 [==============================] - 0s 71us/step - loss: 0.5302 - acc: 0.7177 - val_loss: 0.5966 - val_acc: 0.6617\n",
      "Epoch 559/600\n",
      "1346/1346 [==============================] - 0s 74us/step - loss: 0.5302 - acc: 0.7229 - val_loss: 0.6001 - val_acc: 0.6528\n",
      "Epoch 560/600\n",
      "1346/1346 [==============================] - 0s 77us/step - loss: 0.5303 - acc: 0.7207 - val_loss: 0.6073 - val_acc: 0.6588\n",
      "Epoch 561/600\n",
      "1346/1346 [==============================] - 0s 73us/step - loss: 0.5300 - acc: 0.7125 - val_loss: 0.6029 - val_acc: 0.6617\n",
      "Epoch 562/600\n",
      "1346/1346 [==============================] - 0s 102us/step - loss: 0.5307 - acc: 0.7162 - val_loss: 0.6018 - val_acc: 0.6677\n",
      "Epoch 563/600\n",
      "1346/1346 [==============================] - 0s 105us/step - loss: 0.5299 - acc: 0.7132 - val_loss: 0.5970 - val_acc: 0.6588\n",
      "Epoch 564/600\n",
      "1346/1346 [==============================] - 0s 77us/step - loss: 0.5298 - acc: 0.7214 - val_loss: 0.5906 - val_acc: 0.6706\n",
      "Epoch 565/600\n",
      "1346/1346 [==============================] - 0s 79us/step - loss: 0.5300 - acc: 0.7140 - val_loss: 0.5987 - val_acc: 0.6617\n",
      "Epoch 566/600\n",
      "1346/1346 [==============================] - 0s 74us/step - loss: 0.5297 - acc: 0.7169 - val_loss: 0.5950 - val_acc: 0.6588\n",
      "Epoch 567/600\n",
      "1346/1346 [==============================] - 0s 87us/step - loss: 0.5300 - acc: 0.7192 - val_loss: 0.6007 - val_acc: 0.6558\n",
      "Epoch 568/600\n",
      "1346/1346 [==============================] - 0s 104us/step - loss: 0.5296 - acc: 0.7192 - val_loss: 0.5948 - val_acc: 0.6617\n",
      "Epoch 569/600\n",
      "1346/1346 [==============================] - 0s 88us/step - loss: 0.5310 - acc: 0.7155 - val_loss: 0.5981 - val_acc: 0.6617\n",
      "Epoch 570/600\n",
      "1346/1346 [==============================] - 0s 93us/step - loss: 0.5297 - acc: 0.7192 - val_loss: 0.6018 - val_acc: 0.6558\n",
      "Epoch 571/600\n",
      "1346/1346 [==============================] - 0s 83us/step - loss: 0.5304 - acc: 0.7177 - val_loss: 0.6235 - val_acc: 0.6409\n",
      "Epoch 572/600\n",
      "1346/1346 [==============================] - 0s 89us/step - loss: 0.5317 - acc: 0.7140 - val_loss: 0.6053 - val_acc: 0.6647\n",
      "Epoch 573/600\n",
      "1346/1346 [==============================] - 0s 89us/step - loss: 0.5302 - acc: 0.7147 - val_loss: 0.5934 - val_acc: 0.6677\n",
      "Epoch 574/600\n",
      "1346/1346 [==============================] - 0s 108us/step - loss: 0.5311 - acc: 0.7184 - val_loss: 0.6188 - val_acc: 0.6380\n",
      "Epoch 575/600\n",
      "1346/1346 [==============================] - 0s 74us/step - loss: 0.5302 - acc: 0.7184 - val_loss: 0.6026 - val_acc: 0.6499\n",
      "Epoch 576/600\n",
      "1346/1346 [==============================] - 0s 83us/step - loss: 0.5295 - acc: 0.7184 - val_loss: 0.5997 - val_acc: 0.6588\n",
      "Epoch 577/600\n",
      "1346/1346 [==============================] - 0s 88us/step - loss: 0.5297 - acc: 0.7184 - val_loss: 0.6107 - val_acc: 0.6528\n",
      "Epoch 578/600\n",
      "1346/1346 [==============================] - 0s 117us/step - loss: 0.5300 - acc: 0.7140 - val_loss: 0.5990 - val_acc: 0.6706\n",
      "Epoch 579/600\n",
      "1346/1346 [==============================] - 0s 85us/step - loss: 0.5295 - acc: 0.7199 - val_loss: 0.6087 - val_acc: 0.6499\n",
      "Epoch 580/600\n",
      "1346/1346 [==============================] - 0s 65us/step - loss: 0.5304 - acc: 0.7147 - val_loss: 0.5993 - val_acc: 0.6617\n",
      "Epoch 581/600\n",
      "1346/1346 [==============================] - 0s 70us/step - loss: 0.5306 - acc: 0.7132 - val_loss: 0.5894 - val_acc: 0.6736\n",
      "Epoch 582/600\n",
      "1346/1346 [==============================] - 0s 76us/step - loss: 0.5299 - acc: 0.7199 - val_loss: 0.6007 - val_acc: 0.6588\n",
      "Epoch 583/600\n",
      "1346/1346 [==============================] - 0s 80us/step - loss: 0.5296 - acc: 0.7207 - val_loss: 0.6076 - val_acc: 0.6588\n",
      "Epoch 584/600\n",
      "1346/1346 [==============================] - 0s 83us/step - loss: 0.5293 - acc: 0.7184 - val_loss: 0.6092 - val_acc: 0.6647\n",
      "Epoch 585/600\n",
      "1346/1346 [==============================] - 0s 95us/step - loss: 0.5296 - acc: 0.7147 - val_loss: 0.6011 - val_acc: 0.6588\n",
      "Epoch 586/600\n",
      "1346/1346 [==============================] - 0s 84us/step - loss: 0.5301 - acc: 0.7155 - val_loss: 0.6347 - val_acc: 0.6261\n",
      "Epoch 587/600\n",
      "1346/1346 [==============================] - 0s 88us/step - loss: 0.5297 - acc: 0.7155 - val_loss: 0.6127 - val_acc: 0.6528\n",
      "Epoch 588/600\n",
      "1346/1346 [==============================] - 0s 98us/step - loss: 0.5293 - acc: 0.7117 - val_loss: 0.6037 - val_acc: 0.6647\n",
      "Epoch 589/600\n",
      "1346/1346 [==============================] - 0s 81us/step - loss: 0.5297 - acc: 0.7132 - val_loss: 0.6033 - val_acc: 0.6647\n",
      "Epoch 590/600\n",
      "1346/1346 [==============================] - 0s 76us/step - loss: 0.5295 - acc: 0.7169 - val_loss: 0.6070 - val_acc: 0.6617\n",
      "Epoch 591/600\n",
      "1346/1346 [==============================] - 0s 76us/step - loss: 0.5304 - acc: 0.7177 - val_loss: 0.6001 - val_acc: 0.6647\n",
      "Epoch 592/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1346/1346 [==============================] - 0s 85us/step - loss: 0.5310 - acc: 0.7162 - val_loss: 0.6087 - val_acc: 0.6558\n",
      "Epoch 593/600\n",
      "1346/1346 [==============================] - 0s 88us/step - loss: 0.5293 - acc: 0.7192 - val_loss: 0.6001 - val_acc: 0.6677\n",
      "Epoch 594/600\n",
      "1346/1346 [==============================] - 0s 109us/step - loss: 0.5288 - acc: 0.7162 - val_loss: 0.6023 - val_acc: 0.6677\n",
      "Epoch 595/600\n",
      "1346/1346 [==============================] - 0s 84us/step - loss: 0.5299 - acc: 0.7155 - val_loss: 0.5899 - val_acc: 0.6825\n",
      "Epoch 596/600\n",
      "1346/1346 [==============================] - 0s 87us/step - loss: 0.5294 - acc: 0.7132 - val_loss: 0.6068 - val_acc: 0.6588\n",
      "Epoch 597/600\n",
      "1346/1346 [==============================] - 0s 101us/step - loss: 0.5296 - acc: 0.7162 - val_loss: 0.5883 - val_acc: 0.6766\n",
      "Epoch 598/600\n",
      "1346/1346 [==============================] - 0s 85us/step - loss: 0.5299 - acc: 0.7177 - val_loss: 0.6007 - val_acc: 0.6677\n",
      "Epoch 599/600\n",
      "1346/1346 [==============================] - 0s 80us/step - loss: 0.5295 - acc: 0.7147 - val_loss: 0.5949 - val_acc: 0.6736\n",
      "Epoch 600/600\n",
      "1346/1346 [==============================] - 0s 84us/step - loss: 0.5290 - acc: 0.7169 - val_loss: 0.5998 - val_acc: 0.6706\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(2, kernel_initializer='normal', input_dim=len(X[0]), activation='relu'))\n",
    "model.add(Dense(2, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X, y.values, epochs=600, validation_split = 0.2)\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T20:33:55.533891Z",
     "start_time": "2019-08-16T20:33:39.473083Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1514 samples, validate on 169 samples\n",
      "Epoch 1/100\n",
      "1514/1514 [==============================] - 2s 1ms/step - loss: 0.6847 - acc: 0.5581 - val_loss: 0.6867 - val_acc: 0.4734\n",
      "Epoch 2/100\n",
      "1514/1514 [==============================] - 0s 71us/step - loss: 0.6581 - acc: 0.6057 - val_loss: 0.6876 - val_acc: 0.4793\n",
      "Epoch 3/100\n",
      "1514/1514 [==============================] - 0s 78us/step - loss: 0.6329 - acc: 0.6572 - val_loss: 0.6687 - val_acc: 0.4675\n",
      "Epoch 4/100\n",
      "1514/1514 [==============================] - 0s 79us/step - loss: 0.6074 - acc: 0.6909 - val_loss: 0.6461 - val_acc: 0.5858\n",
      "Epoch 5/100\n",
      "1514/1514 [==============================] - 0s 78us/step - loss: 0.5855 - acc: 0.7081 - val_loss: 0.6173 - val_acc: 0.6746\n",
      "Epoch 6/100\n",
      "1514/1514 [==============================] - 0s 84us/step - loss: 0.5700 - acc: 0.7120 - val_loss: 0.6094 - val_acc: 0.6568\n",
      "Epoch 7/100\n",
      "1514/1514 [==============================] - 0s 84us/step - loss: 0.5621 - acc: 0.7153 - val_loss: 0.5975 - val_acc: 0.6746\n",
      "Epoch 8/100\n",
      "1514/1514 [==============================] - 0s 81us/step - loss: 0.5571 - acc: 0.7180 - val_loss: 0.5783 - val_acc: 0.7456\n",
      "Epoch 9/100\n",
      "1514/1514 [==============================] - 0s 84us/step - loss: 0.5528 - acc: 0.7193 - val_loss: 0.5920 - val_acc: 0.6686\n",
      "Epoch 10/100\n",
      "1514/1514 [==============================] - ETA: 0s - loss: 0.5531 - acc: 0.709 - 0s 83us/step - loss: 0.5510 - acc: 0.7140 - val_loss: 0.5803 - val_acc: 0.6805\n",
      "Epoch 11/100\n",
      "1514/1514 [==============================] - 0s 82us/step - loss: 0.5488 - acc: 0.7193 - val_loss: 0.5796 - val_acc: 0.6805\n",
      "Epoch 12/100\n",
      "1514/1514 [==============================] - 0s 89us/step - loss: 0.5473 - acc: 0.7186 - val_loss: 0.5866 - val_acc: 0.6509\n",
      "Epoch 13/100\n",
      "1514/1514 [==============================] - 0s 96us/step - loss: 0.5456 - acc: 0.7193 - val_loss: 0.5717 - val_acc: 0.6805\n",
      "Epoch 14/100\n",
      "1514/1514 [==============================] - 0s 108us/step - loss: 0.5446 - acc: 0.7199 - val_loss: 0.5732 - val_acc: 0.6805\n",
      "Epoch 15/100\n",
      "1514/1514 [==============================] - 0s 86us/step - loss: 0.5434 - acc: 0.7232 - val_loss: 0.5628 - val_acc: 0.7101\n",
      "Epoch 16/100\n",
      "1514/1514 [==============================] - 0s 89us/step - loss: 0.5418 - acc: 0.7193 - val_loss: 0.5715 - val_acc: 0.6627\n",
      "Epoch 17/100\n",
      "1514/1514 [==============================] - 0s 98us/step - loss: 0.5410 - acc: 0.7239 - val_loss: 0.5617 - val_acc: 0.6982\n",
      "Epoch 18/100\n",
      "1514/1514 [==============================] - 0s 86us/step - loss: 0.5395 - acc: 0.7232 - val_loss: 0.5680 - val_acc: 0.6805\n",
      "Epoch 19/100\n",
      "1514/1514 [==============================] - 0s 80us/step - loss: 0.5393 - acc: 0.7193 - val_loss: 0.5681 - val_acc: 0.6686\n",
      "Epoch 20/100\n",
      "1514/1514 [==============================] - ETA: 0s - loss: 0.5409 - acc: 0.720 - 0s 85us/step - loss: 0.5382 - acc: 0.7246 - val_loss: 0.5664 - val_acc: 0.6686\n",
      "Epoch 21/100\n",
      "1514/1514 [==============================] - 0s 87us/step - loss: 0.5376 - acc: 0.7166 - val_loss: 0.5583 - val_acc: 0.7337\n",
      "Epoch 22/100\n",
      "1514/1514 [==============================] - 0s 84us/step - loss: 0.5360 - acc: 0.7266 - val_loss: 0.5710 - val_acc: 0.6686\n",
      "Epoch 23/100\n",
      "1514/1514 [==============================] - 0s 81us/step - loss: 0.5357 - acc: 0.7246 - val_loss: 0.5668 - val_acc: 0.6686\n",
      "Epoch 24/100\n",
      "1514/1514 [==============================] - 0s 89us/step - loss: 0.5347 - acc: 0.7239 - val_loss: 0.5658 - val_acc: 0.6746\n",
      "Epoch 25/100\n",
      "1514/1514 [==============================] - 0s 88us/step - loss: 0.5339 - acc: 0.7305 - val_loss: 0.5753 - val_acc: 0.6509\n",
      "Epoch 26/100\n",
      "1514/1514 [==============================] - 0s 92us/step - loss: 0.5336 - acc: 0.7252 - val_loss: 0.5587 - val_acc: 0.7101\n",
      "Epoch 27/100\n",
      "1514/1514 [==============================] - 0s 90us/step - loss: 0.5327 - acc: 0.7332 - val_loss: 0.5765 - val_acc: 0.6509\n",
      "Epoch 28/100\n",
      "1514/1514 [==============================] - 0s 97us/step - loss: 0.5317 - acc: 0.7272 - val_loss: 0.5605 - val_acc: 0.6805\n",
      "Epoch 29/100\n",
      "1514/1514 [==============================] - 0s 106us/step - loss: 0.5307 - acc: 0.7285 - val_loss: 0.5655 - val_acc: 0.6627\n",
      "Epoch 30/100\n",
      "1514/1514 [==============================] - 0s 99us/step - loss: 0.5301 - acc: 0.7285 - val_loss: 0.5692 - val_acc: 0.6509\n",
      "Epoch 31/100\n",
      "1514/1514 [==============================] - 0s 98us/step - loss: 0.5291 - acc: 0.7299 - val_loss: 0.5626 - val_acc: 0.6746\n",
      "Epoch 32/100\n",
      "1514/1514 [==============================] - 0s 100us/step - loss: 0.5286 - acc: 0.7312 - val_loss: 0.5721 - val_acc: 0.6509\n",
      "Epoch 33/100\n",
      "1514/1514 [==============================] - 0s 94us/step - loss: 0.5284 - acc: 0.7305 - val_loss: 0.5596 - val_acc: 0.6805\n",
      "Epoch 34/100\n",
      "1514/1514 [==============================] - 0s 92us/step - loss: 0.5274 - acc: 0.7305 - val_loss: 0.5645 - val_acc: 0.6686\n",
      "Epoch 35/100\n",
      "1514/1514 [==============================] - 0s 98us/step - loss: 0.5264 - acc: 0.7305 - val_loss: 0.5769 - val_acc: 0.6509\n",
      "Epoch 36/100\n",
      "1514/1514 [==============================] - 0s 88us/step - loss: 0.5264 - acc: 0.7318 - val_loss: 0.5533 - val_acc: 0.7219\n",
      "Epoch 37/100\n",
      "1514/1514 [==============================] - 0s 91us/step - loss: 0.5254 - acc: 0.7345 - val_loss: 0.5652 - val_acc: 0.6686\n",
      "Epoch 38/100\n",
      "1514/1514 [==============================] - 0s 92us/step - loss: 0.5250 - acc: 0.7305 - val_loss: 0.5624 - val_acc: 0.6805\n",
      "Epoch 39/100\n",
      "1514/1514 [==============================] - 0s 83us/step - loss: 0.5241 - acc: 0.7391 - val_loss: 0.5655 - val_acc: 0.6746\n",
      "Epoch 40/100\n",
      "1514/1514 [==============================] - 0s 84us/step - loss: 0.5239 - acc: 0.7299 - val_loss: 0.5631 - val_acc: 0.6746\n",
      "Epoch 41/100\n",
      "1514/1514 [==============================] - 0s 85us/step - loss: 0.5231 - acc: 0.7332 - val_loss: 0.5622 - val_acc: 0.6805\n",
      "Epoch 42/100\n",
      "1514/1514 [==============================] - 0s 86us/step - loss: 0.5217 - acc: 0.7378 - val_loss: 0.5663 - val_acc: 0.6746\n",
      "Epoch 43/100\n",
      "1514/1514 [==============================] - 0s 88us/step - loss: 0.5218 - acc: 0.7318 - val_loss: 0.5742 - val_acc: 0.6568\n",
      "Epoch 44/100\n",
      "1514/1514 [==============================] - 0s 86us/step - loss: 0.5205 - acc: 0.7338 - val_loss: 0.5571 - val_acc: 0.6923\n",
      "Epoch 45/100\n",
      "1514/1514 [==============================] - 0s 112us/step - loss: 0.5210 - acc: 0.7312 - val_loss: 0.5804 - val_acc: 0.6568\n",
      "Epoch 46/100\n",
      "1514/1514 [==============================] - 0s 92us/step - loss: 0.5206 - acc: 0.7279 - val_loss: 0.6016 - val_acc: 0.6450\n",
      "Epoch 47/100\n",
      "1514/1514 [==============================] - 0s 89us/step - loss: 0.5202 - acc: 0.7358 - val_loss: 0.5694 - val_acc: 0.6805\n",
      "Epoch 48/100\n",
      "1514/1514 [==============================] - 0s 84us/step - loss: 0.5181 - acc: 0.7312 - val_loss: 0.5679 - val_acc: 0.6805\n",
      "Epoch 49/100\n",
      "1514/1514 [==============================] - 0s 83us/step - loss: 0.5170 - acc: 0.7365 - val_loss: 0.5871 - val_acc: 0.6568\n",
      "Epoch 50/100\n",
      "1514/1514 [==============================] - 0s 98us/step - loss: 0.5171 - acc: 0.7365 - val_loss: 0.5693 - val_acc: 0.6746\n",
      "Epoch 51/100\n",
      "1514/1514 [==============================] - 0s 83us/step - loss: 0.5160 - acc: 0.7338 - val_loss: 0.5726 - val_acc: 0.6627\n",
      "Epoch 52/100\n",
      "1514/1514 [==============================] - 0s 87us/step - loss: 0.5157 - acc: 0.7358 - val_loss: 0.5630 - val_acc: 0.6923\n",
      "Epoch 53/100\n",
      "1514/1514 [==============================] - 0s 90us/step - loss: 0.5154 - acc: 0.7351 - val_loss: 0.5904 - val_acc: 0.6568\n",
      "Epoch 54/100\n",
      "1514/1514 [==============================] - 0s 86us/step - loss: 0.5140 - acc: 0.7345 - val_loss: 0.5519 - val_acc: 0.7337\n",
      "Epoch 55/100\n",
      "1514/1514 [==============================] - 0s 84us/step - loss: 0.5140 - acc: 0.7404 - val_loss: 0.5779 - val_acc: 0.6686\n",
      "Epoch 56/100\n",
      "1514/1514 [==============================] - 0s 90us/step - loss: 0.5144 - acc: 0.7358 - val_loss: 0.5716 - val_acc: 0.6746\n",
      "Epoch 57/100\n",
      "1514/1514 [==============================] - 0s 102us/step - loss: 0.5134 - acc: 0.7351 - val_loss: 0.5766 - val_acc: 0.6864\n",
      "Epoch 58/100\n",
      "1514/1514 [==============================] - 0s 85us/step - loss: 0.5119 - acc: 0.7358 - val_loss: 0.5619 - val_acc: 0.6982\n",
      "Epoch 59/100\n",
      "1514/1514 [==============================] - 0s 90us/step - loss: 0.5123 - acc: 0.7384 - val_loss: 0.6010 - val_acc: 0.6450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "1514/1514 [==============================] - 0s 87us/step - loss: 0.5122 - acc: 0.7351 - val_loss: 0.5858 - val_acc: 0.6450\n",
      "Epoch 61/100\n",
      "1514/1514 [==============================] - 0s 94us/step - loss: 0.5104 - acc: 0.7450 - val_loss: 0.5667 - val_acc: 0.6805\n",
      "Epoch 62/100\n",
      "1514/1514 [==============================] - 0s 107us/step - loss: 0.5100 - acc: 0.7391 - val_loss: 0.5779 - val_acc: 0.6746\n",
      "Epoch 63/100\n",
      "1514/1514 [==============================] - 0s 88us/step - loss: 0.5095 - acc: 0.7417 - val_loss: 0.5854 - val_acc: 0.6568\n",
      "Epoch 64/100\n",
      "1514/1514 [==============================] - 0s 92us/step - loss: 0.5101 - acc: 0.7444 - val_loss: 0.5566 - val_acc: 0.7337\n",
      "Epoch 65/100\n",
      "1514/1514 [==============================] - 0s 103us/step - loss: 0.5093 - acc: 0.7411 - val_loss: 0.5815 - val_acc: 0.6627\n",
      "Epoch 66/100\n",
      "1514/1514 [==============================] - 0s 86us/step - loss: 0.5084 - acc: 0.7391 - val_loss: 0.5677 - val_acc: 0.6746\n",
      "Epoch 67/100\n",
      "1514/1514 [==============================] - 0s 81us/step - loss: 0.5088 - acc: 0.7431 - val_loss: 0.5713 - val_acc: 0.6627\n",
      "Epoch 68/100\n",
      "1514/1514 [==============================] - 0s 76us/step - loss: 0.5076 - acc: 0.7424 - val_loss: 0.5836 - val_acc: 0.6686\n",
      "Epoch 69/100\n",
      "1514/1514 [==============================] - 0s 90us/step - loss: 0.5088 - acc: 0.7404 - val_loss: 0.5806 - val_acc: 0.6746\n",
      "Epoch 70/100\n",
      "1514/1514 [==============================] - 0s 98us/step - loss: 0.5075 - acc: 0.7431 - val_loss: 0.5709 - val_acc: 0.6746\n",
      "Epoch 71/100\n",
      "1514/1514 [==============================] - 0s 86us/step - loss: 0.5058 - acc: 0.7457 - val_loss: 0.5848 - val_acc: 0.6686\n",
      "Epoch 72/100\n",
      "1514/1514 [==============================] - 0s 73us/step - loss: 0.5064 - acc: 0.7437 - val_loss: 0.5898 - val_acc: 0.6568\n",
      "Epoch 73/100\n",
      "1514/1514 [==============================] - 0s 69us/step - loss: 0.5063 - acc: 0.7444 - val_loss: 0.5754 - val_acc: 0.6746\n",
      "Epoch 74/100\n",
      "1514/1514 [==============================] - 0s 75us/step - loss: 0.5055 - acc: 0.7404 - val_loss: 0.5796 - val_acc: 0.6746\n",
      "Epoch 75/100\n",
      "1514/1514 [==============================] - 0s 78us/step - loss: 0.5043 - acc: 0.7417 - val_loss: 0.5742 - val_acc: 0.6746\n",
      "Epoch 76/100\n",
      "1514/1514 [==============================] - 0s 73us/step - loss: 0.5051 - acc: 0.7450 - val_loss: 0.5918 - val_acc: 0.6391\n",
      "Epoch 77/100\n",
      "1514/1514 [==============================] - 0s 77us/step - loss: 0.5044 - acc: 0.7437 - val_loss: 0.5603 - val_acc: 0.7337\n",
      "Epoch 78/100\n",
      "1514/1514 [==============================] - 0s 71us/step - loss: 0.5041 - acc: 0.7417 - val_loss: 0.6063 - val_acc: 0.6391\n",
      "Epoch 79/100\n",
      "1514/1514 [==============================] - 0s 79us/step - loss: 0.5033 - acc: 0.7411 - val_loss: 0.5669 - val_acc: 0.6864\n",
      "Epoch 80/100\n",
      "1514/1514 [==============================] - 0s 80us/step - loss: 0.5038 - acc: 0.7444 - val_loss: 0.6264 - val_acc: 0.6154\n",
      "Epoch 81/100\n",
      "1514/1514 [==============================] - 0s 74us/step - loss: 0.5026 - acc: 0.7470 - val_loss: 0.5983 - val_acc: 0.6213\n",
      "Epoch 82/100\n",
      "1514/1514 [==============================] - 0s 77us/step - loss: 0.5037 - acc: 0.7417 - val_loss: 0.5855 - val_acc: 0.6568\n",
      "Epoch 83/100\n",
      "1514/1514 [==============================] - 0s 79us/step - loss: 0.5029 - acc: 0.7444 - val_loss: 0.5778 - val_acc: 0.6686\n",
      "Epoch 84/100\n",
      "1514/1514 [==============================] - 0s 75us/step - loss: 0.5022 - acc: 0.7398 - val_loss: 0.5999 - val_acc: 0.6391\n",
      "Epoch 85/100\n",
      "1514/1514 [==============================] - 0s 78us/step - loss: 0.5020 - acc: 0.7431 - val_loss: 0.5813 - val_acc: 0.6568\n",
      "Epoch 86/100\n",
      "1514/1514 [==============================] - 0s 72us/step - loss: 0.5014 - acc: 0.7464 - val_loss: 0.5784 - val_acc: 0.6568\n",
      "Epoch 87/100\n",
      "1514/1514 [==============================] - 0s 79us/step - loss: 0.4999 - acc: 0.7444 - val_loss: 0.5991 - val_acc: 0.6272\n",
      "Epoch 88/100\n",
      "1514/1514 [==============================] - 0s 88us/step - loss: 0.5005 - acc: 0.7431 - val_loss: 0.5996 - val_acc: 0.6391\n",
      "Epoch 89/100\n",
      "1514/1514 [==============================] - 0s 79us/step - loss: 0.5011 - acc: 0.7398 - val_loss: 0.5936 - val_acc: 0.6509\n",
      "Epoch 90/100\n",
      "1514/1514 [==============================] - 0s 82us/step - loss: 0.4998 - acc: 0.7431 - val_loss: 0.5845 - val_acc: 0.6568\n",
      "Epoch 91/100\n",
      "1514/1514 [==============================] - 0s 74us/step - loss: 0.5005 - acc: 0.7490 - val_loss: 0.5699 - val_acc: 0.6805\n",
      "Epoch 92/100\n",
      "1514/1514 [==============================] - 0s 72us/step - loss: 0.4993 - acc: 0.7404 - val_loss: 0.5936 - val_acc: 0.6331\n",
      "Epoch 93/100\n",
      "1514/1514 [==============================] - 0s 76us/step - loss: 0.4987 - acc: 0.7450 - val_loss: 0.5701 - val_acc: 0.6864\n",
      "Epoch 94/100\n",
      "1514/1514 [==============================] - 0s 77us/step - loss: 0.4981 - acc: 0.7490 - val_loss: 0.6014 - val_acc: 0.6272\n",
      "Epoch 95/100\n",
      "1514/1514 [==============================] - 0s 72us/step - loss: 0.4987 - acc: 0.7457 - val_loss: 0.5878 - val_acc: 0.6568\n",
      "Epoch 96/100\n",
      "1514/1514 [==============================] - 0s 98us/step - loss: 0.4978 - acc: 0.7411 - val_loss: 0.5900 - val_acc: 0.6568\n",
      "Epoch 97/100\n",
      "1514/1514 [==============================] - 0s 93us/step - loss: 0.4978 - acc: 0.7457 - val_loss: 0.5849 - val_acc: 0.6627\n",
      "Epoch 98/100\n",
      "1514/1514 [==============================] - 0s 86us/step - loss: 0.4979 - acc: 0.7457 - val_loss: 0.5643 - val_acc: 0.7101\n",
      "Epoch 99/100\n",
      "1514/1514 [==============================] - 0s 79us/step - loss: 0.4973 - acc: 0.7450 - val_loss: 0.5896 - val_acc: 0.6627\n",
      "Epoch 100/100\n",
      "1514/1514 [==============================] - 0s 82us/step - loss: 0.4964 - acc: 0.7444 - val_loss: 0.6218 - val_acc: 0.6272\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(16, kernel_initializer='normal', input_dim=len(X[0]), activation='relu'))\n",
    "model.add(Dense(16, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adamax',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X, y.values, epochs=100, validation_split = 0.1)\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T21:47:36.098043Z",
     "start_time": "2019-08-16T21:47:36.090046Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x236f2ecae48>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
