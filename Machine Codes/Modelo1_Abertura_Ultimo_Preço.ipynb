{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T20:55:25.440752Z",
     "start_time": "2019-11-12T20:55:25.431755Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Conv2D\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "from keras.callbacks import TensorBoard, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T20:48:29.602766Z",
     "start_time": "2019-11-12T20:48:29.337917Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Contratos Abertos</th>\n",
       "      <th>Contratos Fechados</th>\n",
       "      <th>Número Negócios</th>\n",
       "      <th>Contratos Negociados</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Abertura</th>\n",
       "      <th>Mínimo</th>\n",
       "      <th>Máximo</th>\n",
       "      <th>Médio</th>\n",
       "      <th>Último Preço</th>\n",
       "      <th>Ajuste</th>\n",
       "      <th>Var pontos</th>\n",
       "      <th>Última oferta de compra</th>\n",
       "      <th>Última oferta de venda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29/07/2019</td>\n",
       "      <td>851537</td>\n",
       "      <td>719017</td>\n",
       "      <td>27192</td>\n",
       "      <td>226625</td>\n",
       "      <td>42939771125</td>\n",
       "      <td>3.7850</td>\n",
       "      <td>3.7775</td>\n",
       "      <td>3.8015</td>\n",
       "      <td>3.789499</td>\n",
       "      <td>3.7820</td>\n",
       "      <td>3.784797</td>\n",
       "      <td>145520</td>\n",
       "      <td>3.7820</td>\n",
       "      <td>3.7825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26/07/2019</td>\n",
       "      <td>875047</td>\n",
       "      <td>851537</td>\n",
       "      <td>32128</td>\n",
       "      <td>309480</td>\n",
       "      <td>58414828000</td>\n",
       "      <td>3.7800</td>\n",
       "      <td>3.7610</td>\n",
       "      <td>3.7955</td>\n",
       "      <td>3.775030</td>\n",
       "      <td>3.7760</td>\n",
       "      <td>3.770245</td>\n",
       "      <td>125890</td>\n",
       "      <td>3.7765</td>\n",
       "      <td>3.7780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25/07/2019</td>\n",
       "      <td>890941</td>\n",
       "      <td>875047</td>\n",
       "      <td>41651</td>\n",
       "      <td>381060</td>\n",
       "      <td>72105906125</td>\n",
       "      <td>3.7680</td>\n",
       "      <td>3.7570</td>\n",
       "      <td>3.8070</td>\n",
       "      <td>3.784490</td>\n",
       "      <td>3.7795</td>\n",
       "      <td>3.782834</td>\n",
       "      <td>129780</td>\n",
       "      <td>3.7795</td>\n",
       "      <td>3.7805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24/07/2019</td>\n",
       "      <td>883412</td>\n",
       "      <td>890941</td>\n",
       "      <td>26137</td>\n",
       "      <td>269620</td>\n",
       "      <td>50725252625</td>\n",
       "      <td>3.7675</td>\n",
       "      <td>3.7540</td>\n",
       "      <td>3.7795</td>\n",
       "      <td>3.762721</td>\n",
       "      <td>3.7735</td>\n",
       "      <td>3.769856</td>\n",
       "      <td>31160</td>\n",
       "      <td>3.7735</td>\n",
       "      <td>3.7755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23/07/2019</td>\n",
       "      <td>880504</td>\n",
       "      <td>883412</td>\n",
       "      <td>33586</td>\n",
       "      <td>313840</td>\n",
       "      <td>59121712875</td>\n",
       "      <td>3.7450</td>\n",
       "      <td>3.7430</td>\n",
       "      <td>3.7820</td>\n",
       "      <td>3.767634</td>\n",
       "      <td>3.7750</td>\n",
       "      <td>3.772972</td>\n",
       "      <td>356000</td>\n",
       "      <td>3.7750</td>\n",
       "      <td>3.7770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Data  Contratos Abertos  Contratos Fechados  Número Negócios  \\\n",
       "0  29/07/2019             851537              719017            27192   \n",
       "1  26/07/2019             875047              851537            32128   \n",
       "2  25/07/2019             890941              875047            41651   \n",
       "3  24/07/2019             883412              890941            26137   \n",
       "4  23/07/2019             880504              883412            33586   \n",
       "\n",
       "   Contratos Negociados       Volume  Abertura  Mínimo  Máximo     Médio  \\\n",
       "0                226625  42939771125    3.7850  3.7775  3.8015  3.789499   \n",
       "1                309480  58414828000    3.7800  3.7610  3.7955  3.775030   \n",
       "2                381060  72105906125    3.7680  3.7570  3.8070  3.784490   \n",
       "3                269620  50725252625    3.7675  3.7540  3.7795  3.762721   \n",
       "4                313840  59121712875    3.7450  3.7430  3.7820  3.767634   \n",
       "\n",
       "   Último Preço    Ajuste  Var pontos  Última oferta de compra  \\\n",
       "0        3.7820  3.784797      145520                   3.7820   \n",
       "1        3.7760  3.770245      125890                   3.7765   \n",
       "2        3.7795  3.782834      129780                   3.7795   \n",
       "3        3.7735  3.769856       31160                   3.7735   \n",
       "4        3.7750  3.772972      356000                   3.7750   \n",
       "\n",
       "   Última oferta de venda  \n",
       "0                  3.7825  \n",
       "1                  3.7780  \n",
       "2                  3.7805  \n",
       "3                  3.7755  \n",
       "4                  3.7770  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_hdf('df_dataDOL1.hdf', key='hdf')\n",
    "df2 = pd.read_hdf('df_dataDOL2.hdf', key='hdf')\n",
    "df3 = pd.read_hdf('df_dataDOL3.hdf', key='hdf')\n",
    "\n",
    "df_total = pd.concat([df1,df2,df3],  ignore_index=True)\n",
    "\n",
    "df_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T20:50:44.592655Z",
     "start_time": "2019-11-12T20:50:44.531691Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Número Negócios</th>\n",
       "      <th>Contratos Negociados</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Abertura</th>\n",
       "      <th>Mínimo</th>\n",
       "      <th>Máximo</th>\n",
       "      <th>Médio</th>\n",
       "      <th>Último Preço</th>\n",
       "      <th>Ajuste</th>\n",
       "      <th>Var pontos</th>\n",
       "      <th>Última oferta de compra</th>\n",
       "      <th>Última oferta de venda</th>\n",
       "      <th>Dif_contratos</th>\n",
       "      <th>Dif_minmax</th>\n",
       "      <th>Dif_abert_ultimo</th>\n",
       "      <th>Dif_abert_ajuste</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29/07/2019</td>\n",
       "      <td>271.92</td>\n",
       "      <td>22.6625</td>\n",
       "      <td>42.939771</td>\n",
       "      <td>3.7850</td>\n",
       "      <td>3.7775</td>\n",
       "      <td>3.8015</td>\n",
       "      <td>3.789499</td>\n",
       "      <td>3.7820</td>\n",
       "      <td>3.784797</td>\n",
       "      <td>145520</td>\n",
       "      <td>3.7820</td>\n",
       "      <td>3.7825</td>\n",
       "      <td>132520</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-0.203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26/07/2019</td>\n",
       "      <td>321.28</td>\n",
       "      <td>30.9480</td>\n",
       "      <td>58.414828</td>\n",
       "      <td>3.7800</td>\n",
       "      <td>3.7610</td>\n",
       "      <td>3.7955</td>\n",
       "      <td>3.775030</td>\n",
       "      <td>3.7760</td>\n",
       "      <td>3.770245</td>\n",
       "      <td>125890</td>\n",
       "      <td>3.7765</td>\n",
       "      <td>3.7780</td>\n",
       "      <td>23510</td>\n",
       "      <td>34.5</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-9.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25/07/2019</td>\n",
       "      <td>416.51</td>\n",
       "      <td>38.1060</td>\n",
       "      <td>72.105906</td>\n",
       "      <td>3.7680</td>\n",
       "      <td>3.7570</td>\n",
       "      <td>3.8070</td>\n",
       "      <td>3.784490</td>\n",
       "      <td>3.7795</td>\n",
       "      <td>3.782834</td>\n",
       "      <td>129780</td>\n",
       "      <td>3.7795</td>\n",
       "      <td>3.7805</td>\n",
       "      <td>15894</td>\n",
       "      <td>50.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>14.834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24/07/2019</td>\n",
       "      <td>261.37</td>\n",
       "      <td>26.9620</td>\n",
       "      <td>50.725253</td>\n",
       "      <td>3.7675</td>\n",
       "      <td>3.7540</td>\n",
       "      <td>3.7795</td>\n",
       "      <td>3.762721</td>\n",
       "      <td>3.7735</td>\n",
       "      <td>3.769856</td>\n",
       "      <td>31160</td>\n",
       "      <td>3.7735</td>\n",
       "      <td>3.7755</td>\n",
       "      <td>-7529</td>\n",
       "      <td>25.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23/07/2019</td>\n",
       "      <td>335.86</td>\n",
       "      <td>31.3840</td>\n",
       "      <td>59.121713</td>\n",
       "      <td>3.7450</td>\n",
       "      <td>3.7430</td>\n",
       "      <td>3.7820</td>\n",
       "      <td>3.767634</td>\n",
       "      <td>3.7750</td>\n",
       "      <td>3.772972</td>\n",
       "      <td>356000</td>\n",
       "      <td>3.7750</td>\n",
       "      <td>3.7770</td>\n",
       "      <td>-2908</td>\n",
       "      <td>39.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>27.972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Data  Número Negócios  Contratos Negociados     Volume  Abertura  \\\n",
       "0  29/07/2019           271.92               22.6625  42.939771    3.7850   \n",
       "1  26/07/2019           321.28               30.9480  58.414828    3.7800   \n",
       "2  25/07/2019           416.51               38.1060  72.105906    3.7680   \n",
       "3  24/07/2019           261.37               26.9620  50.725253    3.7675   \n",
       "4  23/07/2019           335.86               31.3840  59.121713    3.7450   \n",
       "\n",
       "   Mínimo  Máximo     Médio  Último Preço    Ajuste  Var pontos  \\\n",
       "0  3.7775  3.8015  3.789499        3.7820  3.784797      145520   \n",
       "1  3.7610  3.7955  3.775030        3.7760  3.770245      125890   \n",
       "2  3.7570  3.8070  3.784490        3.7795  3.782834      129780   \n",
       "3  3.7540  3.7795  3.762721        3.7735  3.769856       31160   \n",
       "4  3.7430  3.7820  3.767634        3.7750  3.772972      356000   \n",
       "\n",
       "   Última oferta de compra  Última oferta de venda  Dif_contratos  Dif_minmax  \\\n",
       "0                   3.7820                  3.7825         132520        24.0   \n",
       "1                   3.7765                  3.7780          23510        34.5   \n",
       "2                   3.7795                  3.7805          15894        50.0   \n",
       "3                   3.7735                  3.7755          -7529        25.5   \n",
       "4                   3.7750                  3.7770          -2908        39.0   \n",
       "\n",
       "   Dif_abert_ultimo  Dif_abert_ajuste  \n",
       "0              -3.0            -0.203  \n",
       "1              -4.0            -9.755  \n",
       "2              11.5            14.834  \n",
       "3               6.0             2.356  \n",
       "4              30.0            27.972  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_total.copy()\n",
    "\n",
    "df['Dif_contratos'] = df['Contratos Abertos'] -df['Contratos Fechados']\n",
    "df['Dif_minmax'] = (df['Máximo'] - df['Mínimo'])*1000\n",
    "df['Dif_abert_ultimo'] = (df['Último Preço'] - df['Abertura'])*1000\n",
    "df['Dif_abert_ajuste'] = (df['Ajuste'] - df['Abertura'])*1000\n",
    "\n",
    "df['Contratos Negociados'] = df['Contratos Negociados']/10000\n",
    "df['Número Negócios'] = df['Número Negócios']/100\n",
    "df['Volume'] = df['Volume']/1000000000\n",
    "\n",
    "df = df.drop(columns = ['Contratos Abertos', 'Contratos Fechados'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prever relação de abertura com último preço do dia anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T20:57:54.946368Z",
     "start_time": "2019-11-12T20:57:54.894394Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Número Negócios</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Var pontos</th>\n",
       "      <th>Dif_contratos</th>\n",
       "      <th>Dif_minmax</th>\n",
       "      <th>Dif_abert_ultimo</th>\n",
       "      <th>Dif_abert_ajuste</th>\n",
       "      <th>Média</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29/07/2019</td>\n",
       "      <td>271.92</td>\n",
       "      <td>42.939771</td>\n",
       "      <td>145520</td>\n",
       "      <td>132520</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>3.785600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26/07/2019</td>\n",
       "      <td>321.28</td>\n",
       "      <td>58.414828</td>\n",
       "      <td>125890</td>\n",
       "      <td>23510</td>\n",
       "      <td>34.5</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-9.755</td>\n",
       "      <td>3.776534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25/07/2019</td>\n",
       "      <td>416.51</td>\n",
       "      <td>72.105906</td>\n",
       "      <td>129780</td>\n",
       "      <td>15894</td>\n",
       "      <td>50.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>14.834</td>\n",
       "      <td>3.779853</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24/07/2019</td>\n",
       "      <td>261.37</td>\n",
       "      <td>50.725253</td>\n",
       "      <td>31160</td>\n",
       "      <td>-7529</td>\n",
       "      <td>25.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.356</td>\n",
       "      <td>3.769510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23/07/2019</td>\n",
       "      <td>335.86</td>\n",
       "      <td>59.121713</td>\n",
       "      <td>356000</td>\n",
       "      <td>-2908</td>\n",
       "      <td>39.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>27.972</td>\n",
       "      <td>3.767201</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Data  Número Negócios     Volume  Var pontos  Dif_contratos  \\\n",
       "0  29/07/2019           271.92  42.939771      145520         132520   \n",
       "1  26/07/2019           321.28  58.414828      125890          23510   \n",
       "2  25/07/2019           416.51  72.105906      129780          15894   \n",
       "3  24/07/2019           261.37  50.725253       31160          -7529   \n",
       "4  23/07/2019           335.86  59.121713      356000          -2908   \n",
       "\n",
       "   Dif_minmax  Dif_abert_ultimo  Dif_abert_ajuste     Média  target  \n",
       "0        24.0              -3.0            -0.203  3.785600       0  \n",
       "1        34.5              -4.0            -9.755  3.776534       0  \n",
       "2        50.0              11.5            14.834  3.779853       0  \n",
       "3        25.5               6.0             2.356  3.769510       0  \n",
       "4        39.0              30.0            27.972  3.767201       0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_abert_old = df.copy()\n",
    "\n",
    "#1 se o Ajuste for maior que a abertura\n",
    "\n",
    "df_abert_old['target'] = df_abert_old.Abertura.shift(-1) - df_abert_old['Último Preço']\n",
    "df_abert_old['target'] = df_abert_old['target'].apply(lambda x: 1 if x > 0 else 0)\n",
    "df_abert_old= df_abert_old.drop(len(df_abert_old)-1)\n",
    "\n",
    "df_abert_old['Média'] = (df_abert_old['Último Preço'] + df_abert_old['Abertura'] + df_abert_old['Máximo'] + df_abert_old['Mínimo'] + df_abert_old['Médio'] + df_abert_old['Ajuste'] + df_abert_old['Última oferta de compra']+ df_abert_old['Última oferta de venda'])/8\n",
    "df_abert_old = df_abert_old.drop(columns = ['Último Preço','Abertura','Máximo','Mínimo','Médio','Última oferta de compra','Última oferta de venda','Contratos Negociados', 'Ajuste'])\n",
    "\n",
    "\n",
    "df_change = df_abert_old[['target']]\n",
    "df_abert_old = df_abert_old.drop(columns = 'target')\n",
    "df_abert_old['target'] = df_change\n",
    "\n",
    "df_abert_old.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T20:57:55.185969Z",
     "start_time": "2019-11-12T20:57:55.088955Z"
    }
   },
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "df_abert_old.iloc[:,1:-1]  = sc.fit_transform(df_abert_old.iloc[:,1:-1])\n",
    "\n",
    "df_moeda = pd.read_csv('moedas_features.csv')\n",
    "\n",
    "sc = StandardScaler()\n",
    "df_moeda.iloc[:,1:] = sc.fit_transform(df_moeda.iloc[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T20:57:55.750830Z",
     "start_time": "2019-11-12T20:57:55.722845Z"
    }
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "dataset = pca.fit_transform(df_moeda.iloc[:,1:])\n",
    "df_moeda_pca = pd.DataFrame(dataset)\n",
    "df_moeda_pca['Data'] = df_moeda.iloc[:,0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T20:57:56.533727Z",
     "start_time": "2019-11-12T20:57:56.514739Z"
    }
   },
   "outputs": [],
   "source": [
    "df_abert = pd.merge(df_moeda_pca, df_abert_old, on = 'Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T20:57:57.401122Z",
     "start_time": "2019-11-12T20:57:57.146071Z"
    }
   },
   "outputs": [],
   "source": [
    "df_abert['Data'] = df_abert['Data'].apply(lambda x: datetime.strptime(x, '%d/%m/%Y'))\n",
    "df_abert = df_abert.set_index('Data')\n",
    "index = df_abert.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T20:58:03.283569Z",
     "start_time": "2019-11-12T20:58:03.266578Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.73532847,  1.39379165,  0.41961072, ...,  1.45966275,\n",
       "        -0.14090923,  2.00404183],\n",
       "       [ 1.09805362,  0.54176439,  0.47191898, ..., -0.04228311,\n",
       "        -0.20152269,  1.96200735],\n",
       "       [ 0.82863613,  1.1162082 ,  0.13776334, ...,  0.32404515,\n",
       "        -0.22171399,  1.97132267],\n",
       "       ...,\n",
       "       [ 2.6451383 ,  0.93990607,  0.91767352, ..., -0.44524419,\n",
       "        -0.23640773, -0.5714771 ],\n",
       "       [ 2.91088089,  0.57818229, -1.4766777 , ..., -0.44890747,\n",
       "        -0.23044289, -0.55704584],\n",
       "       [ 2.26629689,  1.88804074,  0.41997149, ...,  0.34236156,\n",
       "        -0.19171189, -0.55159947]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df_abert[['target']]\n",
    "X = df_abert.drop(columns = ['target'])\n",
    "X_columns = df_abert.drop(columns = ['target'])\n",
    "\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "#X = X.values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T20:58:12.354697Z",
     "start_time": "2019-11-12T20:58:12.272725Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2002-04-08</th>\n",
       "      <td>2.266297</td>\n",
       "      <td>1.888041</td>\n",
       "      <td>0.419971</td>\n",
       "      <td>-0.937079</td>\n",
       "      <td>-1.210821</td>\n",
       "      <td>-0.265971</td>\n",
       "      <td>-0.301365</td>\n",
       "      <td>-0.683915</td>\n",
       "      <td>0.342362</td>\n",
       "      <td>-0.191712</td>\n",
       "      <td>-0.551599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-04-09</th>\n",
       "      <td>2.910881</td>\n",
       "      <td>0.578182</td>\n",
       "      <td>-1.476678</td>\n",
       "      <td>-0.905017</td>\n",
       "      <td>-1.160755</td>\n",
       "      <td>-0.158175</td>\n",
       "      <td>-0.309351</td>\n",
       "      <td>-0.537950</td>\n",
       "      <td>-0.448907</td>\n",
       "      <td>-0.230443</td>\n",
       "      <td>-0.557046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-04-10</th>\n",
       "      <td>2.645138</td>\n",
       "      <td>0.939906</td>\n",
       "      <td>0.917674</td>\n",
       "      <td>-0.856420</td>\n",
       "      <td>-1.074617</td>\n",
       "      <td>-0.016797</td>\n",
       "      <td>-0.305396</td>\n",
       "      <td>0.009417</td>\n",
       "      <td>-0.445244</td>\n",
       "      <td>-0.236408</td>\n",
       "      <td>-0.571477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-04-11</th>\n",
       "      <td>2.543231</td>\n",
       "      <td>1.311120</td>\n",
       "      <td>-1.743147</td>\n",
       "      <td>-0.869307</td>\n",
       "      <td>-1.095037</td>\n",
       "      <td>-0.061335</td>\n",
       "      <td>-0.267990</td>\n",
       "      <td>-0.100057</td>\n",
       "      <td>0.562159</td>\n",
       "      <td>-0.182521</td>\n",
       "      <td>-0.569074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-04-12</th>\n",
       "      <td>2.454396</td>\n",
       "      <td>1.391975</td>\n",
       "      <td>0.899826</td>\n",
       "      <td>-0.919612</td>\n",
       "      <td>-1.161899</td>\n",
       "      <td>-0.406397</td>\n",
       "      <td>-0.325552</td>\n",
       "      <td>-0.428477</td>\n",
       "      <td>0.378994</td>\n",
       "      <td>-0.193771</td>\n",
       "      <td>-0.553645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-04-15</th>\n",
       "      <td>2.471694</td>\n",
       "      <td>1.436088</td>\n",
       "      <td>-0.344062</td>\n",
       "      <td>-0.883901</td>\n",
       "      <td>-1.110660</td>\n",
       "      <td>0.373421</td>\n",
       "      <td>-0.291040</td>\n",
       "      <td>-0.246021</td>\n",
       "      <td>0.690373</td>\n",
       "      <td>-0.177397</td>\n",
       "      <td>-0.535383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-04-16</th>\n",
       "      <td>2.951595</td>\n",
       "      <td>0.259932</td>\n",
       "      <td>1.613336</td>\n",
       "      <td>-0.910451</td>\n",
       "      <td>-1.072995</td>\n",
       "      <td>-0.791804</td>\n",
       "      <td>-0.191132</td>\n",
       "      <td>-0.574441</td>\n",
       "      <td>-0.023967</td>\n",
       "      <td>-0.210913</td>\n",
       "      <td>-0.532911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-04-17</th>\n",
       "      <td>3.048325</td>\n",
       "      <td>0.063750</td>\n",
       "      <td>-0.909315</td>\n",
       "      <td>-0.892208</td>\n",
       "      <td>-1.047026</td>\n",
       "      <td>-0.763843</td>\n",
       "      <td>-0.242325</td>\n",
       "      <td>-0.665669</td>\n",
       "      <td>0.250779</td>\n",
       "      <td>-0.197909</td>\n",
       "      <td>-0.533379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-04-18</th>\n",
       "      <td>2.525020</td>\n",
       "      <td>1.105218</td>\n",
       "      <td>-0.665255</td>\n",
       "      <td>-0.914178</td>\n",
       "      <td>-1.105640</td>\n",
       "      <td>-0.834103</td>\n",
       "      <td>-0.250754</td>\n",
       "      <td>-0.432126</td>\n",
       "      <td>0.049299</td>\n",
       "      <td>-0.205527</td>\n",
       "      <td>-0.526770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-04-19</th>\n",
       "      <td>2.596585</td>\n",
       "      <td>0.880417</td>\n",
       "      <td>0.110808</td>\n",
       "      <td>-0.996545</td>\n",
       "      <td>-1.248565</td>\n",
       "      <td>-0.698679</td>\n",
       "      <td>-0.289258</td>\n",
       "      <td>-0.519705</td>\n",
       "      <td>0.214147</td>\n",
       "      <td>-0.200847</td>\n",
       "      <td>-0.529767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-04-22</th>\n",
       "      <td>2.218764</td>\n",
       "      <td>1.837972</td>\n",
       "      <td>-1.222592</td>\n",
       "      <td>-0.915032</td>\n",
       "      <td>-1.166105</td>\n",
       "      <td>-0.461795</td>\n",
       "      <td>-0.295867</td>\n",
       "      <td>-0.355495</td>\n",
       "      <td>0.232463</td>\n",
       "      <td>-0.201607</td>\n",
       "      <td>-0.522244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-04-23</th>\n",
       "      <td>2.389607</td>\n",
       "      <td>1.428733</td>\n",
       "      <td>-0.576872</td>\n",
       "      <td>-0.868919</td>\n",
       "      <td>-1.014454</td>\n",
       "      <td>-0.067671</td>\n",
       "      <td>-0.219806</td>\n",
       "      <td>-0.246021</td>\n",
       "      <td>0.745323</td>\n",
       "      <td>-0.176714</td>\n",
       "      <td>-0.510245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-04-24</th>\n",
       "      <td>2.691918</td>\n",
       "      <td>0.748745</td>\n",
       "      <td>-1.187293</td>\n",
       "      <td>-0.866900</td>\n",
       "      <td>-0.961818</td>\n",
       "      <td>-0.721925</td>\n",
       "      <td>-0.214384</td>\n",
       "      <td>-0.574441</td>\n",
       "      <td>-0.133865</td>\n",
       "      <td>-0.218258</td>\n",
       "      <td>-0.505611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-04-25</th>\n",
       "      <td>2.824050</td>\n",
       "      <td>0.284073</td>\n",
       "      <td>-0.484901</td>\n",
       "      <td>-0.883436</td>\n",
       "      <td>-1.031726</td>\n",
       "      <td>-0.719924</td>\n",
       "      <td>-0.162409</td>\n",
       "      <td>-0.246021</td>\n",
       "      <td>0.195830</td>\n",
       "      <td>-0.203597</td>\n",
       "      <td>-0.502663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-04-26</th>\n",
       "      <td>2.537419</td>\n",
       "      <td>0.917082</td>\n",
       "      <td>-2.183657</td>\n",
       "      <td>-0.906803</td>\n",
       "      <td>-1.064786</td>\n",
       "      <td>-0.478943</td>\n",
       "      <td>-0.205425</td>\n",
       "      <td>-0.246021</td>\n",
       "      <td>0.378994</td>\n",
       "      <td>-0.190626</td>\n",
       "      <td>-0.502537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-04-29</th>\n",
       "      <td>2.432043</td>\n",
       "      <td>0.957769</td>\n",
       "      <td>-0.425225</td>\n",
       "      <td>-0.858982</td>\n",
       "      <td>-0.739828</td>\n",
       "      <td>-0.482754</td>\n",
       "      <td>-0.144426</td>\n",
       "      <td>-0.574441</td>\n",
       "      <td>-0.390295</td>\n",
       "      <td>-0.228613</td>\n",
       "      <td>-0.500173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-04-30</th>\n",
       "      <td>2.331479</td>\n",
       "      <td>1.109370</td>\n",
       "      <td>1.211189</td>\n",
       "      <td>-1.109110</td>\n",
       "      <td>-1.326473</td>\n",
       "      <td>-0.570544</td>\n",
       "      <td>-0.191613</td>\n",
       "      <td>-0.884616</td>\n",
       "      <td>-0.207131</td>\n",
       "      <td>-0.220156</td>\n",
       "      <td>-0.506619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-05-02</th>\n",
       "      <td>2.072110</td>\n",
       "      <td>1.696645</td>\n",
       "      <td>-0.505742</td>\n",
       "      <td>-1.158562</td>\n",
       "      <td>-1.452475</td>\n",
       "      <td>-0.870353</td>\n",
       "      <td>1.071855</td>\n",
       "      <td>-1.231282</td>\n",
       "      <td>0.012666</td>\n",
       "      <td>4.035564</td>\n",
       "      <td>-2.260460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-05-03</th>\n",
       "      <td>3.025662</td>\n",
       "      <td>-0.418595</td>\n",
       "      <td>-2.013664</td>\n",
       "      <td>-0.870704</td>\n",
       "      <td>-1.080512</td>\n",
       "      <td>-0.436835</td>\n",
       "      <td>-0.304802</td>\n",
       "      <td>-0.282512</td>\n",
       "      <td>0.159197</td>\n",
       "      <td>-0.198680</td>\n",
       "      <td>-0.440062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-05-06</th>\n",
       "      <td>2.135930</td>\n",
       "      <td>1.395892</td>\n",
       "      <td>-1.551590</td>\n",
       "      <td>-0.904784</td>\n",
       "      <td>-1.144886</td>\n",
       "      <td>-0.252681</td>\n",
       "      <td>-0.336546</td>\n",
       "      <td>-0.464968</td>\n",
       "      <td>-0.317029</td>\n",
       "      <td>-0.220305</td>\n",
       "      <td>-0.424844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-05-07</th>\n",
       "      <td>1.958711</td>\n",
       "      <td>1.729192</td>\n",
       "      <td>0.197858</td>\n",
       "      <td>-0.840661</td>\n",
       "      <td>-1.006674</td>\n",
       "      <td>-0.508619</td>\n",
       "      <td>-0.327296</td>\n",
       "      <td>-0.209530</td>\n",
       "      <td>0.598791</td>\n",
       "      <td>-0.186888</td>\n",
       "      <td>-0.428596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-05-08</th>\n",
       "      <td>2.072827</td>\n",
       "      <td>1.402084</td>\n",
       "      <td>4.707945</td>\n",
       "      <td>-0.838565</td>\n",
       "      <td>-1.053542</td>\n",
       "      <td>-0.599886</td>\n",
       "      <td>-0.299494</td>\n",
       "      <td>-0.537950</td>\n",
       "      <td>-0.005650</td>\n",
       "      <td>-0.210830</td>\n",
       "      <td>-0.419030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-05-09</th>\n",
       "      <td>2.571989</td>\n",
       "      <td>0.691832</td>\n",
       "      <td>-1.607957</td>\n",
       "      <td>-0.818303</td>\n",
       "      <td>-0.972771</td>\n",
       "      <td>0.419388</td>\n",
       "      <td>-0.286276</td>\n",
       "      <td>0.009417</td>\n",
       "      <td>1.221549</td>\n",
       "      <td>-0.160373</td>\n",
       "      <td>-0.401135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-05-10</th>\n",
       "      <td>2.487021</td>\n",
       "      <td>0.772483</td>\n",
       "      <td>-1.755250</td>\n",
       "      <td>-0.786940</td>\n",
       "      <td>-0.922980</td>\n",
       "      <td>-0.660810</td>\n",
       "      <td>-0.291672</td>\n",
       "      <td>0.337837</td>\n",
       "      <td>-0.829889</td>\n",
       "      <td>-0.245557</td>\n",
       "      <td>-0.387325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-05-13</th>\n",
       "      <td>2.268850</td>\n",
       "      <td>1.038073</td>\n",
       "      <td>1.754439</td>\n",
       "      <td>-0.840738</td>\n",
       "      <td>-0.998228</td>\n",
       "      <td>1.742854</td>\n",
       "      <td>-0.289044</td>\n",
       "      <td>1.213624</td>\n",
       "      <td>2.045788</td>\n",
       "      <td>-0.104730</td>\n",
       "      <td>-0.368576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-05-14</th>\n",
       "      <td>1.991790</td>\n",
       "      <td>1.763403</td>\n",
       "      <td>2.252742</td>\n",
       "      <td>-0.782049</td>\n",
       "      <td>-0.979765</td>\n",
       "      <td>0.180884</td>\n",
       "      <td>-0.315910</td>\n",
       "      <td>0.994678</td>\n",
       "      <td>-0.463561</td>\n",
       "      <td>-0.244136</td>\n",
       "      <td>-0.355043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-05-15</th>\n",
       "      <td>3.092224</td>\n",
       "      <td>-0.573077</td>\n",
       "      <td>-0.260100</td>\n",
       "      <td>-0.758682</td>\n",
       "      <td>-0.917454</td>\n",
       "      <td>-0.633230</td>\n",
       "      <td>-0.234831</td>\n",
       "      <td>0.191872</td>\n",
       "      <td>-0.170498</td>\n",
       "      <td>-0.210029</td>\n",
       "      <td>-0.363473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-05-16</th>\n",
       "      <td>2.228191</td>\n",
       "      <td>1.192205</td>\n",
       "      <td>0.234377</td>\n",
       "      <td>-0.844542</td>\n",
       "      <td>-1.064697</td>\n",
       "      <td>1.189108</td>\n",
       "      <td>-0.265349</td>\n",
       "      <td>0.410819</td>\n",
       "      <td>-1.562545</td>\n",
       "      <td>-0.284135</td>\n",
       "      <td>-0.387771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-05-17</th>\n",
       "      <td>2.976164</td>\n",
       "      <td>-0.547401</td>\n",
       "      <td>-0.710732</td>\n",
       "      <td>-0.867909</td>\n",
       "      <td>-1.043092</td>\n",
       "      <td>-0.566828</td>\n",
       "      <td>-0.291773</td>\n",
       "      <td>0.082399</td>\n",
       "      <td>0.342362</td>\n",
       "      <td>-0.193608</td>\n",
       "      <td>-0.398242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-05-20</th>\n",
       "      <td>2.236947</td>\n",
       "      <td>0.967380</td>\n",
       "      <td>-1.195967</td>\n",
       "      <td>-0.908511</td>\n",
       "      <td>-1.122908</td>\n",
       "      <td>-0.631658</td>\n",
       "      <td>-0.221512</td>\n",
       "      <td>-0.246021</td>\n",
       "      <td>0.232463</td>\n",
       "      <td>-0.198980</td>\n",
       "      <td>-0.395402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-03</th>\n",
       "      <td>1.572596</td>\n",
       "      <td>-0.320607</td>\n",
       "      <td>0.717437</td>\n",
       "      <td>1.569718</td>\n",
       "      <td>1.474739</td>\n",
       "      <td>0.362799</td>\n",
       "      <td>-0.188264</td>\n",
       "      <td>0.118890</td>\n",
       "      <td>-0.921471</td>\n",
       "      <td>-0.255292</td>\n",
       "      <td>2.081105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-06</th>\n",
       "      <td>1.044927</td>\n",
       "      <td>0.861009</td>\n",
       "      <td>-0.085858</td>\n",
       "      <td>1.291254</td>\n",
       "      <td>1.539624</td>\n",
       "      <td>-0.186327</td>\n",
       "      <td>-0.655907</td>\n",
       "      <td>-0.246021</td>\n",
       "      <td>0.067615</td>\n",
       "      <td>-0.229485</td>\n",
       "      <td>2.101834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-07</th>\n",
       "      <td>0.938439</td>\n",
       "      <td>1.150389</td>\n",
       "      <td>-1.096252</td>\n",
       "      <td>2.689397</td>\n",
       "      <td>2.698273</td>\n",
       "      <td>0.290967</td>\n",
       "      <td>-0.443758</td>\n",
       "      <td>0.082399</td>\n",
       "      <td>0.250779</td>\n",
       "      <td>-0.185670</td>\n",
       "      <td>2.116313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-08</th>\n",
       "      <td>1.053444</td>\n",
       "      <td>0.829761</td>\n",
       "      <td>0.113240</td>\n",
       "      <td>2.730386</td>\n",
       "      <td>2.722381</td>\n",
       "      <td>1.453000</td>\n",
       "      <td>-0.471003</td>\n",
       "      <td>0.739240</td>\n",
       "      <td>-1.837292</td>\n",
       "      <td>-0.297589</td>\n",
       "      <td>2.076157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-09</th>\n",
       "      <td>1.232951</td>\n",
       "      <td>0.465846</td>\n",
       "      <td>-0.512005</td>\n",
       "      <td>3.042542</td>\n",
       "      <td>2.950229</td>\n",
       "      <td>-0.119592</td>\n",
       "      <td>-0.416538</td>\n",
       "      <td>0.556784</td>\n",
       "      <td>0.085932</td>\n",
       "      <td>-0.208160</td>\n",
       "      <td>2.085844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-10</th>\n",
       "      <td>1.256072</td>\n",
       "      <td>0.331032</td>\n",
       "      <td>0.440197</td>\n",
       "      <td>2.579704</td>\n",
       "      <td>2.877954</td>\n",
       "      <td>-0.640042</td>\n",
       "      <td>-0.416879</td>\n",
       "      <td>0.118890</td>\n",
       "      <td>0.232463</td>\n",
       "      <td>-0.197673</td>\n",
       "      <td>2.086331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-13</th>\n",
       "      <td>0.889961</td>\n",
       "      <td>1.259207</td>\n",
       "      <td>-2.074737</td>\n",
       "      <td>3.399802</td>\n",
       "      <td>3.227334</td>\n",
       "      <td>0.317927</td>\n",
       "      <td>-0.432208</td>\n",
       "      <td>-0.063566</td>\n",
       "      <td>0.855221</td>\n",
       "      <td>-0.204959</td>\n",
       "      <td>2.129214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-14</th>\n",
       "      <td>1.101829</td>\n",
       "      <td>0.611026</td>\n",
       "      <td>1.189291</td>\n",
       "      <td>2.135031</td>\n",
       "      <td>2.465796</td>\n",
       "      <td>-0.794996</td>\n",
       "      <td>-0.296942</td>\n",
       "      <td>-0.173039</td>\n",
       "      <td>-0.591775</td>\n",
       "      <td>-0.236262</td>\n",
       "      <td>2.119198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-15</th>\n",
       "      <td>1.126609</td>\n",
       "      <td>0.609357</td>\n",
       "      <td>0.731739</td>\n",
       "      <td>3.006754</td>\n",
       "      <td>3.008820</td>\n",
       "      <td>-0.484326</td>\n",
       "      <td>-0.418345</td>\n",
       "      <td>0.520293</td>\n",
       "      <td>-0.042283</td>\n",
       "      <td>-0.239670</td>\n",
       "      <td>2.141236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-16</th>\n",
       "      <td>0.997059</td>\n",
       "      <td>0.918357</td>\n",
       "      <td>0.996903</td>\n",
       "      <td>2.682876</td>\n",
       "      <td>2.733035</td>\n",
       "      <td>1.409177</td>\n",
       "      <td>-0.423248</td>\n",
       "      <td>0.958186</td>\n",
       "      <td>1.697776</td>\n",
       "      <td>-0.150970</td>\n",
       "      <td>2.179541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-17</th>\n",
       "      <td>0.984709</td>\n",
       "      <td>1.070922</td>\n",
       "      <td>-0.113522</td>\n",
       "      <td>3.698916</td>\n",
       "      <td>4.136810</td>\n",
       "      <td>2.248728</td>\n",
       "      <td>-0.598131</td>\n",
       "      <td>1.140642</td>\n",
       "      <td>1.569561</td>\n",
       "      <td>-0.133034</td>\n",
       "      <td>2.246514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-20</th>\n",
       "      <td>1.158999</td>\n",
       "      <td>0.729133</td>\n",
       "      <td>-0.501854</td>\n",
       "      <td>2.424286</td>\n",
       "      <td>2.618765</td>\n",
       "      <td>-0.837485</td>\n",
       "      <td>-0.310463</td>\n",
       "      <td>0.374328</td>\n",
       "      <td>0.324045</td>\n",
       "      <td>-0.186392</td>\n",
       "      <td>2.256437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-21</th>\n",
       "      <td>1.156838</td>\n",
       "      <td>0.661557</td>\n",
       "      <td>0.994566</td>\n",
       "      <td>2.816945</td>\n",
       "      <td>3.279512</td>\n",
       "      <td>1.558415</td>\n",
       "      <td>0.079349</td>\n",
       "      <td>1.688009</td>\n",
       "      <td>-1.928874</td>\n",
       "      <td>-0.284317</td>\n",
       "      <td>2.210989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-22</th>\n",
       "      <td>1.162221</td>\n",
       "      <td>0.723280</td>\n",
       "      <td>-0.129582</td>\n",
       "      <td>2.592901</td>\n",
       "      <td>2.998015</td>\n",
       "      <td>-0.291456</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>0.392574</td>\n",
       "      <td>0.030983</td>\n",
       "      <td>-0.210908</td>\n",
       "      <td>2.181932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-23</th>\n",
       "      <td>1.269815</td>\n",
       "      <td>0.520350</td>\n",
       "      <td>-1.166300</td>\n",
       "      <td>2.443383</td>\n",
       "      <td>2.558349</td>\n",
       "      <td>-0.457175</td>\n",
       "      <td>-0.358711</td>\n",
       "      <td>0.429065</td>\n",
       "      <td>-0.555143</td>\n",
       "      <td>-0.224972</td>\n",
       "      <td>2.194197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-24</th>\n",
       "      <td>1.437514</td>\n",
       "      <td>-0.027904</td>\n",
       "      <td>0.242691</td>\n",
       "      <td>1.789571</td>\n",
       "      <td>1.940952</td>\n",
       "      <td>0.810369</td>\n",
       "      <td>-0.360366</td>\n",
       "      <td>0.191872</td>\n",
       "      <td>-0.573459</td>\n",
       "      <td>-0.256035</td>\n",
       "      <td>2.168478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-28</th>\n",
       "      <td>0.887036</td>\n",
       "      <td>1.238879</td>\n",
       "      <td>-0.273638</td>\n",
       "      <td>2.239290</td>\n",
       "      <td>2.259935</td>\n",
       "      <td>0.061037</td>\n",
       "      <td>0.131325</td>\n",
       "      <td>0.337837</td>\n",
       "      <td>-0.665041</td>\n",
       "      <td>-0.258885</td>\n",
       "      <td>2.170173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-29</th>\n",
       "      <td>1.039459</td>\n",
       "      <td>0.927443</td>\n",
       "      <td>-0.344717</td>\n",
       "      <td>2.390438</td>\n",
       "      <td>2.900155</td>\n",
       "      <td>0.770642</td>\n",
       "      <td>0.596352</td>\n",
       "      <td>1.414326</td>\n",
       "      <td>-2.368468</td>\n",
       "      <td>-0.311812</td>\n",
       "      <td>2.128152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-30</th>\n",
       "      <td>1.186858</td>\n",
       "      <td>0.562444</td>\n",
       "      <td>0.464503</td>\n",
       "      <td>2.416911</td>\n",
       "      <td>2.866727</td>\n",
       "      <td>-0.104682</td>\n",
       "      <td>1.239118</td>\n",
       "      <td>0.191872</td>\n",
       "      <td>0.415627</td>\n",
       "      <td>-0.216694</td>\n",
       "      <td>2.106207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-31</th>\n",
       "      <td>1.369869</td>\n",
       "      <td>0.207848</td>\n",
       "      <td>-1.507113</td>\n",
       "      <td>-0.906259</td>\n",
       "      <td>-1.212898</td>\n",
       "      <td>0.402716</td>\n",
       "      <td>-0.283332</td>\n",
       "      <td>1.104151</td>\n",
       "      <td>-2.166987</td>\n",
       "      <td>-0.316844</td>\n",
       "      <td>2.085956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-03</th>\n",
       "      <td>1.441688</td>\n",
       "      <td>-0.138140</td>\n",
       "      <td>-0.589428</td>\n",
       "      <td>-1.158562</td>\n",
       "      <td>-1.452475</td>\n",
       "      <td>-0.870353</td>\n",
       "      <td>-0.264679</td>\n",
       "      <td>-1.231282</td>\n",
       "      <td>0.012666</td>\n",
       "      <td>6.871872</td>\n",
       "      <td>-2.026398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-04</th>\n",
       "      <td>1.303184</td>\n",
       "      <td>-0.028032</td>\n",
       "      <td>1.729496</td>\n",
       "      <td>2.319561</td>\n",
       "      <td>2.165101</td>\n",
       "      <td>1.277278</td>\n",
       "      <td>-0.356285</td>\n",
       "      <td>0.228364</td>\n",
       "      <td>-1.214534</td>\n",
       "      <td>-0.270033</td>\n",
       "      <td>1.982946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-05</th>\n",
       "      <td>0.972925</td>\n",
       "      <td>0.749079</td>\n",
       "      <td>0.998726</td>\n",
       "      <td>3.044406</td>\n",
       "      <td>3.274953</td>\n",
       "      <td>0.323786</td>\n",
       "      <td>-0.080824</td>\n",
       "      <td>1.140642</td>\n",
       "      <td>0.855221</td>\n",
       "      <td>-0.168368</td>\n",
       "      <td>1.993482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-06</th>\n",
       "      <td>1.343886</td>\n",
       "      <td>-0.030388</td>\n",
       "      <td>0.508779</td>\n",
       "      <td>1.948405</td>\n",
       "      <td>1.759012</td>\n",
       "      <td>-0.685723</td>\n",
       "      <td>-0.422111</td>\n",
       "      <td>-0.100057</td>\n",
       "      <td>0.232463</td>\n",
       "      <td>-0.204089</td>\n",
       "      <td>1.996038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-07</th>\n",
       "      <td>1.437489</td>\n",
       "      <td>-0.307163</td>\n",
       "      <td>0.818988</td>\n",
       "      <td>1.726068</td>\n",
       "      <td>1.513365</td>\n",
       "      <td>-0.433977</td>\n",
       "      <td>-0.304347</td>\n",
       "      <td>0.100645</td>\n",
       "      <td>-0.133865</td>\n",
       "      <td>-0.233133</td>\n",
       "      <td>1.991358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-10</th>\n",
       "      <td>0.987897</td>\n",
       "      <td>0.700415</td>\n",
       "      <td>0.687378</td>\n",
       "      <td>1.135138</td>\n",
       "      <td>1.009112</td>\n",
       "      <td>-0.530674</td>\n",
       "      <td>-0.044443</td>\n",
       "      <td>-0.063566</td>\n",
       "      <td>-0.298713</td>\n",
       "      <td>-0.242782</td>\n",
       "      <td>2.005664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-11</th>\n",
       "      <td>1.066534</td>\n",
       "      <td>0.566053</td>\n",
       "      <td>0.216478</td>\n",
       "      <td>1.440928</td>\n",
       "      <td>1.360039</td>\n",
       "      <td>0.499652</td>\n",
       "      <td>-0.256491</td>\n",
       "      <td>0.319591</td>\n",
       "      <td>-0.884838</td>\n",
       "      <td>-0.269310</td>\n",
       "      <td>1.975954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-12</th>\n",
       "      <td>0.828636</td>\n",
       "      <td>1.116208</td>\n",
       "      <td>0.137763</td>\n",
       "      <td>2.248373</td>\n",
       "      <td>2.278286</td>\n",
       "      <td>-0.704396</td>\n",
       "      <td>-0.174654</td>\n",
       "      <td>0.301346</td>\n",
       "      <td>0.324045</td>\n",
       "      <td>-0.221714</td>\n",
       "      <td>1.971323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-13</th>\n",
       "      <td>1.098054</td>\n",
       "      <td>0.541764</td>\n",
       "      <td>0.471919</td>\n",
       "      <td>1.809444</td>\n",
       "      <td>2.101556</td>\n",
       "      <td>-0.716256</td>\n",
       "      <td>-0.474011</td>\n",
       "      <td>-0.136548</td>\n",
       "      <td>-0.042283</td>\n",
       "      <td>-0.201523</td>\n",
       "      <td>1.962007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-14</th>\n",
       "      <td>0.735328</td>\n",
       "      <td>1.393792</td>\n",
       "      <td>0.419611</td>\n",
       "      <td>2.600897</td>\n",
       "      <td>2.397367</td>\n",
       "      <td>0.974373</td>\n",
       "      <td>-0.200282</td>\n",
       "      <td>1.158888</td>\n",
       "      <td>1.459663</td>\n",
       "      <td>-0.140909</td>\n",
       "      <td>2.004042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4146 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0         1         2         3         4         5   \\\n",
       "Data                                                                     \n",
       "2002-04-08  2.266297  1.888041  0.419971 -0.937079 -1.210821 -0.265971   \n",
       "2002-04-09  2.910881  0.578182 -1.476678 -0.905017 -1.160755 -0.158175   \n",
       "2002-04-10  2.645138  0.939906  0.917674 -0.856420 -1.074617 -0.016797   \n",
       "2002-04-11  2.543231  1.311120 -1.743147 -0.869307 -1.095037 -0.061335   \n",
       "2002-04-12  2.454396  1.391975  0.899826 -0.919612 -1.161899 -0.406397   \n",
       "2002-04-15  2.471694  1.436088 -0.344062 -0.883901 -1.110660  0.373421   \n",
       "2002-04-16  2.951595  0.259932  1.613336 -0.910451 -1.072995 -0.791804   \n",
       "2002-04-17  3.048325  0.063750 -0.909315 -0.892208 -1.047026 -0.763843   \n",
       "2002-04-18  2.525020  1.105218 -0.665255 -0.914178 -1.105640 -0.834103   \n",
       "2002-04-19  2.596585  0.880417  0.110808 -0.996545 -1.248565 -0.698679   \n",
       "2002-04-22  2.218764  1.837972 -1.222592 -0.915032 -1.166105 -0.461795   \n",
       "2002-04-23  2.389607  1.428733 -0.576872 -0.868919 -1.014454 -0.067671   \n",
       "2002-04-24  2.691918  0.748745 -1.187293 -0.866900 -0.961818 -0.721925   \n",
       "2002-04-25  2.824050  0.284073 -0.484901 -0.883436 -1.031726 -0.719924   \n",
       "2002-04-26  2.537419  0.917082 -2.183657 -0.906803 -1.064786 -0.478943   \n",
       "2002-04-29  2.432043  0.957769 -0.425225 -0.858982 -0.739828 -0.482754   \n",
       "2002-04-30  2.331479  1.109370  1.211189 -1.109110 -1.326473 -0.570544   \n",
       "2002-05-02  2.072110  1.696645 -0.505742 -1.158562 -1.452475 -0.870353   \n",
       "2002-05-03  3.025662 -0.418595 -2.013664 -0.870704 -1.080512 -0.436835   \n",
       "2002-05-06  2.135930  1.395892 -1.551590 -0.904784 -1.144886 -0.252681   \n",
       "2002-05-07  1.958711  1.729192  0.197858 -0.840661 -1.006674 -0.508619   \n",
       "2002-05-08  2.072827  1.402084  4.707945 -0.838565 -1.053542 -0.599886   \n",
       "2002-05-09  2.571989  0.691832 -1.607957 -0.818303 -0.972771  0.419388   \n",
       "2002-05-10  2.487021  0.772483 -1.755250 -0.786940 -0.922980 -0.660810   \n",
       "2002-05-13  2.268850  1.038073  1.754439 -0.840738 -0.998228  1.742854   \n",
       "2002-05-14  1.991790  1.763403  2.252742 -0.782049 -0.979765  0.180884   \n",
       "2002-05-15  3.092224 -0.573077 -0.260100 -0.758682 -0.917454 -0.633230   \n",
       "2002-05-16  2.228191  1.192205  0.234377 -0.844542 -1.064697  1.189108   \n",
       "2002-05-17  2.976164 -0.547401 -0.710732 -0.867909 -1.043092 -0.566828   \n",
       "2002-05-20  2.236947  0.967380 -1.195967 -0.908511 -1.122908 -0.631658   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2019-05-03  1.572596 -0.320607  0.717437  1.569718  1.474739  0.362799   \n",
       "2019-05-06  1.044927  0.861009 -0.085858  1.291254  1.539624 -0.186327   \n",
       "2019-05-07  0.938439  1.150389 -1.096252  2.689397  2.698273  0.290967   \n",
       "2019-05-08  1.053444  0.829761  0.113240  2.730386  2.722381  1.453000   \n",
       "2019-05-09  1.232951  0.465846 -0.512005  3.042542  2.950229 -0.119592   \n",
       "2019-05-10  1.256072  0.331032  0.440197  2.579704  2.877954 -0.640042   \n",
       "2019-05-13  0.889961  1.259207 -2.074737  3.399802  3.227334  0.317927   \n",
       "2019-05-14  1.101829  0.611026  1.189291  2.135031  2.465796 -0.794996   \n",
       "2019-05-15  1.126609  0.609357  0.731739  3.006754  3.008820 -0.484326   \n",
       "2019-05-16  0.997059  0.918357  0.996903  2.682876  2.733035  1.409177   \n",
       "2019-05-17  0.984709  1.070922 -0.113522  3.698916  4.136810  2.248728   \n",
       "2019-05-20  1.158999  0.729133 -0.501854  2.424286  2.618765 -0.837485   \n",
       "2019-05-21  1.156838  0.661557  0.994566  2.816945  3.279512  1.558415   \n",
       "2019-05-22  1.162221  0.723280 -0.129582  2.592901  2.998015 -0.291456   \n",
       "2019-05-23  1.269815  0.520350 -1.166300  2.443383  2.558349 -0.457175   \n",
       "2019-05-24  1.437514 -0.027904  0.242691  1.789571  1.940952  0.810369   \n",
       "2019-05-28  0.887036  1.238879 -0.273638  2.239290  2.259935  0.061037   \n",
       "2019-05-29  1.039459  0.927443 -0.344717  2.390438  2.900155  0.770642   \n",
       "2019-05-30  1.186858  0.562444  0.464503  2.416911  2.866727 -0.104682   \n",
       "2019-05-31  1.369869  0.207848 -1.507113 -0.906259 -1.212898  0.402716   \n",
       "2019-06-03  1.441688 -0.138140 -0.589428 -1.158562 -1.452475 -0.870353   \n",
       "2019-06-04  1.303184 -0.028032  1.729496  2.319561  2.165101  1.277278   \n",
       "2019-06-05  0.972925  0.749079  0.998726  3.044406  3.274953  0.323786   \n",
       "2019-06-06  1.343886 -0.030388  0.508779  1.948405  1.759012 -0.685723   \n",
       "2019-06-07  1.437489 -0.307163  0.818988  1.726068  1.513365 -0.433977   \n",
       "2019-06-10  0.987897  0.700415  0.687378  1.135138  1.009112 -0.530674   \n",
       "2019-06-11  1.066534  0.566053  0.216478  1.440928  1.360039  0.499652   \n",
       "2019-06-12  0.828636  1.116208  0.137763  2.248373  2.278286 -0.704396   \n",
       "2019-06-13  1.098054  0.541764  0.471919  1.809444  2.101556 -0.716256   \n",
       "2019-06-14  0.735328  1.393792  0.419611  2.600897  2.397367  0.974373   \n",
       "\n",
       "                  6         7         8         9         10  \n",
       "Data                                                          \n",
       "2002-04-08 -0.301365 -0.683915  0.342362 -0.191712 -0.551599  \n",
       "2002-04-09 -0.309351 -0.537950 -0.448907 -0.230443 -0.557046  \n",
       "2002-04-10 -0.305396  0.009417 -0.445244 -0.236408 -0.571477  \n",
       "2002-04-11 -0.267990 -0.100057  0.562159 -0.182521 -0.569074  \n",
       "2002-04-12 -0.325552 -0.428477  0.378994 -0.193771 -0.553645  \n",
       "2002-04-15 -0.291040 -0.246021  0.690373 -0.177397 -0.535383  \n",
       "2002-04-16 -0.191132 -0.574441 -0.023967 -0.210913 -0.532911  \n",
       "2002-04-17 -0.242325 -0.665669  0.250779 -0.197909 -0.533379  \n",
       "2002-04-18 -0.250754 -0.432126  0.049299 -0.205527 -0.526770  \n",
       "2002-04-19 -0.289258 -0.519705  0.214147 -0.200847 -0.529767  \n",
       "2002-04-22 -0.295867 -0.355495  0.232463 -0.201607 -0.522244  \n",
       "2002-04-23 -0.219806 -0.246021  0.745323 -0.176714 -0.510245  \n",
       "2002-04-24 -0.214384 -0.574441 -0.133865 -0.218258 -0.505611  \n",
       "2002-04-25 -0.162409 -0.246021  0.195830 -0.203597 -0.502663  \n",
       "2002-04-26 -0.205425 -0.246021  0.378994 -0.190626 -0.502537  \n",
       "2002-04-29 -0.144426 -0.574441 -0.390295 -0.228613 -0.500173  \n",
       "2002-04-30 -0.191613 -0.884616 -0.207131 -0.220156 -0.506619  \n",
       "2002-05-02  1.071855 -1.231282  0.012666  4.035564 -2.260460  \n",
       "2002-05-03 -0.304802 -0.282512  0.159197 -0.198680 -0.440062  \n",
       "2002-05-06 -0.336546 -0.464968 -0.317029 -0.220305 -0.424844  \n",
       "2002-05-07 -0.327296 -0.209530  0.598791 -0.186888 -0.428596  \n",
       "2002-05-08 -0.299494 -0.537950 -0.005650 -0.210830 -0.419030  \n",
       "2002-05-09 -0.286276  0.009417  1.221549 -0.160373 -0.401135  \n",
       "2002-05-10 -0.291672  0.337837 -0.829889 -0.245557 -0.387325  \n",
       "2002-05-13 -0.289044  1.213624  2.045788 -0.104730 -0.368576  \n",
       "2002-05-14 -0.315910  0.994678 -0.463561 -0.244136 -0.355043  \n",
       "2002-05-15 -0.234831  0.191872 -0.170498 -0.210029 -0.363473  \n",
       "2002-05-16 -0.265349  0.410819 -1.562545 -0.284135 -0.387771  \n",
       "2002-05-17 -0.291773  0.082399  0.342362 -0.193608 -0.398242  \n",
       "2002-05-20 -0.221512 -0.246021  0.232463 -0.198980 -0.395402  \n",
       "...              ...       ...       ...       ...       ...  \n",
       "2019-05-03 -0.188264  0.118890 -0.921471 -0.255292  2.081105  \n",
       "2019-05-06 -0.655907 -0.246021  0.067615 -0.229485  2.101834  \n",
       "2019-05-07 -0.443758  0.082399  0.250779 -0.185670  2.116313  \n",
       "2019-05-08 -0.471003  0.739240 -1.837292 -0.297589  2.076157  \n",
       "2019-05-09 -0.416538  0.556784  0.085932 -0.208160  2.085844  \n",
       "2019-05-10 -0.416879  0.118890  0.232463 -0.197673  2.086331  \n",
       "2019-05-13 -0.432208 -0.063566  0.855221 -0.204959  2.129214  \n",
       "2019-05-14 -0.296942 -0.173039 -0.591775 -0.236262  2.119198  \n",
       "2019-05-15 -0.418345  0.520293 -0.042283 -0.239670  2.141236  \n",
       "2019-05-16 -0.423248  0.958186  1.697776 -0.150970  2.179541  \n",
       "2019-05-17 -0.598131  1.140642  1.569561 -0.133034  2.246514  \n",
       "2019-05-20 -0.310463  0.374328  0.324045 -0.186392  2.256437  \n",
       "2019-05-21  0.079349  1.688009 -1.928874 -0.284317  2.210989  \n",
       "2019-05-22 -0.183361  0.392574  0.030983 -0.210908  2.181932  \n",
       "2019-05-23 -0.358711  0.429065 -0.555143 -0.224972  2.194197  \n",
       "2019-05-24 -0.360366  0.191872 -0.573459 -0.256035  2.168478  \n",
       "2019-05-28  0.131325  0.337837 -0.665041 -0.258885  2.170173  \n",
       "2019-05-29  0.596352  1.414326 -2.368468 -0.311812  2.128152  \n",
       "2019-05-30  1.239118  0.191872  0.415627 -0.216694  2.106207  \n",
       "2019-05-31 -0.283332  1.104151 -2.166987 -0.316844  2.085956  \n",
       "2019-06-03 -0.264679 -1.231282  0.012666  6.871872 -2.026398  \n",
       "2019-06-04 -0.356285  0.228364 -1.214534 -0.270033  1.982946  \n",
       "2019-06-05 -0.080824  1.140642  0.855221 -0.168368  1.993482  \n",
       "2019-06-06 -0.422111 -0.100057  0.232463 -0.204089  1.996038  \n",
       "2019-06-07 -0.304347  0.100645 -0.133865 -0.233133  1.991358  \n",
       "2019-06-10 -0.044443 -0.063566 -0.298713 -0.242782  2.005664  \n",
       "2019-06-11 -0.256491  0.319591 -0.884838 -0.269310  1.975954  \n",
       "2019-06-12 -0.174654  0.301346  0.324045 -0.221714  1.971323  \n",
       "2019-06-13 -0.474011 -0.136548 -0.042283 -0.201523  1.962007  \n",
       "2019-06-14 -0.200282  1.158888  1.459663 -0.140909  2.004042  \n",
       "\n",
       "[4146 rows x 11 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = pd.DataFrame(X,index = index)\n",
    "\n",
    "df_final.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T20:58:18.935763Z",
     "start_time": "2019-11-12T20:58:18.925771Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df_final, y, test_size=0.2, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T20:58:19.198239Z",
     "start_time": "2019-11-12T20:58:19.168248Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\choice\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\choice\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7168674698795181"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression().fit(x_train, y_train)\n",
    "\n",
    "predictions = clf.predict(x_test)\n",
    "\n",
    "probas = clf.predict_proba(x_test) \n",
    "\n",
    "\n",
    "score = clf.score(x_test, y_test)\n",
    "\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T14:47:35.752080Z",
     "start_time": "2019-09-13T14:47:35.641570Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\choice\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "c:\\users\\choice\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7108433734939759"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = RandomForestClassifier()\n",
    "r.fit(x_train, y_train)  \n",
    "\n",
    "predictions = r.predict(x_test)\n",
    "\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T14:47:37.858875Z",
     "start_time": "2019-09-13T14:47:37.644114Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = X_columns.columns\n",
    "importances = r.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T21:32:35.252789Z",
     "start_time": "2019-09-12T21:31:57.799368Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0912 18:31:57.806361  8952 deprecation_wrapper.py:119] From c:\\users\\choice\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0912 18:31:58.089492  8952 deprecation_wrapper.py:119] From c:\\users\\choice\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0912 18:31:58.092476  8952 deprecation_wrapper.py:119] From c:\\users\\choice\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "W0912 18:31:58.138451  8952 deprecation_wrapper.py:119] From c:\\users\\choice\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0912 18:31:58.161439  8952 deprecation_wrapper.py:119] From c:\\users\\choice\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0912 18:31:58.189422  8952 deprecation_wrapper.py:119] From c:\\users\\choice\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0912 18:31:58.197418  8952 deprecation.py:323] From c:\\users\\choice\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3730 samples, validate on 415 samples\n",
      "Epoch 1/200\n",
      "3730/3730 [==============================] - 1s 149us/step - loss: 0.6710 - acc: 0.5995 - val_loss: 0.6548 - val_acc: 0.5880\n",
      "Epoch 2/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.6158 - acc: 0.6850 - val_loss: 0.5989 - val_acc: 0.6771\n",
      "Epoch 3/200\n",
      "3730/3730 [==============================] - 0s 56us/step - loss: 0.5693 - acc: 0.7177 - val_loss: 0.5581 - val_acc: 0.6964\n",
      "Epoch 4/200\n",
      "3730/3730 [==============================] - 0s 42us/step - loss: 0.5438 - acc: 0.7290 - val_loss: 0.5457 - val_acc: 0.7036\n",
      "Epoch 5/200\n",
      "3730/3730 [==============================] - 0s 50us/step - loss: 0.5343 - acc: 0.7311 - val_loss: 0.5394 - val_acc: 0.7036\n",
      "Epoch 6/200\n",
      "3730/3730 [==============================] - 0s 54us/step - loss: 0.5301 - acc: 0.7340 - val_loss: 0.5330 - val_acc: 0.7036\n",
      "Epoch 7/200\n",
      "3730/3730 [==============================] - 0s 46us/step - loss: 0.5277 - acc: 0.7362 - val_loss: 0.5281 - val_acc: 0.7036\n",
      "Epoch 8/200\n",
      "3730/3730 [==============================] - 0s 43us/step - loss: 0.5254 - acc: 0.7367 - val_loss: 0.5241 - val_acc: 0.7108\n",
      "Epoch 9/200\n",
      "3730/3730 [==============================] - 0s 46us/step - loss: 0.5239 - acc: 0.7375 - val_loss: 0.5223 - val_acc: 0.7133\n",
      "Epoch 10/200\n",
      "3730/3730 [==============================] - 0s 43us/step - loss: 0.5227 - acc: 0.7359 - val_loss: 0.5221 - val_acc: 0.7133\n",
      "Epoch 11/200\n",
      "3730/3730 [==============================] - 0s 46us/step - loss: 0.5218 - acc: 0.7386 - val_loss: 0.5209 - val_acc: 0.7181\n",
      "Epoch 12/200\n",
      "3730/3730 [==============================] - 0s 46us/step - loss: 0.5206 - acc: 0.7434 - val_loss: 0.5206 - val_acc: 0.7253\n",
      "Epoch 13/200\n",
      "3730/3730 [==============================] - 0s 44us/step - loss: 0.5198 - acc: 0.7373 - val_loss: 0.5186 - val_acc: 0.7229\n",
      "Epoch 14/200\n",
      "3730/3730 [==============================] - 0s 45us/step - loss: 0.5187 - acc: 0.7386 - val_loss: 0.5172 - val_acc: 0.7301\n",
      "Epoch 15/200\n",
      "3730/3730 [==============================] - 0s 46us/step - loss: 0.5180 - acc: 0.7359 - val_loss: 0.5178 - val_acc: 0.7301\n",
      "Epoch 16/200\n",
      "3730/3730 [==============================] - 0s 45us/step - loss: 0.5174 - acc: 0.7367 - val_loss: 0.5161 - val_acc: 0.7277\n",
      "Epoch 17/200\n",
      "3730/3730 [==============================] - 0s 45us/step - loss: 0.5168 - acc: 0.7370 - val_loss: 0.5146 - val_acc: 0.7301\n",
      "Epoch 18/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.5163 - acc: 0.7375 - val_loss: 0.5149 - val_acc: 0.7277\n",
      "Epoch 19/200\n",
      "3730/3730 [==============================] - 0s 55us/step - loss: 0.5157 - acc: 0.7389 - val_loss: 0.5149 - val_acc: 0.7253\n",
      "Epoch 20/200\n",
      "3730/3730 [==============================] - 0s 44us/step - loss: 0.5148 - acc: 0.7394 - val_loss: 0.5141 - val_acc: 0.7301\n",
      "Epoch 21/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.5143 - acc: 0.7383 - val_loss: 0.5141 - val_acc: 0.7301\n",
      "Epoch 22/200\n",
      "3730/3730 [==============================] - 0s 56us/step - loss: 0.5142 - acc: 0.7389 - val_loss: 0.5146 - val_acc: 0.7277\n",
      "Epoch 23/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.5133 - acc: 0.7383 - val_loss: 0.5147 - val_acc: 0.7277\n",
      "Epoch 24/200\n",
      "3730/3730 [==============================] - 0s 46us/step - loss: 0.5128 - acc: 0.7394 - val_loss: 0.5146 - val_acc: 0.7229\n",
      "Epoch 25/200\n",
      "3730/3730 [==============================] - 0s 50us/step - loss: 0.5125 - acc: 0.7381 - val_loss: 0.5130 - val_acc: 0.7205\n",
      "Epoch 26/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.5123 - acc: 0.7391 - val_loss: 0.5123 - val_acc: 0.7205\n",
      "Epoch 27/200\n",
      "3730/3730 [==============================] - 0s 45us/step - loss: 0.5118 - acc: 0.7381 - val_loss: 0.5136 - val_acc: 0.7205\n",
      "Epoch 28/200\n",
      "3730/3730 [==============================] - 0s 50us/step - loss: 0.5111 - acc: 0.7394 - val_loss: 0.5142 - val_acc: 0.7205\n",
      "Epoch 29/200\n",
      "3730/3730 [==============================] - 0s 53us/step - loss: 0.5113 - acc: 0.7375 - val_loss: 0.5138 - val_acc: 0.7205\n",
      "Epoch 30/200\n",
      "3730/3730 [==============================] - 0s 46us/step - loss: 0.5103 - acc: 0.7383 - val_loss: 0.5132 - val_acc: 0.7157\n",
      "Epoch 31/200\n",
      "3730/3730 [==============================] - 0s 55us/step - loss: 0.5102 - acc: 0.7383 - val_loss: 0.5129 - val_acc: 0.7205\n",
      "Epoch 32/200\n",
      "3730/3730 [==============================] - 0s 51us/step - loss: 0.5104 - acc: 0.7383 - val_loss: 0.5120 - val_acc: 0.7205\n",
      "Epoch 33/200\n",
      "3730/3730 [==============================] - 0s 61us/step - loss: 0.5095 - acc: 0.7386 - val_loss: 0.5118 - val_acc: 0.7229\n",
      "Epoch 34/200\n",
      "3730/3730 [==============================] - 0s 53us/step - loss: 0.5094 - acc: 0.7394 - val_loss: 0.5121 - val_acc: 0.7229\n",
      "Epoch 35/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.5092 - acc: 0.7408 - val_loss: 0.5110 - val_acc: 0.7205\n",
      "Epoch 36/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.5084 - acc: 0.7410 - val_loss: 0.5108 - val_acc: 0.7157\n",
      "Epoch 37/200\n",
      "3730/3730 [==============================] - 0s 54us/step - loss: 0.5084 - acc: 0.7397 - val_loss: 0.5108 - val_acc: 0.7157\n",
      "Epoch 38/200\n",
      "3730/3730 [==============================] - 0s 53us/step - loss: 0.5081 - acc: 0.7416 - val_loss: 0.5107 - val_acc: 0.7181\n",
      "Epoch 39/200\n",
      "3730/3730 [==============================] - 0s 66us/step - loss: 0.5077 - acc: 0.7410 - val_loss: 0.5111 - val_acc: 0.7229\n",
      "Epoch 40/200\n",
      "3730/3730 [==============================] - 0s 40us/step - loss: 0.5075 - acc: 0.7405 - val_loss: 0.5102 - val_acc: 0.7181\n",
      "Epoch 41/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.5074 - acc: 0.7426 - val_loss: 0.5100 - val_acc: 0.7229\n",
      "Epoch 42/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.5071 - acc: 0.7399 - val_loss: 0.5102 - val_acc: 0.7205\n",
      "Epoch 43/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.5066 - acc: 0.7434 - val_loss: 0.5094 - val_acc: 0.7205\n",
      "Epoch 44/200\n",
      "3730/3730 [==============================] - 0s 53us/step - loss: 0.5066 - acc: 0.7421 - val_loss: 0.5101 - val_acc: 0.7181\n",
      "Epoch 45/200\n",
      "3730/3730 [==============================] - ETA: 0s - loss: 0.5058 - acc: 0.739 - 0s 54us/step - loss: 0.5060 - acc: 0.7405 - val_loss: 0.5099 - val_acc: 0.7229\n",
      "Epoch 46/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.5059 - acc: 0.7389 - val_loss: 0.5104 - val_acc: 0.7205\n",
      "Epoch 47/200\n",
      "3730/3730 [==============================] - 0s 42us/step - loss: 0.5060 - acc: 0.7424 - val_loss: 0.5106 - val_acc: 0.7253\n",
      "Epoch 48/200\n",
      "3730/3730 [==============================] - 0s 44us/step - loss: 0.5059 - acc: 0.7418 - val_loss: 0.5107 - val_acc: 0.7181\n",
      "Epoch 49/200\n",
      "3730/3730 [==============================] - 0s 53us/step - loss: 0.5053 - acc: 0.7408 - val_loss: 0.5097 - val_acc: 0.7205\n",
      "Epoch 50/200\n",
      "3730/3730 [==============================] - 0s 42us/step - loss: 0.5049 - acc: 0.7408 - val_loss: 0.5089 - val_acc: 0.7253\n",
      "Epoch 51/200\n",
      "3730/3730 [==============================] - 0s 45us/step - loss: 0.5049 - acc: 0.7421 - val_loss: 0.5082 - val_acc: 0.7229\n",
      "Epoch 52/200\n",
      "3730/3730 [==============================] - 0s 50us/step - loss: 0.5047 - acc: 0.7410 - val_loss: 0.5092 - val_acc: 0.7229\n",
      "Epoch 53/200\n",
      "3730/3730 [==============================] - 0s 53us/step - loss: 0.5044 - acc: 0.7432 - val_loss: 0.5095 - val_acc: 0.7157\n",
      "Epoch 54/200\n",
      "3730/3730 [==============================] - 0s 45us/step - loss: 0.5045 - acc: 0.7440 - val_loss: 0.5098 - val_acc: 0.7181\n",
      "Epoch 55/200\n",
      "3730/3730 [==============================] - 0s 53us/step - loss: 0.5042 - acc: 0.7424 - val_loss: 0.5089 - val_acc: 0.7205\n",
      "Epoch 56/200\n",
      "3730/3730 [==============================] - 0s 55us/step - loss: 0.5041 - acc: 0.7472 - val_loss: 0.5076 - val_acc: 0.7253\n",
      "Epoch 57/200\n",
      "3730/3730 [==============================] - 0s 51us/step - loss: 0.5039 - acc: 0.7405 - val_loss: 0.5081 - val_acc: 0.7229\n",
      "Epoch 58/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.5035 - acc: 0.7424 - val_loss: 0.5078 - val_acc: 0.7253\n",
      "Epoch 59/200\n",
      "3730/3730 [==============================] - 0s 51us/step - loss: 0.5036 - acc: 0.7466 - val_loss: 0.5078 - val_acc: 0.7253\n",
      "Epoch 60/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.5036 - acc: 0.7472 - val_loss: 0.5074 - val_acc: 0.7253\n",
      "Epoch 61/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.5037 - acc: 0.7450 - val_loss: 0.5064 - val_acc: 0.7325\n",
      "Epoch 62/200\n",
      "3730/3730 [==============================] - 0s 38us/step - loss: 0.5032 - acc: 0.7466 - val_loss: 0.5076 - val_acc: 0.7253\n",
      "Epoch 63/200\n",
      "3730/3730 [==============================] - 0s 39us/step - loss: 0.5029 - acc: 0.7445 - val_loss: 0.5070 - val_acc: 0.7301\n",
      "Epoch 64/200\n",
      "3730/3730 [==============================] - 0s 39us/step - loss: 0.5029 - acc: 0.7466 - val_loss: 0.5064 - val_acc: 0.7277\n",
      "Epoch 65/200\n",
      "3730/3730 [==============================] - 0s 38us/step - loss: 0.5025 - acc: 0.7469 - val_loss: 0.5070 - val_acc: 0.7229\n",
      "Epoch 66/200\n",
      "3730/3730 [==============================] - 0s 39us/step - loss: 0.5026 - acc: 0.7445 - val_loss: 0.5062 - val_acc: 0.7325\n",
      "Epoch 67/200\n",
      "3730/3730 [==============================] - 0s 44us/step - loss: 0.5022 - acc: 0.7445 - val_loss: 0.5065 - val_acc: 0.7325\n",
      "Epoch 68/200\n",
      "3730/3730 [==============================] - 0s 51us/step - loss: 0.5021 - acc: 0.7485 - val_loss: 0.5065 - val_acc: 0.7349\n",
      "Epoch 69/200\n",
      "3730/3730 [==============================] - 0s 61us/step - loss: 0.5022 - acc: 0.7466 - val_loss: 0.5054 - val_acc: 0.7373\n",
      "Epoch 70/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.5020 - acc: 0.7483 - val_loss: 0.5058 - val_acc: 0.7349\n",
      "Epoch 71/200\n",
      "3730/3730 [==============================] - 0s 39us/step - loss: 0.5019 - acc: 0.7480 - val_loss: 0.5060 - val_acc: 0.7349\n",
      "Epoch 72/200\n",
      "3730/3730 [==============================] - 0s 41us/step - loss: 0.5020 - acc: 0.7480 - val_loss: 0.5063 - val_acc: 0.7325\n",
      "Epoch 73/200\n",
      "3730/3730 [==============================] - 0s 40us/step - loss: 0.5023 - acc: 0.7437 - val_loss: 0.5059 - val_acc: 0.7301\n",
      "Epoch 74/200\n",
      "3730/3730 [==============================] - 0s 39us/step - loss: 0.5018 - acc: 0.7501 - val_loss: 0.5057 - val_acc: 0.7253\n",
      "Epoch 75/200\n",
      "3730/3730 [==============================] - 0s 41us/step - loss: 0.5017 - acc: 0.7445 - val_loss: 0.5061 - val_acc: 0.7301\n",
      "Epoch 76/200\n",
      "3730/3730 [==============================] - 0s 41us/step - loss: 0.5016 - acc: 0.7491 - val_loss: 0.5058 - val_acc: 0.7277\n",
      "Epoch 77/200\n",
      "3730/3730 [==============================] - 0s 42us/step - loss: 0.5015 - acc: 0.7491 - val_loss: 0.5052 - val_acc: 0.7301\n",
      "Epoch 78/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.5017 - acc: 0.7442 - val_loss: 0.5055 - val_acc: 0.7349\n",
      "Epoch 79/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.5014 - acc: 0.7483 - val_loss: 0.5054 - val_acc: 0.7301\n",
      "Epoch 80/200\n",
      "3730/3730 [==============================] - 0s 62us/step - loss: 0.5010 - acc: 0.7464 - val_loss: 0.5053 - val_acc: 0.7325\n",
      "Epoch 81/200\n",
      "3730/3730 [==============================] - 0s 51us/step - loss: 0.5014 - acc: 0.7475 - val_loss: 0.5047 - val_acc: 0.7325\n",
      "Epoch 82/200\n",
      "3730/3730 [==============================] - 0s 54us/step - loss: 0.5009 - acc: 0.7461 - val_loss: 0.5040 - val_acc: 0.7349\n",
      "Epoch 83/200\n",
      "3730/3730 [==============================] - 0s 62us/step - loss: 0.5008 - acc: 0.7437 - val_loss: 0.5045 - val_acc: 0.7325\n",
      "Epoch 84/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.5010 - acc: 0.7488 - val_loss: 0.5053 - val_acc: 0.7325\n",
      "Epoch 85/200\n",
      "3730/3730 [==============================] - 0s 46us/step - loss: 0.5011 - acc: 0.7485 - val_loss: 0.5050 - val_acc: 0.7277\n",
      "Epoch 86/200\n",
      "3730/3730 [==============================] - 0s 46us/step - loss: 0.5010 - acc: 0.7453 - val_loss: 0.5053 - val_acc: 0.7301\n",
      "Epoch 87/200\n",
      "3730/3730 [==============================] - 0s 46us/step - loss: 0.5004 - acc: 0.7464 - val_loss: 0.5048 - val_acc: 0.7325\n",
      "Epoch 88/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.5001 - acc: 0.7466 - val_loss: 0.5036 - val_acc: 0.7398\n",
      "Epoch 89/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.5008 - acc: 0.7472 - val_loss: 0.5035 - val_acc: 0.7325\n",
      "Epoch 90/200\n",
      "3730/3730 [==============================] - 0s 46us/step - loss: 0.5003 - acc: 0.7461 - val_loss: 0.5044 - val_acc: 0.7277\n",
      "Epoch 91/200\n",
      "3730/3730 [==============================] - 0s 43us/step - loss: 0.5004 - acc: 0.7475 - val_loss: 0.5032 - val_acc: 0.7349\n",
      "Epoch 92/200\n",
      "3730/3730 [==============================] - 0s 43us/step - loss: 0.5002 - acc: 0.7450 - val_loss: 0.5041 - val_acc: 0.7277\n",
      "Epoch 93/200\n",
      "3730/3730 [==============================] - 0s 42us/step - loss: 0.5003 - acc: 0.7442 - val_loss: 0.5033 - val_acc: 0.7398\n",
      "Epoch 94/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.4997 - acc: 0.7488 - val_loss: 0.5028 - val_acc: 0.7349\n",
      "Epoch 95/200\n",
      "3730/3730 [==============================] - 0s 50us/step - loss: 0.5001 - acc: 0.7458 - val_loss: 0.5032 - val_acc: 0.7349\n",
      "Epoch 96/200\n",
      "3730/3730 [==============================] - 0s 52us/step - loss: 0.4999 - acc: 0.7442 - val_loss: 0.5031 - val_acc: 0.7422\n",
      "Epoch 97/200\n",
      "3730/3730 [==============================] - 0s 66us/step - loss: 0.4996 - acc: 0.7480 - val_loss: 0.5025 - val_acc: 0.7398\n",
      "Epoch 98/200\n",
      "3730/3730 [==============================] - 0s 50us/step - loss: 0.4997 - acc: 0.7469 - val_loss: 0.5021 - val_acc: 0.7422\n",
      "Epoch 99/200\n",
      "3730/3730 [==============================] - 0s 42us/step - loss: 0.4995 - acc: 0.7456 - val_loss: 0.5022 - val_acc: 0.7349\n",
      "Epoch 100/200\n",
      "3730/3730 [==============================] - 0s 41us/step - loss: 0.4994 - acc: 0.7499 - val_loss: 0.5020 - val_acc: 0.7398\n",
      "Epoch 101/200\n",
      "3730/3730 [==============================] - 0s 50us/step - loss: 0.4989 - acc: 0.7485 - val_loss: 0.5019 - val_acc: 0.7373\n",
      "Epoch 102/200\n",
      "3730/3730 [==============================] - 0s 56us/step - loss: 0.4992 - acc: 0.7483 - val_loss: 0.5017 - val_acc: 0.7422\n",
      "Epoch 103/200\n",
      "3730/3730 [==============================] - 0s 55us/step - loss: 0.4993 - acc: 0.7472 - val_loss: 0.5023 - val_acc: 0.7422\n",
      "Epoch 104/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.4989 - acc: 0.7480 - val_loss: 0.5023 - val_acc: 0.7398\n",
      "Epoch 105/200\n",
      "3730/3730 [==============================] - 0s 41us/step - loss: 0.4990 - acc: 0.7475 - val_loss: 0.5021 - val_acc: 0.7446\n",
      "Epoch 106/200\n",
      "3730/3730 [==============================] - 0s 42us/step - loss: 0.4987 - acc: 0.7464 - val_loss: 0.5016 - val_acc: 0.7422\n",
      "Epoch 107/200\n",
      "3730/3730 [==============================] - 0s 39us/step - loss: 0.4986 - acc: 0.7477 - val_loss: 0.5014 - val_acc: 0.7446\n",
      "Epoch 108/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.4988 - acc: 0.7483 - val_loss: 0.5015 - val_acc: 0.7398A: 0s - loss: 0.4998 - acc: 0.747\n",
      "Epoch 109/200\n",
      "3730/3730 [==============================] - 0s 51us/step - loss: 0.4989 - acc: 0.7483 - val_loss: 0.5010 - val_acc: 0.7446\n",
      "Epoch 110/200\n",
      "3730/3730 [==============================] - 0s 65us/step - loss: 0.4987 - acc: 0.7456 - val_loss: 0.5016 - val_acc: 0.7446\n",
      "Epoch 111/200\n",
      "3730/3730 [==============================] - 0s 61us/step - loss: 0.4984 - acc: 0.7483 - val_loss: 0.5011 - val_acc: 0.7446\n",
      "Epoch 112/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.4983 - acc: 0.7475 - val_loss: 0.5013 - val_acc: 0.7398\n",
      "Epoch 113/200\n",
      "3730/3730 [==============================] - 0s 41us/step - loss: 0.4987 - acc: 0.7466 - val_loss: 0.5022 - val_acc: 0.7373\n",
      "Epoch 114/200\n",
      "3730/3730 [==============================] - 0s 40us/step - loss: 0.4983 - acc: 0.7464 - val_loss: 0.5018 - val_acc: 0.7422\n",
      "Epoch 115/200\n",
      "3730/3730 [==============================] - 0s 39us/step - loss: 0.4983 - acc: 0.7485 - val_loss: 0.5011 - val_acc: 0.7422\n",
      "Epoch 116/200\n",
      "3730/3730 [==============================] - 0s 41us/step - loss: 0.4980 - acc: 0.7472 - val_loss: 0.5020 - val_acc: 0.7446\n",
      "Epoch 117/200\n",
      "3730/3730 [==============================] - 0s 45us/step - loss: 0.4975 - acc: 0.7448 - val_loss: 0.5028 - val_acc: 0.7398\n",
      "Epoch 118/200\n",
      "3730/3730 [==============================] - 0s 45us/step - loss: 0.4984 - acc: 0.7483 - val_loss: 0.5017 - val_acc: 0.7446\n",
      "Epoch 119/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3730/3730 [==============================] - 0s 43us/step - loss: 0.4979 - acc: 0.7466 - val_loss: 0.5018 - val_acc: 0.7422\n",
      "Epoch 120/200\n",
      "3730/3730 [==============================] - 0s 58us/step - loss: 0.4981 - acc: 0.7483 - val_loss: 0.5016 - val_acc: 0.7398\n",
      "Epoch 121/200\n",
      "3730/3730 [==============================] - 0s 53us/step - loss: 0.4977 - acc: 0.7469 - val_loss: 0.5013 - val_acc: 0.7373\n",
      "Epoch 122/200\n",
      "3730/3730 [==============================] - 0s 52us/step - loss: 0.4980 - acc: 0.7456 - val_loss: 0.5017 - val_acc: 0.7373\n",
      "Epoch 123/200\n",
      "3730/3730 [==============================] - 0s 60us/step - loss: 0.4976 - acc: 0.7464 - val_loss: 0.5016 - val_acc: 0.7470\n",
      "Epoch 124/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.4977 - acc: 0.7469 - val_loss: 0.5011 - val_acc: 0.7422\n",
      "Epoch 125/200\n",
      "3730/3730 [==============================] - 0s 45us/step - loss: 0.4970 - acc: 0.7450 - val_loss: 0.5012 - val_acc: 0.7422\n",
      "Epoch 126/200\n",
      "3730/3730 [==============================] - 0s 45us/step - loss: 0.4970 - acc: 0.7466 - val_loss: 0.5031 - val_acc: 0.7398\n",
      "Epoch 127/200\n",
      "3730/3730 [==============================] - 0s 46us/step - loss: 0.4974 - acc: 0.7483 - val_loss: 0.5020 - val_acc: 0.7446\n",
      "Epoch 128/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.4969 - acc: 0.7501 - val_loss: 0.5004 - val_acc: 0.7398\n",
      "Epoch 129/200\n",
      "3730/3730 [==============================] - ETA: 0s - loss: 0.4965 - acc: 0.746 - 0s 45us/step - loss: 0.4973 - acc: 0.7450 - val_loss: 0.5021 - val_acc: 0.7446\n",
      "Epoch 130/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.4972 - acc: 0.7477 - val_loss: 0.5016 - val_acc: 0.7446\n",
      "Epoch 131/200\n",
      "3730/3730 [==============================] - 0s 46us/step - loss: 0.4970 - acc: 0.7485 - val_loss: 0.5016 - val_acc: 0.7446\n",
      "Epoch 132/200\n",
      "3730/3730 [==============================] - 0s 46us/step - loss: 0.4970 - acc: 0.7493 - val_loss: 0.5006 - val_acc: 0.7422\n",
      "Epoch 133/200\n",
      "3730/3730 [==============================] - 0s 45us/step - loss: 0.4967 - acc: 0.7472 - val_loss: 0.5013 - val_acc: 0.7422\n",
      "Epoch 134/200\n",
      "3730/3730 [==============================] - 0s 46us/step - loss: 0.4971 - acc: 0.7469 - val_loss: 0.5010 - val_acc: 0.7398\n",
      "Epoch 135/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.4967 - acc: 0.7456 - val_loss: 0.5010 - val_acc: 0.7470\n",
      "Epoch 136/200\n",
      "3730/3730 [==============================] - 0s 53us/step - loss: 0.4970 - acc: 0.7509 - val_loss: 0.5008 - val_acc: 0.7446\n",
      "Epoch 137/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.4968 - acc: 0.7493 - val_loss: 0.5006 - val_acc: 0.7470\n",
      "Epoch 138/200\n",
      "3730/3730 [==============================] - 0s 46us/step - loss: 0.4965 - acc: 0.7458 - val_loss: 0.5004 - val_acc: 0.7446\n",
      "Epoch 139/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.4960 - acc: 0.7488 - val_loss: 0.5001 - val_acc: 0.7398\n",
      "Epoch 140/200\n",
      "3730/3730 [==============================] - 0s 42us/step - loss: 0.4962 - acc: 0.7475 - val_loss: 0.5007 - val_acc: 0.7422\n",
      "Epoch 141/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.4961 - acc: 0.7464 - val_loss: 0.5007 - val_acc: 0.7398\n",
      "Epoch 142/200\n",
      "3730/3730 [==============================] - 0s 43us/step - loss: 0.4965 - acc: 0.7485 - val_loss: 0.5001 - val_acc: 0.7422\n",
      "Epoch 143/200\n",
      "3730/3730 [==============================] - 0s 42us/step - loss: 0.4963 - acc: 0.7499 - val_loss: 0.4998 - val_acc: 0.7446\n",
      "Epoch 144/200\n",
      "3730/3730 [==============================] - 0s 44us/step - loss: 0.4963 - acc: 0.7477 - val_loss: 0.4996 - val_acc: 0.7446\n",
      "Epoch 145/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.4958 - acc: 0.7477 - val_loss: 0.4998 - val_acc: 0.7446\n",
      "Epoch 146/200\n",
      "3730/3730 [==============================] - 0s 45us/step - loss: 0.4964 - acc: 0.7499 - val_loss: 0.4995 - val_acc: 0.7446\n",
      "Epoch 147/200\n",
      "3730/3730 [==============================] - 0s 43us/step - loss: 0.4964 - acc: 0.7493 - val_loss: 0.4999 - val_acc: 0.7398\n",
      "Epoch 148/200\n",
      "3730/3730 [==============================] - 0s 43us/step - loss: 0.4957 - acc: 0.7493 - val_loss: 0.5002 - val_acc: 0.7422\n",
      "Epoch 149/200\n",
      "3730/3730 [==============================] - 0s 42us/step - loss: 0.4959 - acc: 0.7496 - val_loss: 0.5004 - val_acc: 0.7398\n",
      "Epoch 150/200\n",
      "3730/3730 [==============================] - 0s 53us/step - loss: 0.4956 - acc: 0.7515 - val_loss: 0.4997 - val_acc: 0.7446\n",
      "Epoch 151/200\n",
      "3730/3730 [==============================] - 0s 58us/step - loss: 0.4956 - acc: 0.7469 - val_loss: 0.4998 - val_acc: 0.7446\n",
      "Epoch 152/200\n",
      "3730/3730 [==============================] - 0s 50us/step - loss: 0.4958 - acc: 0.7488 - val_loss: 0.4998 - val_acc: 0.7398\n",
      "Epoch 153/200\n",
      "3730/3730 [==============================] - 0s 51us/step - loss: 0.4958 - acc: 0.7493 - val_loss: 0.4997 - val_acc: 0.7373\n",
      "Epoch 154/200\n",
      "3730/3730 [==============================] - 0s 51us/step - loss: 0.4953 - acc: 0.7501 - val_loss: 0.4996 - val_acc: 0.7398\n",
      "Epoch 155/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.4956 - acc: 0.7485 - val_loss: 0.4999 - val_acc: 0.7373\n",
      "Epoch 156/200\n",
      "3730/3730 [==============================] - 0s 44us/step - loss: 0.4961 - acc: 0.7485 - val_loss: 0.4998 - val_acc: 0.7373\n",
      "Epoch 157/200\n",
      "3730/3730 [==============================] - 0s 50us/step - loss: 0.4953 - acc: 0.7499 - val_loss: 0.4993 - val_acc: 0.7422\n",
      "Epoch 158/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.4950 - acc: 0.7507 - val_loss: 0.4990 - val_acc: 0.7422\n",
      "Epoch 159/200\n",
      "3730/3730 [==============================] - 0s 53us/step - loss: 0.4956 - acc: 0.7453 - val_loss: 0.4990 - val_acc: 0.7398\n",
      "Epoch 160/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.4950 - acc: 0.7477 - val_loss: 0.5001 - val_acc: 0.7398\n",
      "Epoch 161/200\n",
      "3730/3730 [==============================] - 0s 52us/step - loss: 0.4957 - acc: 0.7469 - val_loss: 0.4999 - val_acc: 0.7349\n",
      "Epoch 162/200\n",
      "3730/3730 [==============================] - 0s 53us/step - loss: 0.4949 - acc: 0.7496 - val_loss: 0.4998 - val_acc: 0.7373\n",
      "Epoch 163/200\n",
      "3730/3730 [==============================] - 0s 63us/step - loss: 0.4950 - acc: 0.7512 - val_loss: 0.5006 - val_acc: 0.7398\n",
      "Epoch 164/200\n",
      "3730/3730 [==============================] - 0s 51us/step - loss: 0.4947 - acc: 0.7520 - val_loss: 0.4993 - val_acc: 0.7373\n",
      "Epoch 165/200\n",
      "3730/3730 [==============================] - 0s 46us/step - loss: 0.4947 - acc: 0.7507 - val_loss: 0.4990 - val_acc: 0.7373\n",
      "Epoch 166/200\n",
      "3730/3730 [==============================] - 0s 68us/step - loss: 0.4943 - acc: 0.7512 - val_loss: 0.4993 - val_acc: 0.7422\n",
      "Epoch 167/200\n",
      "3730/3730 [==============================] - 0s 46us/step - loss: 0.4949 - acc: 0.7485 - val_loss: 0.4990 - val_acc: 0.7398\n",
      "Epoch 168/200\n",
      "3730/3730 [==============================] - 0s 42us/step - loss: 0.4943 - acc: 0.7496 - val_loss: 0.4985 - val_acc: 0.7422\n",
      "Epoch 169/200\n",
      "3730/3730 [==============================] - 0s 54us/step - loss: 0.4949 - acc: 0.7485 - val_loss: 0.4986 - val_acc: 0.7373\n",
      "Epoch 170/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.4949 - acc: 0.7491 - val_loss: 0.4982 - val_acc: 0.7446\n",
      "Epoch 171/200\n",
      "3730/3730 [==============================] - 0s 41us/step - loss: 0.4946 - acc: 0.7480 - val_loss: 0.4992 - val_acc: 0.7373\n",
      "Epoch 172/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.4945 - acc: 0.7501 - val_loss: 0.4982 - val_acc: 0.7373\n",
      "Epoch 173/200\n",
      "3730/3730 [==============================] - 0s 56us/step - loss: 0.4946 - acc: 0.7477 - val_loss: 0.4987 - val_acc: 0.7422\n",
      "Epoch 174/200\n",
      "3730/3730 [==============================] - 0s 41us/step - loss: 0.4943 - acc: 0.7491 - val_loss: 0.4984 - val_acc: 0.7422\n",
      "Epoch 175/200\n",
      "3730/3730 [==============================] - 0s 40us/step - loss: 0.4945 - acc: 0.7493 - val_loss: 0.4983 - val_acc: 0.7422\n",
      "Epoch 176/200\n",
      "3730/3730 [==============================] - 0s 40us/step - loss: 0.4940 - acc: 0.7485 - val_loss: 0.4983 - val_acc: 0.7446\n",
      "Epoch 177/200\n",
      "3730/3730 [==============================] - 0s 44us/step - loss: 0.4941 - acc: 0.7477 - val_loss: 0.4977 - val_acc: 0.7422\n",
      "Epoch 178/200\n",
      "3730/3730 [==============================] - 0s 58us/step - loss: 0.4942 - acc: 0.7501 - val_loss: 0.4982 - val_acc: 0.7470\n",
      "Epoch 179/200\n",
      "3730/3730 [==============================] - 0s 52us/step - loss: 0.4939 - acc: 0.7461 - val_loss: 0.4993 - val_acc: 0.7422\n",
      "Epoch 180/200\n",
      "3730/3730 [==============================] - 0s 46us/step - loss: 0.4939 - acc: 0.7469 - val_loss: 0.4981 - val_acc: 0.7398\n",
      "Epoch 181/200\n",
      "3730/3730 [==============================] - 0s 39us/step - loss: 0.4940 - acc: 0.7493 - val_loss: 0.4980 - val_acc: 0.7422\n",
      "Epoch 182/200\n",
      "3730/3730 [==============================] - 0s 41us/step - loss: 0.4938 - acc: 0.7496 - val_loss: 0.4984 - val_acc: 0.7422\n",
      "Epoch 183/200\n",
      "3730/3730 [==============================] - 0s 38us/step - loss: 0.4937 - acc: 0.7488 - val_loss: 0.4980 - val_acc: 0.7373\n",
      "Epoch 184/200\n",
      "3730/3730 [==============================] - 0s 41us/step - loss: 0.4940 - acc: 0.7466 - val_loss: 0.4983 - val_acc: 0.7422\n",
      "Epoch 185/200\n",
      "3730/3730 [==============================] - 0s 40us/step - loss: 0.4940 - acc: 0.7493 - val_loss: 0.4983 - val_acc: 0.7398\n",
      "Epoch 186/200\n",
      "3730/3730 [==============================] - 0s 41us/step - loss: 0.4939 - acc: 0.7488 - val_loss: 0.4984 - val_acc: 0.7349\n",
      "Epoch 187/200\n",
      "3730/3730 [==============================] - 0s 43us/step - loss: 0.4938 - acc: 0.7499 - val_loss: 0.4983 - val_acc: 0.7422\n",
      "Epoch 188/200\n",
      "3730/3730 [==============================] - 0s 43us/step - loss: 0.4935 - acc: 0.7504 - val_loss: 0.4980 - val_acc: 0.7398\n",
      "Epoch 189/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.4932 - acc: 0.7496 - val_loss: 0.4981 - val_acc: 0.7349\n",
      "Epoch 190/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.4932 - acc: 0.7488 - val_loss: 0.4987 - val_acc: 0.7301\n",
      "Epoch 191/200\n",
      "3730/3730 [==============================] - 0s 55us/step - loss: 0.4945 - acc: 0.7450 - val_loss: 0.4980 - val_acc: 0.7398\n",
      "Epoch 192/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.4940 - acc: 0.7469 - val_loss: 0.4981 - val_acc: 0.7373\n",
      "Epoch 193/200\n",
      "3730/3730 [==============================] - 0s 54us/step - loss: 0.4935 - acc: 0.7493 - val_loss: 0.4982 - val_acc: 0.7422\n",
      "Epoch 194/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.4931 - acc: 0.7507 - val_loss: 0.4987 - val_acc: 0.7301\n",
      "Epoch 195/200\n",
      "3730/3730 [==============================] - 0s 48us/step - loss: 0.4935 - acc: 0.7485 - val_loss: 0.4987 - val_acc: 0.7398\n",
      "Epoch 196/200\n",
      "3730/3730 [==============================] - 0s 43us/step - loss: 0.4932 - acc: 0.7493 - val_loss: 0.4991 - val_acc: 0.7398\n",
      "Epoch 197/200\n",
      "3730/3730 [==============================] - 0s 49us/step - loss: 0.4927 - acc: 0.7523 - val_loss: 0.4987 - val_acc: 0.7325\n",
      "Epoch 198/200\n",
      "3730/3730 [==============================] - 0s 42us/step - loss: 0.4929 - acc: 0.7483 - val_loss: 0.4989 - val_acc: 0.7398\n",
      "Epoch 199/200\n",
      "3730/3730 [==============================] - 0s 47us/step - loss: 0.4927 - acc: 0.7496 - val_loss: 0.4986 - val_acc: 0.7277\n",
      "Epoch 200/200\n",
      "3730/3730 [==============================] - 0s 45us/step - loss: 0.4926 - acc: 0.7504 - val_loss: 0.4992 - val_acc: 0.7398\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(8, kernel_initializer='normal', input_dim=len(X[0]), activation='relu'))\n",
    "model.add(Dense(8, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adamax',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X, y.values, epochs=200, validation_split = 0.1)\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, kernel_initializer='normal', input_dim=len(X[0]), activation='relu'))\n",
    "model.add(Dense(10, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adamax',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X, y.values, epochs=200, validation_split = 0.1)\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(8, kernel_initializer='normal', input_dim=len(X[0]), activation='relu'))\n",
    "model.add(Dense(8, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X, y.values, epochs=600, validation_split = 0.1)\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(4, kernel_initializer='normal', input_dim=len(X[0]), activation='relu'))\n",
    "model.add(Dense(4, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X, y.values, epochs=600, validation_split = 0.1)\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(4, kernel_initializer='normal', input_dim=len(X[0]), activation='relu'))\n",
    "model.add(Dense(4, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adamax',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X, y.values, epochs=600, validation_split = 0.1)\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
